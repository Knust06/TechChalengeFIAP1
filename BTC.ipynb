{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6vjRVoAqGsf",
        "outputId": "098aa76e-6e32-4a74-ea39-a7b35368af1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   price\n",
            "timestamp               \n",
            "2023-09-16  26634.631025\n",
            "2023-09-17  26557.768692\n",
            "2023-09-18  26520.988255\n",
            "2023-09-19  26741.461111\n",
            "2023-09-20  27219.296875\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "\n",
        "def get_bitcoin_data():\n",
        "    url = \"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart\"\n",
        "    params = {\n",
        "        'vs_currency': 'usd',\n",
        "        'days': '365',\n",
        "        'interval': 'daily'\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "    return data\n",
        "\n",
        "def prepare_data():\n",
        "    data = get_bitcoin_data()\n",
        "    prices = data['prices']\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(prices, columns=['timestamp', 'price'])\n",
        "\n",
        "\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = prepare_data()\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq4Fv2dbqHee",
        "outputId": "524606dc-3fc6-4626-e868-1079a29622a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   price         lag_1         lag_7          ma_7\n",
            "timestamp                                                         \n",
            "2023-09-23  26572.038112  26561.133454  26634.631025  26755.504706\n",
            "2023-09-24  26573.923480  26572.038112  26557.768692  26757.812533\n",
            "2023-09-25  26249.562898  26573.923480  26520.988255  26719.037482\n",
            "2023-09-26  26298.634678  26249.562898  26741.461111  26655.776563\n",
            "2023-09-27  26204.757591  26298.634678  27219.296875  26510.842380\n"
          ]
        }
      ],
      "source": [
        "#Pré processamento dos dados. Pegando do dia anterior, dos ultimos 7 dias e a média dos últimos 7 dias\n",
        "def create_features(df):\n",
        "    # Criar lags de 1 e 7 dias\n",
        "    df['lag_1'] = df['price'].shift(1)\n",
        "    df['lag_7'] = df['price'].shift(7)\n",
        "\n",
        "\n",
        "    df['ma_7'] = df['price'].rolling(window=7).mean()\n",
        "\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "df_features = create_features(df)\n",
        "print(df_features.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6Wp6WOhVqJdj"
      },
      "outputs": [],
      "source": [
        "X = df_features[['lag_1', 'lag_7', 'ma_7']]\n",
        "y = df_features['price']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Par RIDGE LASSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas da Regressão Ridge:\n",
            "                          MSE        R²\n",
            "0.01  auto       2.446619e+06  0.986019\n",
            "      svd        2.446619e+06  0.986019\n",
            "      cholesky   2.446619e+06  0.986019\n",
            "      lsqr       2.446619e+06  0.986019\n",
            "      sparse_cg  2.446619e+06  0.986019\n",
            "0.10  auto       2.446619e+06  0.986019\n",
            "      svd        2.446619e+06  0.986019\n",
            "      cholesky   2.446619e+06  0.986019\n",
            "      lsqr       2.446619e+06  0.986019\n",
            "      sparse_cg  2.446619e+06  0.986019\n",
            "1.00  auto       2.446619e+06  0.986019\n",
            "      svd        2.446619e+06  0.986019\n",
            "      cholesky   2.446619e+06  0.986019\n",
            "      lsqr       2.446619e+06  0.986019\n",
            "      sparse_cg  2.446619e+06  0.986019\n",
            "10.00 auto       2.446619e+06  0.986019\n",
            "      svd        2.446619e+06  0.986019\n",
            "      cholesky   2.446619e+06  0.986019\n",
            "      lsqr       2.446619e+06  0.986019\n",
            "      sparse_cg  2.446619e+06  0.986019\n",
            "\n",
            "Métricas da Regressão Lasso:\n",
            "                     MSE        R²\n",
            "0.01  100   2.369525e+06  0.986459\n",
            "      500   2.431496e+06  0.986105\n",
            "      1000  2.445653e+06  0.986024\n",
            "0.10  100   2.369525e+06  0.986459\n",
            "      500   2.431496e+06  0.986105\n",
            "      1000  2.445653e+06  0.986024\n",
            "1.00  100   2.369525e+06  0.986459\n",
            "      500   2.431495e+06  0.986105\n",
            "      1000  2.445652e+06  0.986024\n",
            "10.00 100   2.369525e+06  0.986459\n",
            "      500   2.431492e+06  0.986105\n",
            "      1000  2.445648e+06  0.986024\n",
            "\n",
            "Melhores Parâmetros da Regressão Ridge:\n",
            "(np.float64(10.0), 'lsqr')\n",
            "\n",
            "Melhores Parâmetros da Regressão Lasso:\n",
            "(np.float64(10.0), np.int64(100))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.547e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.543e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "alphas = [0.01, 0.1, 1.0, 10.0]\n",
        "solvers = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg']  \n",
        "max_iters = [100, 500, 1000]  \n",
        "\n",
        "ridge_metrics = {}\n",
        "lasso_metrics = {}\n",
        "\n",
        "for alpha in alphas:\n",
        "    for solver in solvers:\n",
        "        ridge_model = Ridge(alpha=alpha, solver=solver)\n",
        "        ridge_model.fit(X_train, y_train)\n",
        "        y_pred = ridge_model.predict(X_test)\n",
        "        ridge_metrics[(alpha, solver)] = {\n",
        "            'MSE': mean_squared_error(y_test, y_pred),\n",
        "            'R²': r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "for alpha in alphas:\n",
        "    for max_iter in max_iters:\n",
        "        lasso_model = Lasso(alpha=alpha, max_iter=max_iter)\n",
        "        lasso_model.fit(X_train, y_train)\n",
        "        y_pred = lasso_model.predict(X_test)\n",
        "        lasso_metrics[(alpha, max_iter)] = {\n",
        "            'MSE': mean_squared_error(y_test, y_pred),\n",
        "            'R²': r2_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "ridge_metrics_df = pd.DataFrame(ridge_metrics).T\n",
        "lasso_metrics_df = pd.DataFrame(lasso_metrics).T\n",
        "\n",
        "print(\"Métricas da Regressão Ridge:\")\n",
        "print(ridge_metrics_df)\n",
        "\n",
        "print(\"\\nMétricas da Regressão Lasso:\")\n",
        "print(lasso_metrics_df)\n",
        "\n",
        "best_params_ridge = ridge_metrics_df['MSE'].idxmin()\n",
        "best_params_lasso = lasso_metrics_df['MSE'].idxmin()\n",
        "\n",
        "print(\"\\nMelhores Parâmetros da Regressão Ridge:\")\n",
        "print(best_params_ridge)\n",
        "\n",
        "print(\"\\nMelhores Parâmetros da Regressão Lasso:\")\n",
        "print(best_params_lasso)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PAR GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas do Gradient Boosting:\n",
            "                        MSE        R²\n",
            "50  3 0.01 2   6.724901e+07  0.615709\n",
            "           5   6.724408e+07  0.615737\n",
            "           10  6.722158e+07  0.615865\n",
            "      0.10 2   3.325504e+06  0.980997\n",
            "           5   3.333973e+06  0.980948\n",
            "...                     ...       ...\n",
            "200 7 0.10 5   3.659864e+06  0.979086\n",
            "           10  3.623319e+06  0.979295\n",
            "      0.20 2   3.833777e+06  0.978092\n",
            "           5   3.912725e+06  0.977641\n",
            "           10  3.444201e+06  0.980318\n",
            "\n",
            "[81 rows x 2 columns]\n",
            "\n",
            "Melhores Parâmetros:\n",
            "(np.int64(100), np.int64(3), np.float64(0.1), np.int64(10))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "n_estimators = [50, 100, 200]\n",
        "max_depth = [3, 5, 7]\n",
        "learning_rates = [0.01, 0.1, 0.2]\n",
        "min_samples_split = [2, 5, 10]\n",
        "\n",
        "gb_metrics = {}\n",
        "\n",
        "for n in n_estimators:\n",
        "    for depth in max_depth:\n",
        "        for lr in learning_rates:\n",
        "            for min_split in min_samples_split:\n",
        "                gb_model = GradientBoostingRegressor(\n",
        "                    n_estimators=n,\n",
        "                    max_depth=depth,\n",
        "                    learning_rate=lr,\n",
        "                    min_samples_split=min_split\n",
        "                )\n",
        "                gb_model.fit(X_train, y_train)\n",
        "                y_pred = gb_model.predict(X_test)\n",
        "                gb_metrics[(n, depth, lr, min_split)] = {\n",
        "                    'MSE': mean_squared_error(y_test, y_pred),\n",
        "                    'R²': r2_score(y_test, y_pred)\n",
        "                }\n",
        "\n",
        "gb_metrics_df = pd.DataFrame(gb_metrics).T\n",
        "print(\"Métricas do Gradient Boosting:\")\n",
        "print(gb_metrics_df)\n",
        "\n",
        "best_params_gb = gb_metrics_df['MSE'].idxmin()\n",
        "print(\"\\nMelhores Parâmetros:\")\n",
        "print(best_params_gb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métricas do XGBoost:\n",
            "                         MSE        R²\n",
            "50  0.01 3 0.8  7.058787e+07  0.596629\n",
            "           0.9  7.021133e+07  0.598781\n",
            "           1.0  6.990041e+07  0.600557\n",
            "         5 0.8  7.029831e+07  0.598284\n",
            "           0.9  6.983088e+07  0.600955\n",
            "...                      ...       ...\n",
            "200 0.20 5 0.9  3.702214e+06  0.978844\n",
            "           1.0  3.791393e+06  0.978334\n",
            "         7 0.8  3.961905e+06  0.977360\n",
            "           0.9  3.547905e+06  0.979726\n",
            "           1.0  3.651771e+06  0.979132\n",
            "\n",
            "[81 rows x 2 columns]\n",
            "\n",
            "Melhores Parâmetros:\n",
            "(np.int64(50), np.float64(0.1), np.int64(3), np.float64(0.9))\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "n_estimators = [50, 100, 200]\n",
        "learning_rates = [0.01, 0.1, 0.2]\n",
        "max_depth = [3, 5, 7]\n",
        "subsample = [0.8, 0.9, 1.0]\n",
        "\n",
        "xgb_metrics = {}\n",
        "\n",
        "for n in n_estimators:\n",
        "    for lr in learning_rates:\n",
        "        for depth in max_depth:\n",
        "            for subs in subsample:\n",
        "                xgb_model = xgb.XGBRegressor(\n",
        "                    objective='reg:squarederror',\n",
        "                    n_estimators=n,\n",
        "                    learning_rate=lr,\n",
        "                    max_depth=depth,\n",
        "                    subsample=subs\n",
        "                )\n",
        "                xgb_model.fit(X_train, y_train)\n",
        "                y_pred = xgb_model.predict(X_test)\n",
        "                xgb_metrics[(n, lr, depth, subs)] = {\n",
        "                    'MSE': mean_squared_error(y_test, y_pred),\n",
        "                    'R²': r2_score(y_test, y_pred)\n",
        "                }\n",
        "\n",
        "xgb_metrics_df = pd.DataFrame(xgb_metrics).T\n",
        "print(\"Métricas do XGBoost:\")\n",
        "print(xgb_metrics_df)\n",
        "\n",
        "best_params_xgb = xgb_metrics_df['MSE'].idxmin()\n",
        "print(\"\\nMelhores Parâmetros:\")\n",
        "print(best_params_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 64170039417.18319702\n",
            "Iteration 2, loss = 2657587310384388957792234850322102396816087350355616737382843027844616945664.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50,), relu, 0.0001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538789663.95386410\n",
            "Iteration 2, loss = 1538766904.74292827\n",
            "Iteration 3, loss = 1538744200.43628979\n",
            "Iteration 4, loss = 1538719701.94540930\n",
            "Iteration 5, loss = 1538693628.58481789\n",
            "Iteration 6, loss = 1538665043.17982769\n",
            "Iteration 7, loss = 1538634542.63840961\n",
            "Iteration 8, loss = 1538600468.25952601\n",
            "Iteration 9, loss = 1538563061.08279681\n",
            "Iteration 10, loss = 1538522448.67628551\n",
            "Iteration 11, loss = 1538476560.66489744\n",
            "Iteration 12, loss = 1538427960.40278888\n",
            "Iteration 13, loss = 1538374224.17242312\n",
            "Iteration 14, loss = 1538314785.69641590\n",
            "Iteration 15, loss = 1538251289.96308994\n",
            "Iteration 16, loss = 1538182635.81452227\n",
            "Iteration 17, loss = 1538108375.50857496\n",
            "Iteration 18, loss = 1538027959.22058129\n",
            "Iteration 19, loss = 1537942172.58791399\n",
            "Iteration 20, loss = 1537850991.70442963\n",
            "Iteration 21, loss = 1537751748.57909894\n",
            "Iteration 22, loss = 1537648352.86750770\n",
            "Iteration 23, loss = 1537535172.24082661\n",
            "Iteration 24, loss = 1537419627.14041233\n",
            "Iteration 25, loss = 1537293677.85022664\n",
            "Iteration 26, loss = 1537162522.08298731\n",
            "Iteration 27, loss = 1537023594.46371984\n",
            "Iteration 28, loss = 1536875886.86828923\n",
            "Iteration 29, loss = 1536722332.76106358\n",
            "Iteration 30, loss = 1536561707.78991652\n",
            "Iteration 31, loss = 1536391574.17775631\n",
            "Iteration 32, loss = 1536214701.57928848\n",
            "Iteration 33, loss = 1536031808.97578859\n",
            "Iteration 34, loss = 1535837539.87944317\n",
            "Iteration 35, loss = 1535637994.91903186\n",
            "Iteration 36, loss = 1535429119.99208832\n",
            "Iteration 37, loss = 1535212231.99126816\n",
            "Iteration 38, loss = 1534991231.34953165\n",
            "Iteration 39, loss = 1534756210.83476496\n",
            "Iteration 40, loss = 1534514067.82424307\n",
            "Iteration 41, loss = 1534267402.00152779\n",
            "Iteration 42, loss = 1534006779.87768674\n",
            "Iteration 43, loss = 1533742204.41932893\n",
            "Iteration 44, loss = 1533466162.00302029\n",
            "Iteration 45, loss = 1533184670.84061432\n",
            "Iteration 46, loss = 1532889873.59692335\n",
            "Iteration 47, loss = 1532590195.71222639\n",
            "Iteration 48, loss = 1532279729.64973307\n",
            "Iteration 49, loss = 1531962415.68383336\n",
            "Iteration 50, loss = 1531636556.92890406\n",
            "Iteration 51, loss = 1531303520.84072232\n",
            "Iteration 52, loss = 1530958837.32468534\n",
            "Iteration 53, loss = 1530603335.63400960\n",
            "Iteration 54, loss = 1530247506.43761516\n",
            "Iteration 55, loss = 1529875987.97221851\n",
            "Iteration 56, loss = 1529501785.88291860\n",
            "Iteration 57, loss = 1529116690.95120692\n",
            "Iteration 58, loss = 1528718236.24236321\n",
            "Iteration 59, loss = 1528313819.49680305\n",
            "Iteration 60, loss = 1527907735.87328601\n",
            "Iteration 61, loss = 1527485401.35011673\n",
            "Iteration 62, loss = 1527057090.17009068\n",
            "Iteration 63, loss = 1526619253.62857747\n",
            "Iteration 64, loss = 1526175641.45227051\n",
            "Iteration 65, loss = 1525721726.24714875\n",
            "Iteration 66, loss = 1525257392.68509889\n",
            "Iteration 67, loss = 1524786749.50930262\n",
            "Iteration 68, loss = 1524301516.76515627\n",
            "Iteration 69, loss = 1523815954.05642986\n",
            "Iteration 70, loss = 1523318943.93071818\n",
            "Iteration 71, loss = 1522813494.69700813\n",
            "Iteration 72, loss = 1522291447.00680733\n",
            "Iteration 73, loss = 1521775849.08064628\n",
            "Iteration 74, loss = 1521237007.82592130\n",
            "Iteration 75, loss = 1520709560.44104099\n",
            "Iteration 76, loss = 1520159149.33070850\n",
            "Iteration 77, loss = 1519606096.85637617\n",
            "Iteration 78, loss = 1519045042.45691252\n",
            "Iteration 79, loss = 1518474095.96012878\n",
            "Iteration 80, loss = 1517898691.64826417\n",
            "Iteration 81, loss = 1517313442.03605437\n",
            "Iteration 82, loss = 1516725204.71886683\n",
            "Iteration 83, loss = 1516120184.10864735\n",
            "Iteration 84, loss = 1515507884.79288864\n",
            "Iteration 85, loss = 1514891092.25447488\n",
            "Iteration 86, loss = 1514268264.68111968\n",
            "Iteration 87, loss = 1513629924.43558741\n",
            "Iteration 88, loss = 1512984593.20784736\n",
            "Iteration 89, loss = 1512330639.16236162\n",
            "Iteration 90, loss = 1511678111.93235064\n",
            "Iteration 91, loss = 1511004771.39586020\n",
            "Iteration 92, loss = 1510332275.61298752\n",
            "Iteration 93, loss = 1509652953.48295832\n",
            "Iteration 94, loss = 1508966996.14062309\n",
            "Iteration 95, loss = 1508262626.42771244\n",
            "Iteration 96, loss = 1507563451.59958172\n",
            "Iteration 97, loss = 1506855899.73089290\n",
            "Iteration 98, loss = 1506130761.75993919\n",
            "Iteration 99, loss = 1505397644.60660744\n",
            "Iteration 100, loss = 1504671256.16161084\n",
            "Iteration 101, loss = 1503918279.12507987\n",
            "Iteration 102, loss = 1503171488.77890205\n",
            "Iteration 103, loss = 1502416978.51353192\n",
            "Iteration 104, loss = 1501651390.05185747\n",
            "Iteration 105, loss = 1500871962.95798373\n",
            "Iteration 106, loss = 1500102509.62438893\n",
            "Iteration 107, loss = 1499307511.54688311\n",
            "Iteration 108, loss = 1498513077.41046357\n",
            "Iteration 109, loss = 1497712423.66740632\n",
            "Iteration 110, loss = 1496885364.61472321\n",
            "Iteration 111, loss = 1496076519.61649799\n",
            "Iteration 112, loss = 1495227692.52099872\n",
            "Iteration 113, loss = 1494387179.36455011\n",
            "Iteration 114, loss = 1493536038.20211959\n",
            "Iteration 115, loss = 1492668633.34344411\n",
            "Iteration 116, loss = 1491799628.15607977\n",
            "Iteration 117, loss = 1490920264.79634666\n",
            "Iteration 118, loss = 1490028097.46663260\n",
            "Iteration 119, loss = 1489122809.34588265\n",
            "Iteration 120, loss = 1488228561.90576911\n",
            "Iteration 121, loss = 1487312491.37915397\n",
            "Iteration 122, loss = 1486388364.54497433\n",
            "Iteration 123, loss = 1485471275.60332847\n",
            "Iteration 124, loss = 1484535669.64152336\n",
            "Iteration 125, loss = 1483597742.53462982\n",
            "Iteration 126, loss = 1482656521.88315582\n",
            "Iteration 127, loss = 1481706105.03059745\n",
            "Iteration 128, loss = 1480744071.61828947\n",
            "Iteration 129, loss = 1479781542.35697556\n",
            "Iteration 130, loss = 1478801259.13914084\n",
            "Iteration 131, loss = 1477822566.13428211\n",
            "Iteration 132, loss = 1476828347.11260915\n",
            "Iteration 133, loss = 1475828128.80900192\n",
            "Iteration 134, loss = 1474827222.81029224\n",
            "Iteration 135, loss = 1473795476.41356659\n",
            "Iteration 136, loss = 1472790038.97381234\n",
            "Iteration 137, loss = 1471752857.21438575\n",
            "Iteration 138, loss = 1470712939.54252625\n",
            "Iteration 139, loss = 1469675805.38346076\n",
            "Iteration 140, loss = 1468635369.48260522\n",
            "Iteration 141, loss = 1467571539.27170610\n",
            "Iteration 142, loss = 1466531055.82641387\n",
            "Iteration 143, loss = 1465469389.97835732\n",
            "Iteration 144, loss = 1464408953.55382872\n",
            "Iteration 145, loss = 1463338958.20944452\n",
            "Iteration 146, loss = 1462252987.20307541\n",
            "Iteration 147, loss = 1461176137.52258182\n",
            "Iteration 148, loss = 1460074465.91794395\n",
            "Iteration 149, loss = 1458971306.43599534\n",
            "Iteration 150, loss = 1457863543.50526643\n",
            "Iteration 151, loss = 1456735501.34165239\n",
            "Iteration 152, loss = 1455618052.53762436\n",
            "Iteration 153, loss = 1454476705.82438636\n",
            "Iteration 154, loss = 1453330031.62966061\n",
            "Iteration 155, loss = 1452197049.29523253\n",
            "Iteration 156, loss = 1451026943.54975462\n",
            "Iteration 157, loss = 1449869580.60211968\n",
            "Iteration 158, loss = 1448704019.91700411\n",
            "Iteration 159, loss = 1447522005.79074740\n",
            "Iteration 160, loss = 1446337910.53270650\n",
            "Iteration 161, loss = 1445153604.24313784\n",
            "Iteration 162, loss = 1443956075.54903483\n",
            "Iteration 163, loss = 1442759661.22382259\n",
            "Iteration 164, loss = 1441525099.53017712\n",
            "Iteration 165, loss = 1440315635.76497722\n",
            "Iteration 166, loss = 1439106020.08518076\n",
            "Iteration 167, loss = 1437843484.12247586\n",
            "Iteration 168, loss = 1436616926.55568361\n",
            "Iteration 169, loss = 1435371637.26638913\n",
            "Iteration 170, loss = 1434103177.25627041\n",
            "Iteration 171, loss = 1432863614.68262506\n",
            "Iteration 172, loss = 1431583973.85149145\n",
            "Iteration 173, loss = 1430329854.94772935\n",
            "Iteration 174, loss = 1429036478.03552985\n",
            "Iteration 175, loss = 1427764044.04808068\n",
            "Iteration 176, loss = 1426457360.09882069\n",
            "Iteration 177, loss = 1425167535.73568439\n",
            "Iteration 178, loss = 1423858077.10995770\n",
            "Iteration 179, loss = 1422545900.41005230\n",
            "Iteration 180, loss = 1421215547.61693692\n",
            "Iteration 181, loss = 1419898332.34172773\n",
            "Iteration 182, loss = 1418554297.75737667\n",
            "Iteration 183, loss = 1417230598.17993188\n",
            "Iteration 184, loss = 1415873763.25724149\n",
            "Iteration 185, loss = 1414525533.89487982\n",
            "Iteration 186, loss = 1413159965.82806802\n",
            "Iteration 187, loss = 1411799819.34880710\n",
            "Iteration 188, loss = 1410409093.05351400\n",
            "Iteration 189, loss = 1409040530.12713289\n",
            "Iteration 190, loss = 1407650701.53430510\n",
            "Iteration 191, loss = 1406241135.23824239\n",
            "Iteration 192, loss = 1404857730.02771378\n",
            "Iteration 193, loss = 1403455390.14066529\n",
            "Iteration 194, loss = 1402051022.29170918\n",
            "Iteration 195, loss = 1400635175.56918001\n",
            "Iteration 196, loss = 1399229593.36683464\n",
            "Iteration 197, loss = 1397804995.95851517\n",
            "Iteration 198, loss = 1396373422.18424010\n",
            "Iteration 199, loss = 1394934956.56907129\n",
            "Iteration 200, loss = 1393488497.33102322\n",
            "Iteration 201, loss = 1392046208.16182494\n",
            "Iteration 202, loss = 1390571602.37888980\n",
            "Iteration 203, loss = 1389125109.13620257\n",
            "Iteration 204, loss = 1387632029.51573563\n",
            "Iteration 205, loss = 1386158316.74597883\n",
            "Iteration 206, loss = 1384681766.39890957\n",
            "Iteration 207, loss = 1383173322.78433204\n",
            "Iteration 208, loss = 1381693003.67933750\n",
            "Iteration 209, loss = 1380162641.23059726\n",
            "Iteration 210, loss = 1378662179.65150142\n",
            "Iteration 211, loss = 1377129548.10395288\n",
            "Iteration 212, loss = 1375625909.91677785\n",
            "Iteration 213, loss = 1374072162.43026400\n",
            "Iteration 214, loss = 1372557647.17507267\n",
            "Iteration 215, loss = 1371012089.78844404\n",
            "Iteration 216, loss = 1369459224.25490689\n",
            "Iteration 217, loss = 1367909742.72177649\n",
            "Iteration 218, loss = 1366360333.66422439\n",
            "Iteration 219, loss = 1364801316.96833253\n",
            "Iteration 220, loss = 1363239732.34596610\n",
            "Iteration 221, loss = 1361652067.10730028\n",
            "Iteration 222, loss = 1360079533.19783998\n",
            "Iteration 223, loss = 1358497261.56864715\n",
            "Iteration 224, loss = 1356919420.04991269\n",
            "Iteration 225, loss = 1355300566.24147987\n",
            "Iteration 226, loss = 1353691341.55983043\n",
            "Iteration 227, loss = 1352094111.32198000\n",
            "Iteration 228, loss = 1350481980.24234796\n",
            "Iteration 229, loss = 1348842771.87455893\n",
            "Iteration 230, loss = 1347222771.63656259\n",
            "Iteration 231, loss = 1345605836.41631794\n",
            "Iteration 232, loss = 1343971434.08820629\n",
            "Iteration 233, loss = 1342339951.06414294\n",
            "Iteration 234, loss = 1340698432.41769481\n",
            "Iteration 235, loss = 1339057787.24752069\n",
            "Iteration 236, loss = 1337436123.71049261\n",
            "Iteration 237, loss = 1335759503.31313753\n",
            "Iteration 238, loss = 1334130247.41176987\n",
            "Iteration 239, loss = 1332484505.70394015\n",
            "Iteration 240, loss = 1330815214.79542708\n",
            "Iteration 241, loss = 1329139526.75906634\n",
            "Iteration 242, loss = 1327473533.54922700\n",
            "Iteration 243, loss = 1325788170.38688111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 244, loss = 1324117428.79830861\n",
            "Iteration 245, loss = 1322406842.18155456\n",
            "Iteration 246, loss = 1320696702.82875586\n",
            "Iteration 247, loss = 1318996995.45208812\n",
            "Iteration 248, loss = 1317290109.32859731\n",
            "Iteration 249, loss = 1315584453.08222413\n",
            "Iteration 250, loss = 1313839774.12186790\n",
            "Iteration 251, loss = 1312148176.67342544\n",
            "Iteration 252, loss = 1310416622.10070491\n",
            "Iteration 253, loss = 1308668826.34212375\n",
            "Iteration 254, loss = 1306973857.34713387\n",
            "Iteration 255, loss = 1305217479.78652167\n",
            "Iteration 256, loss = 1303489001.67490292\n",
            "Iteration 257, loss = 1301761696.76889515\n",
            "Iteration 258, loss = 1300006695.24689865\n",
            "Iteration 259, loss = 1298250882.13687396\n",
            "Iteration 260, loss = 1296485467.63606715\n",
            "Iteration 261, loss = 1294731491.25560188\n",
            "Iteration 262, loss = 1292978593.13598084\n",
            "Iteration 263, loss = 1291191213.58845043\n",
            "Iteration 264, loss = 1289417096.41889524\n",
            "Iteration 265, loss = 1287652849.74672532\n",
            "Iteration 266, loss = 1285879124.21744227\n",
            "Iteration 267, loss = 1284095392.08815360\n",
            "Iteration 268, loss = 1282312724.12249565\n",
            "Iteration 269, loss = 1280513673.43073750\n",
            "Iteration 270, loss = 1278711051.31412697\n",
            "Iteration 271, loss = 1276918094.28303456\n",
            "Iteration 272, loss = 1275116448.93305159\n",
            "Iteration 273, loss = 1273317920.95714855\n",
            "Iteration 274, loss = 1271514754.07431006\n",
            "Iteration 275, loss = 1269704160.44202590\n",
            "Iteration 276, loss = 1267878909.26644206\n",
            "Iteration 277, loss = 1266084346.01775050\n",
            "Iteration 278, loss = 1264247950.57751679\n",
            "Iteration 279, loss = 1262423356.14351559\n",
            "Iteration 280, loss = 1260558489.80178952\n",
            "Iteration 281, loss = 1258718706.31314206\n",
            "Iteration 282, loss = 1256856577.16124034\n",
            "Iteration 283, loss = 1255014305.29257536\n",
            "Iteration 284, loss = 1253128748.95731521\n",
            "Iteration 285, loss = 1251277510.59550834\n",
            "Iteration 286, loss = 1249399284.56397820\n",
            "Iteration 287, loss = 1247516905.68087173\n",
            "Iteration 288, loss = 1245654473.01698089\n",
            "Iteration 289, loss = 1243765961.90028143\n",
            "Iteration 290, loss = 1241874935.43786383\n",
            "Iteration 291, loss = 1239994870.77583790\n",
            "Iteration 292, loss = 1238104573.58267426\n",
            "Iteration 293, loss = 1236221152.25095749\n",
            "Iteration 294, loss = 1234360942.56816864\n",
            "Iteration 295, loss = 1232454151.55611825\n",
            "Iteration 296, loss = 1230572243.14949155\n",
            "Iteration 297, loss = 1228712770.75806832\n",
            "Iteration 298, loss = 1226803105.91992497\n",
            "Iteration 299, loss = 1224950959.75366449\n",
            "Iteration 300, loss = 1223034821.15095043\n",
            "Iteration 301, loss = 1221161215.12130880\n",
            "Iteration 302, loss = 1219248956.10171247\n",
            "Iteration 303, loss = 1217359964.53445601\n",
            "Iteration 304, loss = 1215452962.41678357\n",
            "Iteration 305, loss = 1213528133.20891428\n",
            "Iteration 306, loss = 1211638296.64949226\n",
            "Iteration 307, loss = 1209714686.50250459\n",
            "Iteration 308, loss = 1207781711.29599857\n",
            "Iteration 309, loss = 1205869658.72232294\n",
            "Iteration 310, loss = 1203946019.81170130\n",
            "Iteration 311, loss = 1202030406.34804130\n",
            "Iteration 312, loss = 1200086319.84841752\n",
            "Iteration 313, loss = 1198149235.44502783\n",
            "Iteration 314, loss = 1196208980.92735195\n",
            "Iteration 315, loss = 1194266166.72549868\n",
            "Iteration 316, loss = 1192300837.16815543\n",
            "Iteration 317, loss = 1190342620.73351860\n",
            "Iteration 318, loss = 1188370865.30495071\n",
            "Iteration 319, loss = 1186397754.79843593\n",
            "Iteration 320, loss = 1184422134.74059582\n",
            "Iteration 321, loss = 1182450667.55882192\n",
            "Iteration 322, loss = 1180459531.34060621\n",
            "Iteration 323, loss = 1178472866.69146705\n",
            "Iteration 324, loss = 1176491129.89519167\n",
            "Iteration 325, loss = 1174493740.04498696\n",
            "Iteration 326, loss = 1172506262.73149610\n",
            "Iteration 327, loss = 1170500607.61466289\n",
            "Iteration 328, loss = 1168532245.18646979\n",
            "Iteration 329, loss = 1166509532.86150932\n",
            "Iteration 330, loss = 1164516733.97866130\n",
            "Iteration 331, loss = 1162533335.42554688\n",
            "Iteration 332, loss = 1160505377.40786338\n",
            "Iteration 333, loss = 1158518918.95064020\n",
            "Iteration 334, loss = 1156528930.36504102\n",
            "Iteration 335, loss = 1154525124.92430758\n",
            "Iteration 336, loss = 1152510486.61420941\n",
            "Iteration 337, loss = 1150543314.27580690\n",
            "Iteration 338, loss = 1148513613.98868203\n",
            "Iteration 339, loss = 1146527170.30299282\n",
            "Iteration 340, loss = 1144514182.16939330\n",
            "Iteration 341, loss = 1142500892.87872458\n",
            "Iteration 342, loss = 1140510146.17939281\n",
            "Iteration 343, loss = 1138488554.22556496\n",
            "Iteration 344, loss = 1136460464.50500202\n",
            "Iteration 345, loss = 1134445368.42261481\n",
            "Iteration 346, loss = 1132436155.22784114\n",
            "Iteration 347, loss = 1130364627.26817107\n",
            "Iteration 348, loss = 1128337000.98299050\n",
            "Iteration 349, loss = 1126291618.89036179\n",
            "Iteration 350, loss = 1124233509.64568424\n",
            "Iteration 351, loss = 1122163565.68127584\n",
            "Iteration 352, loss = 1120119694.86021924\n",
            "Iteration 353, loss = 1118056222.58970070\n",
            "Iteration 354, loss = 1115975818.09583831\n",
            "Iteration 355, loss = 1113947829.37585211\n",
            "Iteration 356, loss = 1111869358.16490245\n",
            "Iteration 357, loss = 1109800710.35185266\n",
            "Iteration 358, loss = 1107756965.47617149\n",
            "Iteration 359, loss = 1105710470.00647140\n",
            "Iteration 360, loss = 1103645218.83696318\n",
            "Iteration 361, loss = 1101587194.00280452\n",
            "Iteration 362, loss = 1099520619.77206993\n",
            "Iteration 363, loss = 1097473348.20462203\n",
            "Iteration 364, loss = 1095411397.77654123\n",
            "Iteration 365, loss = 1093375922.02521181\n",
            "Iteration 366, loss = 1091294540.69483280\n",
            "Iteration 367, loss = 1089235291.99525189\n",
            "Iteration 368, loss = 1087188488.26024461\n",
            "Iteration 369, loss = 1085115456.53927445\n",
            "Iteration 370, loss = 1083047944.66624045\n",
            "Iteration 371, loss = 1080942307.56566572\n",
            "Iteration 372, loss = 1078848887.44262338\n",
            "Iteration 373, loss = 1076785870.05602407\n",
            "Iteration 374, loss = 1074656918.16864896\n",
            "Iteration 375, loss = 1072573500.32632589\n",
            "Iteration 376, loss = 1070472141.18797660\n",
            "Iteration 377, loss = 1068381545.72164631\n",
            "Iteration 378, loss = 1066288862.04774976\n",
            "Iteration 379, loss = 1064184788.79490924\n",
            "Iteration 380, loss = 1062120815.59218585\n",
            "Iteration 381, loss = 1060016112.00072849\n",
            "Iteration 382, loss = 1057925826.54800212\n",
            "Iteration 383, loss = 1055789577.40310538\n",
            "Iteration 384, loss = 1053700419.49672961\n",
            "Iteration 385, loss = 1051628701.34587431\n",
            "Iteration 386, loss = 1049484953.71920729\n",
            "Iteration 387, loss = 1047392455.69189441\n",
            "Iteration 388, loss = 1045280815.82030010\n",
            "Iteration 389, loss = 1043187518.96224308\n",
            "Iteration 390, loss = 1041087627.49293208\n",
            "Iteration 391, loss = 1038993852.06244016\n",
            "Iteration 392, loss = 1036878933.73928404\n",
            "Iteration 393, loss = 1034787464.82738197\n",
            "Iteration 394, loss = 1032672645.65444064\n",
            "Iteration 395, loss = 1030572867.43405592\n",
            "Iteration 396, loss = 1028439116.04077196\n",
            "Iteration 397, loss = 1026361484.07875395\n",
            "Iteration 398, loss = 1024232865.82579327\n",
            "Iteration 399, loss = 1022122904.85054028\n",
            "Iteration 400, loss = 1019981033.37853825\n",
            "Iteration 401, loss = 1017906416.92932343\n",
            "Iteration 402, loss = 1015756844.23036313\n",
            "Iteration 403, loss = 1013624497.24144995\n",
            "Iteration 404, loss = 1011499948.98858738\n",
            "Iteration 405, loss = 1009366518.38541758\n",
            "Iteration 406, loss = 1007250362.83629191\n",
            "Iteration 407, loss = 1005096291.38054633\n",
            "Iteration 408, loss = 1002972467.24400640\n",
            "Iteration 409, loss = 1000863873.03183925\n",
            "Iteration 410, loss = 998720969.21117210\n",
            "Iteration 411, loss = 996596821.69365525\n",
            "Iteration 412, loss = 994478992.25124633\n",
            "Iteration 413, loss = 992360769.85832989\n",
            "Iteration 414, loss = 990251297.05062354\n",
            "Iteration 415, loss = 988111322.24333239\n",
            "Iteration 416, loss = 986016279.54175889\n",
            "Iteration 417, loss = 983897500.71031821\n",
            "Iteration 418, loss = 981804183.69956291\n",
            "Iteration 419, loss = 979682769.51679420\n",
            "Iteration 420, loss = 977591564.71943557\n",
            "Iteration 421, loss = 975498478.03386331\n",
            "Iteration 422, loss = 973403405.50634730\n",
            "Iteration 423, loss = 971274996.03994882\n",
            "Iteration 424, loss = 969182927.80215251\n",
            "Iteration 425, loss = 967062038.39721072\n",
            "Iteration 426, loss = 964968437.61495364\n",
            "Iteration 427, loss = 962824602.43805420\n",
            "Iteration 428, loss = 960709202.34570897\n",
            "Iteration 429, loss = 958603632.97276664\n",
            "Iteration 430, loss = 956481320.68615341\n",
            "Iteration 431, loss = 954350142.13269889\n",
            "Iteration 432, loss = 952244070.82407582\n",
            "Iteration 433, loss = 950123877.22277594\n",
            "Iteration 434, loss = 948007260.04517615\n",
            "Iteration 435, loss = 945908518.60304391\n",
            "Iteration 436, loss = 943767602.82815218\n",
            "Iteration 437, loss = 941654660.09368193\n",
            "Iteration 438, loss = 939545809.61228693\n",
            "Iteration 439, loss = 937411214.65314400\n",
            "Iteration 440, loss = 935301753.36492944\n",
            "Iteration 441, loss = 933175949.37442100\n",
            "Iteration 442, loss = 931068614.73119259\n",
            "Iteration 443, loss = 928951685.25689149\n",
            "Iteration 444, loss = 926835142.67944157\n",
            "Iteration 445, loss = 924702457.89363849\n",
            "Iteration 446, loss = 922606645.19694591\n",
            "Iteration 447, loss = 920486068.28643346\n",
            "Iteration 448, loss = 918380530.02774429\n",
            "Iteration 449, loss = 916275612.38196766\n",
            "Iteration 450, loss = 914154101.25309503\n",
            "Iteration 451, loss = 912071323.61114180\n",
            "Iteration 452, loss = 909965506.90554142\n",
            "Iteration 453, loss = 907887154.24632347\n",
            "Iteration 454, loss = 905777688.01478827\n",
            "Iteration 455, loss = 903685983.44139802\n",
            "Iteration 456, loss = 901598865.63305163\n",
            "Iteration 457, loss = 899499401.29560709\n",
            "Iteration 458, loss = 897423222.69369876\n",
            "Iteration 459, loss = 895290759.00117469\n",
            "Iteration 460, loss = 893199757.40457606\n",
            "Iteration 461, loss = 891101851.96177864\n",
            "Iteration 462, loss = 888998686.57867551\n",
            "Iteration 463, loss = 886871364.29826999\n",
            "Iteration 464, loss = 884776601.34150100\n",
            "Iteration 465, loss = 882624174.49970484\n",
            "Iteration 466, loss = 880522484.06867886\n",
            "Iteration 467, loss = 878413327.23586977\n",
            "Iteration 468, loss = 876280027.42753541\n",
            "Iteration 469, loss = 874148861.51303029\n",
            "Iteration 470, loss = 872025140.19515800\n",
            "Iteration 471, loss = 869924632.53027058\n",
            "Iteration 472, loss = 867810048.38675702\n",
            "Iteration 473, loss = 865702635.32038832\n",
            "Iteration 474, loss = 863579892.03862083\n",
            "Iteration 475, loss = 861421671.06833434\n",
            "Iteration 476, loss = 859370962.04357231\n",
            "Iteration 477, loss = 857234499.53735065\n",
            "Iteration 478, loss = 855122065.94070661\n",
            "Iteration 479, loss = 853011947.45148563\n",
            "Iteration 480, loss = 850919202.77236056\n",
            "Iteration 481, loss = 848807789.41163683\n",
            "Iteration 482, loss = 846707185.87687838\n",
            "Iteration 483, loss = 844616462.50264978\n",
            "Iteration 484, loss = 842540941.02040768\n",
            "Iteration 485, loss = 840426783.41392410\n",
            "Iteration 486, loss = 838353592.63929546\n",
            "Iteration 487, loss = 836297964.64242482\n",
            "Iteration 488, loss = 834221272.47917974\n",
            "Iteration 489, loss = 832137225.86733270\n",
            "Iteration 490, loss = 830074050.27845371\n",
            "Iteration 491, loss = 828033395.07860327\n",
            "Iteration 492, loss = 825955079.64619887\n",
            "Iteration 493, loss = 823871913.80514097\n",
            "Iteration 494, loss = 821823690.57549286\n",
            "Iteration 495, loss = 819775227.47169912\n",
            "Iteration 496, loss = 817708464.84125161\n",
            "Iteration 497, loss = 815678882.66543031\n",
            "Iteration 498, loss = 813657511.41956341\n",
            "Iteration 499, loss = 811619835.01201880\n",
            "Iteration 500, loss = 809591143.70125341\n",
            "Iteration 501, loss = 807555770.06855702\n",
            "Iteration 502, loss = 805534443.69763184\n",
            "Iteration 503, loss = 803500867.38323152\n",
            "Iteration 504, loss = 801436064.28070164\n",
            "Iteration 505, loss = 799389525.04402566\n",
            "Iteration 506, loss = 797347711.91813898\n",
            "Iteration 507, loss = 795272342.52517056\n",
            "Iteration 508, loss = 793204464.22844005\n",
            "Iteration 509, loss = 791142769.06016743\n",
            "Iteration 510, loss = 789081822.76428902\n",
            "Iteration 511, loss = 787007829.04047406\n",
            "Iteration 512, loss = 784960432.49748409\n",
            "Iteration 513, loss = 782872529.73267746\n",
            "Iteration 514, loss = 780835950.16715491\n",
            "Iteration 515, loss = 778761290.17119300\n",
            "Iteration 516, loss = 776722552.25410032\n",
            "Iteration 517, loss = 774686461.08204746\n",
            "Iteration 518, loss = 772629798.11668694\n",
            "Iteration 519, loss = 770602468.68927324\n",
            "Iteration 520, loss = 768581044.12081802\n",
            "Iteration 521, loss = 766539139.82769024\n",
            "Iteration 522, loss = 764528197.88111770\n",
            "Iteration 523, loss = 762513372.46857834\n",
            "Iteration 524, loss = 760460834.42716229\n",
            "Iteration 525, loss = 758467205.44020903\n",
            "Iteration 526, loss = 756437158.42763746\n",
            "Iteration 527, loss = 754431212.77291179\n",
            "Iteration 528, loss = 752390330.39281046\n",
            "Iteration 529, loss = 750388819.76228154\n",
            "Iteration 530, loss = 748356828.82499576\n",
            "Iteration 531, loss = 746352220.62434053\n",
            "Iteration 532, loss = 744340958.96556687\n",
            "Iteration 533, loss = 742344156.18591678\n",
            "Iteration 534, loss = 740315161.56706703\n",
            "Iteration 535, loss = 738330396.79491520\n",
            "Iteration 536, loss = 736300178.01551950\n",
            "Iteration 537, loss = 734274158.82437599\n",
            "Iteration 538, loss = 732260401.80385315\n",
            "Iteration 539, loss = 730224125.01897717\n",
            "Iteration 540, loss = 728211747.01238084\n",
            "Iteration 541, loss = 726185724.56826770\n",
            "Iteration 542, loss = 724165068.15610218\n",
            "Iteration 543, loss = 722179526.99304891\n",
            "Iteration 544, loss = 720159089.84668231\n",
            "Iteration 545, loss = 718183092.26738536\n",
            "Iteration 546, loss = 716175862.47685778\n",
            "Iteration 547, loss = 714211925.58443022\n",
            "Iteration 548, loss = 712199230.82488048\n",
            "Iteration 549, loss = 710249827.07319558\n",
            "Iteration 550, loss = 708240308.11340857\n",
            "Iteration 551, loss = 706246629.75469458\n",
            "Iteration 552, loss = 704267942.77339947\n",
            "Iteration 553, loss = 702276423.49321830\n",
            "Iteration 554, loss = 700315185.29525197\n",
            "Iteration 555, loss = 698342854.56095159\n",
            "Iteration 556, loss = 696327904.05690682\n",
            "Iteration 557, loss = 694389727.01503575\n",
            "Iteration 558, loss = 692442420.87398612\n",
            "Iteration 559, loss = 690476993.96339941\n",
            "Iteration 560, loss = 688519239.66832411\n",
            "Iteration 561, loss = 686588600.87704241\n",
            "Iteration 562, loss = 684642130.50749755\n",
            "Iteration 563, loss = 682701396.39868367\n",
            "Iteration 564, loss = 680784567.75271249\n",
            "Iteration 565, loss = 678854665.82207596\n",
            "Iteration 566, loss = 676907871.42610145\n",
            "Iteration 567, loss = 675013177.61881900\n",
            "Iteration 568, loss = 673087445.18991566\n",
            "Iteration 569, loss = 671182755.70145249\n",
            "Iteration 570, loss = 669276168.01764035\n",
            "Iteration 571, loss = 667352863.29446471\n",
            "Iteration 572, loss = 665478833.39655972\n",
            "Iteration 573, loss = 663592761.66350055\n",
            "Iteration 574, loss = 661679098.69197774\n",
            "Iteration 575, loss = 659807155.37674046\n",
            "Iteration 576, loss = 657901597.30699980\n",
            "Iteration 577, loss = 656057036.28101289\n",
            "Iteration 578, loss = 654167420.80354810\n",
            "Iteration 579, loss = 652276962.91918182\n",
            "Iteration 580, loss = 650432526.83954155\n",
            "Iteration 581, loss = 648563519.02320766\n",
            "Iteration 582, loss = 646721540.54311979\n",
            "Iteration 583, loss = 644847778.05400705\n",
            "Iteration 584, loss = 642984982.69046831\n",
            "Iteration 585, loss = 641149148.96199536\n",
            "Iteration 586, loss = 639286706.55769229\n",
            "Iteration 587, loss = 637433554.98880506\n",
            "Iteration 588, loss = 635586140.84467280\n",
            "Iteration 589, loss = 633719792.50049043\n",
            "Iteration 590, loss = 631872544.35247803\n",
            "Iteration 591, loss = 630000606.93332171\n",
            "Iteration 592, loss = 628188330.37416410\n",
            "Iteration 593, loss = 626318848.46274483\n",
            "Iteration 594, loss = 624493689.57729506\n",
            "Iteration 595, loss = 622634752.00302148\n",
            "Iteration 596, loss = 620789164.40724349\n",
            "Iteration 597, loss = 618960230.56411099\n",
            "Iteration 598, loss = 617118133.65924716\n",
            "Iteration 599, loss = 615263182.08608949\n",
            "Iteration 600, loss = 613436231.93498564\n",
            "Iteration 601, loss = 611610817.81931996\n",
            "Iteration 602, loss = 609784828.52150309\n",
            "Iteration 603, loss = 607974056.57826388\n",
            "Iteration 604, loss = 606149934.64802778\n",
            "Iteration 605, loss = 604372884.52808416\n",
            "Iteration 606, loss = 602534260.33418930\n",
            "Iteration 607, loss = 600743558.74142528\n",
            "Iteration 608, loss = 598961900.68231344\n",
            "Iteration 609, loss = 597154109.70723188\n",
            "Iteration 610, loss = 595341860.82328618\n",
            "Iteration 611, loss = 593567029.89531028\n",
            "Iteration 612, loss = 591753936.32553470\n",
            "Iteration 613, loss = 589976464.49866223\n",
            "Iteration 614, loss = 588172914.11675572\n",
            "Iteration 615, loss = 586371970.77403855\n",
            "Iteration 616, loss = 584574533.56157219\n",
            "Iteration 617, loss = 582775741.22081721\n",
            "Iteration 618, loss = 580976614.34604573\n",
            "Iteration 619, loss = 579183223.80480707\n",
            "Iteration 620, loss = 577369072.29155695\n",
            "Iteration 621, loss = 575609062.50518966\n",
            "Iteration 622, loss = 573793171.50186586\n",
            "Iteration 623, loss = 572057313.77202713\n",
            "Iteration 624, loss = 570249845.43319046\n",
            "Iteration 625, loss = 568517240.24671423\n",
            "Iteration 626, loss = 566721560.97655427\n",
            "Iteration 627, loss = 564969732.73895037\n",
            "Iteration 628, loss = 563220570.89615035\n",
            "Iteration 629, loss = 561468060.05621397\n",
            "Iteration 630, loss = 559711956.58502436\n",
            "Iteration 631, loss = 557943114.86336815\n",
            "Iteration 632, loss = 556225905.98533773\n",
            "Iteration 633, loss = 554471733.45906341\n",
            "Iteration 634, loss = 552748526.24736261\n",
            "Iteration 635, loss = 551039174.48553574\n",
            "Iteration 636, loss = 549295206.56702471\n",
            "Iteration 637, loss = 547612845.75441563\n",
            "Iteration 638, loss = 545910769.33098030\n",
            "Iteration 639, loss = 544197130.12662256\n",
            "Iteration 640, loss = 542529285.55264294\n",
            "Iteration 641, loss = 540844461.97154295\n",
            "Iteration 642, loss = 539158846.01900113\n",
            "Iteration 643, loss = 537479940.88223660\n",
            "Iteration 644, loss = 535788467.34169674\n",
            "Iteration 645, loss = 534136041.38991964\n",
            "Iteration 646, loss = 532465993.10406250\n",
            "Iteration 647, loss = 530805768.03614390\n",
            "Iteration 648, loss = 529144512.59974748\n",
            "Iteration 649, loss = 527497509.14090085\n",
            "Iteration 650, loss = 525851314.70441580\n",
            "Iteration 651, loss = 524210415.97995341\n",
            "Iteration 652, loss = 522560787.08553642\n",
            "Iteration 653, loss = 520905609.17647487\n",
            "Iteration 654, loss = 519250139.81153512\n",
            "Iteration 655, loss = 517644848.81024659\n",
            "Iteration 656, loss = 515966994.30620235\n",
            "Iteration 657, loss = 514324508.24012643\n",
            "Iteration 658, loss = 512700892.28468233\n",
            "Iteration 659, loss = 511039252.30264711\n",
            "Iteration 660, loss = 509434423.27828115\n",
            "Iteration 661, loss = 507787724.75451714\n",
            "Iteration 662, loss = 506150428.81241298\n",
            "Iteration 663, loss = 504522549.40065843\n",
            "Iteration 664, loss = 502903108.13084960\n",
            "Iteration 665, loss = 501269732.38835055\n",
            "Iteration 666, loss = 499644589.30077279\n",
            "Iteration 667, loss = 498024906.34829515\n",
            "Iteration 668, loss = 496408430.50763524\n",
            "Iteration 669, loss = 494788860.17454213\n",
            "Iteration 670, loss = 493197285.11865658\n",
            "Iteration 671, loss = 491573939.50001812\n",
            "Iteration 672, loss = 489973340.34200829\n",
            "Iteration 673, loss = 488390457.27321512\n",
            "Iteration 674, loss = 486761834.77504116\n",
            "Iteration 675, loss = 485205392.21455479\n",
            "Iteration 676, loss = 483589661.96305484\n",
            "Iteration 677, loss = 482017230.38121170\n",
            "Iteration 678, loss = 480427222.38648462\n",
            "Iteration 679, loss = 478858505.28427958\n",
            "Iteration 680, loss = 477309518.48880303\n",
            "Iteration 681, loss = 475710603.00101048\n",
            "Iteration 682, loss = 474178375.56737381\n",
            "Iteration 683, loss = 472646322.77698350\n",
            "Iteration 684, loss = 471086036.23511058\n",
            "Iteration 685, loss = 469568779.23622298\n",
            "Iteration 686, loss = 468041001.81552881\n",
            "Iteration 687, loss = 466532950.67615211\n",
            "Iteration 688, loss = 465004843.55491561\n",
            "Iteration 689, loss = 463490099.92827523\n",
            "Iteration 690, loss = 461990200.51856250\n",
            "Iteration 691, loss = 460481329.09012926\n",
            "Iteration 692, loss = 458986231.40465099\n",
            "Iteration 693, loss = 457467116.97054398\n",
            "Iteration 694, loss = 455990043.62445760\n",
            "Iteration 695, loss = 454478048.43215752\n",
            "Iteration 696, loss = 453015536.33860439\n",
            "Iteration 697, loss = 451490651.67897183\n",
            "Iteration 698, loss = 450036550.76530117\n",
            "Iteration 699, loss = 448548833.74967915\n",
            "Iteration 700, loss = 447061416.26736683\n",
            "Iteration 701, loss = 445590486.76525635\n",
            "Iteration 702, loss = 444108271.70584649\n",
            "Iteration 703, loss = 442614854.51877803\n",
            "Iteration 704, loss = 441165325.70983076\n",
            "Iteration 705, loss = 439707095.06700432\n",
            "Iteration 706, loss = 438221456.84232390\n",
            "Iteration 707, loss = 436795566.50678265\n",
            "Iteration 708, loss = 435326750.71881419\n",
            "Iteration 709, loss = 433893952.70148218\n",
            "Iteration 710, loss = 432425607.64694947\n",
            "Iteration 711, loss = 430998101.51765376\n",
            "Iteration 712, loss = 429538718.10327566\n",
            "Iteration 713, loss = 428094410.68668371\n",
            "Iteration 714, loss = 426651775.75728095\n",
            "Iteration 715, loss = 425219111.03426421\n",
            "Iteration 716, loss = 423769513.77521193\n",
            "Iteration 717, loss = 422365005.20514584\n",
            "Iteration 718, loss = 420942094.28450638\n",
            "Iteration 719, loss = 419544678.55488348\n",
            "Iteration 720, loss = 418155049.78257138\n",
            "Iteration 721, loss = 416762909.61549312\n",
            "Iteration 722, loss = 415367508.08118349\n",
            "Iteration 723, loss = 413984862.89873701\n",
            "Iteration 724, loss = 412606878.00782359\n",
            "Iteration 725, loss = 411220728.76342976\n",
            "Iteration 726, loss = 409834653.96977484\n",
            "Iteration 727, loss = 408444870.27398562\n",
            "Iteration 728, loss = 407070828.88091880\n",
            "Iteration 729, loss = 405709174.53403109\n",
            "Iteration 730, loss = 404320567.75946295\n",
            "Iteration 731, loss = 402957720.14727974\n",
            "Iteration 732, loss = 401581972.04198730\n",
            "Iteration 733, loss = 400213146.17596239\n",
            "Iteration 734, loss = 398857943.33391500\n",
            "Iteration 735, loss = 397508251.52821851\n",
            "Iteration 736, loss = 396152128.32602584\n",
            "Iteration 737, loss = 394789470.81733429\n",
            "Iteration 738, loss = 393462784.75758350\n",
            "Iteration 739, loss = 392127208.77818370\n",
            "Iteration 740, loss = 390789368.13656014\n",
            "Iteration 741, loss = 389468020.85579628\n",
            "Iteration 742, loss = 388120660.29175270\n",
            "Iteration 743, loss = 386800058.03507364\n",
            "Iteration 744, loss = 385473559.66638875\n",
            "Iteration 745, loss = 384156321.20390803\n",
            "Iteration 746, loss = 382833773.19554114\n",
            "Iteration 747, loss = 381532262.37902403\n",
            "Iteration 748, loss = 380222903.02941054\n",
            "Iteration 749, loss = 378934249.97704023\n",
            "Iteration 750, loss = 377637226.84139562\n",
            "Iteration 751, loss = 376362093.10383213\n",
            "Iteration 752, loss = 375077561.62527573\n",
            "Iteration 753, loss = 373809838.63704532\n",
            "Iteration 754, loss = 372533524.10798603\n",
            "Iteration 755, loss = 371257787.49260551\n",
            "Iteration 756, loss = 369996122.91148889\n",
            "Iteration 757, loss = 368757033.89947712\n",
            "Iteration 758, loss = 367463946.03289145\n",
            "Iteration 759, loss = 366233806.47402328\n",
            "Iteration 760, loss = 365006117.66631424\n",
            "Iteration 761, loss = 363743174.04320729\n",
            "Iteration 762, loss = 362528055.52622151\n",
            "Iteration 763, loss = 361310211.41243273\n",
            "Iteration 764, loss = 360091569.96926945\n",
            "Iteration 765, loss = 358876197.43640280\n",
            "Iteration 766, loss = 357668158.39391428\n",
            "Iteration 767, loss = 356456486.13334429\n",
            "Iteration 768, loss = 355235909.89454317\n",
            "Iteration 769, loss = 354043805.02129412\n",
            "Iteration 770, loss = 352822238.61049545\n",
            "Iteration 771, loss = 351624019.28214449\n",
            "Iteration 772, loss = 350422812.40661311\n",
            "Iteration 773, loss = 349197438.72717154\n",
            "Iteration 774, loss = 348019083.81247544\n",
            "Iteration 775, loss = 346811958.56982994\n",
            "Iteration 776, loss = 345632734.88835675\n",
            "Iteration 777, loss = 344444904.15839219\n",
            "Iteration 778, loss = 343270881.21518660\n",
            "Iteration 779, loss = 342093977.99873942\n",
            "Iteration 780, loss = 340920489.60945094\n",
            "Iteration 781, loss = 339782744.95215487\n",
            "Iteration 782, loss = 338611860.41284311\n",
            "Iteration 783, loss = 337462766.55558133\n",
            "Iteration 784, loss = 336303707.11410224\n",
            "Iteration 785, loss = 335170285.29533398\n",
            "Iteration 786, loss = 334027943.70740873\n",
            "Iteration 787, loss = 332871268.61613131\n",
            "Iteration 788, loss = 331728211.59468949\n",
            "Iteration 789, loss = 330617601.32706308\n",
            "Iteration 790, loss = 329478789.90399402\n",
            "Iteration 791, loss = 328357008.39930397\n",
            "Iteration 792, loss = 327232895.27207839\n",
            "Iteration 793, loss = 326105769.73268938\n",
            "Iteration 794, loss = 325000032.71683741\n",
            "Iteration 795, loss = 323889039.19618148\n",
            "Iteration 796, loss = 322786811.63517362\n",
            "Iteration 797, loss = 321679447.23121792\n",
            "Iteration 798, loss = 320556730.03733331\n",
            "Iteration 799, loss = 319479621.03363234\n",
            "Iteration 800, loss = 318359182.92440480\n",
            "Iteration 801, loss = 317282369.45840257\n",
            "Iteration 802, loss = 316179038.54184312\n",
            "Iteration 803, loss = 315090666.13807839\n",
            "Iteration 804, loss = 314013798.95029163\n",
            "Iteration 805, loss = 312933634.79922670\n",
            "Iteration 806, loss = 311870819.32041347\n",
            "Iteration 807, loss = 310805610.85711753\n",
            "Iteration 808, loss = 309731413.47545886\n",
            "Iteration 809, loss = 308697815.45135051\n",
            "Iteration 810, loss = 307644604.43250775\n",
            "Iteration 811, loss = 306592187.10322577\n",
            "Iteration 812, loss = 305550519.30091321\n",
            "Iteration 813, loss = 304525184.54451078\n",
            "Iteration 814, loss = 303503607.94340062\n",
            "Iteration 815, loss = 302440327.43550450\n",
            "Iteration 816, loss = 301429976.08864880\n",
            "Iteration 817, loss = 300385768.69718105\n",
            "Iteration 818, loss = 299389607.15173203\n",
            "Iteration 819, loss = 298345159.29678375\n",
            "Iteration 820, loss = 297339526.58107579\n",
            "Iteration 821, loss = 296310907.33656448\n",
            "Iteration 822, loss = 295315287.96518052\n",
            "Iteration 823, loss = 294284051.36517692\n",
            "Iteration 824, loss = 293304997.39142448\n",
            "Iteration 825, loss = 292282997.04873347\n",
            "Iteration 826, loss = 291267735.13821489\n",
            "Iteration 827, loss = 290286899.07757169\n",
            "Iteration 828, loss = 289275537.25107014\n",
            "Iteration 829, loss = 288295925.89395177\n",
            "Iteration 830, loss = 287299153.84689957\n",
            "Iteration 831, loss = 286315406.61815077\n",
            "Iteration 832, loss = 285347920.98871315\n",
            "Iteration 833, loss = 284366293.44544911\n",
            "Iteration 834, loss = 283416737.37086320\n",
            "Iteration 835, loss = 282439987.16995186\n",
            "Iteration 836, loss = 281485502.06427163\n",
            "Iteration 837, loss = 280514727.04508257\n",
            "Iteration 838, loss = 279573455.68288863\n",
            "Iteration 839, loss = 278618773.57530910\n",
            "Iteration 840, loss = 277662925.20450610\n",
            "Iteration 841, loss = 276725271.87765181\n",
            "Iteration 842, loss = 275782181.00325620\n",
            "Iteration 843, loss = 274838787.84791237\n",
            "Iteration 844, loss = 273905474.46199393\n",
            "Iteration 845, loss = 272971015.02626759\n",
            "Iteration 846, loss = 272024257.57510591\n",
            "Iteration 847, loss = 271110569.80227071\n",
            "Iteration 848, loss = 270161623.28849190\n",
            "Iteration 849, loss = 269233801.58591914\n",
            "Iteration 850, loss = 268304454.28878912\n",
            "Iteration 851, loss = 267379029.98307967\n",
            "Iteration 852, loss = 266451055.43624482\n",
            "Iteration 853, loss = 265537906.68101078\n",
            "Iteration 854, loss = 264627157.26357207\n",
            "Iteration 855, loss = 263702739.90428081\n",
            "Iteration 856, loss = 262818546.47666791\n",
            "Iteration 857, loss = 261905806.58411738\n",
            "Iteration 858, loss = 261025894.42406747\n",
            "Iteration 859, loss = 260114596.55497321\n",
            "Iteration 860, loss = 259242198.62539557\n",
            "Iteration 861, loss = 258343174.60385755\n",
            "Iteration 862, loss = 257455960.94791719\n",
            "Iteration 863, loss = 256572351.72330460\n",
            "Iteration 864, loss = 255706684.25407532\n",
            "Iteration 865, loss = 254825592.48221636\n",
            "Iteration 866, loss = 253949480.99330321\n",
            "Iteration 867, loss = 253089207.09970066\n",
            "Iteration 868, loss = 252234559.84589764\n",
            "Iteration 869, loss = 251380750.01317838\n",
            "Iteration 870, loss = 250526547.08772060\n",
            "Iteration 871, loss = 249683265.12299830\n",
            "Iteration 872, loss = 248839909.84504032\n",
            "Iteration 873, loss = 247996589.55889475\n",
            "Iteration 874, loss = 247153186.02873456\n",
            "Iteration 875, loss = 246315057.75997198\n",
            "Iteration 876, loss = 245471663.07620063\n",
            "Iteration 877, loss = 244642655.59387806\n",
            "Iteration 878, loss = 243809683.28381190\n",
            "Iteration 879, loss = 242970184.54894423\n",
            "Iteration 880, loss = 242154925.15938386\n",
            "Iteration 881, loss = 241321705.20137382\n",
            "Iteration 882, loss = 240527802.87769684\n",
            "Iteration 883, loss = 239703222.88883126\n",
            "Iteration 884, loss = 238903054.43279630\n",
            "Iteration 885, loss = 238108109.11417890\n",
            "Iteration 886, loss = 237309185.86202458\n",
            "Iteration 887, loss = 236534262.27816403\n",
            "Iteration 888, loss = 235741750.39234954\n",
            "Iteration 889, loss = 234970098.29610661\n",
            "Iteration 890, loss = 234199101.25481468\n",
            "Iteration 891, loss = 233430159.21271950\n",
            "Iteration 892, loss = 232672856.75596288\n",
            "Iteration 893, loss = 231916850.57548711\n",
            "Iteration 894, loss = 231162127.77828756\n",
            "Iteration 895, loss = 230421637.64751381\n",
            "Iteration 896, loss = 229659430.62384921\n",
            "Iteration 897, loss = 228919922.63959071\n",
            "Iteration 898, loss = 228168298.85518873\n",
            "Iteration 899, loss = 227434190.05770442\n",
            "Iteration 900, loss = 226674642.00642967\n",
            "Iteration 901, loss = 225942771.21246332\n",
            "Iteration 902, loss = 225197092.57201600\n",
            "Iteration 903, loss = 224475294.16657713\n",
            "Iteration 904, loss = 223741173.85989389\n",
            "Iteration 905, loss = 223025814.45858145\n",
            "Iteration 906, loss = 222300409.28047723\n",
            "Iteration 907, loss = 221599418.74493167\n",
            "Iteration 908, loss = 220893327.98756585\n",
            "Iteration 909, loss = 220194116.27454433\n",
            "Iteration 910, loss = 219495355.28816891\n",
            "Iteration 911, loss = 218812338.65690309\n",
            "Iteration 912, loss = 218109850.39117125\n",
            "Iteration 913, loss = 217432479.93322200\n",
            "Iteration 914, loss = 216752732.39879400\n",
            "Iteration 915, loss = 216074877.78267920\n",
            "Iteration 916, loss = 215400228.01604885\n",
            "Iteration 917, loss = 214719377.61335573\n",
            "Iteration 918, loss = 214061256.53338659\n",
            "Iteration 919, loss = 213396513.75521210\n",
            "Iteration 920, loss = 212722072.43854567\n",
            "Iteration 921, loss = 212081979.33876744\n",
            "Iteration 922, loss = 211424007.04786953\n",
            "Iteration 923, loss = 210774363.82454854\n",
            "Iteration 924, loss = 210129739.15546775\n",
            "Iteration 925, loss = 209485798.46932265\n",
            "Iteration 926, loss = 208853351.93247122\n",
            "Iteration 927, loss = 208218377.53781834\n",
            "Iteration 928, loss = 207599975.57029402\n",
            "Iteration 929, loss = 206952785.44985890\n",
            "Iteration 930, loss = 206338113.64776441\n",
            "Iteration 931, loss = 205713726.81403548\n",
            "Iteration 932, loss = 205091452.44720238\n",
            "Iteration 933, loss = 204471163.25061813\n",
            "Iteration 934, loss = 203839170.37838098\n",
            "Iteration 935, loss = 203221721.55024847\n",
            "Iteration 936, loss = 202592216.41311166\n",
            "Iteration 937, loss = 201975419.56282017\n",
            "Iteration 938, loss = 201347164.39958939\n",
            "Iteration 939, loss = 200726088.25184217\n",
            "Iteration 940, loss = 200108867.62320119\n",
            "Iteration 941, loss = 199503142.60660991\n",
            "Iteration 942, loss = 198884679.64134720\n",
            "Iteration 943, loss = 198281343.04711178\n",
            "Iteration 944, loss = 197676025.27435458\n",
            "Iteration 945, loss = 197077929.11719748\n",
            "Iteration 946, loss = 196491383.95168874\n",
            "Iteration 947, loss = 195883169.85364711\n",
            "Iteration 948, loss = 195287280.19677499\n",
            "Iteration 949, loss = 194710595.76561949\n",
            "Iteration 950, loss = 194114757.52324492\n",
            "Iteration 951, loss = 193521969.91167805\n",
            "Iteration 952, loss = 192952474.96311373\n",
            "Iteration 953, loss = 192365643.68515509\n",
            "Iteration 954, loss = 191789361.00460818\n",
            "Iteration 955, loss = 191215190.48199436\n",
            "Iteration 956, loss = 190635751.51608184\n",
            "Iteration 957, loss = 190079301.20540428\n",
            "Iteration 958, loss = 189518350.21554321\n",
            "Iteration 959, loss = 188951334.17251661\n",
            "Iteration 960, loss = 188403647.79285970\n",
            "Iteration 961, loss = 187863487.17625850\n",
            "Iteration 962, loss = 187313982.98949984\n",
            "Iteration 963, loss = 186783671.37527013\n",
            "Iteration 964, loss = 186251843.49146101\n",
            "Iteration 965, loss = 185725213.07483307\n",
            "Iteration 966, loss = 185193378.57335964\n",
            "Iteration 967, loss = 184673152.13229364\n",
            "Iteration 968, loss = 184147680.07526839\n",
            "Iteration 969, loss = 183630524.66420779\n",
            "Iteration 970, loss = 183112658.76725626\n",
            "Iteration 971, loss = 182596459.10859588\n",
            "Iteration 972, loss = 182073282.67596844\n",
            "Iteration 973, loss = 181540895.49180198\n",
            "Iteration 974, loss = 181054565.85689044\n",
            "Iteration 975, loss = 180520353.29132280\n",
            "Iteration 976, loss = 180009330.65340325\n",
            "Iteration 977, loss = 179503280.72648463\n",
            "Iteration 978, loss = 178988482.58868921\n",
            "Iteration 979, loss = 178487451.05148339\n",
            "Iteration 980, loss = 177983235.07812503\n",
            "Iteration 981, loss = 177477420.09962550\n",
            "Iteration 982, loss = 176986717.83949485\n",
            "Iteration 983, loss = 176494162.77646074\n",
            "Iteration 984, loss = 175999421.37014607\n",
            "Iteration 985, loss = 175511619.43495318\n",
            "Iteration 986, loss = 175033800.46173143\n",
            "Iteration 987, loss = 174550302.32000616\n",
            "Iteration 988, loss = 174076449.00625759\n",
            "Iteration 989, loss = 173584135.60371989\n",
            "Iteration 990, loss = 173117580.77812222\n",
            "Iteration 991, loss = 172639277.06790668\n",
            "Iteration 992, loss = 172168053.51327902\n",
            "Iteration 993, loss = 171685861.46118447\n",
            "Iteration 994, loss = 171221651.42474210\n",
            "Iteration 995, loss = 170756488.22439393\n",
            "Iteration 996, loss = 170283255.00945333\n",
            "Iteration 997, loss = 169818046.61354673\n",
            "Iteration 998, loss = 169361948.39581043\n",
            "Iteration 999, loss = 168892647.90557477\n",
            "Iteration 1000, loss = 168441014.22638056\n",
            "Iteration 1, loss = 69454805678.42793274\n",
            "Iteration 2, loss = 134406945048661074320029761841718068157459748748571880971519198523105036206080.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50,), relu, 0.001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538841413.19766688\n",
            "Iteration 2, loss = 1538822411.39228678\n",
            "Iteration 3, loss = 1538805338.14765501\n",
            "Iteration 4, loss = 1538789967.78669095\n",
            "Iteration 5, loss = 1538775218.63413072\n",
            "Iteration 6, loss = 1538760507.30461788\n",
            "Iteration 7, loss = 1538745094.08377337\n",
            "Iteration 8, loss = 1538728343.81008196\n",
            "Iteration 9, loss = 1538709777.50869012\n",
            "Iteration 10, loss = 1538689717.32006478\n",
            "Iteration 11, loss = 1538667614.99497080\n",
            "Iteration 12, loss = 1538643125.29639912\n",
            "Iteration 13, loss = 1538616262.25845218\n",
            "Iteration 14, loss = 1538586827.49811196\n",
            "Iteration 15, loss = 1538554662.43249226\n",
            "Iteration 16, loss = 1538519252.72488737\n",
            "Iteration 17, loss = 1538481215.86370873\n",
            "Iteration 18, loss = 1538439973.57663655\n",
            "Iteration 19, loss = 1538395241.42756438\n",
            "Iteration 20, loss = 1538347186.80119705\n",
            "Iteration 21, loss = 1538295559.09313226\n",
            "Iteration 22, loss = 1538240387.92080855\n",
            "Iteration 23, loss = 1538181262.08566999\n",
            "Iteration 24, loss = 1538118038.53332472\n",
            "Iteration 25, loss = 1538051005.83216667\n",
            "Iteration 26, loss = 1537979723.47675633\n",
            "Iteration 27, loss = 1537903716.61854362\n",
            "Iteration 28, loss = 1537823577.00391960\n",
            "Iteration 29, loss = 1537739877.40228486\n",
            "Iteration 30, loss = 1537650653.99611163\n",
            "Iteration 31, loss = 1537556889.06961036\n",
            "Iteration 32, loss = 1537459484.01933599\n",
            "Iteration 33, loss = 1537356163.16956782\n",
            "Iteration 34, loss = 1537249193.66785383\n",
            "Iteration 35, loss = 1537136122.01221061\n",
            "Iteration 36, loss = 1537018690.04575896\n",
            "Iteration 37, loss = 1536895702.57760692\n",
            "Iteration 38, loss = 1536768151.35961723\n",
            "Iteration 39, loss = 1536634296.11068892\n",
            "Iteration 40, loss = 1536495789.93752670\n",
            "Iteration 41, loss = 1536351761.90799546\n",
            "Iteration 42, loss = 1536202636.18142819\n",
            "Iteration 43, loss = 1536047004.34554029\n",
            "Iteration 44, loss = 1535886896.90118337\n",
            "Iteration 45, loss = 1535721168.66355014\n",
            "Iteration 46, loss = 1535548846.81380630\n",
            "Iteration 47, loss = 1535373113.79215932\n",
            "Iteration 48, loss = 1535189779.32305622\n",
            "Iteration 49, loss = 1535002780.96547365\n",
            "Iteration 50, loss = 1534809632.61001396\n",
            "Iteration 51, loss = 1534609869.33950567\n",
            "Iteration 52, loss = 1534406341.18116713\n",
            "Iteration 53, loss = 1534196018.67429042\n",
            "Iteration 54, loss = 1533980814.31744409\n",
            "Iteration 55, loss = 1533760415.44639611\n",
            "Iteration 56, loss = 1533534119.79481936\n",
            "Iteration 57, loss = 1533300821.25949478\n",
            "Iteration 58, loss = 1533064970.34278798\n",
            "Iteration 59, loss = 1532821449.12017918\n",
            "Iteration 60, loss = 1532572779.92407298\n",
            "Iteration 61, loss = 1532316941.88896275\n",
            "Iteration 62, loss = 1532059715.10563374\n",
            "Iteration 63, loss = 1531793076.73965430\n",
            "Iteration 64, loss = 1531521491.65727663\n",
            "Iteration 65, loss = 1531245407.04942966\n",
            "Iteration 66, loss = 1530962247.86153221\n",
            "Iteration 67, loss = 1530673946.65937877\n",
            "Iteration 68, loss = 1530379318.53702855\n",
            "Iteration 69, loss = 1530081670.29578924\n",
            "Iteration 70, loss = 1529774924.33739495\n",
            "Iteration 71, loss = 1529464002.49656844\n",
            "Iteration 72, loss = 1529148420.88215494\n",
            "Iteration 73, loss = 1528828977.79849410\n",
            "Iteration 74, loss = 1528499583.05904102\n",
            "Iteration 75, loss = 1528167788.84749818\n",
            "Iteration 76, loss = 1527830836.88998175\n",
            "Iteration 77, loss = 1527489315.11855912\n",
            "Iteration 78, loss = 1527140920.51832104\n",
            "Iteration 79, loss = 1526786480.05021214\n",
            "Iteration 80, loss = 1526431207.17023921\n",
            "Iteration 81, loss = 1526063965.59952450\n",
            "Iteration 82, loss = 1525699441.13784933\n",
            "Iteration 83, loss = 1525325805.08003235\n",
            "Iteration 84, loss = 1524943457.97263002\n",
            "Iteration 85, loss = 1524563013.61950922\n",
            "Iteration 86, loss = 1524171753.14241266\n",
            "Iteration 87, loss = 1523777237.83791542\n",
            "Iteration 88, loss = 1523377470.47520900\n",
            "Iteration 89, loss = 1522972723.89406919\n",
            "Iteration 90, loss = 1522561408.01496577\n",
            "Iteration 91, loss = 1522147690.62031913\n",
            "Iteration 92, loss = 1521726771.32129383\n",
            "Iteration 93, loss = 1521299782.10636210\n",
            "Iteration 94, loss = 1520871107.27140832\n",
            "Iteration 95, loss = 1520433442.76390314\n",
            "Iteration 96, loss = 1519994523.52655625\n",
            "Iteration 97, loss = 1519548764.13142323\n",
            "Iteration 98, loss = 1519098936.28012228\n",
            "Iteration 99, loss = 1518642078.51866579\n",
            "Iteration 100, loss = 1518181165.70502710\n",
            "Iteration 101, loss = 1517718568.48349953\n",
            "Iteration 102, loss = 1517248721.49488902\n",
            "Iteration 103, loss = 1516771258.43212748\n",
            "Iteration 104, loss = 1516290599.04992199\n",
            "Iteration 105, loss = 1515802695.14697456\n",
            "Iteration 106, loss = 1515311140.07212305\n",
            "Iteration 107, loss = 1514813848.68696451\n",
            "Iteration 108, loss = 1514306330.48451018\n",
            "Iteration 109, loss = 1513800300.39461279\n",
            "Iteration 110, loss = 1513282424.05741382\n",
            "Iteration 111, loss = 1512765492.78735924\n",
            "Iteration 112, loss = 1512237875.00056076\n",
            "Iteration 113, loss = 1511710178.43643284\n",
            "Iteration 114, loss = 1511177166.47089195\n",
            "Iteration 115, loss = 1510638264.64103150\n",
            "Iteration 116, loss = 1510092402.59737229\n",
            "Iteration 117, loss = 1509547741.79082489\n",
            "Iteration 118, loss = 1508994933.98596764\n",
            "Iteration 119, loss = 1508436372.66048074\n",
            "Iteration 120, loss = 1507876944.45186639\n",
            "Iteration 121, loss = 1507307828.43775725\n",
            "Iteration 122, loss = 1506740747.15229368\n",
            "Iteration 123, loss = 1506165319.08233881\n",
            "Iteration 124, loss = 1505582181.75028658\n",
            "Iteration 125, loss = 1504999782.09172750\n",
            "Iteration 126, loss = 1504412909.43525934\n",
            "Iteration 127, loss = 1503823973.35359359\n",
            "Iteration 128, loss = 1503222465.89667892\n",
            "Iteration 129, loss = 1502624829.87672567\n",
            "Iteration 130, loss = 1502018245.80725741\n",
            "Iteration 131, loss = 1501402793.81947947\n",
            "Iteration 132, loss = 1500793328.55060720\n",
            "Iteration 133, loss = 1500168207.20159006\n",
            "Iteration 134, loss = 1499536453.58237505\n",
            "Iteration 135, loss = 1498911270.03206611\n",
            "Iteration 136, loss = 1498269098.76437283\n",
            "Iteration 137, loss = 1497627516.09105134\n",
            "Iteration 138, loss = 1496980561.70835471\n",
            "Iteration 139, loss = 1496325035.49871945\n",
            "Iteration 140, loss = 1495673366.37921548\n",
            "Iteration 141, loss = 1495004463.39543629\n",
            "Iteration 142, loss = 1494343986.08358979\n",
            "Iteration 143, loss = 1493668137.93128538\n",
            "Iteration 144, loss = 1492995728.69413471\n",
            "Iteration 145, loss = 1492317769.67819118\n",
            "Iteration 146, loss = 1491631569.06464958\n",
            "Iteration 147, loss = 1490943927.91801500\n",
            "Iteration 148, loss = 1490254857.66157913\n",
            "Iteration 149, loss = 1489554917.35396266\n",
            "Iteration 150, loss = 1488847319.00781751\n",
            "Iteration 151, loss = 1488144479.44412303\n",
            "Iteration 152, loss = 1487424827.83795333\n",
            "Iteration 153, loss = 1486705749.83832669\n",
            "Iteration 154, loss = 1485979633.48081756\n",
            "Iteration 155, loss = 1485249414.99719810\n",
            "Iteration 156, loss = 1484514047.02479839\n",
            "Iteration 157, loss = 1483775290.98161149\n",
            "Iteration 158, loss = 1483023113.11987662\n",
            "Iteration 159, loss = 1482281660.18509078\n",
            "Iteration 160, loss = 1481522313.79823112\n",
            "Iteration 161, loss = 1480765785.59296870\n",
            "Iteration 162, loss = 1480000721.66879892\n",
            "Iteration 163, loss = 1479237572.38066840\n",
            "Iteration 164, loss = 1478464558.37739325\n",
            "Iteration 165, loss = 1477695382.97956848\n",
            "Iteration 166, loss = 1476924068.34428835\n",
            "Iteration 167, loss = 1476142826.52890897\n",
            "Iteration 168, loss = 1475364172.30430841\n",
            "Iteration 169, loss = 1474580160.46800542\n",
            "Iteration 170, loss = 1473797468.80822945\n",
            "Iteration 171, loss = 1472999587.53417134\n",
            "Iteration 172, loss = 1472206791.11341238\n",
            "Iteration 173, loss = 1471403786.53176069\n",
            "Iteration 174, loss = 1470595213.24293733\n",
            "Iteration 175, loss = 1469776523.05751777\n",
            "Iteration 176, loss = 1468962542.40436983\n",
            "Iteration 177, loss = 1468131474.64164448\n",
            "Iteration 178, loss = 1467301188.61819243\n",
            "Iteration 179, loss = 1466474273.78265929\n",
            "Iteration 180, loss = 1465633073.29727054\n",
            "Iteration 181, loss = 1464798471.11467767\n",
            "Iteration 182, loss = 1463947495.70942831\n",
            "Iteration 183, loss = 1463112153.36303163\n",
            "Iteration 184, loss = 1462259970.26730371\n",
            "Iteration 185, loss = 1461408600.36482382\n",
            "Iteration 186, loss = 1460547669.31127024\n",
            "Iteration 187, loss = 1459683762.22918725\n",
            "Iteration 188, loss = 1458820031.67437482\n",
            "Iteration 189, loss = 1457946133.92288899\n",
            "Iteration 190, loss = 1457071452.41903782\n",
            "Iteration 191, loss = 1456193273.19005227\n",
            "Iteration 192, loss = 1455312738.74005651\n",
            "Iteration 193, loss = 1454421589.75187612\n",
            "Iteration 194, loss = 1453537933.40067124\n",
            "Iteration 195, loss = 1452636621.54367924\n",
            "Iteration 196, loss = 1451738730.21122718\n",
            "Iteration 197, loss = 1450835948.74356961\n",
            "Iteration 198, loss = 1449923757.37903214\n",
            "Iteration 199, loss = 1449012162.51098442\n",
            "Iteration 200, loss = 1448082815.23972273\n",
            "Iteration 201, loss = 1447162243.01580977\n",
            "Iteration 202, loss = 1446231445.44822550\n",
            "Iteration 203, loss = 1445302466.50771666\n",
            "Iteration 204, loss = 1444362780.82131577\n",
            "Iteration 205, loss = 1443417830.66990685\n",
            "Iteration 206, loss = 1442475928.65273619\n",
            "Iteration 207, loss = 1441527029.48838115\n",
            "Iteration 208, loss = 1440568232.45662928\n",
            "Iteration 209, loss = 1439610054.81669807\n",
            "Iteration 210, loss = 1438653599.84926558\n",
            "Iteration 211, loss = 1437684216.50430465\n",
            "Iteration 212, loss = 1436712700.83535004\n",
            "Iteration 213, loss = 1435733041.36836076\n",
            "Iteration 214, loss = 1434761020.05053210\n",
            "Iteration 215, loss = 1433777703.29920650\n",
            "Iteration 216, loss = 1432789284.07215834\n",
            "Iteration 217, loss = 1431801569.27679253\n",
            "Iteration 218, loss = 1430814857.76393700\n",
            "Iteration 219, loss = 1429818266.13535500\n",
            "Iteration 220, loss = 1428825557.47052908\n",
            "Iteration 221, loss = 1427833245.34274268\n",
            "Iteration 222, loss = 1426832574.30784011\n",
            "Iteration 223, loss = 1425837278.36864448\n",
            "Iteration 224, loss = 1424831173.07221985\n",
            "Iteration 225, loss = 1423821860.96531153\n",
            "Iteration 226, loss = 1422812545.60220122\n",
            "Iteration 227, loss = 1421806946.41581440\n",
            "Iteration 228, loss = 1420782621.15284872\n",
            "Iteration 229, loss = 1419765866.51745319\n",
            "Iteration 230, loss = 1418737842.27885294\n",
            "Iteration 231, loss = 1417711201.52835274\n",
            "Iteration 232, loss = 1416674400.72884488\n",
            "Iteration 233, loss = 1415642918.04734421\n",
            "Iteration 234, loss = 1414588324.94235063\n",
            "Iteration 235, loss = 1413547927.03975439\n",
            "Iteration 236, loss = 1412495971.99452829\n",
            "Iteration 237, loss = 1411440085.46949887\n",
            "Iteration 238, loss = 1410389564.67824364\n",
            "Iteration 239, loss = 1409329568.10522795\n",
            "Iteration 240, loss = 1408269879.01353025\n",
            "Iteration 241, loss = 1407203535.98888373\n",
            "Iteration 242, loss = 1406135573.75816369\n",
            "Iteration 243, loss = 1405069215.87600899\n",
            "Iteration 244, loss = 1403979843.62082410\n",
            "Iteration 245, loss = 1402921657.38684225\n",
            "Iteration 246, loss = 1401825814.30526376\n",
            "Iteration 247, loss = 1400744089.44563341\n",
            "Iteration 248, loss = 1399658681.67904902\n",
            "Iteration 249, loss = 1398566629.39596486\n",
            "Iteration 250, loss = 1397481969.62078142\n",
            "Iteration 251, loss = 1396374255.44403577\n",
            "Iteration 252, loss = 1395278111.17290449\n",
            "Iteration 253, loss = 1394179722.81533289\n",
            "Iteration 254, loss = 1393073010.89288235\n",
            "Iteration 255, loss = 1391962159.88977623\n",
            "Iteration 256, loss = 1390845310.22350764\n",
            "Iteration 257, loss = 1389728882.00296926\n",
            "Iteration 258, loss = 1388604169.75396085\n",
            "Iteration 259, loss = 1387475044.66261864\n",
            "Iteration 260, loss = 1386351391.21214294\n",
            "Iteration 261, loss = 1385208713.93461466\n",
            "Iteration 262, loss = 1384069604.58751583\n",
            "Iteration 263, loss = 1382927183.53043342\n",
            "Iteration 264, loss = 1381787906.96785998\n",
            "Iteration 265, loss = 1380638464.58815789\n",
            "Iteration 266, loss = 1379484131.40210080\n",
            "Iteration 267, loss = 1378341242.25890064\n",
            "Iteration 268, loss = 1377175994.27732444\n",
            "Iteration 269, loss = 1376025193.21274757\n",
            "Iteration 270, loss = 1374868762.47325873\n",
            "Iteration 271, loss = 1373694433.31206679\n",
            "Iteration 272, loss = 1372535353.60478163\n",
            "Iteration 273, loss = 1371365476.45975614\n",
            "Iteration 274, loss = 1370187409.27170086\n",
            "Iteration 275, loss = 1369014972.68314672\n",
            "Iteration 276, loss = 1367837154.45737314\n",
            "Iteration 277, loss = 1366653412.57564068\n",
            "Iteration 278, loss = 1365455488.41831446\n",
            "Iteration 279, loss = 1364279248.79069328\n",
            "Iteration 280, loss = 1363085667.86136746\n",
            "Iteration 281, loss = 1361888801.47996569\n",
            "Iteration 282, loss = 1360692189.90651870\n",
            "Iteration 283, loss = 1359493702.92431235\n",
            "Iteration 284, loss = 1358295613.08335471\n",
            "Iteration 285, loss = 1357082149.04504728\n",
            "Iteration 286, loss = 1355875183.36813545\n",
            "Iteration 287, loss = 1354657270.10390711\n",
            "Iteration 288, loss = 1353448641.43569994\n",
            "Iteration 289, loss = 1352224334.62682533\n",
            "Iteration 290, loss = 1351001029.60918450\n",
            "Iteration 291, loss = 1349784460.23334241\n",
            "Iteration 292, loss = 1348554280.22284150\n",
            "Iteration 293, loss = 1347331325.06877899\n",
            "Iteration 294, loss = 1346106944.76822519\n",
            "Iteration 295, loss = 1344874134.19254255\n",
            "Iteration 296, loss = 1343636404.69564939\n",
            "Iteration 297, loss = 1342394580.13465285\n",
            "Iteration 298, loss = 1341158798.70120883\n",
            "Iteration 299, loss = 1339908537.79021049\n",
            "Iteration 300, loss = 1338666557.08564568\n",
            "Iteration 301, loss = 1337412721.47787404\n",
            "Iteration 302, loss = 1336160101.17284775\n",
            "Iteration 303, loss = 1334903297.67240024\n",
            "Iteration 304, loss = 1333645165.82646465\n",
            "Iteration 305, loss = 1332389513.85312891\n",
            "Iteration 306, loss = 1331118464.10589194\n",
            "Iteration 307, loss = 1329842902.44853258\n",
            "Iteration 308, loss = 1328575981.55654740\n",
            "Iteration 309, loss = 1327301841.01973104\n",
            "Iteration 310, loss = 1326020634.46074581\n",
            "Iteration 311, loss = 1324741190.87260151\n",
            "Iteration 312, loss = 1323461741.90216899\n",
            "Iteration 313, loss = 1322170104.94571161\n",
            "Iteration 314, loss = 1320887201.87544632\n",
            "Iteration 315, loss = 1319598644.45733070\n",
            "Iteration 316, loss = 1318304623.72297502\n",
            "Iteration 317, loss = 1317018893.06493497\n",
            "Iteration 318, loss = 1315724491.62680793\n",
            "Iteration 319, loss = 1314426098.39335132\n",
            "Iteration 320, loss = 1313122846.30391073\n",
            "Iteration 321, loss = 1311826496.24165440\n",
            "Iteration 322, loss = 1310519709.56102681\n",
            "Iteration 323, loss = 1309197853.01892734\n",
            "Iteration 324, loss = 1307883516.95238972\n",
            "Iteration 325, loss = 1306573434.34700108\n",
            "Iteration 326, loss = 1305255459.20507383\n",
            "Iteration 327, loss = 1303925893.05474973\n",
            "Iteration 328, loss = 1302593638.64706516\n",
            "Iteration 329, loss = 1301281900.60531902\n",
            "Iteration 330, loss = 1299951544.40480518\n",
            "Iteration 331, loss = 1298613879.16763711\n",
            "Iteration 332, loss = 1297285519.32355809\n",
            "Iteration 333, loss = 1295949024.87856340\n",
            "Iteration 334, loss = 1294623377.90135527\n",
            "Iteration 335, loss = 1293286437.43360543\n",
            "Iteration 336, loss = 1291943840.89320517\n",
            "Iteration 337, loss = 1290621352.24161267\n",
            "Iteration 338, loss = 1289265034.50584173\n",
            "Iteration 339, loss = 1287934361.97943091\n",
            "Iteration 340, loss = 1286589000.31880236\n",
            "Iteration 341, loss = 1285235990.11697245\n",
            "Iteration 342, loss = 1283889383.27381134\n",
            "Iteration 343, loss = 1282536637.65661097\n",
            "Iteration 344, loss = 1281182800.80026770\n",
            "Iteration 345, loss = 1279840332.99730945\n",
            "Iteration 346, loss = 1278476025.46417165\n",
            "Iteration 347, loss = 1277125249.58165097\n",
            "Iteration 348, loss = 1275764771.65356493\n",
            "Iteration 349, loss = 1274401504.52803898\n",
            "Iteration 350, loss = 1273031694.33905840\n",
            "Iteration 351, loss = 1271669318.17289615\n",
            "Iteration 352, loss = 1270290117.22608924\n",
            "Iteration 353, loss = 1268917821.64866376\n",
            "Iteration 354, loss = 1267535906.97721481\n",
            "Iteration 355, loss = 1266166329.36460829\n",
            "Iteration 356, loss = 1264774141.62841606\n",
            "Iteration 357, loss = 1263403941.61583018\n",
            "Iteration 358, loss = 1262015083.67331696\n",
            "Iteration 359, loss = 1260640796.03803396\n",
            "Iteration 360, loss = 1259263009.17291355\n",
            "Iteration 361, loss = 1257869043.65953827\n",
            "Iteration 362, loss = 1256491502.61459780\n",
            "Iteration 363, loss = 1255096655.93563247\n",
            "Iteration 364, loss = 1253716863.65193772\n",
            "Iteration 365, loss = 1252317662.44917583\n",
            "Iteration 366, loss = 1250929611.49699783\n",
            "Iteration 367, loss = 1249518925.71235013\n",
            "Iteration 368, loss = 1248134995.39349031\n",
            "Iteration 369, loss = 1246729516.11064291\n",
            "Iteration 370, loss = 1245321192.00071168\n",
            "Iteration 371, loss = 1243931532.38621926\n",
            "Iteration 372, loss = 1242516026.30679536\n",
            "Iteration 373, loss = 1241110858.71419358\n",
            "Iteration 374, loss = 1239692735.61745620\n",
            "Iteration 375, loss = 1238288000.65655303\n",
            "Iteration 376, loss = 1236860111.85200644\n",
            "Iteration 377, loss = 1235455309.70283341\n",
            "Iteration 378, loss = 1234031440.19396329\n",
            "Iteration 379, loss = 1232601089.75829101\n",
            "Iteration 380, loss = 1231179806.38530397\n",
            "Iteration 381, loss = 1229756939.55947733\n",
            "Iteration 382, loss = 1228326772.41660261\n",
            "Iteration 383, loss = 1226907897.93359137\n",
            "Iteration 384, loss = 1225484275.85460830\n",
            "Iteration 385, loss = 1224063794.70567131\n",
            "Iteration 386, loss = 1222636728.59917307\n",
            "Iteration 387, loss = 1221226106.46230555\n",
            "Iteration 388, loss = 1219811246.14506030\n",
            "Iteration 389, loss = 1218382805.59051752\n",
            "Iteration 390, loss = 1216971457.60406446\n",
            "Iteration 391, loss = 1215548031.51735759\n",
            "Iteration 392, loss = 1214130909.90027165\n",
            "Iteration 393, loss = 1212693920.27362728\n",
            "Iteration 394, loss = 1211278335.08467436\n",
            "Iteration 395, loss = 1209835502.10752678\n",
            "Iteration 396, loss = 1208400089.02759719\n",
            "Iteration 397, loss = 1206976621.19049478\n",
            "Iteration 398, loss = 1205522661.69248939\n",
            "Iteration 399, loss = 1204094683.34903836\n",
            "Iteration 400, loss = 1202648820.44836068\n",
            "Iteration 401, loss = 1201211772.11286592\n",
            "Iteration 402, loss = 1199771770.41915369\n",
            "Iteration 403, loss = 1198329552.05356717\n",
            "Iteration 404, loss = 1196887339.43655324\n",
            "Iteration 405, loss = 1195431805.27582550\n",
            "Iteration 406, loss = 1193980465.33126354\n",
            "Iteration 407, loss = 1192520161.90450644\n",
            "Iteration 408, loss = 1191070480.36843753\n",
            "Iteration 409, loss = 1189615382.09680867\n",
            "Iteration 410, loss = 1188141919.89669394\n",
            "Iteration 411, loss = 1186686640.34116793\n",
            "Iteration 412, loss = 1185219144.07175279\n",
            "Iteration 413, loss = 1183758689.51281023\n",
            "Iteration 414, loss = 1182292428.63816810\n",
            "Iteration 415, loss = 1180825552.49929357\n",
            "Iteration 416, loss = 1179353039.52124739\n",
            "Iteration 417, loss = 1177885411.64435554\n",
            "Iteration 418, loss = 1176434672.13786411\n",
            "Iteration 419, loss = 1174946247.58970737\n",
            "Iteration 420, loss = 1173484183.43392920\n",
            "Iteration 421, loss = 1172014893.24197698\n",
            "Iteration 422, loss = 1170546760.16096544\n",
            "Iteration 423, loss = 1169066423.35353303\n",
            "Iteration 424, loss = 1167599893.10027289\n",
            "Iteration 425, loss = 1166122156.50908351\n",
            "Iteration 426, loss = 1164657603.20406079\n",
            "Iteration 427, loss = 1163167684.57249308\n",
            "Iteration 428, loss = 1161697172.84126687\n",
            "Iteration 429, loss = 1160218838.05174279\n",
            "Iteration 430, loss = 1158734131.17779231\n",
            "Iteration 431, loss = 1157260773.47937799\n",
            "Iteration 432, loss = 1155755400.90087438\n",
            "Iteration 433, loss = 1154292423.22828031\n",
            "Iteration 434, loss = 1152792053.38318610\n",
            "Iteration 435, loss = 1151311997.00187898\n",
            "Iteration 436, loss = 1149823181.55800438\n",
            "Iteration 437, loss = 1148345548.75104403\n",
            "Iteration 438, loss = 1146856096.14990163\n",
            "Iteration 439, loss = 1145364807.09483004\n",
            "Iteration 440, loss = 1143876146.54157686\n",
            "Iteration 441, loss = 1142379799.16086841\n",
            "Iteration 442, loss = 1140892602.44944000\n",
            "Iteration 443, loss = 1139374231.62364984\n",
            "Iteration 444, loss = 1137894062.41893101\n",
            "Iteration 445, loss = 1136377707.55210662\n",
            "Iteration 446, loss = 1134873114.67873597\n",
            "Iteration 447, loss = 1133375187.24896193\n",
            "Iteration 448, loss = 1131868472.33048916\n",
            "Iteration 449, loss = 1130356056.73199606\n",
            "Iteration 450, loss = 1128859832.80918741\n",
            "Iteration 451, loss = 1127341243.38698053\n",
            "Iteration 452, loss = 1125843957.47380018\n",
            "Iteration 453, loss = 1124336737.10814118\n",
            "Iteration 454, loss = 1122830651.68838954\n",
            "Iteration 455, loss = 1121310925.10410666\n",
            "Iteration 456, loss = 1119809190.15039372\n",
            "Iteration 457, loss = 1118304508.01373243\n",
            "Iteration 458, loss = 1116798748.46920753\n",
            "Iteration 459, loss = 1115285724.42323947\n",
            "Iteration 460, loss = 1113777874.71184945\n",
            "Iteration 461, loss = 1112274857.75951552\n",
            "Iteration 462, loss = 1110779657.61236382\n",
            "Iteration 463, loss = 1109273438.01378608\n",
            "Iteration 464, loss = 1107774441.97320724\n",
            "Iteration 465, loss = 1106285559.62445283\n",
            "Iteration 466, loss = 1104784567.85070658\n",
            "Iteration 467, loss = 1103296117.12215185\n",
            "Iteration 468, loss = 1101797048.02345395\n",
            "Iteration 469, loss = 1100309183.46529078\n",
            "Iteration 470, loss = 1098810761.94035935\n",
            "Iteration 471, loss = 1097325458.54648948\n",
            "Iteration 472, loss = 1095813686.12613988\n",
            "Iteration 473, loss = 1094321664.96081519\n",
            "Iteration 474, loss = 1092813110.96862245\n",
            "Iteration 475, loss = 1091305076.56495380\n",
            "Iteration 476, loss = 1089806607.31949496\n",
            "Iteration 477, loss = 1088290302.38252616\n",
            "Iteration 478, loss = 1086772283.01564574\n",
            "Iteration 479, loss = 1085282275.02712083\n",
            "Iteration 480, loss = 1083756048.67277408\n",
            "Iteration 481, loss = 1082254670.75748992\n",
            "Iteration 482, loss = 1080738759.50413227\n",
            "Iteration 483, loss = 1079231412.55235910\n",
            "Iteration 484, loss = 1077728069.07313371\n",
            "Iteration 485, loss = 1076219881.76344943\n",
            "Iteration 486, loss = 1074722005.83149409\n",
            "Iteration 487, loss = 1073200942.85680878\n",
            "Iteration 488, loss = 1071695686.87693942\n",
            "Iteration 489, loss = 1070191007.91686308\n",
            "Iteration 490, loss = 1068669589.03683257\n",
            "Iteration 491, loss = 1067140584.76779366\n",
            "Iteration 492, loss = 1065615920.53099895\n",
            "Iteration 493, loss = 1064085424.38947320\n",
            "Iteration 494, loss = 1062553552.00209737\n",
            "Iteration 495, loss = 1061006360.18918121\n",
            "Iteration 496, loss = 1059473587.48442590\n",
            "Iteration 497, loss = 1057947651.71710396\n",
            "Iteration 498, loss = 1056416429.19397533\n",
            "Iteration 499, loss = 1054878013.34134388\n",
            "Iteration 500, loss = 1053376046.50223541\n",
            "Iteration 501, loss = 1051838144.73818326\n",
            "Iteration 502, loss = 1050303162.60347497\n",
            "Iteration 503, loss = 1048787759.07420623\n",
            "Iteration 504, loss = 1047260713.86111021\n",
            "Iteration 505, loss = 1045738541.22999513\n",
            "Iteration 506, loss = 1044201852.08481920\n",
            "Iteration 507, loss = 1042668011.75035787\n",
            "Iteration 508, loss = 1041138521.37265646\n",
            "Iteration 509, loss = 1039597007.93657899\n",
            "Iteration 510, loss = 1038059439.18433857\n",
            "Iteration 511, loss = 1036518560.08653283\n",
            "Iteration 512, loss = 1034979180.57679760\n",
            "Iteration 513, loss = 1033436479.89800858\n",
            "Iteration 514, loss = 1031885530.56772971\n",
            "Iteration 515, loss = 1030355506.16475093\n",
            "Iteration 516, loss = 1028801481.44530988\n",
            "Iteration 517, loss = 1027274729.58727634\n",
            "Iteration 518, loss = 1025719210.12934804\n",
            "Iteration 519, loss = 1024189122.07600093\n",
            "Iteration 520, loss = 1022660334.23108757\n",
            "Iteration 521, loss = 1021123590.40583074\n",
            "Iteration 522, loss = 1019603539.37745392\n",
            "Iteration 523, loss = 1018077719.99251354\n",
            "Iteration 524, loss = 1016549381.27134407\n",
            "Iteration 525, loss = 1015037361.45441449\n",
            "Iteration 526, loss = 1013508651.88568819\n",
            "Iteration 527, loss = 1011994679.90280330\n",
            "Iteration 528, loss = 1010463877.73845887\n",
            "Iteration 529, loss = 1008943104.29698586\n",
            "Iteration 530, loss = 1007416488.24699831\n",
            "Iteration 531, loss = 1005889772.74935031\n",
            "Iteration 532, loss = 1004358745.67982328\n",
            "Iteration 533, loss = 1002831341.27528512\n",
            "Iteration 534, loss = 1001301801.66177154\n",
            "Iteration 535, loss = 999767529.48840952\n",
            "Iteration 536, loss = 998246894.42704070\n",
            "Iteration 537, loss = 996718382.63868618\n",
            "Iteration 538, loss = 995182422.79057384\n",
            "Iteration 539, loss = 993673639.62952733\n",
            "Iteration 540, loss = 992144548.30164850\n",
            "Iteration 541, loss = 990610399.48910117\n",
            "Iteration 542, loss = 989104183.16143548\n",
            "Iteration 543, loss = 987576018.14775848\n",
            "Iteration 544, loss = 986049393.38842356\n",
            "Iteration 545, loss = 984520186.77762389\n",
            "Iteration 546, loss = 983003703.64059615\n",
            "Iteration 547, loss = 981476772.80988443\n",
            "Iteration 548, loss = 979942664.69457543\n",
            "Iteration 549, loss = 978413777.25184000\n",
            "Iteration 550, loss = 976867111.56748092\n",
            "Iteration 551, loss = 975326202.06253016\n",
            "Iteration 552, loss = 973799333.24586368\n",
            "Iteration 553, loss = 972244116.00580537\n",
            "Iteration 554, loss = 970705014.96543920\n",
            "Iteration 555, loss = 969168425.45908701\n",
            "Iteration 556, loss = 967641478.03153133\n",
            "Iteration 557, loss = 966118693.61282003\n",
            "Iteration 558, loss = 964581813.55494702\n",
            "Iteration 559, loss = 963079036.03857839\n",
            "Iteration 560, loss = 961555165.27957904\n",
            "Iteration 561, loss = 960044231.03581464\n",
            "Iteration 562, loss = 958530446.50329447\n",
            "Iteration 563, loss = 957011909.52270794\n",
            "Iteration 564, loss = 955499829.78389490\n",
            "Iteration 565, loss = 953980467.80242932\n",
            "Iteration 566, loss = 952481002.99036825\n",
            "Iteration 567, loss = 950960344.32070410\n",
            "Iteration 568, loss = 949451093.50166035\n",
            "Iteration 569, loss = 947924734.79442310\n",
            "Iteration 570, loss = 946421624.46553159\n",
            "Iteration 571, loss = 944895348.51375735\n",
            "Iteration 572, loss = 943376976.06000292\n",
            "Iteration 573, loss = 941850399.46033740\n",
            "Iteration 574, loss = 940317254.01089811\n",
            "Iteration 575, loss = 938796779.85002267\n",
            "Iteration 576, loss = 937262570.23771179\n",
            "Iteration 577, loss = 935732321.76423979\n",
            "Iteration 578, loss = 934207958.98226833\n",
            "Iteration 579, loss = 932685454.14315760\n",
            "Iteration 580, loss = 931174693.94851410\n",
            "Iteration 581, loss = 929651809.27389824\n",
            "Iteration 582, loss = 928140684.15664756\n",
            "Iteration 583, loss = 926621189.93014944\n",
            "Iteration 584, loss = 925123367.29818392\n",
            "Iteration 585, loss = 923605107.58480585\n",
            "Iteration 586, loss = 922091972.07190204\n",
            "Iteration 587, loss = 920582105.50998914\n",
            "Iteration 588, loss = 919063822.52737772\n",
            "Iteration 589, loss = 917536281.72431588\n",
            "Iteration 590, loss = 916027356.69897509\n",
            "Iteration 591, loss = 914497633.40719521\n",
            "Iteration 592, loss = 912984398.89793050\n",
            "Iteration 593, loss = 911468531.77683437\n",
            "Iteration 594, loss = 909957353.94878733\n",
            "Iteration 595, loss = 908433011.04678822\n",
            "Iteration 596, loss = 906927300.01644266\n",
            "Iteration 597, loss = 905432642.79606164\n",
            "Iteration 598, loss = 903907902.93838370\n",
            "Iteration 599, loss = 902419415.45039439\n",
            "Iteration 600, loss = 900900238.05295563\n",
            "Iteration 601, loss = 899399223.34902072\n",
            "Iteration 602, loss = 897884989.98782289\n",
            "Iteration 603, loss = 896406134.12345946\n",
            "Iteration 604, loss = 894895472.39684880\n",
            "Iteration 605, loss = 893414935.18812537\n",
            "Iteration 606, loss = 891912785.32669032\n",
            "Iteration 607, loss = 890419695.46686375\n",
            "Iteration 608, loss = 888924558.28316855\n",
            "Iteration 609, loss = 887432547.80836403\n",
            "Iteration 610, loss = 885930689.10719848\n",
            "Iteration 611, loss = 884440286.55049169\n",
            "Iteration 612, loss = 882947100.51284611\n",
            "Iteration 613, loss = 881456827.91159558\n",
            "Iteration 614, loss = 879972835.47271132\n",
            "Iteration 615, loss = 878506209.59671783\n",
            "Iteration 616, loss = 877006156.25007594\n",
            "Iteration 617, loss = 875541106.56670427\n",
            "Iteration 618, loss = 874073506.89954972\n",
            "Iteration 619, loss = 872594694.92531335\n",
            "Iteration 620, loss = 871111804.71032369\n",
            "Iteration 621, loss = 869644979.95498192\n",
            "Iteration 622, loss = 868168765.88346219\n",
            "Iteration 623, loss = 866663064.10826206\n",
            "Iteration 624, loss = 865201409.26130140\n",
            "Iteration 625, loss = 863715004.98683834\n",
            "Iteration 626, loss = 862235363.32212055\n",
            "Iteration 627, loss = 860744154.84133661\n",
            "Iteration 628, loss = 859275302.77464545\n",
            "Iteration 629, loss = 857809152.57519853\n",
            "Iteration 630, loss = 856337048.54542613\n",
            "Iteration 631, loss = 854866980.98317981\n",
            "Iteration 632, loss = 853397097.22446525\n",
            "Iteration 633, loss = 851953566.10697377\n",
            "Iteration 634, loss = 850477867.41081417\n",
            "Iteration 635, loss = 849029599.16445351\n",
            "Iteration 636, loss = 847563293.57658494\n",
            "Iteration 637, loss = 846106225.15378213\n",
            "Iteration 638, loss = 844654609.68127251\n",
            "Iteration 639, loss = 843193546.85049832\n",
            "Iteration 640, loss = 841739706.45190477\n",
            "Iteration 641, loss = 840267686.15112770\n",
            "Iteration 642, loss = 838823794.81648517\n",
            "Iteration 643, loss = 837366669.59908891\n",
            "Iteration 644, loss = 835895047.09247863\n",
            "Iteration 645, loss = 834449839.60935330\n",
            "Iteration 646, loss = 832986623.23113990\n",
            "Iteration 647, loss = 831520264.10779774\n",
            "Iteration 648, loss = 830082040.89010179\n",
            "Iteration 649, loss = 828611434.50532782\n",
            "Iteration 650, loss = 827161031.49149632\n",
            "Iteration 651, loss = 825712374.74166977\n",
            "Iteration 652, loss = 824264693.69491708\n",
            "Iteration 653, loss = 822813551.21757579\n",
            "Iteration 654, loss = 821381152.74732757\n",
            "Iteration 655, loss = 819934666.77900910\n",
            "Iteration 656, loss = 818480518.39500308\n",
            "Iteration 657, loss = 817039482.03093326\n",
            "Iteration 658, loss = 815594091.49512708\n",
            "Iteration 659, loss = 814163211.10576427\n",
            "Iteration 660, loss = 812708743.57317567\n",
            "Iteration 661, loss = 811241864.40109026\n",
            "Iteration 662, loss = 809825708.66087306\n",
            "Iteration 663, loss = 808371055.96817684\n",
            "Iteration 664, loss = 806926283.92164516\n",
            "Iteration 665, loss = 805496713.62889957\n",
            "Iteration 666, loss = 804062357.86996818\n",
            "Iteration 667, loss = 802632362.32101107\n",
            "Iteration 668, loss = 801192643.75503063\n",
            "Iteration 669, loss = 799780295.83938897\n",
            "Iteration 670, loss = 798330931.91607738\n",
            "Iteration 671, loss = 796913072.24096072\n",
            "Iteration 672, loss = 795475612.27124476\n",
            "Iteration 673, loss = 794058709.22353327\n",
            "Iteration 674, loss = 792611950.94445944\n",
            "Iteration 675, loss = 791201394.16071975\n",
            "Iteration 676, loss = 789777003.30856752\n",
            "Iteration 677, loss = 788342374.15853000\n",
            "Iteration 678, loss = 786910617.63291371\n",
            "Iteration 679, loss = 785484971.39955866\n",
            "Iteration 680, loss = 784080900.52981925\n",
            "Iteration 681, loss = 782629024.65658855\n",
            "Iteration 682, loss = 781199723.89999390\n",
            "Iteration 683, loss = 779758785.64453125\n",
            "Iteration 684, loss = 778359709.97317445\n",
            "Iteration 685, loss = 776892367.87807775\n",
            "Iteration 686, loss = 775492789.42967093\n",
            "Iteration 687, loss = 774067227.67675102\n",
            "Iteration 688, loss = 772632416.89367735\n",
            "Iteration 689, loss = 771216260.06882334\n",
            "Iteration 690, loss = 769807900.90162194\n",
            "Iteration 691, loss = 768390816.40014303\n",
            "Iteration 692, loss = 766972109.32548463\n",
            "Iteration 693, loss = 765572859.21428657\n",
            "Iteration 694, loss = 764157399.30132556\n",
            "Iteration 695, loss = 762738439.27397954\n",
            "Iteration 696, loss = 761354080.45075417\n",
            "Iteration 697, loss = 759954095.25151503\n",
            "Iteration 698, loss = 758523239.97029185\n",
            "Iteration 699, loss = 757137933.19493365\n",
            "Iteration 700, loss = 755743655.93221498\n",
            "Iteration 701, loss = 754349352.43923092\n",
            "Iteration 702, loss = 752925968.64100707\n",
            "Iteration 703, loss = 751544249.36281300\n",
            "Iteration 704, loss = 750155274.07602680\n",
            "Iteration 705, loss = 748761048.34201229\n",
            "Iteration 706, loss = 747383823.90269279\n",
            "Iteration 707, loss = 745992134.50278187\n",
            "Iteration 708, loss = 744596083.87670410\n",
            "Iteration 709, loss = 743218284.95239377\n",
            "Iteration 710, loss = 741825238.28300881\n",
            "Iteration 711, loss = 740436052.17111814\n",
            "Iteration 712, loss = 739074591.14757931\n",
            "Iteration 713, loss = 737666920.62390637\n",
            "Iteration 714, loss = 736279786.18096817\n",
            "Iteration 715, loss = 734894830.93093729\n",
            "Iteration 716, loss = 733510895.39976013\n",
            "Iteration 717, loss = 732117494.90598714\n",
            "Iteration 718, loss = 730722985.29441547\n",
            "Iteration 719, loss = 729328496.50064778\n",
            "Iteration 720, loss = 727939522.40944934\n",
            "Iteration 721, loss = 726572951.59829938\n",
            "Iteration 722, loss = 725183783.06551003\n",
            "Iteration 723, loss = 723792706.52351236\n",
            "Iteration 724, loss = 722409763.82976818\n",
            "Iteration 725, loss = 721031073.69200075\n",
            "Iteration 726, loss = 719662198.29633057\n",
            "Iteration 727, loss = 718273149.05984974\n",
            "Iteration 728, loss = 716870372.24626541\n",
            "Iteration 729, loss = 715525890.03793812\n",
            "Iteration 730, loss = 714132078.25869691\n",
            "Iteration 731, loss = 712774164.55452728\n",
            "Iteration 732, loss = 711385888.08010101\n",
            "Iteration 733, loss = 710041063.43087637\n",
            "Iteration 734, loss = 708665136.51793027\n",
            "Iteration 735, loss = 707329577.73706448\n",
            "Iteration 736, loss = 705964993.10485351\n",
            "Iteration 737, loss = 704611359.46693337\n",
            "Iteration 738, loss = 703264993.06361032\n",
            "Iteration 739, loss = 701908264.61470091\n",
            "Iteration 740, loss = 700588331.90764570\n",
            "Iteration 741, loss = 699230660.79779994\n",
            "Iteration 742, loss = 697893738.11989093\n",
            "Iteration 743, loss = 696543695.13005102\n",
            "Iteration 744, loss = 695211354.89200485\n",
            "Iteration 745, loss = 693867755.38948798\n",
            "Iteration 746, loss = 692507236.82467353\n",
            "Iteration 747, loss = 691162691.74780202\n",
            "Iteration 748, loss = 689817456.20341682\n",
            "Iteration 749, loss = 688472835.83079672\n",
            "Iteration 750, loss = 687108984.39268601\n",
            "Iteration 751, loss = 685759964.44588172\n",
            "Iteration 752, loss = 684414445.85601413\n",
            "Iteration 753, loss = 683075536.92651200\n",
            "Iteration 754, loss = 681752370.68945360\n",
            "Iteration 755, loss = 680410239.35870171\n",
            "Iteration 756, loss = 679103865.57493782\n",
            "Iteration 757, loss = 677766986.13572109\n",
            "Iteration 758, loss = 676460579.62043595\n",
            "Iteration 759, loss = 675133266.59814537\n",
            "Iteration 760, loss = 673828044.90935981\n",
            "Iteration 761, loss = 672504903.47793591\n",
            "Iteration 762, loss = 671205855.66284299\n",
            "Iteration 763, loss = 669887058.63925159\n",
            "Iteration 764, loss = 668586057.38043368\n",
            "Iteration 765, loss = 667302314.20338154\n",
            "Iteration 766, loss = 665988386.68801904\n",
            "Iteration 767, loss = 664720131.90996492\n",
            "Iteration 768, loss = 663437611.28270698\n",
            "Iteration 769, loss = 662150557.27947497\n",
            "Iteration 770, loss = 660876947.06976414\n",
            "Iteration 771, loss = 659592493.71560967\n",
            "Iteration 772, loss = 658312724.15517974\n",
            "Iteration 773, loss = 657025043.80417204\n",
            "Iteration 774, loss = 655748336.12771237\n",
            "Iteration 775, loss = 654464722.17576480\n",
            "Iteration 776, loss = 653176620.12729430\n",
            "Iteration 777, loss = 651910828.23258257\n",
            "Iteration 778, loss = 650640053.51926970\n",
            "Iteration 779, loss = 649335038.65071011\n",
            "Iteration 780, loss = 648070964.13132572\n",
            "Iteration 781, loss = 646812950.56789589\n",
            "Iteration 782, loss = 645516300.07120740\n",
            "Iteration 783, loss = 644252085.43646562\n",
            "Iteration 784, loss = 642988063.21080184\n",
            "Iteration 785, loss = 641699867.82322240\n",
            "Iteration 786, loss = 640440913.79621911\n",
            "Iteration 787, loss = 639178739.60484266\n",
            "Iteration 788, loss = 637913944.69352186\n",
            "Iteration 789, loss = 636625920.01058888\n",
            "Iteration 790, loss = 635364697.35094047\n",
            "Iteration 791, loss = 634102220.12277627\n",
            "Iteration 792, loss = 632803478.39681327\n",
            "Iteration 793, loss = 631526118.10353124\n",
            "Iteration 794, loss = 630226578.70850337\n",
            "Iteration 795, loss = 628966328.77094936\n",
            "Iteration 796, loss = 627658429.29719353\n",
            "Iteration 797, loss = 626390357.42426801\n",
            "Iteration 798, loss = 625122376.03251779\n",
            "Iteration 799, loss = 623830591.07783103\n",
            "Iteration 800, loss = 622560975.80983925\n",
            "Iteration 801, loss = 621313044.35555768\n",
            "Iteration 802, loss = 620029959.20729792\n",
            "Iteration 803, loss = 618778611.62218595\n",
            "Iteration 804, loss = 617500564.48162854\n",
            "Iteration 805, loss = 616264705.75782824\n",
            "Iteration 806, loss = 614993368.66112649\n",
            "Iteration 807, loss = 613759164.85924828\n",
            "Iteration 808, loss = 612491879.70370722\n",
            "Iteration 809, loss = 611258698.78482294\n",
            "Iteration 810, loss = 610014160.17749560\n",
            "Iteration 811, loss = 608771850.70996296\n",
            "Iteration 812, loss = 607548888.71053922\n",
            "Iteration 813, loss = 606300737.44906676\n",
            "Iteration 814, loss = 605095977.12852335\n",
            "Iteration 815, loss = 603873992.12505651\n",
            "Iteration 816, loss = 602631149.27229893\n",
            "Iteration 817, loss = 601416635.21805108\n",
            "Iteration 818, loss = 600158105.27194786\n",
            "Iteration 819, loss = 598947611.56505609\n",
            "Iteration 820, loss = 597708626.24610305\n",
            "Iteration 821, loss = 596440785.70860350\n",
            "Iteration 822, loss = 595204390.83928776\n",
            "Iteration 823, loss = 593977492.11413527\n",
            "Iteration 824, loss = 592743538.20540369\n",
            "Iteration 825, loss = 591529330.00530112\n",
            "Iteration 826, loss = 590300105.81051803\n",
            "Iteration 827, loss = 589066900.16138887\n",
            "Iteration 828, loss = 587886365.75722218\n",
            "Iteration 829, loss = 586655050.06353056\n",
            "Iteration 830, loss = 585446565.47695780\n",
            "Iteration 831, loss = 584246317.23305976\n",
            "Iteration 832, loss = 583053607.85725009\n",
            "Iteration 833, loss = 581858337.83477485\n",
            "Iteration 834, loss = 580657701.56922746\n",
            "Iteration 835, loss = 579471788.06496644\n",
            "Iteration 836, loss = 578273786.69015324\n",
            "Iteration 837, loss = 577097647.12616134\n",
            "Iteration 838, loss = 575893222.77345681\n",
            "Iteration 839, loss = 574699619.15297627\n",
            "Iteration 840, loss = 573487510.63704956\n",
            "Iteration 841, loss = 572308842.26749182\n",
            "Iteration 842, loss = 571106655.35483408\n",
            "Iteration 843, loss = 569924250.81148434\n",
            "Iteration 844, loss = 568702854.01741612\n",
            "Iteration 845, loss = 567507505.38175511\n",
            "Iteration 846, loss = 566323188.88413358\n",
            "Iteration 847, loss = 565132269.93113136\n",
            "Iteration 848, loss = 563931756.04687524\n",
            "Iteration 849, loss = 562741270.05249918\n",
            "Iteration 850, loss = 561557663.40583169\n",
            "Iteration 851, loss = 560370076.50361097\n",
            "Iteration 852, loss = 559171321.48384428\n",
            "Iteration 853, loss = 558013752.60089219\n",
            "Iteration 854, loss = 556835137.97625732\n",
            "Iteration 855, loss = 555649755.57192421\n",
            "Iteration 856, loss = 554500230.14351547\n",
            "Iteration 857, loss = 553315974.11620903\n",
            "Iteration 858, loss = 552159534.52591765\n",
            "Iteration 859, loss = 551006507.55385506\n",
            "Iteration 860, loss = 549852148.74890745\n",
            "Iteration 861, loss = 548687599.55762041\n",
            "Iteration 862, loss = 547543871.57562244\n",
            "Iteration 863, loss = 546384141.59226871\n",
            "Iteration 864, loss = 545235568.00037134\n",
            "Iteration 865, loss = 544079576.81978893\n",
            "Iteration 866, loss = 542923097.45461559\n",
            "Iteration 867, loss = 541774399.84281754\n",
            "Iteration 868, loss = 540611471.10315049\n",
            "Iteration 869, loss = 539458927.02665257\n",
            "Iteration 870, loss = 538316316.31229913\n",
            "Iteration 871, loss = 537165606.51224566\n",
            "Iteration 872, loss = 536010278.62170708\n",
            "Iteration 873, loss = 534869339.08416951\n",
            "Iteration 874, loss = 533743555.50303304\n",
            "Iteration 875, loss = 532594593.76714987\n",
            "Iteration 876, loss = 531451881.76173377\n",
            "Iteration 877, loss = 530334159.76709509\n",
            "Iteration 878, loss = 529209192.43343312\n",
            "Iteration 879, loss = 528061248.52907407\n",
            "Iteration 880, loss = 526955882.57845402\n",
            "Iteration 881, loss = 525823161.20810723\n",
            "Iteration 882, loss = 524710805.61280191\n",
            "Iteration 883, loss = 523586452.71701735\n",
            "Iteration 884, loss = 522467456.11829454\n",
            "Iteration 885, loss = 521343893.71822935\n",
            "Iteration 886, loss = 520233750.88352209\n",
            "Iteration 887, loss = 519116274.82986593\n",
            "Iteration 888, loss = 517991288.45799839\n",
            "Iteration 889, loss = 516896805.96784711\n",
            "Iteration 890, loss = 515769389.48558086\n",
            "Iteration 891, loss = 514663558.23967904\n",
            "Iteration 892, loss = 513550791.59320384\n",
            "Iteration 893, loss = 512438223.93780178\n",
            "Iteration 894, loss = 511329616.14756769\n",
            "Iteration 895, loss = 510213821.03355491\n",
            "Iteration 896, loss = 509101474.09777433\n",
            "Iteration 897, loss = 507988017.10869801\n",
            "Iteration 898, loss = 506897149.83060277\n",
            "Iteration 899, loss = 505781873.37929130\n",
            "Iteration 900, loss = 504684267.23805308\n",
            "Iteration 901, loss = 503592806.86016101\n",
            "Iteration 902, loss = 502512136.82279587\n",
            "Iteration 903, loss = 501402197.20941103\n",
            "Iteration 904, loss = 500346856.44198650\n",
            "Iteration 905, loss = 499250871.66771978\n",
            "Iteration 906, loss = 498175841.04753852\n",
            "Iteration 907, loss = 497111773.06840873\n",
            "Iteration 908, loss = 496042573.53687358\n",
            "Iteration 909, loss = 494958758.83964789\n",
            "Iteration 910, loss = 493889747.77611589\n",
            "Iteration 911, loss = 492815564.53797400\n",
            "Iteration 912, loss = 491750479.87615311\n",
            "Iteration 913, loss = 490662644.27642661\n",
            "Iteration 914, loss = 489590612.41718501\n",
            "Iteration 915, loss = 488515736.15537214\n",
            "Iteration 916, loss = 487460050.97438323\n",
            "Iteration 917, loss = 486362994.98618025\n",
            "Iteration 918, loss = 485312061.29535073\n",
            "Iteration 919, loss = 484227599.55133486\n",
            "Iteration 920, loss = 483155871.56022257\n",
            "Iteration 921, loss = 482089070.74162006\n",
            "Iteration 922, loss = 481032251.25604492\n",
            "Iteration 923, loss = 479949832.43711728\n",
            "Iteration 924, loss = 478910292.68849921\n",
            "Iteration 925, loss = 477859078.60156435\n",
            "Iteration 926, loss = 476793575.65409714\n",
            "Iteration 927, loss = 475762637.78446436\n",
            "Iteration 928, loss = 474716450.40515125\n",
            "Iteration 929, loss = 473671682.50646126\n",
            "Iteration 930, loss = 472651573.67364609\n",
            "Iteration 931, loss = 471602327.94633847\n",
            "Iteration 932, loss = 470601770.85245329\n",
            "Iteration 933, loss = 469568285.57121700\n",
            "Iteration 934, loss = 468560347.05899906\n",
            "Iteration 935, loss = 467544763.81852943\n",
            "Iteration 936, loss = 466557862.54989272\n",
            "Iteration 937, loss = 465539551.12782502\n",
            "Iteration 938, loss = 464525787.87652922\n",
            "Iteration 939, loss = 463523892.79719245\n",
            "Iteration 940, loss = 462490243.22412974\n",
            "Iteration 941, loss = 461469870.84559697\n",
            "Iteration 942, loss = 460462918.98711687\n",
            "Iteration 943, loss = 459403845.49348342\n",
            "Iteration 944, loss = 458391717.53312057\n",
            "Iteration 945, loss = 457348241.96166384\n",
            "Iteration 946, loss = 456331465.94797993\n",
            "Iteration 947, loss = 455305168.85465997\n",
            "Iteration 948, loss = 454295799.96799439\n",
            "Iteration 949, loss = 453268419.01752782\n",
            "Iteration 950, loss = 452247679.00186682\n",
            "Iteration 951, loss = 451260145.39816087\n",
            "Iteration 952, loss = 450247968.02190334\n",
            "Iteration 953, loss = 449234689.48248923\n",
            "Iteration 954, loss = 448238336.96498233\n",
            "Iteration 955, loss = 447229169.83850473\n",
            "Iteration 956, loss = 446243212.48123890\n",
            "Iteration 957, loss = 445240868.23040164\n",
            "Iteration 958, loss = 444243761.00813591\n",
            "Iteration 959, loss = 443255883.06065345\n",
            "Iteration 960, loss = 442260271.24660343\n",
            "Iteration 961, loss = 441292355.11495304\n",
            "Iteration 962, loss = 440284572.29272115\n",
            "Iteration 963, loss = 439297796.80822998\n",
            "Iteration 964, loss = 438320280.35723913\n",
            "Iteration 965, loss = 437304157.17325133\n",
            "Iteration 966, loss = 436319998.97413653\n",
            "Iteration 967, loss = 435320793.18961215\n",
            "Iteration 968, loss = 434297035.27533358\n",
            "Iteration 969, loss = 433318414.49008793\n",
            "Iteration 970, loss = 432328276.35462534\n",
            "Iteration 971, loss = 431333713.81450301\n",
            "Iteration 972, loss = 430340188.89791077\n",
            "Iteration 973, loss = 429355425.42740357\n",
            "Iteration 974, loss = 428355932.67190248\n",
            "Iteration 975, loss = 427380986.85490912\n",
            "Iteration 976, loss = 426401183.29142028\n",
            "Iteration 977, loss = 425403335.39570832\n",
            "Iteration 978, loss = 424443646.88659519\n",
            "Iteration 979, loss = 423446418.43506420\n",
            "Iteration 980, loss = 422479503.67215198\n",
            "Iteration 981, loss = 421518283.21144658\n",
            "Iteration 982, loss = 420555564.58263224\n",
            "Iteration 983, loss = 419575849.57553595\n",
            "Iteration 984, loss = 418623027.48128849\n",
            "Iteration 985, loss = 417653648.62834728\n",
            "Iteration 986, loss = 416692955.61645120\n",
            "Iteration 987, loss = 415747702.10810703\n",
            "Iteration 988, loss = 414780298.22960782\n",
            "Iteration 989, loss = 413830392.17223686\n",
            "Iteration 990, loss = 412899444.01621383\n",
            "Iteration 991, loss = 411938470.73828769\n",
            "Iteration 992, loss = 411002153.49881792\n",
            "Iteration 993, loss = 410047689.91489190\n",
            "Iteration 994, loss = 409104520.43935943\n",
            "Iteration 995, loss = 408164043.98108888\n",
            "Iteration 996, loss = 407204691.18788689\n",
            "Iteration 997, loss = 406284418.57763696\n",
            "Iteration 998, loss = 405325110.88358158\n",
            "Iteration 999, loss = 404396064.45322001\n",
            "Iteration 1000, loss = 403453065.21638072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 52763728601.18246460\n",
            "Iteration 2, loss = 69145131474528193327031107116363621326230544261444535469014614160785092378624.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50,), relu, 0.01, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538839189.98264623\n",
            "Iteration 2, loss = 1538818044.99110556\n",
            "Iteration 3, loss = 1538796049.79180932\n",
            "Iteration 4, loss = 1538772596.11294365\n",
            "Iteration 5, loss = 1538747766.75212979\n",
            "Iteration 6, loss = 1538721386.16695261\n",
            "Iteration 7, loss = 1538693375.19377208\n",
            "Iteration 8, loss = 1538662355.84327483\n",
            "Iteration 9, loss = 1538629111.73619246\n",
            "Iteration 10, loss = 1538593348.49782252\n",
            "Iteration 11, loss = 1538553603.04925013\n",
            "Iteration 12, loss = 1538511241.55949211\n",
            "Iteration 13, loss = 1538464901.32127738\n",
            "Iteration 14, loss = 1538414693.13258600\n",
            "Iteration 15, loss = 1538360225.87312579\n",
            "Iteration 16, loss = 1538301824.50983143\n",
            "Iteration 17, loss = 1538238519.92222023\n",
            "Iteration 18, loss = 1538170252.21534204\n",
            "Iteration 19, loss = 1538097496.95747066\n",
            "Iteration 20, loss = 1538019189.86375403\n",
            "Iteration 21, loss = 1537936141.91745019\n",
            "Iteration 22, loss = 1537847669.31234431\n",
            "Iteration 23, loss = 1537753413.55031967\n",
            "Iteration 24, loss = 1537653617.17292643\n",
            "Iteration 25, loss = 1537547943.89342523\n",
            "Iteration 26, loss = 1537436106.02114511\n",
            "Iteration 27, loss = 1537318996.56354690\n",
            "Iteration 28, loss = 1537195028.60693192\n",
            "Iteration 29, loss = 1537064374.89917350\n",
            "Iteration 30, loss = 1536928000.79680896\n",
            "Iteration 31, loss = 1536785182.48057723\n",
            "Iteration 32, loss = 1536635174.04602981\n",
            "Iteration 33, loss = 1536477825.96244407\n",
            "Iteration 34, loss = 1536315608.38938069\n",
            "Iteration 35, loss = 1536143597.71446466\n",
            "Iteration 36, loss = 1535966091.71301699\n",
            "Iteration 37, loss = 1535781146.05928469\n",
            "Iteration 38, loss = 1535589050.54749846\n",
            "Iteration 39, loss = 1535388272.95605230\n",
            "Iteration 40, loss = 1535179910.69445229\n",
            "Iteration 41, loss = 1534963788.94073510\n",
            "Iteration 42, loss = 1534742151.37052679\n",
            "Iteration 43, loss = 1534510089.42882419\n",
            "Iteration 44, loss = 1534272033.02287388\n",
            "Iteration 45, loss = 1534023658.16260505\n",
            "Iteration 46, loss = 1533772780.45809436\n",
            "Iteration 47, loss = 1533507757.53686094\n",
            "Iteration 48, loss = 1533238751.38805079\n",
            "Iteration 49, loss = 1532962722.13441277\n",
            "Iteration 50, loss = 1532678185.65658236\n",
            "Iteration 51, loss = 1532385523.84692812\n",
            "Iteration 52, loss = 1532085346.50188518\n",
            "Iteration 53, loss = 1531778525.27592993\n",
            "Iteration 54, loss = 1531460588.00108862\n",
            "Iteration 55, loss = 1531138402.12266898\n",
            "Iteration 56, loss = 1530807906.23152852\n",
            "Iteration 57, loss = 1530467781.91504908\n",
            "Iteration 58, loss = 1530120009.92974687\n",
            "Iteration 59, loss = 1529764016.50835347\n",
            "Iteration 60, loss = 1529403110.02588344\n",
            "Iteration 61, loss = 1529031819.39621925\n",
            "Iteration 62, loss = 1528652911.88168716\n",
            "Iteration 63, loss = 1528270149.24283576\n",
            "Iteration 64, loss = 1527876413.21871305\n",
            "Iteration 65, loss = 1527474400.38961387\n",
            "Iteration 66, loss = 1527066377.57078624\n",
            "Iteration 67, loss = 1526648519.33885837\n",
            "Iteration 68, loss = 1526228883.77409482\n",
            "Iteration 69, loss = 1525794713.87335610\n",
            "Iteration 70, loss = 1525352435.48110271\n",
            "Iteration 71, loss = 1524906453.28979135\n",
            "Iteration 72, loss = 1524450382.16696978\n",
            "Iteration 73, loss = 1523986795.73976707\n",
            "Iteration 74, loss = 1523517600.00360203\n",
            "Iteration 75, loss = 1523038301.26528335\n",
            "Iteration 76, loss = 1522549262.64496732\n",
            "Iteration 77, loss = 1522052383.40292788\n",
            "Iteration 78, loss = 1521550713.47430205\n",
            "Iteration 79, loss = 1521035942.98615885\n",
            "Iteration 80, loss = 1520518867.83504653\n",
            "Iteration 81, loss = 1519990533.85401273\n",
            "Iteration 82, loss = 1519453234.01350904\n",
            "Iteration 83, loss = 1518908685.17369366\n",
            "Iteration 84, loss = 1518360089.50669575\n",
            "Iteration 85, loss = 1517797955.15647101\n",
            "Iteration 86, loss = 1517234201.64443254\n",
            "Iteration 87, loss = 1516660902.94248104\n",
            "Iteration 88, loss = 1516076940.27663398\n",
            "Iteration 89, loss = 1515489644.92246485\n",
            "Iteration 90, loss = 1514891923.08327770\n",
            "Iteration 91, loss = 1514288435.55399013\n",
            "Iteration 92, loss = 1513673361.67176461\n",
            "Iteration 93, loss = 1513053482.63277316\n",
            "Iteration 94, loss = 1512427507.78285933\n",
            "Iteration 95, loss = 1511789256.61755013\n",
            "Iteration 96, loss = 1511146203.48958802\n",
            "Iteration 97, loss = 1510498786.82256484\n",
            "Iteration 98, loss = 1509835814.66144943\n",
            "Iteration 99, loss = 1509176205.60486531\n",
            "Iteration 100, loss = 1508506329.32123065\n",
            "Iteration 101, loss = 1507824976.96894360\n",
            "Iteration 102, loss = 1507144623.15427947\n",
            "Iteration 103, loss = 1506452883.53548265\n",
            "Iteration 104, loss = 1505748460.25168276\n",
            "Iteration 105, loss = 1505049054.09872079\n",
            "Iteration 106, loss = 1504337207.94219923\n",
            "Iteration 107, loss = 1503615612.39234090\n",
            "Iteration 108, loss = 1502886781.25663853\n",
            "Iteration 109, loss = 1502150437.62685847\n",
            "Iteration 110, loss = 1501410501.98984623\n",
            "Iteration 111, loss = 1500666181.79743409\n",
            "Iteration 112, loss = 1499901362.34863853\n",
            "Iteration 113, loss = 1499140792.72658801\n",
            "Iteration 114, loss = 1498370471.80732656\n",
            "Iteration 115, loss = 1497594208.76577330\n",
            "Iteration 116, loss = 1496804795.50529122\n",
            "Iteration 117, loss = 1496014764.64566493\n",
            "Iteration 118, loss = 1495224696.10761690\n",
            "Iteration 119, loss = 1494417633.73001051\n",
            "Iteration 120, loss = 1493607996.10688376\n",
            "Iteration 121, loss = 1492788775.77621961\n",
            "Iteration 122, loss = 1491967544.88494062\n",
            "Iteration 123, loss = 1491133909.99724507\n",
            "Iteration 124, loss = 1490300771.75554729\n",
            "Iteration 125, loss = 1489449052.12232518\n",
            "Iteration 126, loss = 1488597551.22080779\n",
            "Iteration 127, loss = 1487733028.07296538\n",
            "Iteration 128, loss = 1486868321.37795591\n",
            "Iteration 129, loss = 1486000140.25799370\n",
            "Iteration 130, loss = 1485112716.66509914\n",
            "Iteration 131, loss = 1484230580.32039762\n",
            "Iteration 132, loss = 1483338654.97450233\n",
            "Iteration 133, loss = 1482437507.69030523\n",
            "Iteration 134, loss = 1481532256.09304690\n",
            "Iteration 135, loss = 1480620161.89887500\n",
            "Iteration 136, loss = 1479708777.83372784\n",
            "Iteration 137, loss = 1478782737.81501198\n",
            "Iteration 138, loss = 1477851691.35783386\n",
            "Iteration 139, loss = 1476917970.28657579\n",
            "Iteration 140, loss = 1475977103.62482285\n",
            "Iteration 141, loss = 1475031244.54995012\n",
            "Iteration 142, loss = 1474075311.81181765\n",
            "Iteration 143, loss = 1473113600.91159368\n",
            "Iteration 144, loss = 1472144661.76902747\n",
            "Iteration 145, loss = 1471176307.10346794\n",
            "Iteration 146, loss = 1470189527.70230842\n",
            "Iteration 147, loss = 1469201133.17736387\n",
            "Iteration 148, loss = 1468202996.82506728\n",
            "Iteration 149, loss = 1467199529.57103729\n",
            "Iteration 150, loss = 1466189656.28888106\n",
            "Iteration 151, loss = 1465169084.09151101\n",
            "Iteration 152, loss = 1464144712.65573502\n",
            "Iteration 153, loss = 1463113047.61922169\n",
            "Iteration 154, loss = 1462069558.72278857\n",
            "Iteration 155, loss = 1461035347.56263590\n",
            "Iteration 156, loss = 1459983209.15160775\n",
            "Iteration 157, loss = 1458927236.29634070\n",
            "Iteration 158, loss = 1457864726.23808289\n",
            "Iteration 159, loss = 1456799494.43766069\n",
            "Iteration 160, loss = 1455721803.46598244\n",
            "Iteration 161, loss = 1454648734.63179731\n",
            "Iteration 162, loss = 1453558436.00045371\n",
            "Iteration 163, loss = 1452468428.72482491\n",
            "Iteration 164, loss = 1451373474.47114205\n",
            "Iteration 165, loss = 1450270769.90809178\n",
            "Iteration 166, loss = 1449164362.34169936\n",
            "Iteration 167, loss = 1448053314.72234988\n",
            "Iteration 168, loss = 1446934490.34577370\n",
            "Iteration 169, loss = 1445804509.92604995\n",
            "Iteration 170, loss = 1444680181.56379294\n",
            "Iteration 171, loss = 1443545042.93177080\n",
            "Iteration 172, loss = 1442401435.09918761\n",
            "Iteration 173, loss = 1441245939.15920210\n",
            "Iteration 174, loss = 1440090856.98049164\n",
            "Iteration 175, loss = 1438926509.38814855\n",
            "Iteration 176, loss = 1437762193.23595548\n",
            "Iteration 177, loss = 1436583302.67380190\n",
            "Iteration 178, loss = 1435398077.37499142\n",
            "Iteration 179, loss = 1434215273.79891801\n",
            "Iteration 180, loss = 1433011417.44424987\n",
            "Iteration 181, loss = 1431823159.11551023\n",
            "Iteration 182, loss = 1430611416.45623302\n",
            "Iteration 183, loss = 1429402598.28259492\n",
            "Iteration 184, loss = 1428189329.33011866\n",
            "Iteration 185, loss = 1426972102.62894392\n",
            "Iteration 186, loss = 1425741056.16378045\n",
            "Iteration 187, loss = 1424519353.58055329\n",
            "Iteration 188, loss = 1423277844.03210926\n",
            "Iteration 189, loss = 1422034534.09244084\n",
            "Iteration 190, loss = 1420794731.86818671\n",
            "Iteration 191, loss = 1419544392.73576450\n",
            "Iteration 192, loss = 1418274653.00707459\n",
            "Iteration 193, loss = 1417022432.71129799\n",
            "Iteration 194, loss = 1415756984.81314182\n",
            "Iteration 195, loss = 1414481213.79575777\n",
            "Iteration 196, loss = 1413211637.83651423\n",
            "Iteration 197, loss = 1411932700.93752265\n",
            "Iteration 198, loss = 1410652758.48388004\n",
            "Iteration 199, loss = 1409360700.75145507\n",
            "Iteration 200, loss = 1408071311.48307753\n",
            "Iteration 201, loss = 1406767491.82393408\n",
            "Iteration 202, loss = 1405462115.71157217\n",
            "Iteration 203, loss = 1404152844.72109890\n",
            "Iteration 204, loss = 1402833785.58926105\n",
            "Iteration 205, loss = 1401518226.98490381\n",
            "Iteration 206, loss = 1400191014.69399452\n",
            "Iteration 207, loss = 1398862093.49774218\n",
            "Iteration 208, loss = 1397522390.64458656\n",
            "Iteration 209, loss = 1396184624.94769073\n",
            "Iteration 210, loss = 1394834993.19560361\n",
            "Iteration 211, loss = 1393481692.64476657\n",
            "Iteration 212, loss = 1392118905.89783382\n",
            "Iteration 213, loss = 1390745793.35280633\n",
            "Iteration 214, loss = 1389374726.36121726\n",
            "Iteration 215, loss = 1387997502.38501549\n",
            "Iteration 216, loss = 1386618155.10231709\n",
            "Iteration 217, loss = 1385230902.85585237\n",
            "Iteration 218, loss = 1383838757.18011999\n",
            "Iteration 219, loss = 1382449749.88603711\n",
            "Iteration 220, loss = 1381057824.51199365\n",
            "Iteration 221, loss = 1379653759.45086074\n",
            "Iteration 222, loss = 1378244940.02031112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 223, loss = 1376837185.84322834\n",
            "Iteration 224, loss = 1375418558.16447210\n",
            "Iteration 225, loss = 1373996584.68336892\n",
            "Iteration 226, loss = 1372568666.34840608\n",
            "Iteration 227, loss = 1371136410.42806005\n",
            "Iteration 228, loss = 1369701972.57178140\n",
            "Iteration 229, loss = 1368261629.44369078\n",
            "Iteration 230, loss = 1366814991.99540353\n",
            "Iteration 231, loss = 1365372863.82046676\n",
            "Iteration 232, loss = 1363921055.86779261\n",
            "Iteration 233, loss = 1362475999.51537824\n",
            "Iteration 234, loss = 1361017393.28477836\n",
            "Iteration 235, loss = 1359563770.69573665\n",
            "Iteration 236, loss = 1358089991.77736688\n",
            "Iteration 237, loss = 1356630589.30752015\n",
            "Iteration 238, loss = 1355168783.17054629\n",
            "Iteration 239, loss = 1353678495.93664098\n",
            "Iteration 240, loss = 1352202983.03872156\n",
            "Iteration 241, loss = 1350725512.76181936\n",
            "Iteration 242, loss = 1349227613.80890274\n",
            "Iteration 243, loss = 1347740194.93806529\n",
            "Iteration 244, loss = 1346239444.82919168\n",
            "Iteration 245, loss = 1344733678.39805627\n",
            "Iteration 246, loss = 1343239404.53333521\n",
            "Iteration 247, loss = 1341722960.92283535\n",
            "Iteration 248, loss = 1340205977.98321295\n",
            "Iteration 249, loss = 1338684940.25792265\n",
            "Iteration 250, loss = 1337172851.58837771\n",
            "Iteration 251, loss = 1335639625.04272079\n",
            "Iteration 252, loss = 1334107862.84951353\n",
            "Iteration 253, loss = 1332574608.05713081\n",
            "Iteration 254, loss = 1331033425.12047362\n",
            "Iteration 255, loss = 1329485819.07927275\n",
            "Iteration 256, loss = 1327946886.68463564\n",
            "Iteration 257, loss = 1326399832.85121584\n",
            "Iteration 258, loss = 1324864039.30780983\n",
            "Iteration 259, loss = 1323307632.83666492\n",
            "Iteration 260, loss = 1321752436.59997654\n",
            "Iteration 261, loss = 1320206993.10827327\n",
            "Iteration 262, loss = 1318649754.06129956\n",
            "Iteration 263, loss = 1317092009.25047994\n",
            "Iteration 264, loss = 1315522257.32746696\n",
            "Iteration 265, loss = 1313947502.23046613\n",
            "Iteration 266, loss = 1312373848.29109931\n",
            "Iteration 267, loss = 1310785138.94526672\n",
            "Iteration 268, loss = 1309207954.02771330\n",
            "Iteration 269, loss = 1307617583.88766766\n",
            "Iteration 270, loss = 1306022711.49604034\n",
            "Iteration 271, loss = 1304429433.51261425\n",
            "Iteration 272, loss = 1302829394.65369010\n",
            "Iteration 273, loss = 1301215042.22014332\n",
            "Iteration 274, loss = 1299611861.53229642\n",
            "Iteration 275, loss = 1298003670.43411660\n",
            "Iteration 276, loss = 1296369242.12769961\n",
            "Iteration 277, loss = 1294773986.93150544\n",
            "Iteration 278, loss = 1293143333.43257713\n",
            "Iteration 279, loss = 1291507007.06238604\n",
            "Iteration 280, loss = 1289895413.45841742\n",
            "Iteration 281, loss = 1288259095.72486115\n",
            "Iteration 282, loss = 1286629771.84830141\n",
            "Iteration 283, loss = 1284983882.20351791\n",
            "Iteration 284, loss = 1283341780.88626575\n",
            "Iteration 285, loss = 1281689139.89463234\n",
            "Iteration 286, loss = 1280054622.16322565\n",
            "Iteration 287, loss = 1278391711.99563694\n",
            "Iteration 288, loss = 1276730914.31390882\n",
            "Iteration 289, loss = 1275069426.24216366\n",
            "Iteration 290, loss = 1273409194.05279946\n",
            "Iteration 291, loss = 1271740156.19882822\n",
            "Iteration 292, loss = 1270078457.18487096\n",
            "Iteration 293, loss = 1268403331.60138226\n",
            "Iteration 294, loss = 1266742592.36602068\n",
            "Iteration 295, loss = 1265069777.26626992\n",
            "Iteration 296, loss = 1263393243.67776704\n",
            "Iteration 297, loss = 1261717966.25068045\n",
            "Iteration 298, loss = 1260047431.60773993\n",
            "Iteration 299, loss = 1258348925.76703906\n",
            "Iteration 300, loss = 1256655926.26490712\n",
            "Iteration 301, loss = 1254955929.17939544\n",
            "Iteration 302, loss = 1253260890.40576291\n",
            "Iteration 303, loss = 1251557941.87620807\n",
            "Iteration 304, loss = 1249843328.61078835\n",
            "Iteration 305, loss = 1248132324.00381184\n",
            "Iteration 306, loss = 1246430417.33124804\n",
            "Iteration 307, loss = 1244709958.46614981\n",
            "Iteration 308, loss = 1242991495.57799816\n",
            "Iteration 309, loss = 1241305164.27151084\n",
            "Iteration 310, loss = 1239573133.92449021\n",
            "Iteration 311, loss = 1237856808.00357294\n",
            "Iteration 312, loss = 1236153681.05202842\n",
            "Iteration 313, loss = 1234430293.60099936\n",
            "Iteration 314, loss = 1232720314.94729590\n",
            "Iteration 315, loss = 1231003999.76163125\n",
            "Iteration 316, loss = 1229276356.76747370\n",
            "Iteration 317, loss = 1227558538.17677283\n",
            "Iteration 318, loss = 1225834667.73704910\n",
            "Iteration 319, loss = 1224104101.61082220\n",
            "Iteration 320, loss = 1222373825.38525152\n",
            "Iteration 321, loss = 1220646691.76394367\n",
            "Iteration 322, loss = 1218911436.20737386\n",
            "Iteration 323, loss = 1217176937.15448475\n",
            "Iteration 324, loss = 1215432533.05440021\n",
            "Iteration 325, loss = 1213702926.44045854\n",
            "Iteration 326, loss = 1211953639.43985772\n",
            "Iteration 327, loss = 1210201654.98272038\n",
            "Iteration 328, loss = 1208449467.77193046\n",
            "Iteration 329, loss = 1206708786.38915133\n",
            "Iteration 330, loss = 1204944579.76467109\n",
            "Iteration 331, loss = 1203172401.11808348\n",
            "Iteration 332, loss = 1201410814.01357865\n",
            "Iteration 333, loss = 1199658993.02188301\n",
            "Iteration 334, loss = 1197890872.15408206\n",
            "Iteration 335, loss = 1196103889.05417466\n",
            "Iteration 336, loss = 1194354047.05265284\n",
            "Iteration 337, loss = 1192585598.07539558\n",
            "Iteration 338, loss = 1190801883.92283201\n",
            "Iteration 339, loss = 1189041281.90815067\n",
            "Iteration 340, loss = 1187244520.63568449\n",
            "Iteration 341, loss = 1185457274.27862930\n",
            "Iteration 342, loss = 1183696250.69780469\n",
            "Iteration 343, loss = 1181880609.20731378\n",
            "Iteration 344, loss = 1180110754.05844164\n",
            "Iteration 345, loss = 1178303800.17331386\n",
            "Iteration 346, loss = 1176526451.54675269\n",
            "Iteration 347, loss = 1174749790.09059882\n",
            "Iteration 348, loss = 1172955598.27551723\n",
            "Iteration 349, loss = 1171173979.87485051\n",
            "Iteration 350, loss = 1169385081.10310388\n",
            "Iteration 351, loss = 1167598585.57324362\n",
            "Iteration 352, loss = 1165806527.15183687\n",
            "Iteration 353, loss = 1164007040.86481261\n",
            "Iteration 354, loss = 1162207777.80389810\n",
            "Iteration 355, loss = 1160408153.10020709\n",
            "Iteration 356, loss = 1158600395.41394615\n",
            "Iteration 357, loss = 1156786561.88453460\n",
            "Iteration 358, loss = 1154982777.55214548\n",
            "Iteration 359, loss = 1153171602.40006304\n",
            "Iteration 360, loss = 1151340611.48064947\n",
            "Iteration 361, loss = 1149540024.20279717\n",
            "Iteration 362, loss = 1147729170.09946442\n",
            "Iteration 363, loss = 1145897747.67244935\n",
            "Iteration 364, loss = 1144062082.68457365\n",
            "Iteration 365, loss = 1142267065.10068941\n",
            "Iteration 366, loss = 1140436482.39826155\n",
            "Iteration 367, loss = 1138603861.68734908\n",
            "Iteration 368, loss = 1136778844.59576201\n",
            "Iteration 369, loss = 1134947942.42294049\n",
            "Iteration 370, loss = 1133135867.13140392\n",
            "Iteration 371, loss = 1131296211.69444919\n",
            "Iteration 372, loss = 1129462921.52730680\n",
            "Iteration 373, loss = 1127656398.43686652\n",
            "Iteration 374, loss = 1125816292.94711041\n",
            "Iteration 375, loss = 1123995483.94699931\n",
            "Iteration 376, loss = 1122156452.05457735\n",
            "Iteration 377, loss = 1120328577.85771799\n",
            "Iteration 378, loss = 1118475537.26664186\n",
            "Iteration 379, loss = 1116663145.96241355\n",
            "Iteration 380, loss = 1114802766.30698895\n",
            "Iteration 381, loss = 1112971102.07145238\n",
            "Iteration 382, loss = 1111118467.88203478\n",
            "Iteration 383, loss = 1109296809.01410961\n",
            "Iteration 384, loss = 1107447548.22675061\n",
            "Iteration 385, loss = 1105622427.35817313\n",
            "Iteration 386, loss = 1103780853.22825074\n",
            "Iteration 387, loss = 1101959892.86434436\n",
            "Iteration 388, loss = 1100134031.29663086\n",
            "Iteration 389, loss = 1098285381.99599266\n",
            "Iteration 390, loss = 1096463323.03288746\n",
            "Iteration 391, loss = 1094632986.74296784\n",
            "Iteration 392, loss = 1092807320.06063771\n",
            "Iteration 393, loss = 1090968347.40279174\n",
            "Iteration 394, loss = 1089150077.62842464\n",
            "Iteration 395, loss = 1087295021.24369168\n",
            "Iteration 396, loss = 1085504725.38467264\n",
            "Iteration 397, loss = 1083650140.88120270\n",
            "Iteration 398, loss = 1081833265.23179555\n",
            "Iteration 399, loss = 1079987035.72804809\n",
            "Iteration 400, loss = 1078155169.19457889\n",
            "Iteration 401, loss = 1076310430.43799162\n",
            "Iteration 402, loss = 1074466048.26155353\n",
            "Iteration 403, loss = 1072627781.79779732\n",
            "Iteration 404, loss = 1070778911.86839747\n",
            "Iteration 405, loss = 1068929404.05052972\n",
            "Iteration 406, loss = 1067072213.20188284\n",
            "Iteration 407, loss = 1065236959.41943216\n",
            "Iteration 408, loss = 1063374443.39760780\n",
            "Iteration 409, loss = 1061519508.11867571\n",
            "Iteration 410, loss = 1059671492.17547512\n",
            "Iteration 411, loss = 1057804828.21726227\n",
            "Iteration 412, loss = 1055939164.04263318\n",
            "Iteration 413, loss = 1054079275.90020001\n",
            "Iteration 414, loss = 1052241542.76104295\n",
            "Iteration 415, loss = 1050369144.99130273\n",
            "Iteration 416, loss = 1048514874.17526793\n",
            "Iteration 417, loss = 1046656235.19439626\n",
            "Iteration 418, loss = 1044803841.73087358\n",
            "Iteration 419, loss = 1042941775.58542776\n",
            "Iteration 420, loss = 1041072433.69113147\n",
            "Iteration 421, loss = 1039211492.91387796\n",
            "Iteration 422, loss = 1037359838.52966547\n",
            "Iteration 423, loss = 1035462480.30499315\n",
            "Iteration 424, loss = 1033604415.73469961\n",
            "Iteration 425, loss = 1031727838.39048326\n",
            "Iteration 426, loss = 1029872599.16982508\n",
            "Iteration 427, loss = 1027982129.12874401\n",
            "Iteration 428, loss = 1026136161.46265519\n",
            "Iteration 429, loss = 1024256829.20207477\n",
            "Iteration 430, loss = 1022392141.60653722\n",
            "Iteration 431, loss = 1020546265.74041605\n",
            "Iteration 432, loss = 1018690219.87548411\n",
            "Iteration 433, loss = 1016825544.16748309\n",
            "Iteration 434, loss = 1014974145.95494390\n",
            "Iteration 435, loss = 1013124290.31201077\n",
            "Iteration 436, loss = 1011268436.09980249\n",
            "Iteration 437, loss = 1009434848.11236155\n",
            "Iteration 438, loss = 1007581165.74501538\n",
            "Iteration 439, loss = 1005743898.05114627\n",
            "Iteration 440, loss = 1003889237.35879922\n",
            "Iteration 441, loss = 1002059302.80513620\n",
            "Iteration 442, loss = 1000205668.04223442\n",
            "Iteration 443, loss = 998364694.65642834\n",
            "Iteration 444, loss = 996530604.17633748\n",
            "Iteration 445, loss = 994688149.54884684\n",
            "Iteration 446, loss = 992833409.71086478\n",
            "Iteration 447, loss = 990998500.35701263\n",
            "Iteration 448, loss = 989159468.06620431\n",
            "Iteration 449, loss = 987325663.87481844\n",
            "Iteration 450, loss = 985488556.99516940\n",
            "Iteration 451, loss = 983648346.86873662\n",
            "Iteration 452, loss = 981821395.76619053\n",
            "Iteration 453, loss = 979994581.80233800\n",
            "Iteration 454, loss = 978157512.64185369\n",
            "Iteration 455, loss = 976329007.74345565\n",
            "Iteration 456, loss = 974488140.77097785\n",
            "Iteration 457, loss = 972663164.30279469\n",
            "Iteration 458, loss = 970811687.43561566\n",
            "Iteration 459, loss = 968973860.14702380\n",
            "Iteration 460, loss = 967134424.11876273\n",
            "Iteration 461, loss = 965300833.17254806\n",
            "Iteration 462, loss = 963441723.33914816\n",
            "Iteration 463, loss = 961610955.25028861\n",
            "Iteration 464, loss = 959778913.72313654\n",
            "Iteration 465, loss = 957926822.62990141\n",
            "Iteration 466, loss = 956097939.31767094\n",
            "Iteration 467, loss = 954263065.13901246\n",
            "Iteration 468, loss = 952433110.61073458\n",
            "Iteration 469, loss = 950600075.83363283\n",
            "Iteration 470, loss = 948760545.97169018\n",
            "Iteration 471, loss = 946926618.91123295\n",
            "Iteration 472, loss = 945107649.34181702\n",
            "Iteration 473, loss = 943279287.64404273\n",
            "Iteration 474, loss = 941453671.00818801\n",
            "Iteration 475, loss = 939627841.76405251\n",
            "Iteration 476, loss = 937806110.37419415\n",
            "Iteration 477, loss = 935983750.34957075\n",
            "Iteration 478, loss = 934199202.00340402\n",
            "Iteration 479, loss = 932364380.69039357\n",
            "Iteration 480, loss = 930552331.24045157\n",
            "Iteration 481, loss = 928745564.32750762\n",
            "Iteration 482, loss = 926927238.84013307\n",
            "Iteration 483, loss = 925120200.49900568\n",
            "Iteration 484, loss = 923297153.03560543\n",
            "Iteration 485, loss = 921457968.48557425\n",
            "Iteration 486, loss = 919649843.78681922\n",
            "Iteration 487, loss = 917796929.16837943\n",
            "Iteration 488, loss = 915983623.93706810\n",
            "Iteration 489, loss = 914149390.56315148\n",
            "Iteration 490, loss = 912320914.96669817\n",
            "Iteration 491, loss = 910485290.62429547\n",
            "Iteration 492, loss = 908661439.05150259\n",
            "Iteration 493, loss = 906875360.74124014\n",
            "Iteration 494, loss = 905022809.12580001\n",
            "Iteration 495, loss = 903231955.95817339\n",
            "Iteration 496, loss = 901422979.31771731\n",
            "Iteration 497, loss = 899630062.67246270\n",
            "Iteration 498, loss = 897822750.78427100\n",
            "Iteration 499, loss = 896028579.73980486\n",
            "Iteration 500, loss = 894254933.18320107\n",
            "Iteration 501, loss = 892452755.74465084\n",
            "Iteration 502, loss = 890694070.74436581\n",
            "Iteration 503, loss = 888912601.83969247\n",
            "Iteration 504, loss = 887119915.47045469\n",
            "Iteration 505, loss = 885382264.88829219\n",
            "Iteration 506, loss = 883599263.46596992\n",
            "Iteration 507, loss = 881811367.79366338\n",
            "Iteration 508, loss = 880067846.32393110\n",
            "Iteration 509, loss = 878276562.23685098\n",
            "Iteration 510, loss = 876509714.70541441\n",
            "Iteration 511, loss = 874709795.32669151\n",
            "Iteration 512, loss = 872950827.73451996\n",
            "Iteration 513, loss = 871168353.23671377\n",
            "Iteration 514, loss = 869404027.02530646\n",
            "Iteration 515, loss = 867605537.49699891\n",
            "Iteration 516, loss = 865844673.16402769\n",
            "Iteration 517, loss = 864072568.28503466\n",
            "Iteration 518, loss = 862303576.90922153\n",
            "Iteration 519, loss = 860536316.86213017\n",
            "Iteration 520, loss = 858752726.46559501\n",
            "Iteration 521, loss = 856992303.39716673\n",
            "Iteration 522, loss = 855223915.05093229\n",
            "Iteration 523, loss = 853433462.03529894\n",
            "Iteration 524, loss = 851672236.45994031\n",
            "Iteration 525, loss = 849931904.24075341\n",
            "Iteration 526, loss = 848128454.93326437\n",
            "Iteration 527, loss = 846354314.27113664\n",
            "Iteration 528, loss = 844623885.70515549\n",
            "Iteration 529, loss = 842835555.80158293\n",
            "Iteration 530, loss = 841084297.45343447\n",
            "Iteration 531, loss = 839326880.55007434\n",
            "Iteration 532, loss = 837571489.71696508\n",
            "Iteration 533, loss = 835829368.15101242\n",
            "Iteration 534, loss = 834078678.77876186\n",
            "Iteration 535, loss = 832335576.75713408\n",
            "Iteration 536, loss = 830591705.78707218\n",
            "Iteration 537, loss = 828833384.93551624\n",
            "Iteration 538, loss = 827099454.17309237\n",
            "Iteration 539, loss = 825340100.33364165\n",
            "Iteration 540, loss = 823569613.15949416\n",
            "Iteration 541, loss = 821839273.02944911\n",
            "Iteration 542, loss = 820087463.16008675\n",
            "Iteration 543, loss = 818337870.54935920\n",
            "Iteration 544, loss = 816590417.98719597\n",
            "Iteration 545, loss = 814860969.51674330\n",
            "Iteration 546, loss = 813132694.03549862\n",
            "Iteration 547, loss = 811398776.89754522\n",
            "Iteration 548, loss = 809703893.05894423\n",
            "Iteration 549, loss = 807955206.44745314\n",
            "Iteration 550, loss = 806259792.22434938\n",
            "Iteration 551, loss = 804528662.92184114\n",
            "Iteration 552, loss = 802788434.71611345\n",
            "Iteration 553, loss = 801060594.65005481\n",
            "Iteration 554, loss = 799347584.62246895\n",
            "Iteration 555, loss = 797603172.91242135\n",
            "Iteration 556, loss = 795852946.72458816\n",
            "Iteration 557, loss = 794146615.00075042\n",
            "Iteration 558, loss = 792406879.01558435\n",
            "Iteration 559, loss = 790660278.45635140\n",
            "Iteration 560, loss = 788955097.79469776\n",
            "Iteration 561, loss = 787220418.53892732\n",
            "Iteration 562, loss = 785492609.98738289\n",
            "Iteration 563, loss = 783772478.28547823\n",
            "Iteration 564, loss = 782033798.44382477\n",
            "Iteration 565, loss = 780316069.68319893\n",
            "Iteration 566, loss = 778606641.54978657\n",
            "Iteration 567, loss = 776886045.88111377\n",
            "Iteration 568, loss = 775168124.42880094\n",
            "Iteration 569, loss = 773470865.44379532\n",
            "Iteration 570, loss = 771736854.20781934\n",
            "Iteration 571, loss = 770045366.14912426\n",
            "Iteration 572, loss = 768350797.75002778\n",
            "Iteration 573, loss = 766632704.18623590\n",
            "Iteration 574, loss = 764955288.38391745\n",
            "Iteration 575, loss = 763254195.19328082\n",
            "Iteration 576, loss = 761555358.09387922\n",
            "Iteration 577, loss = 759875288.63637590\n",
            "Iteration 578, loss = 758182983.70050490\n",
            "Iteration 579, loss = 756505753.96887982\n",
            "Iteration 580, loss = 754813161.68904829\n",
            "Iteration 581, loss = 753146090.23499584\n",
            "Iteration 582, loss = 751478822.90229535\n",
            "Iteration 583, loss = 749779106.78072762\n",
            "Iteration 584, loss = 748130002.45466971\n",
            "Iteration 585, loss = 746445226.22164488\n",
            "Iteration 586, loss = 744755043.01731062\n",
            "Iteration 587, loss = 743075242.29735744\n",
            "Iteration 588, loss = 741430497.03986907\n",
            "Iteration 589, loss = 739708948.92067707\n",
            "Iteration 590, loss = 738066626.95031786\n",
            "Iteration 591, loss = 736381581.61879957\n",
            "Iteration 592, loss = 734736010.59602678\n",
            "Iteration 593, loss = 733072646.71004891\n",
            "Iteration 594, loss = 731417983.60140574\n",
            "Iteration 595, loss = 729794644.21191061\n",
            "Iteration 596, loss = 728116398.43268168\n",
            "Iteration 597, loss = 726508194.62337172\n",
            "Iteration 598, loss = 724813592.63937831\n",
            "Iteration 599, loss = 723192714.67008531\n",
            "Iteration 600, loss = 721554682.86238587\n",
            "Iteration 601, loss = 719901419.26839030\n",
            "Iteration 602, loss = 718281311.53573656\n",
            "Iteration 603, loss = 716653667.84904253\n",
            "Iteration 604, loss = 715016459.85550654\n",
            "Iteration 605, loss = 713437717.67214119\n",
            "Iteration 606, loss = 711815446.48516834\n",
            "Iteration 607, loss = 710208250.18151224\n",
            "Iteration 608, loss = 708599077.46851254\n",
            "Iteration 609, loss = 707021462.54188931\n",
            "Iteration 610, loss = 705412985.47857046\n",
            "Iteration 611, loss = 703807614.60487950\n",
            "Iteration 612, loss = 702173356.46672177\n",
            "Iteration 613, loss = 700609321.56845522\n",
            "Iteration 614, loss = 699000914.70045936\n",
            "Iteration 615, loss = 697371166.72095370\n",
            "Iteration 616, loss = 695787263.67037988\n",
            "Iteration 617, loss = 694196232.21280301\n",
            "Iteration 618, loss = 692598699.79010797\n",
            "Iteration 619, loss = 691008171.14192522\n",
            "Iteration 620, loss = 689404187.69402790\n",
            "Iteration 621, loss = 687803459.63104999\n",
            "Iteration 622, loss = 686224430.95671248\n",
            "Iteration 623, loss = 684639662.76695621\n",
            "Iteration 624, loss = 683025985.18932498\n",
            "Iteration 625, loss = 681438757.15798473\n",
            "Iteration 626, loss = 679861057.46722686\n",
            "Iteration 627, loss = 678259411.78865552\n",
            "Iteration 628, loss = 676686144.39551771\n",
            "Iteration 629, loss = 675074310.44019651\n",
            "Iteration 630, loss = 673526787.31804633\n",
            "Iteration 631, loss = 671901509.42337787\n",
            "Iteration 632, loss = 670343827.95557809\n",
            "Iteration 633, loss = 668767859.44484258\n",
            "Iteration 634, loss = 667171856.01596642\n",
            "Iteration 635, loss = 665629473.54462087\n",
            "Iteration 636, loss = 664037168.26803386\n",
            "Iteration 637, loss = 662481207.26130986\n",
            "Iteration 638, loss = 660939194.72993767\n",
            "Iteration 639, loss = 659388686.01242149\n",
            "Iteration 640, loss = 657839030.86598611\n",
            "Iteration 641, loss = 656318018.21881986\n",
            "Iteration 642, loss = 654798455.45228410\n",
            "Iteration 643, loss = 653261118.36619556\n",
            "Iteration 644, loss = 651745482.72753930\n",
            "Iteration 645, loss = 650233571.57637000\n",
            "Iteration 646, loss = 648715399.01982355\n",
            "Iteration 647, loss = 647184616.98515213\n",
            "Iteration 648, loss = 645666976.17805755\n",
            "Iteration 649, loss = 644178707.50974154\n",
            "Iteration 650, loss = 642656462.26126790\n",
            "Iteration 651, loss = 641149026.38290083\n",
            "Iteration 652, loss = 639634081.24284256\n",
            "Iteration 653, loss = 638129482.80803859\n",
            "Iteration 654, loss = 636621818.60721421\n",
            "Iteration 655, loss = 635087165.45829356\n",
            "Iteration 656, loss = 633602136.24424875\n",
            "Iteration 657, loss = 632082483.53267145\n",
            "Iteration 658, loss = 630543661.67952526\n",
            "Iteration 659, loss = 629057678.26169479\n",
            "Iteration 660, loss = 627535156.38976693\n",
            "Iteration 661, loss = 625987825.98700666\n",
            "Iteration 662, loss = 624480305.10642648\n",
            "Iteration 663, loss = 622978078.02463114\n",
            "Iteration 664, loss = 621442255.50358522\n",
            "Iteration 665, loss = 619912856.39325690\n",
            "Iteration 666, loss = 618399793.24584115\n",
            "Iteration 667, loss = 616904699.97983408\n",
            "Iteration 668, loss = 615397855.23251235\n",
            "Iteration 669, loss = 613863013.88302243\n",
            "Iteration 670, loss = 612390092.10092318\n",
            "Iteration 671, loss = 610895033.75396991\n",
            "Iteration 672, loss = 609415607.50737596\n",
            "Iteration 673, loss = 607921652.80229282\n",
            "Iteration 674, loss = 606416847.14038277\n",
            "Iteration 675, loss = 604915858.74255526\n",
            "Iteration 676, loss = 603428762.36257124\n",
            "Iteration 677, loss = 601955222.25610316\n",
            "Iteration 678, loss = 600457405.69638169\n",
            "Iteration 679, loss = 598954422.55104601\n",
            "Iteration 680, loss = 597486800.25718665\n",
            "Iteration 681, loss = 596029271.25672281\n",
            "Iteration 682, loss = 594531601.78589869\n",
            "Iteration 683, loss = 593070621.41908717\n",
            "Iteration 684, loss = 591611613.42789364\n",
            "Iteration 685, loss = 590150039.46277738\n",
            "Iteration 686, loss = 588673304.59916985\n",
            "Iteration 687, loss = 587229568.04046178\n",
            "Iteration 688, loss = 585774403.92038250\n",
            "Iteration 689, loss = 584293855.44626129\n",
            "Iteration 690, loss = 582859111.46865904\n",
            "Iteration 691, loss = 581402459.00731564\n",
            "Iteration 692, loss = 579968998.09506869\n",
            "Iteration 693, loss = 578535860.59905994\n",
            "Iteration 694, loss = 577101319.18724406\n",
            "Iteration 695, loss = 575652407.39154947\n",
            "Iteration 696, loss = 574269033.95507061\n",
            "Iteration 697, loss = 572828085.48363137\n",
            "Iteration 698, loss = 571398070.80102992\n",
            "Iteration 699, loss = 569975938.10316896\n",
            "Iteration 700, loss = 568570691.19371343\n",
            "Iteration 701, loss = 567174559.17638183\n",
            "Iteration 702, loss = 565757711.11952388\n",
            "Iteration 703, loss = 564336037.47822273\n",
            "Iteration 704, loss = 562959029.49779701\n",
            "Iteration 705, loss = 561562753.36247349\n",
            "Iteration 706, loss = 560152996.81316233\n",
            "Iteration 707, loss = 558766492.22143233\n",
            "Iteration 708, loss = 557370736.50752974\n",
            "Iteration 709, loss = 555991360.44178975\n",
            "Iteration 710, loss = 554608492.97617638\n",
            "Iteration 711, loss = 553233807.37142515\n",
            "Iteration 712, loss = 551846403.51253343\n",
            "Iteration 713, loss = 550493252.95914555\n",
            "Iteration 714, loss = 549121421.70588481\n",
            "Iteration 715, loss = 547769440.39100194\n",
            "Iteration 716, loss = 546417575.62127674\n",
            "Iteration 717, loss = 545067112.20199502\n",
            "Iteration 718, loss = 543708207.56203413\n",
            "Iteration 719, loss = 542368787.36678326\n",
            "Iteration 720, loss = 541037682.78242421\n",
            "Iteration 721, loss = 539671993.19469357\n",
            "Iteration 722, loss = 538318002.44790423\n",
            "Iteration 723, loss = 536957877.61022592\n",
            "Iteration 724, loss = 535621168.21929139\n",
            "Iteration 725, loss = 534254866.92654145\n",
            "Iteration 726, loss = 532884003.78760540\n",
            "Iteration 727, loss = 531540480.52254462\n",
            "Iteration 728, loss = 530175902.03127855\n",
            "Iteration 729, loss = 528826178.81637365\n",
            "Iteration 730, loss = 527469421.92874163\n",
            "Iteration 731, loss = 526116531.47307676\n",
            "Iteration 732, loss = 524763559.79273796\n",
            "Iteration 733, loss = 523430386.28926408\n",
            "Iteration 734, loss = 522102896.40755010\n",
            "Iteration 735, loss = 520734509.54296148\n",
            "Iteration 736, loss = 519404449.17346400\n",
            "Iteration 737, loss = 518057456.96106154\n",
            "Iteration 738, loss = 516736071.45643383\n",
            "Iteration 739, loss = 515360960.31117350\n",
            "Iteration 740, loss = 514045187.91367775\n",
            "Iteration 741, loss = 512700020.30152440\n",
            "Iteration 742, loss = 511360127.02287054\n",
            "Iteration 743, loss = 510044708.43400741\n",
            "Iteration 744, loss = 508711371.76052219\n",
            "Iteration 745, loss = 507379385.64970732\n",
            "Iteration 746, loss = 506053046.88940853\n",
            "Iteration 747, loss = 504729207.17549163\n",
            "Iteration 748, loss = 503396260.05035120\n",
            "Iteration 749, loss = 502052419.51916575\n",
            "Iteration 750, loss = 500726810.46758437\n",
            "Iteration 751, loss = 499410706.01863813\n",
            "Iteration 752, loss = 498105945.89973253\n",
            "Iteration 753, loss = 496759936.53307778\n",
            "Iteration 754, loss = 495457984.08977288\n",
            "Iteration 755, loss = 494159580.35861599\n",
            "Iteration 756, loss = 492850232.60357183\n",
            "Iteration 757, loss = 491546072.82376051\n",
            "Iteration 758, loss = 490235333.89190841\n",
            "Iteration 759, loss = 488950713.17487693\n",
            "Iteration 760, loss = 487665475.01728886\n",
            "Iteration 761, loss = 486399790.67307848\n",
            "Iteration 762, loss = 485109148.85940188\n",
            "Iteration 763, loss = 483852132.14450401\n",
            "Iteration 764, loss = 482595739.40132779\n",
            "Iteration 765, loss = 481350187.35983056\n",
            "Iteration 766, loss = 480102099.09214920\n",
            "Iteration 767, loss = 478846481.99717766\n",
            "Iteration 768, loss = 477584905.78708994\n",
            "Iteration 769, loss = 476340117.32849795\n",
            "Iteration 770, loss = 475103757.95611513\n",
            "Iteration 771, loss = 473835915.14470404\n",
            "Iteration 772, loss = 472601664.13516212\n",
            "Iteration 773, loss = 471344833.72623330\n",
            "Iteration 774, loss = 470100552.78619391\n",
            "Iteration 775, loss = 468874913.32992315\n",
            "Iteration 776, loss = 467607196.24760705\n",
            "Iteration 777, loss = 466360130.89131737\n",
            "Iteration 778, loss = 465131596.83423144\n",
            "Iteration 779, loss = 463856785.26308411\n",
            "Iteration 780, loss = 462630580.17096299\n",
            "Iteration 781, loss = 461375195.41776460\n",
            "Iteration 782, loss = 460128058.88080013\n",
            "Iteration 783, loss = 458907024.29084444\n",
            "Iteration 784, loss = 457672319.00825751\n",
            "Iteration 785, loss = 456434443.22427982\n",
            "Iteration 786, loss = 455178298.46975881\n",
            "Iteration 787, loss = 453982528.92198431\n",
            "Iteration 788, loss = 452739617.36378980\n",
            "Iteration 789, loss = 451524118.95906657\n",
            "Iteration 790, loss = 450301664.17583376\n",
            "Iteration 791, loss = 449078415.29544252\n",
            "Iteration 792, loss = 447893406.74246860\n",
            "Iteration 793, loss = 446667484.00720280\n",
            "Iteration 794, loss = 445445759.85163230\n",
            "Iteration 795, loss = 444257120.77419138\n",
            "Iteration 796, loss = 443043727.11923563\n",
            "Iteration 797, loss = 441844549.69816953\n",
            "Iteration 798, loss = 440635026.40171635\n",
            "Iteration 799, loss = 439433233.22034872\n",
            "Iteration 800, loss = 438235732.30375010\n",
            "Iteration 801, loss = 437025860.14695549\n",
            "Iteration 802, loss = 435854749.62510395\n",
            "Iteration 803, loss = 434664738.84381032\n",
            "Iteration 804, loss = 433499359.46005636\n",
            "Iteration 805, loss = 432323069.44246590\n",
            "Iteration 806, loss = 431170568.97739559\n",
            "Iteration 807, loss = 430065475.94896603\n",
            "Iteration 808, loss = 428900949.69634789\n",
            "Iteration 809, loss = 427765533.36949486\n",
            "Iteration 810, loss = 426645130.40915948\n",
            "Iteration 811, loss = 425489344.99670482\n",
            "Iteration 812, loss = 424323700.79034543\n",
            "Iteration 813, loss = 423208451.03574640\n",
            "Iteration 814, loss = 422023536.57578969\n",
            "Iteration 815, loss = 420877329.77472067\n",
            "Iteration 816, loss = 419726733.00417554\n",
            "Iteration 817, loss = 418585191.72706479\n",
            "Iteration 818, loss = 417435260.63086855\n",
            "Iteration 819, loss = 416292341.17328840\n",
            "Iteration 820, loss = 415150547.01808882\n",
            "Iteration 821, loss = 414005424.81640148\n",
            "Iteration 822, loss = 412848619.08578825\n",
            "Iteration 823, loss = 411710942.32967907\n",
            "Iteration 824, loss = 410542474.22203702\n",
            "Iteration 825, loss = 409396408.18714994\n",
            "Iteration 826, loss = 408246773.08345586\n",
            "Iteration 827, loss = 407092436.30627650\n",
            "Iteration 828, loss = 405927939.58409053\n",
            "Iteration 829, loss = 404766907.13295245\n",
            "Iteration 830, loss = 403626325.60872185\n",
            "Iteration 831, loss = 402465724.41871053\n",
            "Iteration 832, loss = 401294574.20201159\n",
            "Iteration 833, loss = 400158517.63077557\n",
            "Iteration 834, loss = 398997579.21308273\n",
            "Iteration 835, loss = 397863868.95622718\n",
            "Iteration 836, loss = 396713794.48452175\n",
            "Iteration 837, loss = 395569647.37403709\n",
            "Iteration 838, loss = 394457256.86511952\n",
            "Iteration 839, loss = 393298653.50098431\n",
            "Iteration 840, loss = 392190219.36900395\n",
            "Iteration 841, loss = 391068597.57381624\n",
            "Iteration 842, loss = 389961637.42686301\n",
            "Iteration 843, loss = 388842614.61418319\n",
            "Iteration 844, loss = 387742888.61969018\n",
            "Iteration 845, loss = 386640020.13043815\n",
            "Iteration 846, loss = 385513204.60979456\n",
            "Iteration 847, loss = 384432601.58948642\n",
            "Iteration 848, loss = 383310181.66439515\n",
            "Iteration 849, loss = 382225622.00674087\n",
            "Iteration 850, loss = 381114825.16448271\n",
            "Iteration 851, loss = 380034581.15008271\n",
            "Iteration 852, loss = 378929804.27103513\n",
            "Iteration 853, loss = 377842320.45256001\n",
            "Iteration 854, loss = 376759190.21560133\n",
            "Iteration 855, loss = 375663977.51916140\n",
            "Iteration 856, loss = 374592796.48072284\n",
            "Iteration 857, loss = 373513360.65726584\n",
            "Iteration 858, loss = 372415359.34213656\n",
            "Iteration 859, loss = 371362533.53558534\n",
            "Iteration 860, loss = 370286837.48836964\n",
            "Iteration 861, loss = 369212567.57381856\n",
            "Iteration 862, loss = 368152928.68073368\n",
            "Iteration 863, loss = 367090752.55232197\n",
            "Iteration 864, loss = 366030570.44625378\n",
            "Iteration 865, loss = 364976972.59334642\n",
            "Iteration 866, loss = 363895645.14648312\n",
            "Iteration 867, loss = 362860367.59728265\n",
            "Iteration 868, loss = 361804715.76834017\n",
            "Iteration 869, loss = 360748082.68667275\n",
            "Iteration 870, loss = 359706603.63365167\n",
            "Iteration 871, loss = 358639046.99673903\n",
            "Iteration 872, loss = 357607453.66379660\n",
            "Iteration 873, loss = 356566394.34769791\n",
            "Iteration 874, loss = 355517759.84085900\n",
            "Iteration 875, loss = 354456015.86194247\n",
            "Iteration 876, loss = 353423717.83219784\n",
            "Iteration 877, loss = 352379384.25196081\n",
            "Iteration 878, loss = 351350451.46070886\n",
            "Iteration 879, loss = 350285092.89094210\n",
            "Iteration 880, loss = 349279654.06534070\n",
            "Iteration 881, loss = 348218384.18175668\n",
            "Iteration 882, loss = 347229567.20474058\n",
            "Iteration 883, loss = 346195124.63672912\n",
            "Iteration 884, loss = 345179238.12765807\n",
            "Iteration 885, loss = 344186986.52904773\n",
            "Iteration 886, loss = 343166996.30812585\n",
            "Iteration 887, loss = 342160543.09516686\n",
            "Iteration 888, loss = 341172036.16830891\n",
            "Iteration 889, loss = 340183745.98500991\n",
            "Iteration 890, loss = 339147545.85269374\n",
            "Iteration 891, loss = 338162124.38426983\n",
            "Iteration 892, loss = 337165544.56890798\n",
            "Iteration 893, loss = 336159974.75808221\n",
            "Iteration 894, loss = 335164572.43375874\n",
            "Iteration 895, loss = 334184424.33019555\n",
            "Iteration 896, loss = 333167824.20590276\n",
            "Iteration 897, loss = 332193369.64002240\n",
            "Iteration 898, loss = 331217438.90442145\n",
            "Iteration 899, loss = 330222120.57696480\n",
            "Iteration 900, loss = 329254620.15745825\n",
            "Iteration 901, loss = 328269539.15833312\n",
            "Iteration 902, loss = 327305935.67256558\n",
            "Iteration 903, loss = 326330002.90996325\n",
            "Iteration 904, loss = 325359103.11000383\n",
            "Iteration 905, loss = 324397927.00596672\n",
            "Iteration 906, loss = 323412718.32456565\n",
            "Iteration 907, loss = 322454035.87299967\n",
            "Iteration 908, loss = 321494027.04816103\n",
            "Iteration 909, loss = 320519236.90235299\n",
            "Iteration 910, loss = 319558580.39759237\n",
            "Iteration 911, loss = 318618644.73723578\n",
            "Iteration 912, loss = 317635034.80232441\n",
            "Iteration 913, loss = 316700505.77142072\n",
            "Iteration 914, loss = 315733375.72185087\n",
            "Iteration 915, loss = 314819431.72941601\n",
            "Iteration 916, loss = 313866574.21410251\n",
            "Iteration 917, loss = 312934101.22452235\n",
            "Iteration 918, loss = 312004981.34124935\n",
            "Iteration 919, loss = 311070640.45261204\n",
            "Iteration 920, loss = 310153103.91408402\n",
            "Iteration 921, loss = 309209578.30316484\n",
            "Iteration 922, loss = 308270651.90286803\n",
            "Iteration 923, loss = 307335571.34487689\n",
            "Iteration 924, loss = 306424496.88850105\n",
            "Iteration 925, loss = 305464389.87466818\n",
            "Iteration 926, loss = 304520385.16381615\n",
            "Iteration 927, loss = 303606072.18312258\n",
            "Iteration 928, loss = 302655140.84552294\n",
            "Iteration 929, loss = 301739024.38142377\n",
            "Iteration 930, loss = 300816998.04555273\n",
            "Iteration 931, loss = 299895573.44204479\n",
            "Iteration 932, loss = 298991634.31287050\n",
            "Iteration 933, loss = 298080556.08493459\n",
            "Iteration 934, loss = 297194573.15583640\n",
            "Iteration 935, loss = 296297579.32174248\n",
            "Iteration 936, loss = 295410803.09870183\n",
            "Iteration 937, loss = 294522103.75530910\n",
            "Iteration 938, loss = 293626271.63362128\n",
            "Iteration 939, loss = 292724394.05291885\n",
            "Iteration 940, loss = 291831814.02338004\n",
            "Iteration 941, loss = 290928980.21925932\n",
            "Iteration 942, loss = 290010146.06667852\n",
            "Iteration 943, loss = 289123576.35575670\n",
            "Iteration 944, loss = 288223512.84476173\n",
            "Iteration 945, loss = 287329363.60335934\n",
            "Iteration 946, loss = 286441500.54618001\n",
            "Iteration 947, loss = 285546543.58861125\n",
            "Iteration 948, loss = 284659756.61354059\n",
            "Iteration 949, loss = 283785131.17386043\n",
            "Iteration 950, loss = 282907691.97376275\n",
            "Iteration 951, loss = 282018615.63479435\n",
            "Iteration 952, loss = 281151219.91283488\n",
            "Iteration 953, loss = 280270134.72526741\n",
            "Iteration 954, loss = 279403518.86586964\n",
            "Iteration 955, loss = 278550498.37877774\n",
            "Iteration 956, loss = 277676791.79684353\n",
            "Iteration 957, loss = 276816848.09762472\n",
            "Iteration 958, loss = 275965641.64513707\n",
            "Iteration 959, loss = 275095953.40498263\n",
            "Iteration 960, loss = 274242024.40813935\n",
            "Iteration 961, loss = 273388926.18995804\n",
            "Iteration 962, loss = 272541649.28127372\n",
            "Iteration 963, loss = 271679067.45043534\n",
            "Iteration 964, loss = 270844801.43642741\n",
            "Iteration 965, loss = 269990495.63884282\n",
            "Iteration 966, loss = 269152709.68041384\n",
            "Iteration 967, loss = 268310944.19262105\n",
            "Iteration 968, loss = 267468625.65264243\n",
            "Iteration 969, loss = 266638755.58842665\n",
            "Iteration 970, loss = 265811484.09914905\n",
            "Iteration 971, loss = 264977782.44755912\n",
            "Iteration 972, loss = 264147539.53809601\n",
            "Iteration 973, loss = 263325274.32993636\n",
            "Iteration 974, loss = 262502387.18655202\n",
            "Iteration 975, loss = 261692515.72894949\n",
            "Iteration 976, loss = 260862075.60639259\n",
            "Iteration 977, loss = 260044770.90823567\n",
            "Iteration 978, loss = 259240164.71264872\n",
            "Iteration 979, loss = 258420887.99606431\n",
            "Iteration 980, loss = 257611372.52977356\n",
            "Iteration 981, loss = 256806349.50568166\n",
            "Iteration 982, loss = 256001422.67843083\n",
            "Iteration 983, loss = 255198001.07745561\n",
            "Iteration 984, loss = 254410416.85370561\n",
            "Iteration 985, loss = 253605728.62333363\n",
            "Iteration 986, loss = 252815878.22514161\n",
            "Iteration 987, loss = 252032934.52084768\n",
            "Iteration 988, loss = 251245569.62083426\n",
            "Iteration 989, loss = 250458116.69114336\n",
            "Iteration 990, loss = 249656914.89773673\n",
            "Iteration 991, loss = 248884152.73655993\n",
            "Iteration 992, loss = 248099629.68852478\n",
            "Iteration 993, loss = 247325878.90939817\n",
            "Iteration 994, loss = 246546207.97934660\n",
            "Iteration 995, loss = 245763021.36312938\n",
            "Iteration 996, loss = 244994312.37133718\n",
            "Iteration 997, loss = 244224179.19454539\n",
            "Iteration 998, loss = 243450266.12031311\n",
            "Iteration 999, loss = 242675379.06983918\n",
            "Iteration 1000, loss = 241896999.51718813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1525397353.08589363\n",
            "Iteration 2, loss = 325241935.18747163\n",
            "Iteration 3, loss = 155784059.09354731\n",
            "Iteration 4, loss = 164352333.55051005\n",
            "Iteration 5, loss = 75850817.22241737\n",
            "Iteration 6, loss = 33910591.88795347\n",
            "Iteration 7, loss = 40255346.82780410\n",
            "Iteration 8, loss = 24363513.70663182\n",
            "Iteration 9, loss = 17922620.39409375\n",
            "Iteration 10, loss = 18769257.26405119\n",
            "Iteration 11, loss = 15240564.32798865\n",
            "Iteration 12, loss = 13493056.23077602\n",
            "Iteration 13, loss = 14368267.94215937\n",
            "Iteration 14, loss = 13902536.94938860\n",
            "Iteration 15, loss = 13104465.57105906\n",
            "Iteration 16, loss = 12592189.49941099\n",
            "Iteration 17, loss = 11839833.70504304\n",
            "Iteration 18, loss = 11150081.60819210\n",
            "Iteration 19, loss = 10297593.96735588\n",
            "Iteration 20, loss = 8710332.33971660\n",
            "Iteration 21, loss = 8614595.73801161\n",
            "Iteration 22, loss = 8415548.81958649\n",
            "Iteration 23, loss = 8873494.03636981\n",
            "Iteration 24, loss = 9001872.96090701\n",
            "Iteration 25, loss = 8783841.08092935\n",
            "Iteration 26, loss = 8591774.36159495\n",
            "Iteration 27, loss = 8216419.07427086\n",
            "Iteration 28, loss = 7870585.76430742\n",
            "Iteration 29, loss = 7529703.00008620\n",
            "Iteration 30, loss = 7464481.57966483\n",
            "Iteration 31, loss = 7131453.98390451\n",
            "Iteration 32, loss = 6928966.68756610\n",
            "Iteration 33, loss = 6701591.14291686\n",
            "Iteration 34, loss = 6528331.30097109\n",
            "Iteration 35, loss = 6326987.06516456\n",
            "Iteration 36, loss = 6073097.99073790\n",
            "Iteration 37, loss = 5989391.70671274\n",
            "Iteration 38, loss = 5770488.62245234\n",
            "Iteration 39, loss = 5692845.57840104\n",
            "Iteration 40, loss = 5587428.18868675\n",
            "Iteration 41, loss = 5398641.75589311\n",
            "Iteration 42, loss = 5302890.53787177\n",
            "Iteration 43, loss = 5251674.31126352\n",
            "Iteration 44, loss = 5140562.56663591\n",
            "Iteration 45, loss = 5076640.32152996\n",
            "Iteration 46, loss = 5022617.53699526\n",
            "Iteration 47, loss = 4974145.99483950\n",
            "Iteration 48, loss = 4888170.64316042\n",
            "Iteration 49, loss = 4797530.94450833\n",
            "Iteration 50, loss = 4742550.31417955\n",
            "Iteration 51, loss = 4683288.81956982\n",
            "Iteration 52, loss = 4669424.53880157\n",
            "Iteration 53, loss = 4550747.57605537\n",
            "Iteration 54, loss = 4564919.25143503\n",
            "Iteration 55, loss = 4499871.61726692\n",
            "Iteration 56, loss = 4427448.88512718\n",
            "Iteration 57, loss = 4427829.73697129\n",
            "Iteration 58, loss = 4321226.31856868\n",
            "Iteration 59, loss = 4276852.93253631\n",
            "Iteration 60, loss = 4219679.48539634\n",
            "Iteration 61, loss = 4202387.31241623\n",
            "Iteration 62, loss = 4199623.91471059\n",
            "Iteration 63, loss = 4158614.35834367\n",
            "Iteration 64, loss = 4103202.67175788\n",
            "Iteration 65, loss = 4049441.83692162\n",
            "Iteration 66, loss = 4052955.68272960\n",
            "Iteration 67, loss = 4019911.86807420\n",
            "Iteration 68, loss = 3990958.61943371\n",
            "Iteration 69, loss = 3972677.15428838\n",
            "Iteration 70, loss = 3953825.99057089\n",
            "Iteration 71, loss = 3904333.49344674\n",
            "Iteration 72, loss = 3881689.69567538\n",
            "Iteration 73, loss = 3889819.64468954\n",
            "Iteration 74, loss = 3854493.72083221\n",
            "Iteration 75, loss = 3855228.92854024\n",
            "Iteration 76, loss = 3804868.30745550\n",
            "Iteration 77, loss = 3811105.82056498\n",
            "Iteration 78, loss = 3805710.23137469\n",
            "Iteration 79, loss = 3775387.65922450\n",
            "Iteration 80, loss = 3730602.34785208\n",
            "Iteration 81, loss = 3754760.48792240\n",
            "Iteration 82, loss = 3719285.74844996\n",
            "Iteration 83, loss = 3690513.90182433\n",
            "Iteration 84, loss = 3676205.99586079\n",
            "Iteration 85, loss = 3659096.18654701\n",
            "Iteration 86, loss = 3642043.79136491\n",
            "Iteration 87, loss = 3612021.15042545\n",
            "Iteration 88, loss = 3657833.11723608\n",
            "Iteration 89, loss = 3590915.19175992\n",
            "Iteration 90, loss = 3550080.84383734\n",
            "Iteration 91, loss = 3557945.74554626\n",
            "Iteration 92, loss = 3513565.84110853\n",
            "Iteration 93, loss = 3520738.43202920\n",
            "Iteration 94, loss = 3496038.78025134\n",
            "Iteration 95, loss = 3539800.34165262\n",
            "Iteration 96, loss = 3473577.28126017\n",
            "Iteration 97, loss = 3443776.47576027\n",
            "Iteration 98, loss = 3485794.76867111\n",
            "Iteration 99, loss = 3422792.95123114\n",
            "Iteration 100, loss = 3425962.87225763\n",
            "Iteration 101, loss = 3434818.80174027\n",
            "Iteration 102, loss = 3383402.05184443\n",
            "Iteration 103, loss = 3404296.24064972\n",
            "Iteration 104, loss = 3400187.91670356\n",
            "Iteration 105, loss = 3357792.51397161\n",
            "Iteration 106, loss = 3358044.80046889\n",
            "Iteration 107, loss = 3337618.94566576\n",
            "Iteration 108, loss = 3337998.95515122\n",
            "Iteration 109, loss = 3308355.89414914\n",
            "Iteration 110, loss = 3318804.97139772\n",
            "Iteration 111, loss = 3303268.23136449\n",
            "Iteration 112, loss = 3279944.67933044\n",
            "Iteration 113, loss = 3287058.54506605\n",
            "Iteration 114, loss = 3266053.66873700\n",
            "Iteration 115, loss = 3244777.13691080\n",
            "Iteration 116, loss = 3228257.87787639\n",
            "Iteration 117, loss = 3227904.68984456\n",
            "Iteration 118, loss = 3243032.80284177\n",
            "Iteration 119, loss = 3270644.46640840\n",
            "Iteration 120, loss = 3221189.21187769\n",
            "Iteration 121, loss = 3239974.87856359\n",
            "Iteration 122, loss = 3212495.81872261\n",
            "Iteration 123, loss = 3172888.78668468\n",
            "Iteration 124, loss = 3182350.43774923\n",
            "Iteration 125, loss = 3229301.14359302\n",
            "Iteration 126, loss = 3180143.38149602\n",
            "Iteration 127, loss = 3192090.28573775\n",
            "Iteration 128, loss = 3163905.90069371\n",
            "Iteration 129, loss = 3127840.34722083\n",
            "Iteration 130, loss = 3135578.74724628\n",
            "Iteration 131, loss = 3115027.20527985\n",
            "Iteration 132, loss = 3131805.92537821\n",
            "Iteration 133, loss = 3141056.94746868\n",
            "Iteration 134, loss = 3135637.16748274\n",
            "Iteration 135, loss = 3095455.97059813\n",
            "Iteration 136, loss = 3079057.87038835\n",
            "Iteration 137, loss = 3083479.71109849\n",
            "Iteration 138, loss = 3073069.34049211\n",
            "Iteration 139, loss = 3086075.52023297\n",
            "Iteration 140, loss = 3094403.18420640\n",
            "Iteration 141, loss = 3068395.44955178\n",
            "Iteration 142, loss = 3052648.91241785\n",
            "Iteration 143, loss = 3065707.52724641\n",
            "Iteration 144, loss = 3041070.57229174\n",
            "Iteration 145, loss = 3034566.89177241\n",
            "Iteration 146, loss = 3035662.64114889\n",
            "Iteration 147, loss = 3035957.44048918\n",
            "Iteration 148, loss = 3036997.57205024\n",
            "Iteration 149, loss = 3008455.92998280\n",
            "Iteration 150, loss = 3000941.90639956\n",
            "Iteration 151, loss = 3002399.11946051\n",
            "Iteration 152, loss = 2999680.46059150\n",
            "Iteration 153, loss = 3064716.93786334\n",
            "Iteration 154, loss = 3069312.74155101\n",
            "Iteration 155, loss = 2991988.51896749\n",
            "Iteration 156, loss = 2966493.50739341\n",
            "Iteration 157, loss = 2973457.14825194\n",
            "Iteration 158, loss = 3004936.11536855\n",
            "Iteration 159, loss = 2986446.82763465\n",
            "Iteration 160, loss = 2943744.78651585\n",
            "Iteration 161, loss = 2977125.64776550\n",
            "Iteration 162, loss = 2934457.42111949\n",
            "Iteration 163, loss = 2942574.98097775\n",
            "Iteration 164, loss = 2941930.04364962\n",
            "Iteration 165, loss = 2937863.09289588\n",
            "Iteration 166, loss = 2932035.34483003\n",
            "Iteration 167, loss = 2918717.15534562\n",
            "Iteration 168, loss = 2915720.33847034\n",
            "Iteration 169, loss = 2916496.60596826\n",
            "Iteration 170, loss = 2912912.36195994\n",
            "Iteration 171, loss = 2911590.98926343\n",
            "Iteration 172, loss = 2911719.25009687\n",
            "Iteration 173, loss = 2898049.21722367\n",
            "Iteration 174, loss = 2900370.92779494\n",
            "Iteration 175, loss = 2893599.70794433\n",
            "Iteration 176, loss = 2900356.17908766\n",
            "Iteration 177, loss = 2914609.73458174\n",
            "Iteration 178, loss = 2897953.25288797\n",
            "Iteration 179, loss = 2878185.96021194\n",
            "Iteration 180, loss = 2888565.66169905\n",
            "Iteration 181, loss = 2894224.54563811\n",
            "Iteration 182, loss = 2871920.15488539\n",
            "Iteration 183, loss = 2889230.35283568\n",
            "Iteration 184, loss = 2894127.01310306\n",
            "Iteration 185, loss = 2864819.09686985\n",
            "Iteration 186, loss = 2851075.09962951\n",
            "Iteration 187, loss = 2856406.05155464\n",
            "Iteration 188, loss = 2850390.67105902\n",
            "Iteration 189, loss = 2867306.39539003\n",
            "Iteration 190, loss = 2848412.82131011\n",
            "Iteration 191, loss = 2843900.78667264\n",
            "Iteration 192, loss = 2825647.43942137\n",
            "Iteration 193, loss = 2826388.02590382\n",
            "Iteration 194, loss = 2829473.12185306\n",
            "Iteration 195, loss = 2846319.74332676\n",
            "Iteration 196, loss = 2816899.82117929\n",
            "Iteration 197, loss = 2830271.78878875\n",
            "Iteration 198, loss = 2842672.16371159\n",
            "Iteration 199, loss = 2820088.19006002\n",
            "Iteration 200, loss = 2829157.94541566\n",
            "Iteration 201, loss = 2801456.75439461\n",
            "Iteration 202, loss = 2821008.47795724\n",
            "Iteration 203, loss = 2796623.87110000\n",
            "Iteration 204, loss = 2802669.44659506\n",
            "Iteration 205, loss = 2795437.86409353\n",
            "Iteration 206, loss = 2796453.53061586\n",
            "Iteration 207, loss = 2801984.40697923\n",
            "Iteration 208, loss = 2781653.70938665\n",
            "Iteration 209, loss = 2787060.93960276\n",
            "Iteration 210, loss = 2776951.18792529\n",
            "Iteration 211, loss = 2779518.63874626\n",
            "Iteration 212, loss = 2772980.00130951\n",
            "Iteration 213, loss = 2774127.26205732\n",
            "Iteration 214, loss = 2789325.67162048\n",
            "Iteration 215, loss = 2805519.32755322\n",
            "Iteration 216, loss = 2795228.86503343\n",
            "Iteration 217, loss = 2878486.05776379\n",
            "Iteration 218, loss = 2760567.51172471\n",
            "Iteration 219, loss = 2759093.05224639\n",
            "Iteration 220, loss = 2745836.52257317\n",
            "Iteration 221, loss = 2754115.41536049\n",
            "Iteration 222, loss = 2752027.90999592\n",
            "Iteration 223, loss = 2764050.33615435\n",
            "Iteration 224, loss = 2737731.59847546\n",
            "Iteration 225, loss = 2781009.67972489\n",
            "Iteration 226, loss = 2746939.21148654\n",
            "Iteration 227, loss = 2727129.61721528\n",
            "Iteration 228, loss = 2728149.89792906\n",
            "Iteration 229, loss = 2732271.92583158\n",
            "Iteration 230, loss = 2736551.97070224\n",
            "Iteration 231, loss = 2721166.38578451\n",
            "Iteration 232, loss = 2722657.58411350\n",
            "Iteration 233, loss = 2737168.67978502\n",
            "Iteration 234, loss = 2727763.78282580\n",
            "Iteration 235, loss = 2731992.24087011\n",
            "Iteration 236, loss = 2761716.65737084\n",
            "Iteration 237, loss = 2715705.16752364\n",
            "Iteration 238, loss = 2704236.79564147\n",
            "Iteration 239, loss = 2706223.32030916\n",
            "Iteration 240, loss = 2707938.11920495\n",
            "Iteration 241, loss = 2705081.79257010\n",
            "Iteration 242, loss = 2695761.69532571\n",
            "Iteration 243, loss = 2706550.65640955\n",
            "Iteration 244, loss = 2705954.46774893\n",
            "Iteration 245, loss = 2707842.12949364\n",
            "Iteration 246, loss = 2692015.08569935\n",
            "Iteration 247, loss = 2688176.35376735\n",
            "Iteration 248, loss = 2692621.93876795\n",
            "Iteration 249, loss = 2694167.42735748\n",
            "Iteration 250, loss = 2713877.25629862\n",
            "Iteration 251, loss = 2728950.24079167\n",
            "Iteration 252, loss = 2680868.11749079\n",
            "Iteration 253, loss = 2683575.75710565\n",
            "Iteration 254, loss = 2695802.52346116\n",
            "Iteration 255, loss = 2677926.20734269\n",
            "Iteration 256, loss = 2677369.39623332\n",
            "Iteration 257, loss = 2674134.09933271\n",
            "Iteration 258, loss = 2677897.58736963\n",
            "Iteration 259, loss = 2672054.03196301\n",
            "Iteration 260, loss = 2674941.85729617\n",
            "Iteration 261, loss = 2685130.94678789\n",
            "Iteration 262, loss = 2679174.40681234\n",
            "Iteration 263, loss = 2662641.72188285\n",
            "Iteration 264, loss = 2672014.34488673\n",
            "Iteration 265, loss = 2669963.05311573\n",
            "Iteration 266, loss = 2661727.43334062\n",
            "Iteration 267, loss = 2665797.27412329\n",
            "Iteration 268, loss = 2700988.90263535\n",
            "Iteration 269, loss = 2774149.61910311\n",
            "Iteration 270, loss = 2715693.74695686\n",
            "Iteration 271, loss = 2706052.65337171\n",
            "Iteration 272, loss = 2698151.34439621\n",
            "Iteration 273, loss = 2680670.77371478\n",
            "Iteration 274, loss = 2647369.50829351\n",
            "Iteration 275, loss = 2651980.38074473\n",
            "Iteration 276, loss = 2657569.83323720\n",
            "Iteration 277, loss = 2664151.57033861\n",
            "Iteration 278, loss = 2665031.51629154\n",
            "Iteration 279, loss = 2649357.41366421\n",
            "Iteration 280, loss = 2656095.17008601\n",
            "Iteration 281, loss = 2652983.66234347\n",
            "Iteration 282, loss = 2645714.00827564\n",
            "Iteration 283, loss = 2648292.92793334\n",
            "Iteration 284, loss = 2646057.75742030\n",
            "Iteration 285, loss = 2643032.18712815\n",
            "Iteration 286, loss = 2667664.35900768\n",
            "Iteration 287, loss = 2671840.35189062\n",
            "Iteration 288, loss = 2655153.03081231\n",
            "Iteration 289, loss = 2635837.34413420\n",
            "Iteration 290, loss = 2666421.67573398\n",
            "Iteration 291, loss = 2684049.49306257\n",
            "Iteration 292, loss = 2669858.56570194\n",
            "Iteration 293, loss = 2656826.94623311\n",
            "Iteration 294, loss = 2640268.24705296\n",
            "Iteration 295, loss = 2617616.71956882\n",
            "Iteration 296, loss = 2636056.72643446\n",
            "Iteration 297, loss = 2636533.12557889\n",
            "Iteration 298, loss = 2625499.67172156\n",
            "Iteration 299, loss = 2643204.41051287\n",
            "Iteration 300, loss = 2637867.73004608\n",
            "Iteration 301, loss = 2633574.87985729\n",
            "Iteration 302, loss = 2621171.64181322\n",
            "Iteration 303, loss = 2633776.82590766\n",
            "Iteration 304, loss = 2632709.29997967\n",
            "Iteration 305, loss = 2641017.12050654\n",
            "Iteration 306, loss = 2630490.10623449\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538807482.10075092\n",
            "Iteration 2, loss = 1538781699.41134810\n",
            "Iteration 3, loss = 1538756861.10007095\n",
            "Iteration 4, loss = 1538731070.07879615\n",
            "Iteration 5, loss = 1538704777.41135454\n",
            "Iteration 6, loss = 1538678462.77184343\n",
            "Iteration 7, loss = 1538651013.08010674\n",
            "Iteration 8, loss = 1538622843.97127795\n",
            "Iteration 9, loss = 1538593289.35102463\n",
            "Iteration 10, loss = 1538562251.74414897\n",
            "Iteration 11, loss = 1538530666.69050884\n",
            "Iteration 12, loss = 1538497147.27937317\n",
            "Iteration 13, loss = 1538463350.11137772\n",
            "Iteration 14, loss = 1538427835.72540474\n",
            "Iteration 15, loss = 1538390108.38594508\n",
            "Iteration 16, loss = 1538351862.05112672\n",
            "Iteration 17, loss = 1538311172.09754086\n",
            "Iteration 18, loss = 1538270475.19629550\n",
            "Iteration 19, loss = 1538225582.26842308\n",
            "Iteration 20, loss = 1538180590.03806949\n",
            "Iteration 21, loss = 1538134381.63026309\n",
            "Iteration 22, loss = 1538085195.17309165\n",
            "Iteration 23, loss = 1538034215.63332486\n",
            "Iteration 24, loss = 1537981188.63319778\n",
            "Iteration 25, loss = 1537926952.50616860\n",
            "Iteration 26, loss = 1537870356.22714067\n",
            "Iteration 27, loss = 1537811624.93281794\n",
            "Iteration 28, loss = 1537751573.62109780\n",
            "Iteration 29, loss = 1537689970.18509579\n",
            "Iteration 30, loss = 1537627065.52301407\n",
            "Iteration 31, loss = 1537561609.46134734\n",
            "Iteration 32, loss = 1537494195.14977598\n",
            "Iteration 33, loss = 1537424629.13443494\n",
            "Iteration 34, loss = 1537352788.36823630\n",
            "Iteration 35, loss = 1537278516.55613422\n",
            "Iteration 36, loss = 1537202981.43819594\n",
            "Iteration 37, loss = 1537126462.75666332\n",
            "Iteration 38, loss = 1537049518.69763446\n",
            "Iteration 39, loss = 1536972425.55925369\n",
            "Iteration 40, loss = 1536894974.85485935\n",
            "Iteration 41, loss = 1536817559.76923108\n",
            "Iteration 42, loss = 1536739516.96073341\n",
            "Iteration 43, loss = 1536661032.32098937\n",
            "Iteration 44, loss = 1536582015.53008890\n",
            "Iteration 45, loss = 1536502406.89314222\n",
            "Iteration 46, loss = 1536422168.67351460\n",
            "Iteration 47, loss = 1536341393.42438650\n",
            "Iteration 48, loss = 1536259419.04253602\n",
            "Iteration 49, loss = 1536177042.19146228\n",
            "Iteration 50, loss = 1536092809.59995079\n",
            "Iteration 51, loss = 1536006434.50007176\n",
            "Iteration 52, loss = 1535918712.54636788\n",
            "Iteration 53, loss = 1535827960.97000217\n",
            "Iteration 54, loss = 1535735387.84873414\n",
            "Iteration 55, loss = 1535641359.88802052\n",
            "Iteration 56, loss = 1535545630.87178636\n",
            "Iteration 57, loss = 1535449459.02153206\n",
            "Iteration 58, loss = 1535353411.15440655\n",
            "Iteration 59, loss = 1535257264.39578891\n",
            "Iteration 60, loss = 1535162293.91233540\n",
            "Iteration 61, loss = 1535068258.48605227\n",
            "Iteration 62, loss = 1534975080.36296606\n",
            "Iteration 63, loss = 1534883073.19461942\n",
            "Iteration 64, loss = 1534791743.32551479\n",
            "Iteration 65, loss = 1534700882.84983873\n",
            "Iteration 66, loss = 1534611551.93527603\n",
            "Iteration 67, loss = 1534523041.93512177\n",
            "Iteration 68, loss = 1534436304.14286900\n",
            "Iteration 69, loss = 1534350795.71992517\n",
            "Iteration 70, loss = 1534265936.22227049\n",
            "Iteration 71, loss = 1534182533.45020056\n",
            "Iteration 72, loss = 1534099642.35010362\n",
            "Iteration 73, loss = 1534016886.29185009\n",
            "Iteration 74, loss = 1533935076.87542629\n",
            "Iteration 75, loss = 1533853751.52734804\n",
            "Iteration 76, loss = 1533772908.41358757\n",
            "Iteration 77, loss = 1533692945.78806400\n",
            "Iteration 78, loss = 1533613484.66584468\n",
            "Iteration 79, loss = 1533534685.17125702\n",
            "Iteration 80, loss = 1533456553.30268955\n",
            "Iteration 81, loss = 1533378552.53823256\n",
            "Iteration 82, loss = 1533301199.59574103\n",
            "Iteration 83, loss = 1533223660.29500532\n",
            "Iteration 84, loss = 1533147256.34816194\n",
            "Iteration 85, loss = 1533070622.94372892\n",
            "Iteration 86, loss = 1532994517.52751160\n",
            "Iteration 87, loss = 1532919109.80058718\n",
            "Iteration 88, loss = 1532843692.02446604\n",
            "Iteration 89, loss = 1532769059.24772358\n",
            "Iteration 90, loss = 1532694222.40265656\n",
            "Iteration 91, loss = 1532619826.75024867\n",
            "Iteration 92, loss = 1532546028.41263318\n",
            "Iteration 93, loss = 1532472513.14386201\n",
            "Iteration 94, loss = 1532399206.13427258\n",
            "Iteration 95, loss = 1532326318.71271896\n",
            "Iteration 96, loss = 1532253744.46888995\n",
            "Iteration 97, loss = 1532181531.57311487\n",
            "Iteration 98, loss = 1532109323.39414501\n",
            "Iteration 99, loss = 1532037883.09278655\n",
            "Iteration 100, loss = 1531966073.36055231\n",
            "Iteration 101, loss = 1531895055.72636795\n",
            "Iteration 102, loss = 1531823519.91754699\n",
            "Iteration 103, loss = 1531753076.48084307\n",
            "Iteration 104, loss = 1531682261.71853590\n",
            "Iteration 105, loss = 1531611025.11848879\n",
            "Iteration 106, loss = 1531541194.48006225\n",
            "Iteration 107, loss = 1531470689.51212811\n",
            "Iteration 108, loss = 1531401044.61574459\n",
            "Iteration 109, loss = 1531330853.03708553\n",
            "Iteration 110, loss = 1531261247.70155334\n",
            "Iteration 111, loss = 1531192715.82873392\n",
            "Iteration 112, loss = 1531122477.10142970\n",
            "Iteration 113, loss = 1531053943.37343550\n",
            "Iteration 114, loss = 1530985189.78728127\n",
            "Iteration 115, loss = 1530917132.24290681\n",
            "Iteration 116, loss = 1530848249.28711772\n",
            "Iteration 117, loss = 1530780931.71987319\n",
            "Iteration 118, loss = 1530712839.40814424\n",
            "Iteration 119, loss = 1530645612.60472846\n",
            "Iteration 120, loss = 1530578189.91890144\n",
            "Iteration 121, loss = 1530511076.74363041\n",
            "Iteration 122, loss = 1530444206.35441446\n",
            "Iteration 123, loss = 1530376923.85388041\n",
            "Iteration 124, loss = 1530310383.65792871\n",
            "Iteration 125, loss = 1530243723.07571173\n",
            "Iteration 126, loss = 1530177333.55043793\n",
            "Iteration 127, loss = 1530111007.75315380\n",
            "Iteration 128, loss = 1530044815.71883559\n",
            "Iteration 129, loss = 1529978834.98751783\n",
            "Iteration 130, loss = 1529912875.25568771\n",
            "Iteration 131, loss = 1529847153.97054935\n",
            "Iteration 132, loss = 1529781616.07524896\n",
            "Iteration 133, loss = 1529716093.68842220\n",
            "Iteration 134, loss = 1529650423.35170317\n",
            "Iteration 135, loss = 1529585413.12443614\n",
            "Iteration 136, loss = 1529520291.24654222\n",
            "Iteration 137, loss = 1529454929.93527937\n",
            "Iteration 138, loss = 1529390545.86767387\n",
            "Iteration 139, loss = 1529325326.59023595\n",
            "Iteration 140, loss = 1529260472.21395636\n",
            "Iteration 141, loss = 1529196500.28174090\n",
            "Iteration 142, loss = 1529131722.90539956\n",
            "Iteration 143, loss = 1529067382.69786620\n",
            "Iteration 144, loss = 1529002837.03029418\n",
            "Iteration 145, loss = 1528939167.49532890\n",
            "Iteration 146, loss = 1528875138.87239361\n",
            "Iteration 147, loss = 1528811127.01473236\n",
            "Iteration 148, loss = 1528747498.09125209\n",
            "Iteration 149, loss = 1528683577.81206369\n",
            "Iteration 150, loss = 1528620050.89949775\n",
            "Iteration 151, loss = 1528556353.13170934\n",
            "Iteration 152, loss = 1528492710.07812428\n",
            "Iteration 153, loss = 1528428965.35902095\n",
            "Iteration 154, loss = 1528365336.60799241\n",
            "Iteration 155, loss = 1528301653.90800452\n",
            "Iteration 156, loss = 1528238012.54223871\n",
            "Iteration 157, loss = 1528174383.19735932\n",
            "Iteration 158, loss = 1528110891.64380240\n",
            "Iteration 159, loss = 1528047131.81949759\n",
            "Iteration 160, loss = 1527984100.89115119\n",
            "Iteration 161, loss = 1527920575.02693582\n",
            "Iteration 162, loss = 1527857558.83869290\n",
            "Iteration 163, loss = 1527794763.65967870\n",
            "Iteration 164, loss = 1527731613.01360297\n",
            "Iteration 165, loss = 1527669154.20602679\n",
            "Iteration 166, loss = 1527606492.99265194\n",
            "Iteration 167, loss = 1527544327.05884361\n",
            "Iteration 168, loss = 1527481869.61105919\n",
            "Iteration 169, loss = 1527419352.22475338\n",
            "Iteration 170, loss = 1527356871.21827912\n",
            "Iteration 171, loss = 1527294976.11147213\n",
            "Iteration 172, loss = 1527232641.30066848\n",
            "Iteration 173, loss = 1527170019.65642309\n",
            "Iteration 174, loss = 1527107399.80611229\n",
            "Iteration 175, loss = 1527045540.12413383\n",
            "Iteration 176, loss = 1526982756.52450442\n",
            "Iteration 177, loss = 1526920725.73410010\n",
            "Iteration 178, loss = 1526858058.58075762\n",
            "Iteration 179, loss = 1526796532.84487987\n",
            "Iteration 180, loss = 1526734160.25989199\n",
            "Iteration 181, loss = 1526672093.01550102\n",
            "Iteration 182, loss = 1526610734.31372213\n",
            "Iteration 183, loss = 1526549022.25225234\n",
            "Iteration 184, loss = 1526487376.71597648\n",
            "Iteration 185, loss = 1526426145.54461622\n",
            "Iteration 186, loss = 1526365040.68084693\n",
            "Iteration 187, loss = 1526303631.18579888\n",
            "Iteration 188, loss = 1526242180.22228503\n",
            "Iteration 189, loss = 1526180973.84851074\n",
            "Iteration 190, loss = 1526119995.79395533\n",
            "Iteration 191, loss = 1526058079.44918752\n",
            "Iteration 192, loss = 1525997211.92640615\n",
            "Iteration 193, loss = 1525935823.63793707\n",
            "Iteration 194, loss = 1525874818.92881441\n",
            "Iteration 195, loss = 1525813775.75509596\n",
            "Iteration 196, loss = 1525752562.58684516\n",
            "Iteration 197, loss = 1525691655.95368433\n",
            "Iteration 198, loss = 1525630624.86769271\n",
            "Iteration 199, loss = 1525569395.00737214\n",
            "Iteration 200, loss = 1525508606.38434672\n",
            "Iteration 201, loss = 1525447446.68913054\n",
            "Iteration 202, loss = 1525386974.99062467\n",
            "Iteration 203, loss = 1525325025.14689517\n",
            "Iteration 204, loss = 1525264847.96079946\n",
            "Iteration 205, loss = 1525203727.74419594\n",
            "Iteration 206, loss = 1525143149.00429416\n",
            "Iteration 207, loss = 1525082634.67059851\n",
            "Iteration 208, loss = 1525022029.09544182\n",
            "Iteration 209, loss = 1524962128.10981989\n",
            "Iteration 210, loss = 1524901698.88012600\n",
            "Iteration 211, loss = 1524841671.80937171\n",
            "Iteration 212, loss = 1524781702.01518130\n",
            "Iteration 213, loss = 1524721709.43110085\n",
            "Iteration 214, loss = 1524661904.67701674\n",
            "Iteration 215, loss = 1524601628.56118679\n",
            "Iteration 216, loss = 1524541873.37859344\n",
            "Iteration 217, loss = 1524481774.07453299\n",
            "Iteration 218, loss = 1524421481.58055425\n",
            "Iteration 219, loss = 1524361917.58628678\n",
            "Iteration 220, loss = 1524301775.26809096\n",
            "Iteration 221, loss = 1524241833.94877100\n",
            "Iteration 222, loss = 1524181697.35177231\n",
            "Iteration 223, loss = 1524121528.81471705\n",
            "Iteration 224, loss = 1524061846.42275167\n",
            "Iteration 225, loss = 1524001462.58537292\n",
            "Iteration 226, loss = 1523941588.42542982\n",
            "Iteration 227, loss = 1523881237.40873313\n",
            "Iteration 228, loss = 1523821164.92086291\n",
            "Iteration 229, loss = 1523761573.91121817\n",
            "Iteration 230, loss = 1523701071.43321395\n",
            "Iteration 231, loss = 1523641456.07207799\n",
            "Iteration 232, loss = 1523581883.79031086\n",
            "Iteration 233, loss = 1523522220.09645867\n",
            "Iteration 234, loss = 1523462865.17276263\n",
            "Iteration 235, loss = 1523403302.89174151\n",
            "Iteration 236, loss = 1523344124.59643006\n",
            "Iteration 237, loss = 1523284456.24764132\n",
            "Iteration 238, loss = 1523225631.55332518\n",
            "Iteration 239, loss = 1523165993.49342942\n",
            "Iteration 240, loss = 1523106545.25676131\n",
            "Iteration 241, loss = 1523047185.45850468\n",
            "Iteration 242, loss = 1522988132.50249386\n",
            "Iteration 243, loss = 1522928595.93719983\n",
            "Iteration 244, loss = 1522869271.63155222\n",
            "Iteration 245, loss = 1522810403.26269913\n",
            "Iteration 246, loss = 1522750924.11868644\n",
            "Iteration 247, loss = 1522691995.22619963\n",
            "Iteration 248, loss = 1522633189.36891413\n",
            "Iteration 249, loss = 1522573805.23503542\n",
            "Iteration 250, loss = 1522515262.80089688\n",
            "Iteration 251, loss = 1522456148.01377892\n",
            "Iteration 252, loss = 1522397104.10556865\n",
            "Iteration 253, loss = 1522338115.61100531\n",
            "Iteration 254, loss = 1522279236.35528088\n",
            "Iteration 255, loss = 1522220386.40388155\n",
            "Iteration 256, loss = 1522161164.39298415\n",
            "Iteration 257, loss = 1522102207.20373297\n",
            "Iteration 258, loss = 1522043105.93724990\n",
            "Iteration 259, loss = 1521984204.32412386\n",
            "Iteration 260, loss = 1521925491.85725665\n",
            "Iteration 261, loss = 1521866365.43861175\n",
            "Iteration 262, loss = 1521807375.86680746\n",
            "Iteration 263, loss = 1521748951.57777786\n",
            "Iteration 264, loss = 1521690149.38666868\n",
            "Iteration 265, loss = 1521631382.70799518\n",
            "Iteration 266, loss = 1521572649.17611766\n",
            "Iteration 267, loss = 1521514240.53051400\n",
            "Iteration 268, loss = 1521455388.56005335\n",
            "Iteration 269, loss = 1521397160.62453032\n",
            "Iteration 270, loss = 1521338286.60993552\n",
            "Iteration 271, loss = 1521280034.98974562\n",
            "Iteration 272, loss = 1521221450.05978251\n",
            "Iteration 273, loss = 1521162995.09656405\n",
            "Iteration 274, loss = 1521104601.23005605\n",
            "Iteration 275, loss = 1521046430.01821399\n",
            "Iteration 276, loss = 1520987946.23587823\n",
            "Iteration 277, loss = 1520929844.91625142\n",
            "Iteration 278, loss = 1520871139.06725097\n",
            "Iteration 279, loss = 1520813199.04070592\n",
            "Iteration 280, loss = 1520754981.95780540\n",
            "Iteration 281, loss = 1520696514.18509936\n",
            "Iteration 282, loss = 1520638307.23461366\n",
            "Iteration 283, loss = 1520580163.59686589\n",
            "Iteration 284, loss = 1520521849.60667872\n",
            "Iteration 285, loss = 1520463629.07413554\n",
            "Iteration 286, loss = 1520405194.35160470\n",
            "Iteration 287, loss = 1520347420.41689110\n",
            "Iteration 288, loss = 1520289078.62044621\n",
            "Iteration 289, loss = 1520231029.80550838\n",
            "Iteration 290, loss = 1520172412.88349724\n",
            "Iteration 291, loss = 1520114858.72579551\n",
            "Iteration 292, loss = 1520056121.48184085\n",
            "Iteration 293, loss = 1519998087.65546989\n",
            "Iteration 294, loss = 1519939869.66972232\n",
            "Iteration 295, loss = 1519881847.49746847\n",
            "Iteration 296, loss = 1519823409.87842083\n",
            "Iteration 297, loss = 1519765565.22118258\n",
            "Iteration 298, loss = 1519707386.73700929\n",
            "Iteration 299, loss = 1519649440.71458411\n",
            "Iteration 300, loss = 1519591706.01633286\n",
            "Iteration 301, loss = 1519533492.14898157\n",
            "Iteration 302, loss = 1519475590.28432250\n",
            "Iteration 303, loss = 1519417760.03564119\n",
            "Iteration 304, loss = 1519360198.82394695\n",
            "Iteration 305, loss = 1519302190.17890429\n",
            "Iteration 306, loss = 1519244454.79755449\n",
            "Iteration 307, loss = 1519186676.31152678\n",
            "Iteration 308, loss = 1519128919.93384314\n",
            "Iteration 309, loss = 1519071168.62901378\n",
            "Iteration 310, loss = 1519013451.16080737\n",
            "Iteration 311, loss = 1518955843.04176188\n",
            "Iteration 312, loss = 1518897841.13985515\n",
            "Iteration 313, loss = 1518840571.36702657\n",
            "Iteration 314, loss = 1518782899.49819422\n",
            "Iteration 315, loss = 1518725370.41600537\n",
            "Iteration 316, loss = 1518667844.40417862\n",
            "Iteration 317, loss = 1518610583.18792343\n",
            "Iteration 318, loss = 1518553395.70594382\n",
            "Iteration 319, loss = 1518495613.01920176\n",
            "Iteration 320, loss = 1518438167.45557809\n",
            "Iteration 321, loss = 1518380870.61664748\n",
            "Iteration 322, loss = 1518323049.79011774\n",
            "Iteration 323, loss = 1518265924.52252412\n",
            "Iteration 324, loss = 1518207921.19211388\n",
            "Iteration 325, loss = 1518150532.53812814\n",
            "Iteration 326, loss = 1518092767.74166465\n",
            "Iteration 327, loss = 1518035625.92627954\n",
            "Iteration 328, loss = 1517977907.38802052\n",
            "Iteration 329, loss = 1517920788.27332854\n",
            "Iteration 330, loss = 1517863271.67347121\n",
            "Iteration 331, loss = 1517805859.50661063\n",
            "Iteration 332, loss = 1517748568.63558865\n",
            "Iteration 333, loss = 1517691014.68821597\n",
            "Iteration 334, loss = 1517633946.13773775\n",
            "Iteration 335, loss = 1517576876.18020940\n",
            "Iteration 336, loss = 1517519181.30545688\n",
            "Iteration 337, loss = 1517461982.22207952\n",
            "Iteration 338, loss = 1517404955.88614655\n",
            "Iteration 339, loss = 1517347564.74510932\n",
            "Iteration 340, loss = 1517290480.22960019\n",
            "Iteration 341, loss = 1517233358.00683308\n",
            "Iteration 342, loss = 1517175979.74636579\n",
            "Iteration 343, loss = 1517118847.25129437\n",
            "Iteration 344, loss = 1517061230.91107750\n",
            "Iteration 345, loss = 1517004279.43321371\n",
            "Iteration 346, loss = 1516946862.09410477\n",
            "Iteration 347, loss = 1516889764.30757737\n",
            "Iteration 348, loss = 1516832414.85962057\n",
            "Iteration 349, loss = 1516775262.80179167\n",
            "Iteration 350, loss = 1516718119.82538843\n",
            "Iteration 351, loss = 1516660942.80883622\n",
            "Iteration 352, loss = 1516604242.53607488\n",
            "Iteration 353, loss = 1516546532.93418431\n",
            "Iteration 354, loss = 1516489558.21781445\n",
            "Iteration 355, loss = 1516432281.07952619\n",
            "Iteration 356, loss = 1516375389.41967583\n",
            "Iteration 357, loss = 1516318061.50681186\n",
            "Iteration 358, loss = 1516260801.76311016\n",
            "Iteration 359, loss = 1516203914.91731501\n",
            "Iteration 360, loss = 1516147148.01162148\n",
            "Iteration 361, loss = 1516089736.67309380\n",
            "Iteration 362, loss = 1516033134.96742988\n",
            "Iteration 363, loss = 1515976061.80550265\n",
            "Iteration 364, loss = 1515919179.59412432\n",
            "Iteration 365, loss = 1515862452.70372367\n",
            "Iteration 366, loss = 1515805465.40571928\n",
            "Iteration 367, loss = 1515748277.11440086\n",
            "Iteration 368, loss = 1515692047.28846097\n",
            "Iteration 369, loss = 1515635089.89138031\n",
            "Iteration 370, loss = 1515578171.24746561\n",
            "Iteration 371, loss = 1515521651.12607837\n",
            "Iteration 372, loss = 1515464977.15200138\n",
            "Iteration 373, loss = 1515408229.47837257\n",
            "Iteration 374, loss = 1515351643.08467269\n",
            "Iteration 375, loss = 1515294707.33735061\n",
            "Iteration 376, loss = 1515238174.24831724\n",
            "Iteration 377, loss = 1515181635.86164713\n",
            "Iteration 378, loss = 1515125104.50341940\n",
            "Iteration 379, loss = 1515068498.19277501\n",
            "Iteration 380, loss = 1515012088.48672509\n",
            "Iteration 381, loss = 1514955656.32718349\n",
            "Iteration 382, loss = 1514898953.46150041\n",
            "Iteration 383, loss = 1514842726.28180718\n",
            "Iteration 384, loss = 1514785822.94886851\n",
            "Iteration 385, loss = 1514729281.08215189\n",
            "Iteration 386, loss = 1514672884.56572223\n",
            "Iteration 387, loss = 1514615851.63792086\n",
            "Iteration 388, loss = 1514559556.47398901\n",
            "Iteration 389, loss = 1514502673.01983476\n",
            "Iteration 390, loss = 1514446080.70733619\n",
            "Iteration 391, loss = 1514389623.39803576\n",
            "Iteration 392, loss = 1514332601.80748487\n",
            "Iteration 393, loss = 1514276249.80673766\n",
            "Iteration 394, loss = 1514220101.04423404\n",
            "Iteration 395, loss = 1514163091.76002049\n",
            "Iteration 396, loss = 1514106394.91286874\n",
            "Iteration 397, loss = 1514050259.20131946\n",
            "Iteration 398, loss = 1513993595.42513633\n",
            "Iteration 399, loss = 1513937307.32312584\n",
            "Iteration 400, loss = 1513880521.71034455\n",
            "Iteration 401, loss = 1513824275.37654805\n",
            "Iteration 402, loss = 1513767511.71846890\n",
            "Iteration 403, loss = 1513711404.01265502\n",
            "Iteration 404, loss = 1513654725.01693416\n",
            "Iteration 405, loss = 1513597904.86853313\n",
            "Iteration 406, loss = 1513541790.50105953\n",
            "Iteration 407, loss = 1513485198.99546552\n",
            "Iteration 408, loss = 1513428242.54458594\n",
            "Iteration 409, loss = 1513372253.96850467\n",
            "Iteration 410, loss = 1513315519.86397290\n",
            "Iteration 411, loss = 1513258972.08726335\n",
            "Iteration 412, loss = 1513202676.41176462\n",
            "Iteration 413, loss = 1513146227.62980437\n",
            "Iteration 414, loss = 1513089724.05388236\n",
            "Iteration 415, loss = 1513033459.36290669\n",
            "Iteration 416, loss = 1512976921.33233190\n",
            "Iteration 417, loss = 1512920514.81677103\n",
            "Iteration 418, loss = 1512864022.66768003\n",
            "Iteration 419, loss = 1512807547.31296420\n",
            "Iteration 420, loss = 1512750746.73084021\n",
            "Iteration 421, loss = 1512694743.69921374\n",
            "Iteration 422, loss = 1512637808.83705306\n",
            "Iteration 423, loss = 1512581685.33708382\n",
            "Iteration 424, loss = 1512525091.00916696\n",
            "Iteration 425, loss = 1512468798.61653519\n",
            "Iteration 426, loss = 1512412422.52711868\n",
            "Iteration 427, loss = 1512356149.63486195\n",
            "Iteration 428, loss = 1512299792.11256599\n",
            "Iteration 429, loss = 1512243431.96619701\n",
            "Iteration 430, loss = 1512187123.87777305\n",
            "Iteration 431, loss = 1512130954.36173677\n",
            "Iteration 432, loss = 1512074739.39474034\n",
            "Iteration 433, loss = 1512018450.38966942\n",
            "Iteration 434, loss = 1511962190.02322507\n",
            "Iteration 435, loss = 1511906153.74740291\n",
            "Iteration 436, loss = 1511850090.29265356\n",
            "Iteration 437, loss = 1511793808.48359609\n",
            "Iteration 438, loss = 1511738153.32130504\n",
            "Iteration 439, loss = 1511682035.52848816\n",
            "Iteration 440, loss = 1511626265.85772061\n",
            "Iteration 441, loss = 1511570564.43806744\n",
            "Iteration 442, loss = 1511514838.01116824\n",
            "Iteration 443, loss = 1511459144.09351349\n",
            "Iteration 444, loss = 1511403489.87424898\n",
            "Iteration 445, loss = 1511347658.07810068\n",
            "Iteration 446, loss = 1511292073.92729473\n",
            "Iteration 447, loss = 1511236191.53001761\n",
            "Iteration 448, loss = 1511180240.95897031\n",
            "Iteration 449, loss = 1511124370.84860730\n",
            "Iteration 450, loss = 1511068357.06026268\n",
            "Iteration 451, loss = 1511012528.39658880\n",
            "Iteration 452, loss = 1510956130.68490720\n",
            "Iteration 453, loss = 1510900128.07512641\n",
            "Iteration 454, loss = 1510843697.90973401\n",
            "Iteration 455, loss = 1510787253.26467681\n",
            "Iteration 456, loss = 1510731399.75747561\n",
            "Iteration 457, loss = 1510675028.09956956\n",
            "Iteration 458, loss = 1510618708.00783515\n",
            "Iteration 459, loss = 1510563135.72991681\n",
            "Iteration 460, loss = 1510506838.97961521\n",
            "Iteration 461, loss = 1510450806.25654674\n",
            "Iteration 462, loss = 1510395286.26234961\n",
            "Iteration 463, loss = 1510339575.17960835\n",
            "Iteration 464, loss = 1510283620.46031737\n",
            "Iteration 465, loss = 1510227665.60634112\n",
            "Iteration 466, loss = 1510172339.36582136\n",
            "Iteration 467, loss = 1510116279.96853518\n",
            "Iteration 468, loss = 1510060895.36056018\n",
            "Iteration 469, loss = 1510005275.16520810\n",
            "Iteration 470, loss = 1509949531.31601644\n",
            "Iteration 471, loss = 1509894338.03076339\n",
            "Iteration 472, loss = 1509838772.95144367\n",
            "Iteration 473, loss = 1509783358.57919717\n",
            "Iteration 474, loss = 1509727700.58373761\n",
            "Iteration 475, loss = 1509672419.73729348\n",
            "Iteration 476, loss = 1509616879.92960501\n",
            "Iteration 477, loss = 1509561016.71504784\n",
            "Iteration 478, loss = 1509505650.94656038\n",
            "Iteration 479, loss = 1509449997.86075807\n",
            "Iteration 480, loss = 1509394731.04495573\n",
            "Iteration 481, loss = 1509339134.69950342\n",
            "Iteration 482, loss = 1509283520.05291653\n",
            "Iteration 483, loss = 1509228559.14448380\n",
            "Iteration 484, loss = 1509172959.92548156\n",
            "Iteration 485, loss = 1509117776.19810963\n",
            "Iteration 486, loss = 1509062129.92934251\n",
            "Iteration 487, loss = 1509006704.38250136\n",
            "Iteration 488, loss = 1508951263.67182302\n",
            "Iteration 489, loss = 1508895821.23329830\n",
            "Iteration 490, loss = 1508840649.42157269\n",
            "Iteration 491, loss = 1508784866.98779798\n",
            "Iteration 492, loss = 1508729904.89766264\n",
            "Iteration 493, loss = 1508674208.40250373\n",
            "Iteration 494, loss = 1508618990.39881611\n",
            "Iteration 495, loss = 1508563920.48482728\n",
            "Iteration 496, loss = 1508508944.71439934\n",
            "Iteration 497, loss = 1508453384.25377631\n",
            "Iteration 498, loss = 1508398316.64945531\n",
            "Iteration 499, loss = 1508343078.08245254\n",
            "Iteration 500, loss = 1508287642.84172583\n",
            "Iteration 501, loss = 1508232849.22060061\n",
            "Iteration 502, loss = 1508177055.81348324\n",
            "Iteration 503, loss = 1508121763.55578041\n",
            "Iteration 504, loss = 1508066148.37717795\n",
            "Iteration 505, loss = 1508010472.60025883\n",
            "Iteration 506, loss = 1507955177.01672506\n",
            "Iteration 507, loss = 1507898897.37350273\n",
            "Iteration 508, loss = 1507843536.47789192\n",
            "Iteration 509, loss = 1507787434.54557514\n",
            "Iteration 510, loss = 1507731714.27669525\n",
            "Iteration 511, loss = 1507676066.68724227\n",
            "Iteration 512, loss = 1507620771.52556062\n",
            "Iteration 513, loss = 1507564344.65705323\n",
            "Iteration 514, loss = 1507509530.52537560\n",
            "Iteration 515, loss = 1507453474.92367840\n",
            "Iteration 516, loss = 1507398020.38016152\n",
            "Iteration 517, loss = 1507342363.71388960\n",
            "Iteration 518, loss = 1507287219.55948615\n",
            "Iteration 519, loss = 1507231300.52748680\n",
            "Iteration 520, loss = 1507175855.70472741\n",
            "Iteration 521, loss = 1507120534.39232230\n",
            "Iteration 522, loss = 1507065168.04780912\n",
            "Iteration 523, loss = 1507009447.31738281\n",
            "Iteration 524, loss = 1506954254.78493237\n",
            "Iteration 525, loss = 1506898714.26663518\n",
            "Iteration 526, loss = 1506843457.44511342\n",
            "Iteration 527, loss = 1506788304.58150387\n",
            "Iteration 528, loss = 1506732515.20307994\n",
            "Iteration 529, loss = 1506677549.07908559\n",
            "Iteration 530, loss = 1506622274.87298775\n",
            "Iteration 531, loss = 1506566917.54430938\n",
            "Iteration 532, loss = 1506511848.98889899\n",
            "Iteration 533, loss = 1506456697.85604405\n",
            "Iteration 534, loss = 1506401238.59031296\n",
            "Iteration 535, loss = 1506346058.68545866\n",
            "Iteration 536, loss = 1506290770.49934673\n",
            "Iteration 537, loss = 1506235283.80791807\n",
            "Iteration 538, loss = 1506179898.65120435\n",
            "Iteration 539, loss = 1506124323.66901278\n",
            "Iteration 540, loss = 1506068631.04228592\n",
            "Iteration 541, loss = 1506012834.76285982\n",
            "Iteration 542, loss = 1505957488.82427931\n",
            "Iteration 543, loss = 1505901571.60752225\n",
            "Iteration 544, loss = 1505846222.41804647\n",
            "Iteration 545, loss = 1505790614.66922545\n",
            "Iteration 546, loss = 1505735388.13200545\n",
            "Iteration 547, loss = 1505680529.68002343\n",
            "Iteration 548, loss = 1505624603.68583465\n",
            "Iteration 549, loss = 1505569570.86333466\n",
            "Iteration 550, loss = 1505514490.64205766\n",
            "Iteration 551, loss = 1505459513.01172018\n",
            "Iteration 552, loss = 1505404195.87309074\n",
            "Iteration 553, loss = 1505348748.87285876\n",
            "Iteration 554, loss = 1505293523.63286495\n",
            "Iteration 555, loss = 1505238439.46789241\n",
            "Iteration 556, loss = 1505182813.85516644\n",
            "Iteration 557, loss = 1505127846.70881891\n",
            "Iteration 558, loss = 1505072683.39837956\n",
            "Iteration 559, loss = 1505017275.35326695\n",
            "Iteration 560, loss = 1504962462.57589698\n",
            "Iteration 561, loss = 1504907369.00779605\n",
            "Iteration 562, loss = 1504852165.97100949\n",
            "Iteration 563, loss = 1504797183.40570664\n",
            "Iteration 564, loss = 1504742194.89972925\n",
            "Iteration 565, loss = 1504687077.16788769\n",
            "Iteration 566, loss = 1504631929.37127018\n",
            "Iteration 567, loss = 1504577190.04915261\n",
            "Iteration 568, loss = 1504521873.43570828\n",
            "Iteration 569, loss = 1504466311.37640738\n",
            "Iteration 570, loss = 1504411388.44569683\n",
            "Iteration 571, loss = 1504356032.34775734\n",
            "Iteration 572, loss = 1504300867.59126329\n",
            "Iteration 573, loss = 1504245667.29554892\n",
            "Iteration 574, loss = 1504190270.51236749\n",
            "Iteration 575, loss = 1504135133.49306536\n",
            "Iteration 576, loss = 1504079917.20605564\n",
            "Iteration 577, loss = 1504024810.56801653\n",
            "Iteration 578, loss = 1503970186.28359675\n",
            "Iteration 579, loss = 1503914813.14485121\n",
            "Iteration 580, loss = 1503859816.21898198\n",
            "Iteration 581, loss = 1503804836.14272904\n",
            "Iteration 582, loss = 1503749821.78938055\n",
            "Iteration 583, loss = 1503694698.46519208\n",
            "Iteration 584, loss = 1503639481.69511747\n",
            "Iteration 585, loss = 1503584772.84635282\n",
            "Iteration 586, loss = 1503529395.01198387\n",
            "Iteration 587, loss = 1503474139.27233577\n",
            "Iteration 588, loss = 1503419070.70813131\n",
            "Iteration 589, loss = 1503363836.81132269\n",
            "Iteration 590, loss = 1503308502.20202518\n",
            "Iteration 591, loss = 1503253200.73851538\n",
            "Iteration 592, loss = 1503198183.89184356\n",
            "Iteration 593, loss = 1503143016.21588469\n",
            "Iteration 594, loss = 1503087718.18420124\n",
            "Iteration 595, loss = 1503032520.52005935\n",
            "Iteration 596, loss = 1502977473.99730253\n",
            "Iteration 597, loss = 1502922589.37437296\n",
            "Iteration 598, loss = 1502867021.27235246\n",
            "Iteration 599, loss = 1502812201.00392890\n",
            "Iteration 600, loss = 1502756997.44730043\n",
            "Iteration 601, loss = 1502702029.36074162\n",
            "Iteration 602, loss = 1502646791.60193610\n",
            "Iteration 603, loss = 1502591900.28985262\n",
            "Iteration 604, loss = 1502536828.93239999\n",
            "Iteration 605, loss = 1502482035.11161685\n",
            "Iteration 606, loss = 1502427046.42295361\n",
            "Iteration 607, loss = 1502372222.18075490\n",
            "Iteration 608, loss = 1502317190.98330402\n",
            "Iteration 609, loss = 1502262403.23768544\n",
            "Iteration 610, loss = 1502207459.74770546\n",
            "Iteration 611, loss = 1502152419.65921783\n",
            "Iteration 612, loss = 1502097500.55240083\n",
            "Iteration 613, loss = 1502042650.62256455\n",
            "Iteration 614, loss = 1501987252.20008850\n",
            "Iteration 615, loss = 1501932702.93987918\n",
            "Iteration 616, loss = 1501877294.76376486\n",
            "Iteration 617, loss = 1501822433.57069564\n",
            "Iteration 618, loss = 1501767623.29386020\n",
            "Iteration 619, loss = 1501712735.18093324\n",
            "Iteration 620, loss = 1501657720.83951640\n",
            "Iteration 621, loss = 1501602727.83648086\n",
            "Iteration 622, loss = 1501547850.03322339\n",
            "Iteration 623, loss = 1501493245.74415135\n",
            "Iteration 624, loss = 1501438181.55439425\n",
            "Iteration 625, loss = 1501383188.55277634\n",
            "Iteration 626, loss = 1501328546.71277142\n",
            "Iteration 627, loss = 1501273581.95984960\n",
            "Iteration 628, loss = 1501218580.02532911\n",
            "Iteration 629, loss = 1501163765.65005660\n",
            "Iteration 630, loss = 1501108935.20918965\n",
            "Iteration 631, loss = 1501054034.17190170\n",
            "Iteration 632, loss = 1500998907.30596876\n",
            "Iteration 633, loss = 1500944199.56410980\n",
            "Iteration 634, loss = 1500889160.11321163\n",
            "Iteration 635, loss = 1500833668.57576776\n",
            "Iteration 636, loss = 1500779203.91731644\n",
            "Iteration 637, loss = 1500724054.19251919\n",
            "Iteration 638, loss = 1500668734.27847767\n",
            "Iteration 639, loss = 1500613947.40527821\n",
            "Iteration 640, loss = 1500558900.30681133\n",
            "Iteration 641, loss = 1500504052.63527179\n",
            "Iteration 642, loss = 1500449030.25529838\n",
            "Iteration 643, loss = 1500394182.64525294\n",
            "Iteration 644, loss = 1500339414.61117363\n",
            "Iteration 645, loss = 1500284333.39485002\n",
            "Iteration 646, loss = 1500230141.29693389\n",
            "Iteration 647, loss = 1500174838.16695333\n",
            "Iteration 648, loss = 1500119966.31648183\n",
            "Iteration 649, loss = 1500065681.51056266\n",
            "Iteration 650, loss = 1500010569.69859672\n",
            "Iteration 651, loss = 1499955781.76071239\n",
            "Iteration 652, loss = 1499900941.51960182\n",
            "Iteration 653, loss = 1499846158.39665961\n",
            "Iteration 654, loss = 1499791669.16122580\n",
            "Iteration 655, loss = 1499736725.03318286\n",
            "Iteration 656, loss = 1499682009.33915043\n",
            "Iteration 657, loss = 1499627077.71992469\n",
            "Iteration 658, loss = 1499572747.93787050\n",
            "Iteration 659, loss = 1499517364.83352852\n",
            "Iteration 660, loss = 1499462723.92133927\n",
            "Iteration 661, loss = 1499407876.63883996\n",
            "Iteration 662, loss = 1499352992.85503435\n",
            "Iteration 663, loss = 1499298356.28342867\n",
            "Iteration 664, loss = 1499243516.83728600\n",
            "Iteration 665, loss = 1499188652.31778717\n",
            "Iteration 666, loss = 1499134139.47249579\n",
            "Iteration 667, loss = 1499079590.80291486\n",
            "Iteration 668, loss = 1499024867.35165048\n",
            "Iteration 669, loss = 1498970097.88959980\n",
            "Iteration 670, loss = 1498915270.77115226\n",
            "Iteration 671, loss = 1498860920.35763049\n",
            "Iteration 672, loss = 1498805991.25201225\n",
            "Iteration 673, loss = 1498750819.73735476\n",
            "Iteration 674, loss = 1498696750.50926232\n",
            "Iteration 675, loss = 1498641683.45739079\n",
            "Iteration 676, loss = 1498586704.62248302\n",
            "Iteration 677, loss = 1498532198.66510868\n",
            "Iteration 678, loss = 1498477651.16127491\n",
            "Iteration 679, loss = 1498422731.59063458\n",
            "Iteration 680, loss = 1498367722.58542514\n",
            "Iteration 681, loss = 1498313108.56808209\n",
            "Iteration 682, loss = 1498258773.24611163\n",
            "Iteration 683, loss = 1498203760.47504044\n",
            "Iteration 684, loss = 1498148879.37706876\n",
            "Iteration 685, loss = 1498094397.12413263\n",
            "Iteration 686, loss = 1498039444.22709417\n",
            "Iteration 687, loss = 1497985144.55219531\n",
            "Iteration 688, loss = 1497930880.50181794\n",
            "Iteration 689, loss = 1497875936.05016208\n",
            "Iteration 690, loss = 1497821419.58722663\n",
            "Iteration 691, loss = 1497766982.82769465\n",
            "Iteration 692, loss = 1497712706.64124656\n",
            "Iteration 693, loss = 1497657926.53482533\n",
            "Iteration 694, loss = 1497603485.03041577\n",
            "Iteration 695, loss = 1497548858.39261937\n",
            "Iteration 696, loss = 1497494513.80286050\n",
            "Iteration 697, loss = 1497440081.31020999\n",
            "Iteration 698, loss = 1497385385.76784611\n",
            "Iteration 699, loss = 1497330854.39765882\n",
            "Iteration 700, loss = 1497276439.01303792\n",
            "Iteration 701, loss = 1497221679.54743004\n",
            "Iteration 702, loss = 1497167236.14881396\n",
            "Iteration 703, loss = 1497112487.70684767\n",
            "Iteration 704, loss = 1497058362.82328176\n",
            "Iteration 705, loss = 1497003629.22021890\n",
            "Iteration 706, loss = 1496949371.69319057\n",
            "Iteration 707, loss = 1496895106.83470106\n",
            "Iteration 708, loss = 1496840792.97585630\n",
            "Iteration 709, loss = 1496786569.80122328\n",
            "Iteration 710, loss = 1496732369.03640795\n",
            "Iteration 711, loss = 1496677902.32616091\n",
            "Iteration 712, loss = 1496623670.01553249\n",
            "Iteration 713, loss = 1496569091.46887994\n",
            "Iteration 714, loss = 1496514727.22249079\n",
            "Iteration 715, loss = 1496459719.61010647\n",
            "Iteration 716, loss = 1496405379.02699065\n",
            "Iteration 717, loss = 1496350650.14626884\n",
            "Iteration 718, loss = 1496295735.19428587\n",
            "Iteration 719, loss = 1496241012.02081084\n",
            "Iteration 720, loss = 1496186162.93878818\n",
            "Iteration 721, loss = 1496131215.73527122\n",
            "Iteration 722, loss = 1496076856.07166839\n",
            "Iteration 723, loss = 1496022165.36240554\n",
            "Iteration 724, loss = 1495967443.33338594\n",
            "Iteration 725, loss = 1495912219.34765267\n",
            "Iteration 726, loss = 1495858211.90331292\n",
            "Iteration 727, loss = 1495803511.98846722\n",
            "Iteration 728, loss = 1495748697.80728316\n",
            "Iteration 729, loss = 1495693900.08683133\n",
            "Iteration 730, loss = 1495639515.13966584\n",
            "Iteration 731, loss = 1495584731.34981751\n",
            "Iteration 732, loss = 1495529930.15074706\n",
            "Iteration 733, loss = 1495475535.69343090\n",
            "Iteration 734, loss = 1495420827.65660071\n",
            "Iteration 735, loss = 1495366243.80074644\n",
            "Iteration 736, loss = 1495311512.39859438\n",
            "Iteration 737, loss = 1495257079.01401854\n",
            "Iteration 738, loss = 1495202203.85495830\n",
            "Iteration 739, loss = 1495147446.51490355\n",
            "Iteration 740, loss = 1495092705.69142914\n",
            "Iteration 741, loss = 1495038078.93241334\n",
            "Iteration 742, loss = 1494982682.48616743\n",
            "Iteration 743, loss = 1494928203.56025505\n",
            "Iteration 744, loss = 1494873515.07547545\n",
            "Iteration 745, loss = 1494818684.03525949\n",
            "Iteration 746, loss = 1494764274.94265580\n",
            "Iteration 747, loss = 1494710206.60022473\n",
            "Iteration 748, loss = 1494655566.67007422\n",
            "Iteration 749, loss = 1494601206.25154305\n",
            "Iteration 750, loss = 1494547154.72633576\n",
            "Iteration 751, loss = 1494492849.71927619\n",
            "Iteration 752, loss = 1494438646.78732657\n",
            "Iteration 753, loss = 1494384845.07949686\n",
            "Iteration 754, loss = 1494330165.92466497\n",
            "Iteration 755, loss = 1494276370.14259791\n",
            "Iteration 756, loss = 1494221972.98707223\n",
            "Iteration 757, loss = 1494167848.42969131\n",
            "Iteration 758, loss = 1494113555.91385794\n",
            "Iteration 759, loss = 1494059253.45928144\n",
            "Iteration 760, loss = 1494005100.45681548\n",
            "Iteration 761, loss = 1493950720.79080892\n",
            "Iteration 762, loss = 1493896135.14362788\n",
            "Iteration 763, loss = 1493841964.91052413\n",
            "Iteration 764, loss = 1493787851.91855192\n",
            "Iteration 765, loss = 1493733144.83148575\n",
            "Iteration 766, loss = 1493679111.17554498\n",
            "Iteration 767, loss = 1493624634.51219320\n",
            "Iteration 768, loss = 1493570630.53454518\n",
            "Iteration 769, loss = 1493516143.78472424\n",
            "Iteration 770, loss = 1493461649.18663430\n",
            "Iteration 771, loss = 1493407756.41360831\n",
            "Iteration 772, loss = 1493353600.98348284\n",
            "Iteration 773, loss = 1493299434.13251877\n",
            "Iteration 774, loss = 1493245017.14897561\n",
            "Iteration 775, loss = 1493190757.61504602\n",
            "Iteration 776, loss = 1493136588.19789290\n",
            "Iteration 777, loss = 1493082161.34639406\n",
            "Iteration 778, loss = 1493027920.94151950\n",
            "Iteration 779, loss = 1492973520.69116306\n",
            "Iteration 780, loss = 1492918679.89360094\n",
            "Iteration 781, loss = 1492864355.27368593\n",
            "Iteration 782, loss = 1492809897.15249419\n",
            "Iteration 783, loss = 1492755572.20290542\n",
            "Iteration 784, loss = 1492700822.85300398\n",
            "Iteration 785, loss = 1492646785.02209091\n",
            "Iteration 786, loss = 1492591939.95321727\n",
            "Iteration 787, loss = 1492537684.36710477\n",
            "Iteration 788, loss = 1492483552.61082196\n",
            "Iteration 789, loss = 1492429119.34797955\n",
            "Iteration 790, loss = 1492374520.09942698\n",
            "Iteration 791, loss = 1492320429.70049143\n",
            "Iteration 792, loss = 1492266395.27359295\n",
            "Iteration 793, loss = 1492212178.15001345\n",
            "Iteration 794, loss = 1492157782.93337560\n",
            "Iteration 795, loss = 1492103829.34567857\n",
            "Iteration 796, loss = 1492049683.53100419\n",
            "Iteration 797, loss = 1491995790.79272366\n",
            "Iteration 798, loss = 1491941289.87414217\n",
            "Iteration 799, loss = 1491887369.02758884\n",
            "Iteration 800, loss = 1491833112.03637552\n",
            "Iteration 801, loss = 1491778843.58162999\n",
            "Iteration 802, loss = 1491724507.91477966\n",
            "Iteration 803, loss = 1491670264.17579103\n",
            "Iteration 804, loss = 1491615966.33974600\n",
            "Iteration 805, loss = 1491561253.24541187\n",
            "Iteration 806, loss = 1491507211.92222309\n",
            "Iteration 807, loss = 1491452611.28719401\n",
            "Iteration 808, loss = 1491398266.39050031\n",
            "Iteration 809, loss = 1491343960.72322845\n",
            "Iteration 810, loss = 1491289158.37869334\n",
            "Iteration 811, loss = 1491235366.14165473\n",
            "Iteration 812, loss = 1491180832.95657849\n",
            "Iteration 813, loss = 1491126724.32911181\n",
            "Iteration 814, loss = 1491072188.30762458\n",
            "Iteration 815, loss = 1491018313.71444678\n",
            "Iteration 816, loss = 1490963582.85008478\n",
            "Iteration 817, loss = 1490909440.68908000\n",
            "Iteration 818, loss = 1490855188.62371182\n",
            "Iteration 819, loss = 1490800861.51585770\n",
            "Iteration 820, loss = 1490746652.02422595\n",
            "Iteration 821, loss = 1490692393.10092640\n",
            "Iteration 822, loss = 1490638113.21691895\n",
            "Iteration 823, loss = 1490583957.04069376\n",
            "Iteration 824, loss = 1490529813.58283329\n",
            "Iteration 825, loss = 1490475718.36480880\n",
            "Iteration 826, loss = 1490421510.83724856\n",
            "Iteration 827, loss = 1490367359.04092145\n",
            "Iteration 828, loss = 1490313191.08835101\n",
            "Iteration 829, loss = 1490259239.24835920\n",
            "Iteration 830, loss = 1490204762.41786146\n",
            "Iteration 831, loss = 1490150932.14228153\n",
            "Iteration 832, loss = 1490096830.21818399\n",
            "Iteration 833, loss = 1490042607.66841483\n",
            "Iteration 834, loss = 1489988369.42856693\n",
            "Iteration 835, loss = 1489934770.88655543\n",
            "Iteration 836, loss = 1489880565.62699771\n",
            "Iteration 837, loss = 1489826283.22458410\n",
            "Iteration 838, loss = 1489772036.48807454\n",
            "Iteration 839, loss = 1489718093.34027362\n",
            "Iteration 840, loss = 1489663915.44441772\n",
            "Iteration 841, loss = 1489609622.26726699\n",
            "Iteration 842, loss = 1489555399.86632299\n",
            "Iteration 843, loss = 1489501375.89972997\n",
            "Iteration 844, loss = 1489447417.86559701\n",
            "Iteration 845, loss = 1489393529.08892298\n",
            "Iteration 846, loss = 1489339647.83857894\n",
            "Iteration 847, loss = 1489285039.99561095\n",
            "Iteration 848, loss = 1489231449.89011955\n",
            "Iteration 849, loss = 1489177418.95417285\n",
            "Iteration 850, loss = 1489122951.18849254\n",
            "Iteration 851, loss = 1489068757.39186120\n",
            "Iteration 852, loss = 1489014323.28272724\n",
            "Iteration 853, loss = 1488960325.85999608\n",
            "Iteration 854, loss = 1488905557.51892185\n",
            "Iteration 855, loss = 1488851180.51149368\n",
            "Iteration 856, loss = 1488797006.73378038\n",
            "Iteration 857, loss = 1488743058.46313953\n",
            "Iteration 858, loss = 1488688358.59401059\n",
            "Iteration 859, loss = 1488634303.66329885\n",
            "Iteration 860, loss = 1488580091.17093110\n",
            "Iteration 861, loss = 1488526098.20503807\n",
            "Iteration 862, loss = 1488471932.42728186\n",
            "Iteration 863, loss = 1488417906.48725557\n",
            "Iteration 864, loss = 1488363837.38676786\n",
            "Iteration 865, loss = 1488309783.11330938\n",
            "Iteration 866, loss = 1488255851.95161223\n",
            "Iteration 867, loss = 1488202222.36241031\n",
            "Iteration 868, loss = 1488147724.86261940\n",
            "Iteration 869, loss = 1488093995.16480613\n",
            "Iteration 870, loss = 1488039895.21344447\n",
            "Iteration 871, loss = 1487986061.70338202\n",
            "Iteration 872, loss = 1487931898.22213292\n",
            "Iteration 873, loss = 1487877681.95045137\n",
            "Iteration 874, loss = 1487823560.87290072\n",
            "Iteration 875, loss = 1487769396.88985610\n",
            "Iteration 876, loss = 1487715430.26583600\n",
            "Iteration 877, loss = 1487661151.58616114\n",
            "Iteration 878, loss = 1487607133.08540273\n",
            "Iteration 879, loss = 1487553231.69781542\n",
            "Iteration 880, loss = 1487498906.81019998\n",
            "Iteration 881, loss = 1487445354.42659640\n",
            "Iteration 882, loss = 1487390984.06648231\n",
            "Iteration 883, loss = 1487337482.76276469\n",
            "Iteration 884, loss = 1487283124.20358539\n",
            "Iteration 885, loss = 1487228990.88042712\n",
            "Iteration 886, loss = 1487175099.17777729\n",
            "Iteration 887, loss = 1487121002.46795535\n",
            "Iteration 888, loss = 1487066927.04924583\n",
            "Iteration 889, loss = 1487012991.86416197\n",
            "Iteration 890, loss = 1486958759.71763515\n",
            "Iteration 891, loss = 1486905049.48673773\n",
            "Iteration 892, loss = 1486850894.24650717\n",
            "Iteration 893, loss = 1486796979.89404011\n",
            "Iteration 894, loss = 1486742810.84997988\n",
            "Iteration 895, loss = 1486688594.54710531\n",
            "Iteration 896, loss = 1486634341.60663414\n",
            "Iteration 897, loss = 1486579560.11407495\n",
            "Iteration 898, loss = 1486525508.33817458\n",
            "Iteration 899, loss = 1486470686.42774963\n",
            "Iteration 900, loss = 1486416486.62959957\n",
            "Iteration 901, loss = 1486361936.94964290\n",
            "Iteration 902, loss = 1486307455.93105006\n",
            "Iteration 903, loss = 1486252888.32012868\n",
            "Iteration 904, loss = 1486198695.31306171\n",
            "Iteration 905, loss = 1486143912.20871282\n",
            "Iteration 906, loss = 1486089698.55754185\n",
            "Iteration 907, loss = 1486035392.13388205\n",
            "Iteration 908, loss = 1485980981.48886752\n",
            "Iteration 909, loss = 1485926409.25084281\n",
            "Iteration 910, loss = 1485872005.92189789\n",
            "Iteration 911, loss = 1485818374.51326776\n",
            "Iteration 912, loss = 1485764225.70744371\n",
            "Iteration 913, loss = 1485709703.71347404\n",
            "Iteration 914, loss = 1485656001.54294205\n",
            "Iteration 915, loss = 1485601606.17455220\n",
            "Iteration 916, loss = 1485547726.84109831\n",
            "Iteration 917, loss = 1485493613.80517864\n",
            "Iteration 918, loss = 1485439659.39262891\n",
            "Iteration 919, loss = 1485385325.54164553\n",
            "Iteration 920, loss = 1485331670.92931271\n",
            "Iteration 921, loss = 1485277363.36043024\n",
            "Iteration 922, loss = 1485223539.35877013\n",
            "Iteration 923, loss = 1485169485.69460487\n",
            "Iteration 924, loss = 1485115253.12063313\n",
            "Iteration 925, loss = 1485061446.41105604\n",
            "Iteration 926, loss = 1485007340.89514041\n",
            "Iteration 927, loss = 1484953660.96882558\n",
            "Iteration 928, loss = 1484899697.16719413\n",
            "Iteration 929, loss = 1484845867.40090561\n",
            "Iteration 930, loss = 1484792124.34765482\n",
            "Iteration 931, loss = 1484738495.88833499\n",
            "Iteration 932, loss = 1484684706.58471346\n",
            "Iteration 933, loss = 1484631028.83951044\n",
            "Iteration 934, loss = 1484577091.70046973\n",
            "Iteration 935, loss = 1484523152.94374633\n",
            "Iteration 936, loss = 1484469354.48942709\n",
            "Iteration 937, loss = 1484415163.22881603\n",
            "Iteration 938, loss = 1484361113.69782734\n",
            "Iteration 939, loss = 1484307379.36925364\n",
            "Iteration 940, loss = 1484253107.83123183\n",
            "Iteration 941, loss = 1484199307.91323829\n",
            "Iteration 942, loss = 1484145453.04444718\n",
            "Iteration 943, loss = 1484091602.03781247\n",
            "Iteration 944, loss = 1484037616.51418257\n",
            "Iteration 945, loss = 1483984079.05219102\n",
            "Iteration 946, loss = 1483930324.68232918\n",
            "Iteration 947, loss = 1483876739.25181150\n",
            "Iteration 948, loss = 1483822965.25780272\n",
            "Iteration 949, loss = 1483769266.64249825\n",
            "Iteration 950, loss = 1483715784.14578271\n",
            "Iteration 951, loss = 1483662123.83187914\n",
            "Iteration 952, loss = 1483608627.44910741\n",
            "Iteration 953, loss = 1483555070.94466949\n",
            "Iteration 954, loss = 1483501498.45425320\n",
            "Iteration 955, loss = 1483448125.91065669\n",
            "Iteration 956, loss = 1483394259.96956420\n",
            "Iteration 957, loss = 1483340780.11893749\n",
            "Iteration 958, loss = 1483287176.81176257\n",
            "Iteration 959, loss = 1483233156.53895760\n",
            "Iteration 960, loss = 1483179599.33728862\n",
            "Iteration 961, loss = 1483125405.14600134\n",
            "Iteration 962, loss = 1483071526.29538250\n",
            "Iteration 963, loss = 1483017535.10413814\n",
            "Iteration 964, loss = 1482963672.03390598\n",
            "Iteration 965, loss = 1482910139.53032970\n",
            "Iteration 966, loss = 1482856248.91462159\n",
            "Iteration 967, loss = 1482802880.31502604\n",
            "Iteration 968, loss = 1482748967.27175975\n",
            "Iteration 969, loss = 1482695491.60056543\n",
            "Iteration 970, loss = 1482641948.75443196\n",
            "Iteration 971, loss = 1482588475.57067418\n",
            "Iteration 972, loss = 1482534552.25826049\n",
            "Iteration 973, loss = 1482480694.97173834\n",
            "Iteration 974, loss = 1482427346.18590021\n",
            "Iteration 975, loss = 1482373476.29570413\n",
            "Iteration 976, loss = 1482319967.91679406\n",
            "Iteration 977, loss = 1482266043.37532592\n",
            "Iteration 978, loss = 1482212483.14516687\n",
            "Iteration 979, loss = 1482158746.59049153\n",
            "Iteration 980, loss = 1482104798.33315516\n",
            "Iteration 981, loss = 1482051172.13790941\n",
            "Iteration 982, loss = 1481997309.25169110\n",
            "Iteration 983, loss = 1481943758.94141173\n",
            "Iteration 984, loss = 1481889782.19754720\n",
            "Iteration 985, loss = 1481836185.01109362\n",
            "Iteration 986, loss = 1481782879.60932589\n",
            "Iteration 987, loss = 1481729584.75555587\n",
            "Iteration 988, loss = 1481675899.65535259\n",
            "Iteration 989, loss = 1481622862.71291780\n",
            "Iteration 990, loss = 1481569446.87881136\n",
            "Iteration 991, loss = 1481515969.34608626\n",
            "Iteration 992, loss = 1481463027.71553636\n",
            "Iteration 993, loss = 1481409160.93664622\n",
            "Iteration 994, loss = 1481355751.12112522\n",
            "Iteration 995, loss = 1481302496.88773203\n",
            "Iteration 996, loss = 1481248926.62358856\n",
            "Iteration 997, loss = 1481195457.88680291\n",
            "Iteration 998, loss = 1481141834.10709453\n",
            "Iteration 999, loss = 1481088500.72919202\n",
            "Iteration 1000, loss = 1481034830.14032578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1535283020.35876107\n",
            "Iteration 2, loss = 313745864.21333671\n",
            "Iteration 3, loss = 136829473.06907964\n",
            "Iteration 4, loss = 146792907.17400247\n",
            "Iteration 5, loss = 53600489.02012508\n",
            "Iteration 6, loss = 22886354.01286212\n",
            "Iteration 7, loss = 25477365.12474183\n",
            "Iteration 8, loss = 19979518.66042015\n",
            "Iteration 9, loss = 22083544.48821037\n",
            "Iteration 10, loss = 22782353.25693518\n",
            "Iteration 11, loss = 23657781.38626236\n",
            "Iteration 12, loss = 22348822.15164983\n",
            "Iteration 13, loss = 20309358.98632009\n",
            "Iteration 14, loss = 18960645.92942203\n",
            "Iteration 15, loss = 17636093.92174664\n",
            "Iteration 16, loss = 16197826.45280719\n",
            "Iteration 17, loss = 15228713.39030463\n",
            "Iteration 18, loss = 14122284.74464249\n",
            "Iteration 19, loss = 13221835.32203677\n",
            "Iteration 20, loss = 12460379.25696633\n",
            "Iteration 21, loss = 11854828.03363256\n",
            "Iteration 22, loss = 11294868.86376836\n",
            "Iteration 23, loss = 10750674.83228894\n",
            "Iteration 24, loss = 10340567.36868956\n",
            "Iteration 25, loss = 9807377.88250212\n",
            "Iteration 26, loss = 9407001.01325345\n",
            "Iteration 27, loss = 8703681.70104346\n",
            "Iteration 28, loss = 8619629.31247304\n",
            "Iteration 29, loss = 8959077.45387847\n",
            "Iteration 30, loss = 8489246.98476039\n",
            "Iteration 31, loss = 8336452.68260699\n",
            "Iteration 32, loss = 8131058.85664813\n",
            "Iteration 33, loss = 7646876.22117876\n",
            "Iteration 34, loss = 7472418.63503763\n",
            "Iteration 35, loss = 7300395.96254458\n",
            "Iteration 36, loss = 7172554.18975358\n",
            "Iteration 37, loss = 7065466.87751113\n",
            "Iteration 38, loss = 6887164.20340003\n",
            "Iteration 39, loss = 6746534.57966706\n",
            "Iteration 40, loss = 6584035.95072004\n",
            "Iteration 41, loss = 6472175.10912242\n",
            "Iteration 42, loss = 6332521.98564646\n",
            "Iteration 43, loss = 6287058.85011072\n",
            "Iteration 44, loss = 6261162.43708138\n",
            "Iteration 45, loss = 6380900.10418863\n",
            "Iteration 46, loss = 6092295.63810326\n",
            "Iteration 47, loss = 5978889.32248540\n",
            "Iteration 48, loss = 5945379.40379424\n",
            "Iteration 49, loss = 5878752.00723677\n",
            "Iteration 50, loss = 5817937.16747240\n",
            "Iteration 51, loss = 5843269.42923205\n",
            "Iteration 52, loss = 5792510.03785637\n",
            "Iteration 53, loss = 5718823.80288851\n",
            "Iteration 54, loss = 5650978.87386995\n",
            "Iteration 55, loss = 5624175.19030512\n",
            "Iteration 56, loss = 5568370.15489939\n",
            "Iteration 57, loss = 5528948.89331344\n",
            "Iteration 58, loss = 5514344.25599841\n",
            "Iteration 59, loss = 5508522.74833717\n",
            "Iteration 60, loss = 5453228.39277500\n",
            "Iteration 61, loss = 5528798.89186295\n",
            "Iteration 62, loss = 5467633.83584024\n",
            "Iteration 63, loss = 5381703.39787517\n",
            "Iteration 64, loss = 5396197.76081648\n",
            "Iteration 65, loss = 5414579.00547809\n",
            "Iteration 66, loss = 5375996.81203839\n",
            "Iteration 67, loss = 5320998.25380218\n",
            "Iteration 68, loss = 5281486.35985751\n",
            "Iteration 69, loss = 5281736.61891162\n",
            "Iteration 70, loss = 5258840.99275691\n",
            "Iteration 71, loss = 5248135.72425266\n",
            "Iteration 72, loss = 5255304.23524624\n",
            "Iteration 73, loss = 5215980.86327267\n",
            "Iteration 74, loss = 5237787.56759914\n",
            "Iteration 75, loss = 5211804.20901319\n",
            "Iteration 76, loss = 5190011.28857069\n",
            "Iteration 77, loss = 5194770.33620885\n",
            "Iteration 78, loss = 5202780.11289242\n",
            "Iteration 79, loss = 5172243.44529691\n",
            "Iteration 80, loss = 5189450.31535846\n",
            "Iteration 81, loss = 5149961.75999266\n",
            "Iteration 82, loss = 5156549.52397280\n",
            "Iteration 83, loss = 5132579.93741354\n",
            "Iteration 84, loss = 5147060.04292665\n",
            "Iteration 85, loss = 5123854.51915590\n",
            "Iteration 86, loss = 5109583.87855335\n",
            "Iteration 87, loss = 5102503.19416042\n",
            "Iteration 88, loss = 5094756.51172651\n",
            "Iteration 89, loss = 5096488.01381915\n",
            "Iteration 90, loss = 5107177.38709241\n",
            "Iteration 91, loss = 5077253.69384986\n",
            "Iteration 92, loss = 5068980.32713582\n",
            "Iteration 93, loss = 5069321.18871210\n",
            "Iteration 94, loss = 5095369.94524879\n",
            "Iteration 95, loss = 5047668.93069741\n",
            "Iteration 96, loss = 5050739.94170526\n",
            "Iteration 97, loss = 5055981.03867673\n",
            "Iteration 98, loss = 5060672.08760602\n",
            "Iteration 99, loss = 5100451.15412222\n",
            "Iteration 100, loss = 5145564.51892264\n",
            "Iteration 101, loss = 5039985.24655260\n",
            "Iteration 102, loss = 5011299.88229464\n",
            "Iteration 103, loss = 5071728.66655743\n",
            "Iteration 104, loss = 5075065.59739095\n",
            "Iteration 105, loss = 5061665.27177125\n",
            "Iteration 106, loss = 5003332.63780711\n",
            "Iteration 107, loss = 5003617.94173616\n",
            "Iteration 108, loss = 4991041.16763239\n",
            "Iteration 109, loss = 4992679.52864745\n",
            "Iteration 110, loss = 4973251.40184551\n",
            "Iteration 111, loss = 5035367.25887298\n",
            "Iteration 112, loss = 4982477.91450405\n",
            "Iteration 113, loss = 4957032.31758941\n",
            "Iteration 114, loss = 5017150.10534780\n",
            "Iteration 115, loss = 5003515.03791722\n",
            "Iteration 116, loss = 4993768.11939713\n",
            "Iteration 117, loss = 5033532.13043103\n",
            "Iteration 118, loss = 4959088.60950035\n",
            "Iteration 119, loss = 4981158.95809989\n",
            "Iteration 120, loss = 4974503.75862018\n",
            "Iteration 121, loss = 4983567.96674948\n",
            "Iteration 122, loss = 5065880.63335335\n",
            "Iteration 123, loss = 4934100.39061518\n",
            "Iteration 124, loss = 4940678.80209743\n",
            "Iteration 125, loss = 4952397.40418167\n",
            "Iteration 126, loss = 5018585.62336062\n",
            "Iteration 127, loss = 5028397.07723992\n",
            "Iteration 128, loss = 4943009.66680596\n",
            "Iteration 129, loss = 4910972.61250484\n",
            "Iteration 130, loss = 4908833.43951384\n",
            "Iteration 131, loss = 4894462.97009185\n",
            "Iteration 132, loss = 4938765.50015449\n",
            "Iteration 133, loss = 4953016.92269952\n",
            "Iteration 134, loss = 4948331.86733180\n",
            "Iteration 135, loss = 4872572.98509643\n",
            "Iteration 136, loss = 4894003.18986940\n",
            "Iteration 137, loss = 4876517.33704076\n",
            "Iteration 138, loss = 4921187.58499637\n",
            "Iteration 139, loss = 4867841.57494571\n",
            "Iteration 140, loss = 4887157.76955187\n",
            "Iteration 141, loss = 4891030.65390548\n",
            "Iteration 142, loss = 4855077.39868340\n",
            "Iteration 143, loss = 4867354.63626397\n",
            "Iteration 144, loss = 4850264.22546068\n",
            "Iteration 145, loss = 4863513.51962243\n",
            "Iteration 146, loss = 4883314.64963753\n",
            "Iteration 147, loss = 4878966.52122531\n",
            "Iteration 148, loss = 4874620.68961255\n",
            "Iteration 149, loss = 4866182.42958087\n",
            "Iteration 150, loss = 4859709.34040684\n",
            "Iteration 151, loss = 4894236.76054198\n",
            "Iteration 152, loss = 4931857.43820897\n",
            "Iteration 153, loss = 4877463.36001930\n",
            "Iteration 154, loss = 4829934.60272380\n",
            "Iteration 155, loss = 4837296.66906159\n",
            "Iteration 156, loss = 4849160.17622223\n",
            "Iteration 157, loss = 4814771.06804981\n",
            "Iteration 158, loss = 4845237.81672780\n",
            "Iteration 159, loss = 4826707.84160873\n",
            "Iteration 160, loss = 4834716.34493361\n",
            "Iteration 161, loss = 4852809.45241716\n",
            "Iteration 162, loss = 4858913.16133182\n",
            "Iteration 163, loss = 4813601.82542892\n",
            "Iteration 164, loss = 4810310.21312911\n",
            "Iteration 165, loss = 4800656.37112412\n",
            "Iteration 166, loss = 4807172.83440230\n",
            "Iteration 167, loss = 4787197.82247555\n",
            "Iteration 168, loss = 4805473.12866798\n",
            "Iteration 169, loss = 4796699.87952804\n",
            "Iteration 170, loss = 4805314.10158277\n",
            "Iteration 171, loss = 4848515.63607315\n",
            "Iteration 172, loss = 4787158.17750627\n",
            "Iteration 173, loss = 4776484.47756241\n",
            "Iteration 174, loss = 4777072.64558472\n",
            "Iteration 175, loss = 4772804.51091976\n",
            "Iteration 176, loss = 4770637.21268854\n",
            "Iteration 177, loss = 4785853.94428937\n",
            "Iteration 178, loss = 4806084.90669885\n",
            "Iteration 179, loss = 4774216.07242168\n",
            "Iteration 180, loss = 4758532.84632410\n",
            "Iteration 181, loss = 4753661.86904341\n",
            "Iteration 182, loss = 4766624.92416553\n",
            "Iteration 183, loss = 4796257.25194977\n",
            "Iteration 184, loss = 4803061.25657775\n",
            "Iteration 185, loss = 4759658.27637628\n",
            "Iteration 186, loss = 4763299.55561029\n",
            "Iteration 187, loss = 4757829.62163984\n",
            "Iteration 188, loss = 4770136.29988169\n",
            "Iteration 189, loss = 4739443.99701759\n",
            "Iteration 190, loss = 4740899.75915606\n",
            "Iteration 191, loss = 4765531.66001504\n",
            "Iteration 192, loss = 4767527.73573631\n",
            "Iteration 193, loss = 4737366.47813600\n",
            "Iteration 194, loss = 4797593.80248752\n",
            "Iteration 195, loss = 4725506.79632667\n",
            "Iteration 196, loss = 4719857.30093245\n",
            "Iteration 197, loss = 4752213.21216470\n",
            "Iteration 198, loss = 4710593.72727897\n",
            "Iteration 199, loss = 4796947.80338119\n",
            "Iteration 200, loss = 4725128.94103018\n",
            "Iteration 201, loss = 4717793.54150864\n",
            "Iteration 202, loss = 4704487.61487290\n",
            "Iteration 203, loss = 4713879.56446951\n",
            "Iteration 204, loss = 4719055.31753942\n",
            "Iteration 205, loss = 4818885.59988524\n",
            "Iteration 206, loss = 4743908.24386071\n",
            "Iteration 207, loss = 4706824.99283211\n",
            "Iteration 208, loss = 4707055.47222046\n",
            "Iteration 209, loss = 4696140.63870576\n",
            "Iteration 210, loss = 4707636.71925433\n",
            "Iteration 211, loss = 4700288.49876387\n",
            "Iteration 212, loss = 4689168.61464728\n",
            "Iteration 213, loss = 4689891.99222528\n",
            "Iteration 214, loss = 4690692.03553188\n",
            "Iteration 215, loss = 4686445.55890371\n",
            "Iteration 216, loss = 4688639.83896194\n",
            "Iteration 217, loss = 4761164.81894014\n",
            "Iteration 218, loss = 4832609.57489816\n",
            "Iteration 219, loss = 4729077.73074458\n",
            "Iteration 220, loss = 4680688.79177597\n",
            "Iteration 221, loss = 4691842.02076201\n",
            "Iteration 222, loss = 4776763.31948569\n",
            "Iteration 223, loss = 4768736.56403969\n",
            "Iteration 224, loss = 4687138.89981113\n",
            "Iteration 225, loss = 4675853.05432223\n",
            "Iteration 226, loss = 4678134.67170644\n",
            "Iteration 227, loss = 4718288.18333154\n",
            "Iteration 228, loss = 4676180.86144900\n",
            "Iteration 229, loss = 4660042.04753257\n",
            "Iteration 230, loss = 4655785.67136670\n",
            "Iteration 231, loss = 4691159.01127503\n",
            "Iteration 232, loss = 4819649.08553374\n",
            "Iteration 233, loss = 4733619.97956196\n",
            "Iteration 234, loss = 4661189.87048307\n",
            "Iteration 235, loss = 4652871.13292653\n",
            "Iteration 236, loss = 4675161.14528671\n",
            "Iteration 237, loss = 4672742.72284549\n",
            "Iteration 238, loss = 4641466.37672046\n",
            "Iteration 239, loss = 4656368.36661005\n",
            "Iteration 240, loss = 4723970.18866338\n",
            "Iteration 241, loss = 4628919.95800001\n",
            "Iteration 242, loss = 4741826.55480060\n",
            "Iteration 243, loss = 4678734.22332694\n",
            "Iteration 244, loss = 4695357.76304576\n",
            "Iteration 245, loss = 4670402.17713300\n",
            "Iteration 246, loss = 4632076.09417286\n",
            "Iteration 247, loss = 4677259.06110203\n",
            "Iteration 248, loss = 4672635.27659113\n",
            "Iteration 249, loss = 4664709.92823102\n",
            "Iteration 250, loss = 4629570.31549066\n",
            "Iteration 251, loss = 4669091.69784676\n",
            "Iteration 252, loss = 4669639.08361021\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538853420.69172692\n",
            "Iteration 2, loss = 1538826637.97610235\n",
            "Iteration 3, loss = 1538801542.00690246\n",
            "Iteration 4, loss = 1538777575.71682549\n",
            "Iteration 5, loss = 1538752345.41246843\n",
            "Iteration 6, loss = 1538728005.67126417\n",
            "Iteration 7, loss = 1538702446.79675317\n",
            "Iteration 8, loss = 1538676730.19205952\n",
            "Iteration 9, loss = 1538650185.86601710\n",
            "Iteration 10, loss = 1538623041.96110773\n",
            "Iteration 11, loss = 1538593431.65903163\n",
            "Iteration 12, loss = 1538565106.65217733\n",
            "Iteration 13, loss = 1538533967.41419291\n",
            "Iteration 14, loss = 1538501839.63444114\n",
            "Iteration 15, loss = 1538468833.68297052\n",
            "Iteration 16, loss = 1538433401.01760817\n",
            "Iteration 17, loss = 1538397205.07117438\n",
            "Iteration 18, loss = 1538358295.23427534\n",
            "Iteration 19, loss = 1538318173.13918257\n",
            "Iteration 20, loss = 1538276135.33234215\n",
            "Iteration 21, loss = 1538231599.68143678\n",
            "Iteration 22, loss = 1538185699.81937289\n",
            "Iteration 23, loss = 1538137838.03331399\n",
            "Iteration 24, loss = 1538087502.23712111\n",
            "Iteration 25, loss = 1538035725.92555070\n",
            "Iteration 26, loss = 1537981731.72124720\n",
            "Iteration 27, loss = 1537926138.24828887\n",
            "Iteration 28, loss = 1537869308.46386814\n",
            "Iteration 29, loss = 1537809552.36929607\n",
            "Iteration 30, loss = 1537748714.27647519\n",
            "Iteration 31, loss = 1537685660.12982512\n",
            "Iteration 32, loss = 1537620829.23672414\n",
            "Iteration 33, loss = 1537553667.01389217\n",
            "Iteration 34, loss = 1537485684.81902337\n",
            "Iteration 35, loss = 1537415643.85966969\n",
            "Iteration 36, loss = 1537343585.72986746\n",
            "Iteration 37, loss = 1537269571.13700414\n",
            "Iteration 38, loss = 1537194278.50508738\n",
            "Iteration 39, loss = 1537116687.77646446\n",
            "Iteration 40, loss = 1537037204.76519775\n",
            "Iteration 41, loss = 1536956709.53918839\n",
            "Iteration 42, loss = 1536873675.86253619\n",
            "Iteration 43, loss = 1536789329.62390590\n",
            "Iteration 44, loss = 1536703558.27046061\n",
            "Iteration 45, loss = 1536616992.09225249\n",
            "Iteration 46, loss = 1536529225.71811080\n",
            "Iteration 47, loss = 1536439971.21975112\n",
            "Iteration 48, loss = 1536349946.93885684\n",
            "Iteration 49, loss = 1536258664.62811422\n",
            "Iteration 50, loss = 1536166806.31335974\n",
            "Iteration 51, loss = 1536074055.17547774\n",
            "Iteration 52, loss = 1535981161.75907373\n",
            "Iteration 53, loss = 1535888293.08050561\n",
            "Iteration 54, loss = 1535795509.16311812\n",
            "Iteration 55, loss = 1535701966.10029316\n",
            "Iteration 56, loss = 1535607790.69391418\n",
            "Iteration 57, loss = 1535512281.64568877\n",
            "Iteration 58, loss = 1535416593.51417589\n",
            "Iteration 59, loss = 1535320149.01257586\n",
            "Iteration 60, loss = 1535224091.77152896\n",
            "Iteration 61, loss = 1535129127.91998482\n",
            "Iteration 62, loss = 1535034867.99047589\n",
            "Iteration 63, loss = 1534941616.87074494\n",
            "Iteration 64, loss = 1534849166.55946469\n",
            "Iteration 65, loss = 1534758025.70313287\n",
            "Iteration 66, loss = 1534667781.62526226\n",
            "Iteration 67, loss = 1534579179.07796502\n",
            "Iteration 68, loss = 1534492154.29332232\n",
            "Iteration 69, loss = 1534405392.61302876\n",
            "Iteration 70, loss = 1534320014.30311203\n",
            "Iteration 71, loss = 1534235187.18897367\n",
            "Iteration 72, loss = 1534151405.36174583\n",
            "Iteration 73, loss = 1534067768.80228162\n",
            "Iteration 74, loss = 1533984680.74216008\n",
            "Iteration 75, loss = 1533902461.02979541\n",
            "Iteration 76, loss = 1533820538.64451718\n",
            "Iteration 77, loss = 1533739199.37688470\n",
            "Iteration 78, loss = 1533658477.13035893\n",
            "Iteration 79, loss = 1533578694.73310089\n",
            "Iteration 80, loss = 1533499791.72470927\n",
            "Iteration 81, loss = 1533421081.31210232\n",
            "Iteration 82, loss = 1533342521.99702382\n",
            "Iteration 83, loss = 1533264456.10278821\n",
            "Iteration 84, loss = 1533186840.54016447\n",
            "Iteration 85, loss = 1533109926.72487521\n",
            "Iteration 86, loss = 1533032397.25263476\n",
            "Iteration 87, loss = 1532955455.53580761\n",
            "Iteration 88, loss = 1532879165.68989897\n",
            "Iteration 89, loss = 1532803438.89726496\n",
            "Iteration 90, loss = 1532727707.61234951\n",
            "Iteration 91, loss = 1532652274.02605247\n",
            "Iteration 92, loss = 1532577303.59669900\n",
            "Iteration 93, loss = 1532502857.04647374\n",
            "Iteration 94, loss = 1532429097.02365899\n",
            "Iteration 95, loss = 1532354878.26733494\n",
            "Iteration 96, loss = 1532281650.17132139\n",
            "Iteration 97, loss = 1532208370.01337886\n",
            "Iteration 98, loss = 1532135710.53386903\n",
            "Iteration 99, loss = 1532062919.01676059\n",
            "Iteration 100, loss = 1531989830.68198299\n",
            "Iteration 101, loss = 1531917589.10096335\n",
            "Iteration 102, loss = 1531845326.56312895\n",
            "Iteration 103, loss = 1531773642.73473215\n",
            "Iteration 104, loss = 1531701950.07071614\n",
            "Iteration 105, loss = 1531630360.84436321\n",
            "Iteration 106, loss = 1531558781.32240963\n",
            "Iteration 107, loss = 1531488213.31161928\n",
            "Iteration 108, loss = 1531417220.03573656\n",
            "Iteration 109, loss = 1531346605.03278637\n",
            "Iteration 110, loss = 1531276414.65027094\n",
            "Iteration 111, loss = 1531206120.63332963\n",
            "Iteration 112, loss = 1531136476.46740127\n",
            "Iteration 113, loss = 1531067118.85825610\n",
            "Iteration 114, loss = 1530997554.47435713\n",
            "Iteration 115, loss = 1530928281.09891486\n",
            "Iteration 116, loss = 1530859971.41716409\n",
            "Iteration 117, loss = 1530790643.88246059\n",
            "Iteration 118, loss = 1530722144.46461868\n",
            "Iteration 119, loss = 1530653535.06320119\n",
            "Iteration 120, loss = 1530585592.14186215\n",
            "Iteration 121, loss = 1530517091.03648782\n",
            "Iteration 122, loss = 1530449187.58898377\n",
            "Iteration 123, loss = 1530381260.47841859\n",
            "Iteration 124, loss = 1530313789.96772528\n",
            "Iteration 125, loss = 1530246318.93257475\n",
            "Iteration 126, loss = 1530178187.84133983\n",
            "Iteration 127, loss = 1530111552.44327974\n",
            "Iteration 128, loss = 1530043927.71155620\n",
            "Iteration 129, loss = 1529977354.73548818\n",
            "Iteration 130, loss = 1529910396.09439206\n",
            "Iteration 131, loss = 1529843148.06822872\n",
            "Iteration 132, loss = 1529777004.17175293\n",
            "Iteration 133, loss = 1529710558.89728355\n",
            "Iteration 134, loss = 1529643883.83527255\n",
            "Iteration 135, loss = 1529577609.24921370\n",
            "Iteration 136, loss = 1529511718.85608053\n",
            "Iteration 137, loss = 1529445462.79169941\n",
            "Iteration 138, loss = 1529379664.24796057\n",
            "Iteration 139, loss = 1529313615.11413121\n",
            "Iteration 140, loss = 1529248364.58598709\n",
            "Iteration 141, loss = 1529182277.42373252\n",
            "Iteration 142, loss = 1529117254.49414229\n",
            "Iteration 143, loss = 1529051594.08219647\n",
            "Iteration 144, loss = 1528986607.17303514\n",
            "Iteration 145, loss = 1528921604.68599701\n",
            "Iteration 146, loss = 1528856813.40895653\n",
            "Iteration 147, loss = 1528791871.95703530\n",
            "Iteration 148, loss = 1528727520.75729465\n",
            "Iteration 149, loss = 1528663149.64504862\n",
            "Iteration 150, loss = 1528598725.10106206\n",
            "Iteration 151, loss = 1528534272.57805467\n",
            "Iteration 152, loss = 1528470379.37374187\n",
            "Iteration 153, loss = 1528406349.49690366\n",
            "Iteration 154, loss = 1528342002.32212496\n",
            "Iteration 155, loss = 1528278279.83478665\n",
            "Iteration 156, loss = 1528214346.67335296\n",
            "Iteration 157, loss = 1528150864.87479138\n",
            "Iteration 158, loss = 1528086970.29166508\n",
            "Iteration 159, loss = 1528023502.84261394\n",
            "Iteration 160, loss = 1527959970.75498843\n",
            "Iteration 161, loss = 1527896717.71664405\n",
            "Iteration 162, loss = 1527832788.97463179\n",
            "Iteration 163, loss = 1527769973.13667417\n",
            "Iteration 164, loss = 1527706600.21214843\n",
            "Iteration 165, loss = 1527643526.95062733\n",
            "Iteration 166, loss = 1527580553.79244876\n",
            "Iteration 167, loss = 1527517451.84970522\n",
            "Iteration 168, loss = 1527455313.95190716\n",
            "Iteration 169, loss = 1527392420.22383857\n",
            "Iteration 170, loss = 1527329975.95251751\n",
            "Iteration 171, loss = 1527267656.14449954\n",
            "Iteration 172, loss = 1527205301.45849228\n",
            "Iteration 173, loss = 1527142991.68522978\n",
            "Iteration 174, loss = 1527081007.62105083\n",
            "Iteration 175, loss = 1527018748.28223133\n",
            "Iteration 176, loss = 1526956860.48228860\n",
            "Iteration 177, loss = 1526895104.44020724\n",
            "Iteration 178, loss = 1526832857.51831484\n",
            "Iteration 179, loss = 1526771743.21079850\n",
            "Iteration 180, loss = 1526709326.64303994\n",
            "Iteration 181, loss = 1526648238.17599106\n",
            "Iteration 182, loss = 1526586072.99985480\n",
            "Iteration 183, loss = 1526524297.98414755\n",
            "Iteration 184, loss = 1526462931.87746859\n",
            "Iteration 185, loss = 1526400930.28918791\n",
            "Iteration 186, loss = 1526339531.10360503\n",
            "Iteration 187, loss = 1526278114.92358351\n",
            "Iteration 188, loss = 1526216153.98047614\n",
            "Iteration 189, loss = 1526155021.61725569\n",
            "Iteration 190, loss = 1526093937.35076976\n",
            "Iteration 191, loss = 1526032648.93587184\n",
            "Iteration 192, loss = 1525971773.83980012\n",
            "Iteration 193, loss = 1525910247.46385050\n",
            "Iteration 194, loss = 1525849300.40334988\n",
            "Iteration 195, loss = 1525788426.77287292\n",
            "Iteration 196, loss = 1525727202.71039915\n",
            "Iteration 197, loss = 1525666084.48734307\n",
            "Iteration 198, loss = 1525605388.19944692\n",
            "Iteration 199, loss = 1525543930.82108402\n",
            "Iteration 200, loss = 1525482992.98352194\n",
            "Iteration 201, loss = 1525421742.75208402\n",
            "Iteration 202, loss = 1525361118.36228681\n",
            "Iteration 203, loss = 1525300169.61554909\n",
            "Iteration 204, loss = 1525239129.09005833\n",
            "Iteration 205, loss = 1525178142.60580039\n",
            "Iteration 206, loss = 1525117756.90856290\n",
            "Iteration 207, loss = 1525057076.96973014\n",
            "Iteration 208, loss = 1524996137.13922286\n",
            "Iteration 209, loss = 1524935639.24777102\n",
            "Iteration 210, loss = 1524875300.49546814\n",
            "Iteration 211, loss = 1524814844.24105382\n",
            "Iteration 212, loss = 1524754402.01907372\n",
            "Iteration 213, loss = 1524693834.33211350\n",
            "Iteration 214, loss = 1524633659.45501423\n",
            "Iteration 215, loss = 1524573474.93046284\n",
            "Iteration 216, loss = 1524512788.66392255\n",
            "Iteration 217, loss = 1524452672.80051780\n",
            "Iteration 218, loss = 1524392367.37600994\n",
            "Iteration 219, loss = 1524331835.87226200\n",
            "Iteration 220, loss = 1524271469.42682099\n",
            "Iteration 221, loss = 1524211338.72539139\n",
            "Iteration 222, loss = 1524150840.31023026\n",
            "Iteration 223, loss = 1524090373.26706934\n",
            "Iteration 224, loss = 1524030662.98595047\n",
            "Iteration 225, loss = 1523970159.14388323\n",
            "Iteration 226, loss = 1523909917.01974177\n",
            "Iteration 227, loss = 1523850252.56779909\n",
            "Iteration 228, loss = 1523789998.05520582\n",
            "Iteration 229, loss = 1523729948.35360074\n",
            "Iteration 230, loss = 1523670291.73579502\n",
            "Iteration 231, loss = 1523609972.00943613\n",
            "Iteration 232, loss = 1523550446.86923718\n",
            "Iteration 233, loss = 1523490527.55950737\n",
            "Iteration 234, loss = 1523430945.42876005\n",
            "Iteration 235, loss = 1523371316.36533856\n",
            "Iteration 236, loss = 1523311501.63221169\n",
            "Iteration 237, loss = 1523252103.57721210\n",
            "Iteration 238, loss = 1523192696.88303924\n",
            "Iteration 239, loss = 1523132610.49448633\n",
            "Iteration 240, loss = 1523073594.69041085\n",
            "Iteration 241, loss = 1523014039.19696736\n",
            "Iteration 242, loss = 1522954366.02907228\n",
            "Iteration 243, loss = 1522895102.57793713\n",
            "Iteration 244, loss = 1522835675.91567516\n",
            "Iteration 245, loss = 1522776027.68231106\n",
            "Iteration 246, loss = 1522716985.53089905\n",
            "Iteration 247, loss = 1522657440.54893947\n",
            "Iteration 248, loss = 1522598000.68584204\n",
            "Iteration 249, loss = 1522538966.97008085\n",
            "Iteration 250, loss = 1522479405.14584947\n",
            "Iteration 251, loss = 1522420184.92349792\n",
            "Iteration 252, loss = 1522361127.90003896\n",
            "Iteration 253, loss = 1522301827.12835026\n",
            "Iteration 254, loss = 1522242975.51994228\n",
            "Iteration 255, loss = 1522183643.67218018\n",
            "Iteration 256, loss = 1522124425.01379991\n",
            "Iteration 257, loss = 1522065511.40460134\n",
            "Iteration 258, loss = 1522006351.18188286\n",
            "Iteration 259, loss = 1521947014.70771456\n",
            "Iteration 260, loss = 1521888450.30972266\n",
            "Iteration 261, loss = 1521829119.23278213\n",
            "Iteration 262, loss = 1521770551.15040612\n",
            "Iteration 263, loss = 1521711444.09902859\n",
            "Iteration 264, loss = 1521653312.58717227\n",
            "Iteration 265, loss = 1521594504.34824061\n",
            "Iteration 266, loss = 1521535891.74808717\n",
            "Iteration 267, loss = 1521477366.28569841\n",
            "Iteration 268, loss = 1521418903.07321334\n",
            "Iteration 269, loss = 1521360441.85428262\n",
            "Iteration 270, loss = 1521301897.10682130\n",
            "Iteration 271, loss = 1521243944.77183151\n",
            "Iteration 272, loss = 1521185169.69131684\n",
            "Iteration 273, loss = 1521127034.22892284\n",
            "Iteration 274, loss = 1521069006.55945206\n",
            "Iteration 275, loss = 1521011128.89633489\n",
            "Iteration 276, loss = 1520952576.27530074\n",
            "Iteration 277, loss = 1520894509.96234226\n",
            "Iteration 278, loss = 1520836469.71794200\n",
            "Iteration 279, loss = 1520778301.65348125\n",
            "Iteration 280, loss = 1520720170.88031197\n",
            "Iteration 281, loss = 1520662133.84461570\n",
            "Iteration 282, loss = 1520603917.51619506\n",
            "Iteration 283, loss = 1520545792.32876897\n",
            "Iteration 284, loss = 1520487823.81563663\n",
            "Iteration 285, loss = 1520429718.53818917\n",
            "Iteration 286, loss = 1520371597.31928515\n",
            "Iteration 287, loss = 1520313131.20586252\n",
            "Iteration 288, loss = 1520255431.98472834\n",
            "Iteration 289, loss = 1520196998.06208920\n",
            "Iteration 290, loss = 1520138970.87598729\n",
            "Iteration 291, loss = 1520080696.73164725\n",
            "Iteration 292, loss = 1520022831.38485599\n",
            "Iteration 293, loss = 1519964635.81459713\n",
            "Iteration 294, loss = 1519906577.47675061\n",
            "Iteration 295, loss = 1519848299.22712135\n",
            "Iteration 296, loss = 1519790490.69931269\n",
            "Iteration 297, loss = 1519732468.18282819\n",
            "Iteration 298, loss = 1519674194.04715776\n",
            "Iteration 299, loss = 1519616573.71315360\n",
            "Iteration 300, loss = 1519558427.44053698\n",
            "Iteration 301, loss = 1519500846.15840673\n",
            "Iteration 302, loss = 1519442709.07680750\n",
            "Iteration 303, loss = 1519384976.32874274\n",
            "Iteration 304, loss = 1519327416.09278083\n",
            "Iteration 305, loss = 1519269381.86051226\n",
            "Iteration 306, loss = 1519211607.55143976\n",
            "Iteration 307, loss = 1519153672.26598835\n",
            "Iteration 308, loss = 1519096329.64598227\n",
            "Iteration 309, loss = 1519038034.33011079\n",
            "Iteration 310, loss = 1518980480.47001910\n",
            "Iteration 311, loss = 1518922156.42983699\n",
            "Iteration 312, loss = 1518864251.90493941\n",
            "Iteration 313, loss = 1518806698.47222972\n",
            "Iteration 314, loss = 1518748561.27752185\n",
            "Iteration 315, loss = 1518690829.21570325\n",
            "Iteration 316, loss = 1518632515.17730880\n",
            "Iteration 317, loss = 1518574578.62825680\n",
            "Iteration 318, loss = 1518517282.49084616\n",
            "Iteration 319, loss = 1518458668.27837849\n",
            "Iteration 320, loss = 1518400834.15888333\n",
            "Iteration 321, loss = 1518342747.94140148\n",
            "Iteration 322, loss = 1518285092.58085155\n",
            "Iteration 323, loss = 1518227053.40945697\n",
            "Iteration 324, loss = 1518169113.61983848\n",
            "Iteration 325, loss = 1518111787.23409986\n",
            "Iteration 326, loss = 1518053504.25118423\n",
            "Iteration 327, loss = 1517996199.22663307\n",
            "Iteration 328, loss = 1517938937.69104910\n",
            "Iteration 329, loss = 1517881236.87828350\n",
            "Iteration 330, loss = 1517823578.14081645\n",
            "Iteration 331, loss = 1517766559.97145295\n",
            "Iteration 332, loss = 1517709517.16486359\n",
            "Iteration 333, loss = 1517652231.74493217\n",
            "Iteration 334, loss = 1517595023.89506865\n",
            "Iteration 335, loss = 1517538356.70209432\n",
            "Iteration 336, loss = 1517481128.91200233\n",
            "Iteration 337, loss = 1517424215.83854795\n",
            "Iteration 338, loss = 1517367252.53046989\n",
            "Iteration 339, loss = 1517310261.76953030\n",
            "Iteration 340, loss = 1517253490.03291225\n",
            "Iteration 341, loss = 1517196435.30124640\n",
            "Iteration 342, loss = 1517139527.51760650\n",
            "Iteration 343, loss = 1517082255.23644185\n",
            "Iteration 344, loss = 1517024843.33384538\n",
            "Iteration 345, loss = 1516967871.51874638\n",
            "Iteration 346, loss = 1516910487.01476955\n",
            "Iteration 347, loss = 1516852849.19737411\n",
            "Iteration 348, loss = 1516795253.46099997\n",
            "Iteration 349, loss = 1516737909.00480509\n",
            "Iteration 350, loss = 1516680192.64168477\n",
            "Iteration 351, loss = 1516622864.82260990\n",
            "Iteration 352, loss = 1516565353.45058346\n",
            "Iteration 353, loss = 1516507959.33018780\n",
            "Iteration 354, loss = 1516450899.83621335\n",
            "Iteration 355, loss = 1516393414.30803227\n",
            "Iteration 356, loss = 1516336267.56003571\n",
            "Iteration 357, loss = 1516279427.20362711\n",
            "Iteration 358, loss = 1516221976.87215829\n",
            "Iteration 359, loss = 1516165081.88576317\n",
            "Iteration 360, loss = 1516107782.19071364\n",
            "Iteration 361, loss = 1516050851.80416298\n",
            "Iteration 362, loss = 1515993464.45113802\n",
            "Iteration 363, loss = 1515936386.91214418\n",
            "Iteration 364, loss = 1515879359.33865833\n",
            "Iteration 365, loss = 1515821622.06609082\n",
            "Iteration 366, loss = 1515764718.03115606\n",
            "Iteration 367, loss = 1515707211.86529326\n",
            "Iteration 368, loss = 1515649928.94332457\n",
            "Iteration 369, loss = 1515592707.59460235\n",
            "Iteration 370, loss = 1515535380.36992574\n",
            "Iteration 371, loss = 1515478006.79788709\n",
            "Iteration 372, loss = 1515420629.29165864\n",
            "Iteration 373, loss = 1515363216.75189972\n",
            "Iteration 374, loss = 1515305853.33855152\n",
            "Iteration 375, loss = 1515248679.78281379\n",
            "Iteration 376, loss = 1515191095.99113464\n",
            "Iteration 377, loss = 1515134170.33647442\n",
            "Iteration 378, loss = 1515076809.14242744\n",
            "Iteration 379, loss = 1515019754.84751105\n",
            "Iteration 380, loss = 1514962414.73434949\n",
            "Iteration 381, loss = 1514905607.81886315\n",
            "Iteration 382, loss = 1514848484.79342604\n",
            "Iteration 383, loss = 1514791867.21437335\n",
            "Iteration 384, loss = 1514734866.66929555\n",
            "Iteration 385, loss = 1514678141.80473900\n",
            "Iteration 386, loss = 1514621761.77511621\n",
            "Iteration 387, loss = 1514564853.13835907\n",
            "Iteration 388, loss = 1514508569.17465591\n",
            "Iteration 389, loss = 1514452091.93468356\n",
            "Iteration 390, loss = 1514395649.57215714\n",
            "Iteration 391, loss = 1514338947.65578508\n",
            "Iteration 392, loss = 1514282377.60217595\n",
            "Iteration 393, loss = 1514225944.59803224\n",
            "Iteration 394, loss = 1514169534.86593151\n",
            "Iteration 395, loss = 1514112675.53099513\n",
            "Iteration 396, loss = 1514056397.20432448\n",
            "Iteration 397, loss = 1514000058.72493768\n",
            "Iteration 398, loss = 1513943267.47597504\n",
            "Iteration 399, loss = 1513886558.49782872\n",
            "Iteration 400, loss = 1513830156.71431565\n",
            "Iteration 401, loss = 1513773679.55845904\n",
            "Iteration 402, loss = 1513717142.81163597\n",
            "Iteration 403, loss = 1513660532.14413285\n",
            "Iteration 404, loss = 1513604104.19258022\n",
            "Iteration 405, loss = 1513547318.42756248\n",
            "Iteration 406, loss = 1513491107.26343083\n",
            "Iteration 407, loss = 1513434258.65901351\n",
            "Iteration 408, loss = 1513378116.44418550\n",
            "Iteration 409, loss = 1513321219.42793941\n",
            "Iteration 410, loss = 1513264502.93899918\n",
            "Iteration 411, loss = 1513208395.83034372\n",
            "Iteration 412, loss = 1513151378.37339306\n",
            "Iteration 413, loss = 1513095433.51466060\n",
            "Iteration 414, loss = 1513038431.17899537\n",
            "Iteration 415, loss = 1512982175.25660300\n",
            "Iteration 416, loss = 1512926026.19721794\n",
            "Iteration 417, loss = 1512869524.05281830\n",
            "Iteration 418, loss = 1512813419.83714509\n",
            "Iteration 419, loss = 1512757197.02836347\n",
            "Iteration 420, loss = 1512700810.17643189\n",
            "Iteration 421, loss = 1512644477.90343904\n",
            "Iteration 422, loss = 1512588243.11481547\n",
            "Iteration 423, loss = 1512531962.55517197\n",
            "Iteration 424, loss = 1512475259.90521312\n",
            "Iteration 425, loss = 1512418753.26726580\n",
            "Iteration 426, loss = 1512362310.59011507\n",
            "Iteration 427, loss = 1512306131.21673799\n",
            "Iteration 428, loss = 1512249317.52058673\n",
            "Iteration 429, loss = 1512193080.24324083\n",
            "Iteration 430, loss = 1512136740.24323916\n",
            "Iteration 431, loss = 1512080316.72275043\n",
            "Iteration 432, loss = 1512024071.82335949\n",
            "Iteration 433, loss = 1511967764.68723488\n",
            "Iteration 434, loss = 1511911323.10454392\n",
            "Iteration 435, loss = 1511855611.53062892\n",
            "Iteration 436, loss = 1511799044.74481225\n",
            "Iteration 437, loss = 1511743206.19324231\n",
            "Iteration 438, loss = 1511687322.60088992\n",
            "Iteration 439, loss = 1511631162.39659142\n",
            "Iteration 440, loss = 1511575125.98622775\n",
            "Iteration 441, loss = 1511519492.50045085\n",
            "Iteration 442, loss = 1511463352.78025985\n",
            "Iteration 443, loss = 1511407547.59146166\n",
            "Iteration 444, loss = 1511351605.17738986\n",
            "Iteration 445, loss = 1511295761.69528294\n",
            "Iteration 446, loss = 1511239524.22191215\n",
            "Iteration 447, loss = 1511183759.48027468\n",
            "Iteration 448, loss = 1511127590.04212952\n",
            "Iteration 449, loss = 1511071655.94893622\n",
            "Iteration 450, loss = 1511015581.41854167\n",
            "Iteration 451, loss = 1510959702.17035437\n",
            "Iteration 452, loss = 1510903885.30244851\n",
            "Iteration 453, loss = 1510847980.29900074\n",
            "Iteration 454, loss = 1510791654.57871079\n",
            "Iteration 455, loss = 1510735885.63596678\n",
            "Iteration 456, loss = 1510679802.34168696\n",
            "Iteration 457, loss = 1510623780.53613281\n",
            "Iteration 458, loss = 1510567398.97771406\n",
            "Iteration 459, loss = 1510511776.76745105\n",
            "Iteration 460, loss = 1510455122.54038334\n",
            "Iteration 461, loss = 1510399367.50026417\n",
            "Iteration 462, loss = 1510343270.42877269\n",
            "Iteration 463, loss = 1510287199.35129690\n",
            "Iteration 464, loss = 1510231075.50502658\n",
            "Iteration 465, loss = 1510175237.28883648\n",
            "Iteration 466, loss = 1510119384.83358812\n",
            "Iteration 467, loss = 1510063144.01199198\n",
            "Iteration 468, loss = 1510007086.68475056\n",
            "Iteration 469, loss = 1509951218.03290987\n",
            "Iteration 470, loss = 1509894986.03606176\n",
            "Iteration 471, loss = 1509839184.14603162\n",
            "Iteration 472, loss = 1509782881.10813737\n",
            "Iteration 473, loss = 1509726928.91676378\n",
            "Iteration 474, loss = 1509670621.26528883\n",
            "Iteration 475, loss = 1509614374.88462758\n",
            "Iteration 476, loss = 1509558279.47536230\n",
            "Iteration 477, loss = 1509501932.23157215\n",
            "Iteration 478, loss = 1509446256.63653994\n",
            "Iteration 479, loss = 1509389950.54615402\n",
            "Iteration 480, loss = 1509334162.54561186\n",
            "Iteration 481, loss = 1509278082.67408109\n",
            "Iteration 482, loss = 1509222376.66449809\n",
            "Iteration 483, loss = 1509166847.14042640\n",
            "Iteration 484, loss = 1509110875.46103835\n",
            "Iteration 485, loss = 1509054967.28276324\n",
            "Iteration 486, loss = 1508999195.50365138\n",
            "Iteration 487, loss = 1508943430.15415001\n",
            "Iteration 488, loss = 1508887817.39075804\n",
            "Iteration 489, loss = 1508831589.24215198\n",
            "Iteration 490, loss = 1508775986.72352386\n",
            "Iteration 491, loss = 1508720221.31435728\n",
            "Iteration 492, loss = 1508664296.74744058\n",
            "Iteration 493, loss = 1508608413.63728333\n",
            "Iteration 494, loss = 1508552836.58116055\n",
            "Iteration 495, loss = 1508496946.27873421\n",
            "Iteration 496, loss = 1508441128.20575261\n",
            "Iteration 497, loss = 1508385633.98942327\n",
            "Iteration 498, loss = 1508329646.54606938\n",
            "Iteration 499, loss = 1508274043.27130556\n",
            "Iteration 500, loss = 1508218325.80874419\n",
            "Iteration 501, loss = 1508163108.52215266\n",
            "Iteration 502, loss = 1508106946.91027904\n",
            "Iteration 503, loss = 1508051369.51829910\n",
            "Iteration 504, loss = 1507995495.80882049\n",
            "Iteration 505, loss = 1507939943.41154289\n",
            "Iteration 506, loss = 1507883649.43778253\n",
            "Iteration 507, loss = 1507827878.29021764\n",
            "Iteration 508, loss = 1507772412.52454925\n",
            "Iteration 509, loss = 1507716476.52609730\n",
            "Iteration 510, loss = 1507660666.77103448\n",
            "Iteration 511, loss = 1507605266.21202946\n",
            "Iteration 512, loss = 1507549969.50398612\n",
            "Iteration 513, loss = 1507494317.53193426\n",
            "Iteration 514, loss = 1507438832.55504441\n",
            "Iteration 515, loss = 1507383161.36864519\n",
            "Iteration 516, loss = 1507327848.85958171\n",
            "Iteration 517, loss = 1507272003.75857162\n",
            "Iteration 518, loss = 1507216846.36130214\n",
            "Iteration 519, loss = 1507160800.52234125\n",
            "Iteration 520, loss = 1507105486.00154042\n",
            "Iteration 521, loss = 1507049862.44618344\n",
            "Iteration 522, loss = 1506994172.40841985\n",
            "Iteration 523, loss = 1506938976.26609874\n",
            "Iteration 524, loss = 1506882803.02211857\n",
            "Iteration 525, loss = 1506827406.42248011\n",
            "Iteration 526, loss = 1506771906.62440276\n",
            "Iteration 527, loss = 1506716145.67660666\n",
            "Iteration 528, loss = 1506660403.60989738\n",
            "Iteration 529, loss = 1506604971.45435214\n",
            "Iteration 530, loss = 1506549442.24938035\n",
            "Iteration 531, loss = 1506493931.52715850\n",
            "Iteration 532, loss = 1506438448.21500993\n",
            "Iteration 533, loss = 1506382901.17432165\n",
            "Iteration 534, loss = 1506327719.67250586\n",
            "Iteration 535, loss = 1506272366.13420534\n",
            "Iteration 536, loss = 1506216974.46631575\n",
            "Iteration 537, loss = 1506161535.81187201\n",
            "Iteration 538, loss = 1506106488.10555696\n",
            "Iteration 539, loss = 1506051015.46162701\n",
            "Iteration 540, loss = 1505995749.15750313\n",
            "Iteration 541, loss = 1505940766.84757185\n",
            "Iteration 542, loss = 1505885095.09113002\n",
            "Iteration 543, loss = 1505830073.95448828\n",
            "Iteration 544, loss = 1505774912.62189579\n",
            "Iteration 545, loss = 1505719824.23312712\n",
            "Iteration 546, loss = 1505664655.96124434\n",
            "Iteration 547, loss = 1505609697.63306427\n",
            "Iteration 548, loss = 1505554718.45228672\n",
            "Iteration 549, loss = 1505499239.81065154\n",
            "Iteration 550, loss = 1505444371.94524956\n",
            "Iteration 551, loss = 1505389149.21120405\n",
            "Iteration 552, loss = 1505334215.49760771\n",
            "Iteration 553, loss = 1505278959.17267442\n",
            "Iteration 554, loss = 1505224014.01911926\n",
            "Iteration 555, loss = 1505168884.91818953\n",
            "Iteration 556, loss = 1505113652.05241823\n",
            "Iteration 557, loss = 1505058765.31075048\n",
            "Iteration 558, loss = 1505003109.86918783\n",
            "Iteration 559, loss = 1504948227.31371903\n",
            "Iteration 560, loss = 1504892752.25867271\n",
            "Iteration 561, loss = 1504837378.84121275\n",
            "Iteration 562, loss = 1504781918.86755347\n",
            "Iteration 563, loss = 1504726955.68245721\n",
            "Iteration 564, loss = 1504671669.87213159\n",
            "Iteration 565, loss = 1504616195.18323040\n",
            "Iteration 566, loss = 1504561144.15071607\n",
            "Iteration 567, loss = 1504505660.47616768\n",
            "Iteration 568, loss = 1504450588.17934608\n",
            "Iteration 569, loss = 1504395474.48697710\n",
            "Iteration 570, loss = 1504340093.53408933\n",
            "Iteration 571, loss = 1504284894.61421180\n",
            "Iteration 572, loss = 1504229641.65267849\n",
            "Iteration 573, loss = 1504174393.02210736\n",
            "Iteration 574, loss = 1504118846.51267076\n",
            "Iteration 575, loss = 1504063460.98407292\n",
            "Iteration 576, loss = 1504008247.50047660\n",
            "Iteration 577, loss = 1503952788.99319911\n",
            "Iteration 578, loss = 1503897400.76141357\n",
            "Iteration 579, loss = 1503841968.37251425\n",
            "Iteration 580, loss = 1503786929.73285747\n",
            "Iteration 581, loss = 1503731660.36741495\n",
            "Iteration 582, loss = 1503676435.91934299\n",
            "Iteration 583, loss = 1503621119.85797834\n",
            "Iteration 584, loss = 1503566358.21111846\n",
            "Iteration 585, loss = 1503510802.59835982\n",
            "Iteration 586, loss = 1503455763.86131239\n",
            "Iteration 587, loss = 1503400271.20145941\n",
            "Iteration 588, loss = 1503345404.57587719\n",
            "Iteration 589, loss = 1503289970.37361574\n",
            "Iteration 590, loss = 1503235023.43707061\n",
            "Iteration 591, loss = 1503180029.60877395\n",
            "Iteration 592, loss = 1503124782.21125793\n",
            "Iteration 593, loss = 1503069869.18989706\n",
            "Iteration 594, loss = 1503014693.84605169\n",
            "Iteration 595, loss = 1502959758.99437356\n",
            "Iteration 596, loss = 1502904536.01306701\n",
            "Iteration 597, loss = 1502849570.93585253\n",
            "Iteration 598, loss = 1502794471.47644615\n",
            "Iteration 599, loss = 1502739326.54846168\n",
            "Iteration 600, loss = 1502684647.81534958\n",
            "Iteration 601, loss = 1502629746.25538158\n",
            "Iteration 602, loss = 1502574594.08971310\n",
            "Iteration 603, loss = 1502519896.25508165\n",
            "Iteration 604, loss = 1502465203.83418727\n",
            "Iteration 605, loss = 1502410039.36168194\n",
            "Iteration 606, loss = 1502355017.99706006\n",
            "Iteration 607, loss = 1502300115.19491911\n",
            "Iteration 608, loss = 1502244853.42025638\n",
            "Iteration 609, loss = 1502189918.38385344\n",
            "Iteration 610, loss = 1502134488.31303596\n",
            "Iteration 611, loss = 1502079375.38607740\n",
            "Iteration 612, loss = 1502024352.46438837\n",
            "Iteration 613, loss = 1501969119.38546395\n",
            "Iteration 614, loss = 1501913856.52348328\n",
            "Iteration 615, loss = 1501858875.95541954\n",
            "Iteration 616, loss = 1501803576.81195974\n",
            "Iteration 617, loss = 1501748155.46181107\n",
            "Iteration 618, loss = 1501693442.56331921\n",
            "Iteration 619, loss = 1501637698.07793617\n",
            "Iteration 620, loss = 1501582832.34591985\n",
            "Iteration 621, loss = 1501527568.94880271\n",
            "Iteration 622, loss = 1501472329.49995613\n",
            "Iteration 623, loss = 1501417147.08131552\n",
            "Iteration 624, loss = 1501362266.76450586\n",
            "Iteration 625, loss = 1501307018.87303615\n",
            "Iteration 626, loss = 1501251799.94864178\n",
            "Iteration 627, loss = 1501196577.58039379\n",
            "Iteration 628, loss = 1501141676.39015722\n",
            "Iteration 629, loss = 1501086984.27102852\n",
            "Iteration 630, loss = 1501031764.32842875\n",
            "Iteration 631, loss = 1500977002.48067999\n",
            "Iteration 632, loss = 1500922223.31869817\n",
            "Iteration 633, loss = 1500867293.14836597\n",
            "Iteration 634, loss = 1500812488.47054172\n",
            "Iteration 635, loss = 1500757743.11232901\n",
            "Iteration 636, loss = 1500703149.24121881\n",
            "Iteration 637, loss = 1500648426.56313133\n",
            "Iteration 638, loss = 1500593372.49515796\n",
            "Iteration 639, loss = 1500538853.36918831\n",
            "Iteration 640, loss = 1500484493.44344234\n",
            "Iteration 641, loss = 1500429640.94613290\n",
            "Iteration 642, loss = 1500375137.32167196\n",
            "Iteration 643, loss = 1500320325.82249022\n",
            "Iteration 644, loss = 1500265784.53181887\n",
            "Iteration 645, loss = 1500211672.44335461\n",
            "Iteration 646, loss = 1500156577.35130262\n",
            "Iteration 647, loss = 1500101977.93779325\n",
            "Iteration 648, loss = 1500047369.09411240\n",
            "Iteration 649, loss = 1499992822.98716259\n",
            "Iteration 650, loss = 1499937924.76914454\n",
            "Iteration 651, loss = 1499883088.77941608\n",
            "Iteration 652, loss = 1499828529.93114138\n",
            "Iteration 653, loss = 1499773385.09473968\n",
            "Iteration 654, loss = 1499718755.33850241\n",
            "Iteration 655, loss = 1499664141.16257906\n",
            "Iteration 656, loss = 1499609118.52695751\n",
            "Iteration 657, loss = 1499554301.03093147\n",
            "Iteration 658, loss = 1499500020.31423283\n",
            "Iteration 659, loss = 1499444753.16428804\n",
            "Iteration 660, loss = 1499390421.21395564\n",
            "Iteration 661, loss = 1499335394.53349662\n",
            "Iteration 662, loss = 1499280816.61790013\n",
            "Iteration 663, loss = 1499225858.03283596\n",
            "Iteration 664, loss = 1499171457.91018009\n",
            "Iteration 665, loss = 1499116569.43041420\n",
            "Iteration 666, loss = 1499061526.94217491\n",
            "Iteration 667, loss = 1499007428.38631392\n",
            "Iteration 668, loss = 1498952599.94153762\n",
            "Iteration 669, loss = 1498897707.70360065\n",
            "Iteration 670, loss = 1498843258.07308078\n",
            "Iteration 671, loss = 1498788516.95626760\n",
            "Iteration 672, loss = 1498733507.87768459\n",
            "Iteration 673, loss = 1498678884.64442968\n",
            "Iteration 674, loss = 1498623798.83740544\n",
            "Iteration 675, loss = 1498569147.32698011\n",
            "Iteration 676, loss = 1498513928.31836295\n",
            "Iteration 677, loss = 1498459008.11048126\n",
            "Iteration 678, loss = 1498404491.45338058\n",
            "Iteration 679, loss = 1498349623.45470452\n",
            "Iteration 680, loss = 1498295085.38592434\n",
            "Iteration 681, loss = 1498240235.88574910\n",
            "Iteration 682, loss = 1498186055.24379587\n",
            "Iteration 683, loss = 1498131295.21256423\n",
            "Iteration 684, loss = 1498076801.73759055\n",
            "Iteration 685, loss = 1498022205.91562629\n",
            "Iteration 686, loss = 1497967490.62074304\n",
            "Iteration 687, loss = 1497912989.78432870\n",
            "Iteration 688, loss = 1497857812.00483370\n",
            "Iteration 689, loss = 1497803221.66479254\n",
            "Iteration 690, loss = 1497748183.36782527\n",
            "Iteration 691, loss = 1497693187.22297263\n",
            "Iteration 692, loss = 1497638195.32647181\n",
            "Iteration 693, loss = 1497583500.40008807\n",
            "Iteration 694, loss = 1497528394.33323336\n",
            "Iteration 695, loss = 1497473600.69054580\n",
            "Iteration 696, loss = 1497418891.79762125\n",
            "Iteration 697, loss = 1497364243.99382997\n",
            "Iteration 698, loss = 1497309467.72859740\n",
            "Iteration 699, loss = 1497254916.66322279\n",
            "Iteration 700, loss = 1497200028.30107570\n",
            "Iteration 701, loss = 1497145463.87245226\n",
            "Iteration 702, loss = 1497090725.98646021\n",
            "Iteration 703, loss = 1497036487.43894029\n",
            "Iteration 704, loss = 1496981647.44454885\n",
            "Iteration 705, loss = 1496926911.15769386\n",
            "Iteration 706, loss = 1496872401.01933789\n",
            "Iteration 707, loss = 1496818067.44669843\n",
            "Iteration 708, loss = 1496763376.30858874\n",
            "Iteration 709, loss = 1496708828.57909679\n",
            "Iteration 710, loss = 1496654334.90914130\n",
            "Iteration 711, loss = 1496599735.35133362\n",
            "Iteration 712, loss = 1496545105.42533875\n",
            "Iteration 713, loss = 1496490831.92244911\n",
            "Iteration 714, loss = 1496436108.97010636\n",
            "Iteration 715, loss = 1496381148.84484076\n",
            "Iteration 716, loss = 1496327038.05949640\n",
            "Iteration 717, loss = 1496272141.10616875\n",
            "Iteration 718, loss = 1496217869.49784398\n",
            "Iteration 719, loss = 1496162799.67359924\n",
            "Iteration 720, loss = 1496108554.30861950\n",
            "Iteration 721, loss = 1496053876.65688920\n",
            "Iteration 722, loss = 1495999169.72589111\n",
            "Iteration 723, loss = 1495944333.78273153\n",
            "Iteration 724, loss = 1495890089.77811360\n",
            "Iteration 725, loss = 1495834941.10756183\n",
            "Iteration 726, loss = 1495780657.24153590\n",
            "Iteration 727, loss = 1495726044.21399927\n",
            "Iteration 728, loss = 1495671382.33005857\n",
            "Iteration 729, loss = 1495616707.70762348\n",
            "Iteration 730, loss = 1495562338.72933578\n",
            "Iteration 731, loss = 1495507671.92422628\n",
            "Iteration 732, loss = 1495452723.35427570\n",
            "Iteration 733, loss = 1495398479.07559347\n",
            "Iteration 734, loss = 1495343408.44088864\n",
            "Iteration 735, loss = 1495288796.78715372\n",
            "Iteration 736, loss = 1495234042.87604284\n",
            "Iteration 737, loss = 1495179338.92632723\n",
            "Iteration 738, loss = 1495124728.83691239\n",
            "Iteration 739, loss = 1495069760.47930932\n",
            "Iteration 740, loss = 1495015170.74494743\n",
            "Iteration 741, loss = 1494960498.10354972\n",
            "Iteration 742, loss = 1494905766.78323746\n",
            "Iteration 743, loss = 1494850654.17039847\n",
            "Iteration 744, loss = 1494795739.75830269\n",
            "Iteration 745, loss = 1494741607.46846509\n",
            "Iteration 746, loss = 1494686718.62387848\n",
            "Iteration 747, loss = 1494631922.13013244\n",
            "Iteration 748, loss = 1494577206.87889814\n",
            "Iteration 749, loss = 1494523010.00954604\n",
            "Iteration 750, loss = 1494468734.01968527\n",
            "Iteration 751, loss = 1494413533.86845922\n",
            "Iteration 752, loss = 1494359390.26861501\n",
            "Iteration 753, loss = 1494305109.81921911\n",
            "Iteration 754, loss = 1494250640.29058170\n",
            "Iteration 755, loss = 1494196107.69934750\n",
            "Iteration 756, loss = 1494141787.47750235\n",
            "Iteration 757, loss = 1494087488.91219640\n",
            "Iteration 758, loss = 1494033199.01539660\n",
            "Iteration 759, loss = 1493978814.11753964\n",
            "Iteration 760, loss = 1493924542.88981843\n",
            "Iteration 761, loss = 1493870140.31008983\n",
            "Iteration 762, loss = 1493816068.91019106\n",
            "Iteration 763, loss = 1493761421.01137280\n",
            "Iteration 764, loss = 1493707089.03963780\n",
            "Iteration 765, loss = 1493652598.72865868\n",
            "Iteration 766, loss = 1493598219.27023745\n",
            "Iteration 767, loss = 1493543390.35886621\n",
            "Iteration 768, loss = 1493489135.84418392\n",
            "Iteration 769, loss = 1493434628.25074363\n",
            "Iteration 770, loss = 1493380191.63302326\n",
            "Iteration 771, loss = 1493326188.78659129\n",
            "Iteration 772, loss = 1493271580.32360530\n",
            "Iteration 773, loss = 1493217537.10380602\n",
            "Iteration 774, loss = 1493163491.12235832\n",
            "Iteration 775, loss = 1493109295.83341098\n",
            "Iteration 776, loss = 1493054781.05089164\n",
            "Iteration 777, loss = 1493000497.09598422\n",
            "Iteration 778, loss = 1492946612.19508696\n",
            "Iteration 779, loss = 1492892212.00131202\n",
            "Iteration 780, loss = 1492837820.10054731\n",
            "Iteration 781, loss = 1492783666.06275654\n",
            "Iteration 782, loss = 1492729297.57181478\n",
            "Iteration 783, loss = 1492675466.40795684\n",
            "Iteration 784, loss = 1492620958.35584903\n",
            "Iteration 785, loss = 1492566787.70952201\n",
            "Iteration 786, loss = 1492512115.34125090\n",
            "Iteration 787, loss = 1492458103.00334239\n",
            "Iteration 788, loss = 1492403896.25876069\n",
            "Iteration 789, loss = 1492349722.56462765\n",
            "Iteration 790, loss = 1492295153.74923158\n",
            "Iteration 791, loss = 1492240890.35460019\n",
            "Iteration 792, loss = 1492186605.97971606\n",
            "Iteration 793, loss = 1492132354.24371505\n",
            "Iteration 794, loss = 1492077896.12719250\n",
            "Iteration 795, loss = 1492023656.08823109\n",
            "Iteration 796, loss = 1491969192.21267414\n",
            "Iteration 797, loss = 1491914994.32192373\n",
            "Iteration 798, loss = 1491860629.37299085\n",
            "Iteration 799, loss = 1491806627.49272656\n",
            "Iteration 800, loss = 1491752331.60942006\n",
            "Iteration 801, loss = 1491698025.29141569\n",
            "Iteration 802, loss = 1491643744.69743204\n",
            "Iteration 803, loss = 1491589869.17874646\n",
            "Iteration 804, loss = 1491535605.75725245\n",
            "Iteration 805, loss = 1491481142.60839629\n",
            "Iteration 806, loss = 1491426724.98139620\n",
            "Iteration 807, loss = 1491372727.08027554\n",
            "Iteration 808, loss = 1491318154.72322369\n",
            "Iteration 809, loss = 1491263501.34611320\n",
            "Iteration 810, loss = 1491209388.25762606\n",
            "Iteration 811, loss = 1491155025.97432709\n",
            "Iteration 812, loss = 1491100368.11586118\n",
            "Iteration 813, loss = 1491046081.02879548\n",
            "Iteration 814, loss = 1490992259.74747562\n",
            "Iteration 815, loss = 1490937650.92296696\n",
            "Iteration 816, loss = 1490883417.78360486\n",
            "Iteration 817, loss = 1490829605.63405895\n",
            "Iteration 818, loss = 1490775211.48006010\n",
            "Iteration 819, loss = 1490720985.00495672\n",
            "Iteration 820, loss = 1490666695.39642930\n",
            "Iteration 821, loss = 1490612745.38822389\n",
            "Iteration 822, loss = 1490558591.92893624\n",
            "Iteration 823, loss = 1490503918.17029047\n",
            "Iteration 824, loss = 1490449892.82215238\n",
            "Iteration 825, loss = 1490395733.37522268\n",
            "Iteration 826, loss = 1490341495.50159907\n",
            "Iteration 827, loss = 1490287217.00500655\n",
            "Iteration 828, loss = 1490233292.40199447\n",
            "Iteration 829, loss = 1490178740.97805309\n",
            "Iteration 830, loss = 1490124784.22116947\n",
            "Iteration 831, loss = 1490070301.49191523\n",
            "Iteration 832, loss = 1490016138.11760235\n",
            "Iteration 833, loss = 1489961694.31016254\n",
            "Iteration 834, loss = 1489907293.55280137\n",
            "Iteration 835, loss = 1489853333.66387296\n",
            "Iteration 836, loss = 1489798821.25325727\n",
            "Iteration 837, loss = 1489744293.76470089\n",
            "Iteration 838, loss = 1489690208.03450894\n",
            "Iteration 839, loss = 1489636180.45013952\n",
            "Iteration 840, loss = 1489581666.24515224\n",
            "Iteration 841, loss = 1489527310.99409604\n",
            "Iteration 842, loss = 1489473131.07971168\n",
            "Iteration 843, loss = 1489418956.13783884\n",
            "Iteration 844, loss = 1489364717.58108258\n",
            "Iteration 845, loss = 1489310486.35082412\n",
            "Iteration 846, loss = 1489256571.98993921\n",
            "Iteration 847, loss = 1489202286.53167272\n",
            "Iteration 848, loss = 1489148210.40546155\n",
            "Iteration 849, loss = 1489093762.59405136\n",
            "Iteration 850, loss = 1489039532.35709715\n",
            "Iteration 851, loss = 1488985441.91040802\n",
            "Iteration 852, loss = 1488930788.77018952\n",
            "Iteration 853, loss = 1488876159.91598797\n",
            "Iteration 854, loss = 1488821813.15156174\n",
            "Iteration 855, loss = 1488767516.73220158\n",
            "Iteration 856, loss = 1488712954.85000229\n",
            "Iteration 857, loss = 1488658559.97984314\n",
            "Iteration 858, loss = 1488604426.79432344\n",
            "Iteration 859, loss = 1488550073.53386211\n",
            "Iteration 860, loss = 1488495862.93690562\n",
            "Iteration 861, loss = 1488441840.29560494\n",
            "Iteration 862, loss = 1488387484.00088096\n",
            "Iteration 863, loss = 1488333571.37635660\n",
            "Iteration 864, loss = 1488279535.90453553\n",
            "Iteration 865, loss = 1488225269.07888412\n",
            "Iteration 866, loss = 1488171261.05465746\n",
            "Iteration 867, loss = 1488117303.85279465\n",
            "Iteration 868, loss = 1488062709.47961283\n",
            "Iteration 869, loss = 1488009159.96231866\n",
            "Iteration 870, loss = 1487954779.00102615\n",
            "Iteration 871, loss = 1487900349.00002480\n",
            "Iteration 872, loss = 1487846498.31456208\n",
            "Iteration 873, loss = 1487792327.06981540\n",
            "Iteration 874, loss = 1487738283.33510160\n",
            "Iteration 875, loss = 1487684053.05018067\n",
            "Iteration 876, loss = 1487629929.00783372\n",
            "Iteration 877, loss = 1487575740.99238276\n",
            "Iteration 878, loss = 1487521238.73944402\n",
            "Iteration 879, loss = 1487466944.61501980\n",
            "Iteration 880, loss = 1487412480.11392617\n",
            "Iteration 881, loss = 1487358451.86150146\n",
            "Iteration 882, loss = 1487303928.68928075\n",
            "Iteration 883, loss = 1487249955.25404382\n",
            "Iteration 884, loss = 1487195741.50589800\n",
            "Iteration 885, loss = 1487141918.46064663\n",
            "Iteration 886, loss = 1487087679.79905605\n",
            "Iteration 887, loss = 1487033927.50584817\n",
            "Iteration 888, loss = 1486980314.78819323\n",
            "Iteration 889, loss = 1486926417.09115386\n",
            "Iteration 890, loss = 1486872564.76345849\n",
            "Iteration 891, loss = 1486818534.67846775\n",
            "Iteration 892, loss = 1486764696.50733638\n",
            "Iteration 893, loss = 1486710415.26343179\n",
            "Iteration 894, loss = 1486656602.32264304\n",
            "Iteration 895, loss = 1486602179.05312634\n",
            "Iteration 896, loss = 1486547832.96839786\n",
            "Iteration 897, loss = 1486493825.51186943\n",
            "Iteration 898, loss = 1486439500.85412693\n",
            "Iteration 899, loss = 1486385022.99042821\n",
            "Iteration 900, loss = 1486330821.61672926\n",
            "Iteration 901, loss = 1486276755.45621037\n",
            "Iteration 902, loss = 1486222247.75168943\n",
            "Iteration 903, loss = 1486168313.91809034\n",
            "Iteration 904, loss = 1486113780.77224088\n",
            "Iteration 905, loss = 1486059880.77803922\n",
            "Iteration 906, loss = 1486005629.93427277\n",
            "Iteration 907, loss = 1485951377.65224290\n",
            "Iteration 908, loss = 1485897407.80493069\n",
            "Iteration 909, loss = 1485843294.40492225\n",
            "Iteration 910, loss = 1485789152.86903405\n",
            "Iteration 911, loss = 1485734988.34415507\n",
            "Iteration 912, loss = 1485680859.99038553\n",
            "Iteration 913, loss = 1485626998.92751837\n",
            "Iteration 914, loss = 1485572854.70380712\n",
            "Iteration 915, loss = 1485518639.63059783\n",
            "Iteration 916, loss = 1485464872.82568097\n",
            "Iteration 917, loss = 1485410885.65285492\n",
            "Iteration 918, loss = 1485356962.67981625\n",
            "Iteration 919, loss = 1485302786.73624468\n",
            "Iteration 920, loss = 1485248792.93526983\n",
            "Iteration 921, loss = 1485195333.87534690\n",
            "Iteration 922, loss = 1485141088.22008991\n",
            "Iteration 923, loss = 1485087393.07496858\n",
            "Iteration 924, loss = 1485033539.75568104\n",
            "Iteration 925, loss = 1484979748.16165304\n",
            "Iteration 926, loss = 1484925734.94665575\n",
            "Iteration 927, loss = 1484872007.51490855\n",
            "Iteration 928, loss = 1484817825.95512724\n",
            "Iteration 929, loss = 1484764195.37920189\n",
            "Iteration 930, loss = 1484710027.17502689\n",
            "Iteration 931, loss = 1484656163.78194332\n",
            "Iteration 932, loss = 1484602193.82716703\n",
            "Iteration 933, loss = 1484548473.62893653\n",
            "Iteration 934, loss = 1484494623.33678365\n",
            "Iteration 935, loss = 1484440788.88312173\n",
            "Iteration 936, loss = 1484387211.55119753\n",
            "Iteration 937, loss = 1484333382.93988538\n",
            "Iteration 938, loss = 1484279772.06312728\n",
            "Iteration 939, loss = 1484226324.28725719\n",
            "Iteration 940, loss = 1484172858.63180995\n",
            "Iteration 941, loss = 1484119406.65582180\n",
            "Iteration 942, loss = 1484065916.82855606\n",
            "Iteration 943, loss = 1484012404.71863818\n",
            "Iteration 944, loss = 1483959087.05960655\n",
            "Iteration 945, loss = 1483905488.23565960\n",
            "Iteration 946, loss = 1483851866.62895370\n",
            "Iteration 947, loss = 1483798096.00200438\n",
            "Iteration 948, loss = 1483744473.61435056\n",
            "Iteration 949, loss = 1483690713.97172976\n",
            "Iteration 950, loss = 1483636646.01587558\n",
            "Iteration 951, loss = 1483582825.21937418\n",
            "Iteration 952, loss = 1483528405.11472440\n",
            "Iteration 953, loss = 1483474525.84381509\n",
            "Iteration 954, loss = 1483419777.34147954\n",
            "Iteration 955, loss = 1483365782.66157794\n",
            "Iteration 956, loss = 1483311100.10976124\n",
            "Iteration 957, loss = 1483256717.65059352\n",
            "Iteration 958, loss = 1483202251.09814024\n",
            "Iteration 959, loss = 1483147979.90676689\n",
            "Iteration 960, loss = 1483093626.32314682\n",
            "Iteration 961, loss = 1483039501.53740549\n",
            "Iteration 962, loss = 1482985385.09032345\n",
            "Iteration 963, loss = 1482931290.58327150\n",
            "Iteration 964, loss = 1482877377.26409674\n",
            "Iteration 965, loss = 1482823796.68381214\n",
            "Iteration 966, loss = 1482769671.84001684\n",
            "Iteration 967, loss = 1482715872.01882648\n",
            "Iteration 968, loss = 1482662106.45203662\n",
            "Iteration 969, loss = 1482608226.17530560\n",
            "Iteration 970, loss = 1482554285.86807990\n",
            "Iteration 971, loss = 1482500810.01667213\n",
            "Iteration 972, loss = 1482446740.15683031\n",
            "Iteration 973, loss = 1482392644.10768485\n",
            "Iteration 974, loss = 1482339054.60539460\n",
            "Iteration 975, loss = 1482285209.85713649\n",
            "Iteration 976, loss = 1482231130.04739928\n",
            "Iteration 977, loss = 1482177269.80033422\n",
            "Iteration 978, loss = 1482123739.06429195\n",
            "Iteration 979, loss = 1482069762.16099596\n",
            "Iteration 980, loss = 1482016088.29933405\n",
            "Iteration 981, loss = 1481962587.87355828\n",
            "Iteration 982, loss = 1481908937.82104683\n",
            "Iteration 983, loss = 1481855572.23895955\n",
            "Iteration 984, loss = 1481801580.10331964\n",
            "Iteration 985, loss = 1481747907.91129804\n",
            "Iteration 986, loss = 1481694314.47922134\n",
            "Iteration 987, loss = 1481640620.81723166\n",
            "Iteration 988, loss = 1481586714.52902412\n",
            "Iteration 989, loss = 1481532937.42591286\n",
            "Iteration 990, loss = 1481479018.00209284\n",
            "Iteration 991, loss = 1481425180.58115339\n",
            "Iteration 992, loss = 1481371429.43148541\n",
            "Iteration 993, loss = 1481317232.33850980\n",
            "Iteration 994, loss = 1481263511.87109160\n",
            "Iteration 995, loss = 1481209675.96915364\n",
            "Iteration 996, loss = 1481155399.80588818\n",
            "Iteration 997, loss = 1481101859.32075143\n",
            "Iteration 998, loss = 1481048142.38307166\n",
            "Iteration 999, loss = 1480993931.20728803\n",
            "Iteration 1000, loss = 1480940392.03624892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1519338193.40074730\n",
            "Iteration 2, loss = 502727726.88187295\n",
            "Iteration 3, loss = 181373456.76476321\n",
            "Iteration 4, loss = 193391148.41163248\n",
            "Iteration 5, loss = 113703808.80454075\n",
            "Iteration 6, loss = 41909962.90051908\n",
            "Iteration 7, loss = 32898744.36217202\n",
            "Iteration 8, loss = 36818363.01212216\n",
            "Iteration 9, loss = 29682297.99960962\n",
            "Iteration 10, loss = 28944227.85830556\n",
            "Iteration 11, loss = 31359302.00648579\n",
            "Iteration 12, loss = 29500965.38813332\n",
            "Iteration 13, loss = 30448787.12122264\n",
            "Iteration 14, loss = 27949266.89575749\n",
            "Iteration 15, loss = 26805529.70933548\n",
            "Iteration 16, loss = 30011191.46949454\n",
            "Iteration 17, loss = 27471051.84539215\n",
            "Iteration 18, loss = 26373956.98113587\n",
            "Iteration 19, loss = 25884091.51405013\n",
            "Iteration 20, loss = 25440541.02011523\n",
            "Iteration 21, loss = 24474868.92727971\n",
            "Iteration 22, loss = 23049522.15177253\n",
            "Iteration 23, loss = 22955952.81110585\n",
            "Iteration 24, loss = 22939224.96473895\n",
            "Iteration 25, loss = 23058443.60764991\n",
            "Iteration 26, loss = 23113754.67871282\n",
            "Iteration 27, loss = 22915896.63980442\n",
            "Iteration 28, loss = 22776624.93379847\n",
            "Iteration 29, loss = 22666422.59554143\n",
            "Iteration 30, loss = 22571351.41385619\n",
            "Iteration 31, loss = 22414138.75751586\n",
            "Iteration 32, loss = 22282309.24526514\n",
            "Iteration 33, loss = 22087762.33477811\n",
            "Iteration 34, loss = 21930825.47147913\n",
            "Iteration 35, loss = 21710052.05214758\n",
            "Iteration 36, loss = 21647477.95196337\n",
            "Iteration 37, loss = 21494080.70137307\n",
            "Iteration 38, loss = 21300649.79343567\n",
            "Iteration 39, loss = 21028454.96097242\n",
            "Iteration 40, loss = 21353781.13751990\n",
            "Iteration 41, loss = 21584699.68545200\n",
            "Iteration 42, loss = 21555531.77128315\n",
            "Iteration 43, loss = 21352563.13084052\n",
            "Iteration 44, loss = 21125990.13493432\n",
            "Iteration 45, loss = 20710590.12457489\n",
            "Iteration 46, loss = 19881136.68518719\n",
            "Iteration 47, loss = 19674460.28462103\n",
            "Iteration 48, loss = 20086590.44684159\n",
            "Iteration 49, loss = 20624557.08138591\n",
            "Iteration 50, loss = 19806687.19542807\n",
            "Iteration 51, loss = 19694221.36165112\n",
            "Iteration 52, loss = 20165058.26237545\n",
            "Iteration 53, loss = 20298230.30559343\n",
            "Iteration 54, loss = 20254102.92449733\n",
            "Iteration 55, loss = 20189826.18867230\n",
            "Iteration 56, loss = 20145427.19606140\n",
            "Iteration 57, loss = 19930722.60542645\n",
            "Iteration 58, loss = 19903423.18142758\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538831788.76625514\n",
            "Iteration 2, loss = 1538806542.16044116\n",
            "Iteration 3, loss = 1538781320.74065018\n",
            "Iteration 4, loss = 1538756436.65470481\n",
            "Iteration 5, loss = 1538731811.63192105\n",
            "Iteration 6, loss = 1538707027.02311420\n",
            "Iteration 7, loss = 1538681391.40124035\n",
            "Iteration 8, loss = 1538655361.44037604\n",
            "Iteration 9, loss = 1538630626.67343950\n",
            "Iteration 10, loss = 1538602394.58117580\n",
            "Iteration 11, loss = 1538574474.78793287\n",
            "Iteration 12, loss = 1538545261.42145538\n",
            "Iteration 13, loss = 1538516576.18523788\n",
            "Iteration 14, loss = 1538485061.39977646\n",
            "Iteration 15, loss = 1538452088.71292067\n",
            "Iteration 16, loss = 1538418094.13992476\n",
            "Iteration 17, loss = 1538382514.15476298\n",
            "Iteration 18, loss = 1538345008.48850489\n",
            "Iteration 19, loss = 1538305710.02057981\n",
            "Iteration 20, loss = 1538263690.17632627\n",
            "Iteration 21, loss = 1538219978.92793489\n",
            "Iteration 22, loss = 1538174015.65796089\n",
            "Iteration 23, loss = 1538125517.50875211\n",
            "Iteration 24, loss = 1538074585.88397431\n",
            "Iteration 25, loss = 1538021304.49749207\n",
            "Iteration 26, loss = 1537966464.70853758\n",
            "Iteration 27, loss = 1537908748.13136816\n",
            "Iteration 28, loss = 1537849055.05292010\n",
            "Iteration 29, loss = 1537787747.29108548\n",
            "Iteration 30, loss = 1537724947.14578080\n",
            "Iteration 31, loss = 1537660772.45423889\n",
            "Iteration 32, loss = 1537595567.11894417\n",
            "Iteration 33, loss = 1537528389.68419003\n",
            "Iteration 34, loss = 1537459752.90825057\n",
            "Iteration 35, loss = 1537389864.27747750\n",
            "Iteration 36, loss = 1537317968.80837798\n",
            "Iteration 37, loss = 1537245606.85791302\n",
            "Iteration 38, loss = 1537171059.38809538\n",
            "Iteration 39, loss = 1537095934.99851370\n",
            "Iteration 40, loss = 1537019506.27573109\n",
            "Iteration 41, loss = 1536941651.37106943\n",
            "Iteration 42, loss = 1536862466.80633998\n",
            "Iteration 43, loss = 1536781039.72860217\n",
            "Iteration 44, loss = 1536697899.01398993\n",
            "Iteration 45, loss = 1536612090.16888595\n",
            "Iteration 46, loss = 1536524608.64617944\n",
            "Iteration 47, loss = 1536435100.93120098\n",
            "Iteration 48, loss = 1536343599.15722847\n",
            "Iteration 49, loss = 1536250659.89229345\n",
            "Iteration 50, loss = 1536156646.42871809\n",
            "Iteration 51, loss = 1536061438.44913888\n",
            "Iteration 52, loss = 1535966074.24701071\n",
            "Iteration 53, loss = 1535869781.27934718\n",
            "Iteration 54, loss = 1535773617.83656573\n",
            "Iteration 55, loss = 1535676587.54227328\n",
            "Iteration 56, loss = 1535579184.77877736\n",
            "Iteration 57, loss = 1535481983.84807801\n",
            "Iteration 58, loss = 1535385035.74456120\n",
            "Iteration 59, loss = 1535288572.70788360\n",
            "Iteration 60, loss = 1535192957.74684834\n",
            "Iteration 61, loss = 1535099164.93064666\n",
            "Iteration 62, loss = 1535007094.00052190\n",
            "Iteration 63, loss = 1534916966.39010501\n",
            "Iteration 64, loss = 1534827417.09129119\n",
            "Iteration 65, loss = 1534739181.18650460\n",
            "Iteration 66, loss = 1534651492.23007464\n",
            "Iteration 67, loss = 1534563945.94631171\n",
            "Iteration 68, loss = 1534477374.26728439\n",
            "Iteration 69, loss = 1534390279.93046212\n",
            "Iteration 70, loss = 1534304312.38620949\n",
            "Iteration 71, loss = 1534219944.00224781\n",
            "Iteration 72, loss = 1534135242.80380654\n",
            "Iteration 73, loss = 1534051593.07901144\n",
            "Iteration 74, loss = 1533968841.85543299\n",
            "Iteration 75, loss = 1533886380.79080081\n",
            "Iteration 76, loss = 1533804594.94452620\n",
            "Iteration 77, loss = 1533723618.29203033\n",
            "Iteration 78, loss = 1533643043.35317254\n",
            "Iteration 79, loss = 1533562447.55215621\n",
            "Iteration 80, loss = 1533482813.37990308\n",
            "Iteration 81, loss = 1533403963.45573330\n",
            "Iteration 82, loss = 1533325126.34153175\n",
            "Iteration 83, loss = 1533247447.19779277\n",
            "Iteration 84, loss = 1533169230.03861117\n",
            "Iteration 85, loss = 1533092336.62861919\n",
            "Iteration 86, loss = 1533014730.08032417\n",
            "Iteration 87, loss = 1532938516.28551531\n",
            "Iteration 88, loss = 1532862160.16843200\n",
            "Iteration 89, loss = 1532785870.30054259\n",
            "Iteration 90, loss = 1532710520.00453448\n",
            "Iteration 91, loss = 1532635862.98901391\n",
            "Iteration 92, loss = 1532560379.15543318\n",
            "Iteration 93, loss = 1532485847.42647934\n",
            "Iteration 94, loss = 1532411700.40233588\n",
            "Iteration 95, loss = 1532337936.58451200\n",
            "Iteration 96, loss = 1532264634.94168210\n",
            "Iteration 97, loss = 1532191474.92674279\n",
            "Iteration 98, loss = 1532119346.09070563\n",
            "Iteration 99, loss = 1532046737.64601946\n",
            "Iteration 100, loss = 1531974678.81841826\n",
            "Iteration 101, loss = 1531903253.74688911\n",
            "Iteration 102, loss = 1531831329.24514437\n",
            "Iteration 103, loss = 1531760407.72002316\n",
            "Iteration 104, loss = 1531689120.18413806\n",
            "Iteration 105, loss = 1531618130.98977375\n",
            "Iteration 106, loss = 1531547607.72267818\n",
            "Iteration 107, loss = 1531476568.73204589\n",
            "Iteration 108, loss = 1531406518.20979166\n",
            "Iteration 109, loss = 1531336706.38571000\n",
            "Iteration 110, loss = 1531266438.11441803\n",
            "Iteration 111, loss = 1531196810.94810128\n",
            "Iteration 112, loss = 1531127461.80684400\n",
            "Iteration 113, loss = 1531058294.91172981\n",
            "Iteration 114, loss = 1530989345.90313148\n",
            "Iteration 115, loss = 1530920619.75461411\n",
            "Iteration 116, loss = 1530852536.96835303\n",
            "Iteration 117, loss = 1530784014.75357985\n",
            "Iteration 118, loss = 1530716161.17842960\n",
            "Iteration 119, loss = 1530647883.97130656\n",
            "Iteration 120, loss = 1530580017.09119940\n",
            "Iteration 121, loss = 1530512365.05999732\n",
            "Iteration 122, loss = 1530445003.51642895\n",
            "Iteration 123, loss = 1530377187.10215402\n",
            "Iteration 124, loss = 1530309888.67328954\n",
            "Iteration 125, loss = 1530243051.54376030\n",
            "Iteration 126, loss = 1530175568.99127316\n",
            "Iteration 127, loss = 1530109287.47499657\n",
            "Iteration 128, loss = 1530042459.35698700\n",
            "Iteration 129, loss = 1529976073.11747503\n",
            "Iteration 130, loss = 1529909610.66572809\n",
            "Iteration 131, loss = 1529843517.62016559\n",
            "Iteration 132, loss = 1529777135.50526595\n",
            "Iteration 133, loss = 1529711528.95209718\n",
            "Iteration 134, loss = 1529645269.38438797\n",
            "Iteration 135, loss = 1529579663.75832176\n",
            "Iteration 136, loss = 1529513806.02531338\n",
            "Iteration 137, loss = 1529448227.06268191\n",
            "Iteration 138, loss = 1529382758.30660796\n",
            "Iteration 139, loss = 1529317894.55118275\n",
            "Iteration 140, loss = 1529252125.49169874\n",
            "Iteration 141, loss = 1529187370.21819496\n",
            "Iteration 142, loss = 1529122585.42741203\n",
            "Iteration 143, loss = 1529057852.60822773\n",
            "Iteration 144, loss = 1528992875.09482503\n",
            "Iteration 145, loss = 1528928849.76375890\n",
            "Iteration 146, loss = 1528864457.93897128\n",
            "Iteration 147, loss = 1528800009.85720873\n",
            "Iteration 148, loss = 1528735842.89360666\n",
            "Iteration 149, loss = 1528671550.09169030\n",
            "Iteration 150, loss = 1528607806.86742926\n",
            "Iteration 151, loss = 1528544146.28124666\n",
            "Iteration 152, loss = 1528480021.17422771\n",
            "Iteration 153, loss = 1528416237.58745527\n",
            "Iteration 154, loss = 1528352640.57862830\n",
            "Iteration 155, loss = 1528289242.49463749\n",
            "Iteration 156, loss = 1528225713.02492905\n",
            "Iteration 157, loss = 1528162231.81456256\n",
            "Iteration 158, loss = 1528098965.75251555\n",
            "Iteration 159, loss = 1528036117.07239962\n",
            "Iteration 160, loss = 1527972983.67898917\n",
            "Iteration 161, loss = 1527910108.35522914\n",
            "Iteration 162, loss = 1527847201.22750735\n",
            "Iteration 163, loss = 1527784352.55397654\n",
            "Iteration 164, loss = 1527721829.58080196\n",
            "Iteration 165, loss = 1527658864.77025580\n",
            "Iteration 166, loss = 1527596457.41611671\n",
            "Iteration 167, loss = 1527533358.90981793\n",
            "Iteration 168, loss = 1527471379.74828815\n",
            "Iteration 169, loss = 1527408701.94357157\n",
            "Iteration 170, loss = 1527346438.65788245\n",
            "Iteration 171, loss = 1527284067.05112815\n",
            "Iteration 172, loss = 1527221815.75479388\n",
            "Iteration 173, loss = 1527159514.44979596\n",
            "Iteration 174, loss = 1527097389.33109140\n",
            "Iteration 175, loss = 1527034822.49562788\n",
            "Iteration 176, loss = 1526972709.94452357\n",
            "Iteration 177, loss = 1526910299.68017721\n",
            "Iteration 178, loss = 1526848386.12808824\n",
            "Iteration 179, loss = 1526785801.58849406\n",
            "Iteration 180, loss = 1526724742.98025918\n",
            "Iteration 181, loss = 1526662535.23572659\n",
            "Iteration 182, loss = 1526600812.34248996\n",
            "Iteration 183, loss = 1526539425.90057921\n",
            "Iteration 184, loss = 1526477917.42372704\n",
            "Iteration 185, loss = 1526416631.84815097\n",
            "Iteration 186, loss = 1526355093.29618144\n",
            "Iteration 187, loss = 1526293931.73850918\n",
            "Iteration 188, loss = 1526232039.42477942\n",
            "Iteration 189, loss = 1526170737.73851204\n",
            "Iteration 190, loss = 1526109417.46971154\n",
            "Iteration 191, loss = 1526047733.30414104\n",
            "Iteration 192, loss = 1525986046.22269940\n",
            "Iteration 193, loss = 1525924195.45745778\n",
            "Iteration 194, loss = 1525862751.11019874\n",
            "Iteration 195, loss = 1525801613.15573955\n",
            "Iteration 196, loss = 1525739678.41704273\n",
            "Iteration 197, loss = 1525678807.81128502\n",
            "Iteration 198, loss = 1525617268.60040855\n",
            "Iteration 199, loss = 1525556048.64567947\n",
            "Iteration 200, loss = 1525495556.57474875\n",
            "Iteration 201, loss = 1525434501.20817757\n",
            "Iteration 202, loss = 1525373517.22105980\n",
            "Iteration 203, loss = 1525312673.16045594\n",
            "Iteration 204, loss = 1525251859.46473145\n",
            "Iteration 205, loss = 1525191147.63773513\n",
            "Iteration 206, loss = 1525130265.60596752\n",
            "Iteration 207, loss = 1525069403.75810528\n",
            "Iteration 208, loss = 1525008733.77995682\n",
            "Iteration 209, loss = 1524948024.20804238\n",
            "Iteration 210, loss = 1524887449.90127873\n",
            "Iteration 211, loss = 1524826465.31900191\n",
            "Iteration 212, loss = 1524766737.40633273\n",
            "Iteration 213, loss = 1524705307.63355374\n",
            "Iteration 214, loss = 1524645302.36401582\n",
            "Iteration 215, loss = 1524584947.50599742\n",
            "Iteration 216, loss = 1524524611.60859919\n",
            "Iteration 217, loss = 1524464087.76151705\n",
            "Iteration 218, loss = 1524404105.28363276\n",
            "Iteration 219, loss = 1524344215.00336623\n",
            "Iteration 220, loss = 1524284156.91497588\n",
            "Iteration 221, loss = 1524224069.55427957\n",
            "Iteration 222, loss = 1524164159.80744767\n",
            "Iteration 223, loss = 1524104187.99293280\n",
            "Iteration 224, loss = 1524044504.37757492\n",
            "Iteration 225, loss = 1523984254.01330948\n",
            "Iteration 226, loss = 1523924433.82311368\n",
            "Iteration 227, loss = 1523864958.65093708\n",
            "Iteration 228, loss = 1523805021.04553771\n",
            "Iteration 229, loss = 1523745500.32577133\n",
            "Iteration 230, loss = 1523686180.34565520\n",
            "Iteration 231, loss = 1523626440.74823928\n",
            "Iteration 232, loss = 1523567037.93104482\n",
            "Iteration 233, loss = 1523507430.43069935\n",
            "Iteration 234, loss = 1523447964.12512922\n",
            "Iteration 235, loss = 1523388088.23492932\n",
            "Iteration 236, loss = 1523328665.04963303\n",
            "Iteration 237, loss = 1523269174.10790205\n",
            "Iteration 238, loss = 1523209903.50482726\n",
            "Iteration 239, loss = 1523150045.27905917\n",
            "Iteration 240, loss = 1523090770.01459503\n",
            "Iteration 241, loss = 1523031540.42635536\n",
            "Iteration 242, loss = 1522972200.05254078\n",
            "Iteration 243, loss = 1522913010.25176549\n",
            "Iteration 244, loss = 1522853443.96132326\n",
            "Iteration 245, loss = 1522794591.06180954\n",
            "Iteration 246, loss = 1522735552.28420877\n",
            "Iteration 247, loss = 1522676382.65608311\n",
            "Iteration 248, loss = 1522617724.61744618\n",
            "Iteration 249, loss = 1522558538.22148085\n",
            "Iteration 250, loss = 1522499539.64558530\n",
            "Iteration 251, loss = 1522440516.06671906\n",
            "Iteration 252, loss = 1522381562.83180761\n",
            "Iteration 253, loss = 1522322762.51589513\n",
            "Iteration 254, loss = 1522263294.01911831\n",
            "Iteration 255, loss = 1522204307.15660524\n",
            "Iteration 256, loss = 1522145319.55506015\n",
            "Iteration 257, loss = 1522086565.21659422\n",
            "Iteration 258, loss = 1522026970.83228326\n",
            "Iteration 259, loss = 1521968339.75532031\n",
            "Iteration 260, loss = 1521909655.11057878\n",
            "Iteration 261, loss = 1521850438.58772683\n",
            "Iteration 262, loss = 1521791766.27140856\n",
            "Iteration 263, loss = 1521732982.27584577\n",
            "Iteration 264, loss = 1521674138.70972991\n",
            "Iteration 265, loss = 1521615545.78874683\n",
            "Iteration 266, loss = 1521556708.04933310\n",
            "Iteration 267, loss = 1521497848.30498552\n",
            "Iteration 268, loss = 1521439541.86100435\n",
            "Iteration 269, loss = 1521380314.52658319\n",
            "Iteration 270, loss = 1521321974.28733349\n",
            "Iteration 271, loss = 1521263080.68228245\n",
            "Iteration 272, loss = 1521204352.52085304\n",
            "Iteration 273, loss = 1521145755.96867609\n",
            "Iteration 274, loss = 1521087289.86747408\n",
            "Iteration 275, loss = 1521028613.26214552\n",
            "Iteration 276, loss = 1520970053.56225681\n",
            "Iteration 277, loss = 1520911661.01045680\n",
            "Iteration 278, loss = 1520853090.91615272\n",
            "Iteration 279, loss = 1520794914.00062823\n",
            "Iteration 280, loss = 1520736569.04617810\n",
            "Iteration 281, loss = 1520678239.48086333\n",
            "Iteration 282, loss = 1520619831.00098801\n",
            "Iteration 283, loss = 1520561926.96979547\n",
            "Iteration 284, loss = 1520503415.59923434\n",
            "Iteration 285, loss = 1520445545.21048498\n",
            "Iteration 286, loss = 1520387383.39500928\n",
            "Iteration 287, loss = 1520329036.44958329\n",
            "Iteration 288, loss = 1520270822.08035469\n",
            "Iteration 289, loss = 1520212908.26746583\n",
            "Iteration 290, loss = 1520154772.71201372\n",
            "Iteration 291, loss = 1520096501.38813806\n",
            "Iteration 292, loss = 1520038690.30910659\n",
            "Iteration 293, loss = 1519980761.51630139\n",
            "Iteration 294, loss = 1519922682.62058306\n",
            "Iteration 295, loss = 1519864315.87423348\n",
            "Iteration 296, loss = 1519806857.33239388\n",
            "Iteration 297, loss = 1519748940.00064731\n",
            "Iteration 298, loss = 1519690872.88474703\n",
            "Iteration 299, loss = 1519633037.87854600\n",
            "Iteration 300, loss = 1519575263.59703159\n",
            "Iteration 301, loss = 1519517826.63579774\n",
            "Iteration 302, loss = 1519460195.18694520\n",
            "Iteration 303, loss = 1519402176.40014410\n",
            "Iteration 304, loss = 1519344807.33740711\n",
            "Iteration 305, loss = 1519287048.52980709\n",
            "Iteration 306, loss = 1519229873.35139513\n",
            "Iteration 307, loss = 1519171838.56156540\n",
            "Iteration 308, loss = 1519114602.47403264\n",
            "Iteration 309, loss = 1519056919.51378870\n",
            "Iteration 310, loss = 1518999120.95992994\n",
            "Iteration 311, loss = 1518941832.61875534\n",
            "Iteration 312, loss = 1518884209.26443291\n",
            "Iteration 313, loss = 1518826298.78719950\n",
            "Iteration 314, loss = 1518769140.63276029\n",
            "Iteration 315, loss = 1518711215.83389711\n",
            "Iteration 316, loss = 1518653896.04583597\n",
            "Iteration 317, loss = 1518596679.77158904\n",
            "Iteration 318, loss = 1518539291.22030187\n",
            "Iteration 319, loss = 1518481927.10710716\n",
            "Iteration 320, loss = 1518424723.32110190\n",
            "Iteration 321, loss = 1518367542.54027390\n",
            "Iteration 322, loss = 1518310635.39054060\n",
            "Iteration 323, loss = 1518253242.71795177\n",
            "Iteration 324, loss = 1518195963.40188456\n",
            "Iteration 325, loss = 1518138885.94209194\n",
            "Iteration 326, loss = 1518081628.42070127\n",
            "Iteration 327, loss = 1518024373.85773873\n",
            "Iteration 328, loss = 1517966958.62931275\n",
            "Iteration 329, loss = 1517909515.77173662\n",
            "Iteration 330, loss = 1517852336.99864888\n",
            "Iteration 331, loss = 1517794230.53536534\n",
            "Iteration 332, loss = 1517736861.66771293\n",
            "Iteration 333, loss = 1517679347.90356469\n",
            "Iteration 334, loss = 1517621389.30069852\n",
            "Iteration 335, loss = 1517564054.89237547\n",
            "Iteration 336, loss = 1517506274.61827898\n",
            "Iteration 337, loss = 1517448372.49731040\n",
            "Iteration 338, loss = 1517391115.43534708\n",
            "Iteration 339, loss = 1517333403.33603168\n",
            "Iteration 340, loss = 1517276060.81950188\n",
            "Iteration 341, loss = 1517218592.77215743\n",
            "Iteration 342, loss = 1517161176.60275340\n",
            "Iteration 343, loss = 1517103754.31305814\n",
            "Iteration 344, loss = 1517047001.56208086\n",
            "Iteration 345, loss = 1516989503.77230024\n",
            "Iteration 346, loss = 1516932515.14425898\n",
            "Iteration 347, loss = 1516875418.05535769\n",
            "Iteration 348, loss = 1516818126.47799277\n",
            "Iteration 349, loss = 1516761296.64597940\n",
            "Iteration 350, loss = 1516703982.87948728\n",
            "Iteration 351, loss = 1516647146.30570936\n",
            "Iteration 352, loss = 1516589715.00543714\n",
            "Iteration 353, loss = 1516532829.39846468\n",
            "Iteration 354, loss = 1516475891.53589344\n",
            "Iteration 355, loss = 1516418818.34618211\n",
            "Iteration 356, loss = 1516361800.01611352\n",
            "Iteration 357, loss = 1516304489.41504908\n",
            "Iteration 358, loss = 1516247637.39339352\n",
            "Iteration 359, loss = 1516190345.53054976\n",
            "Iteration 360, loss = 1516133603.49773932\n",
            "Iteration 361, loss = 1516076042.55278397\n",
            "Iteration 362, loss = 1516019455.94879961\n",
            "Iteration 363, loss = 1515962623.59972119\n",
            "Iteration 364, loss = 1515905754.10246325\n",
            "Iteration 365, loss = 1515848902.27178907\n",
            "Iteration 366, loss = 1515792316.18674088\n",
            "Iteration 367, loss = 1515735623.26969719\n",
            "Iteration 368, loss = 1515679050.17102909\n",
            "Iteration 369, loss = 1515621941.08043599\n",
            "Iteration 370, loss = 1515565164.65251160\n",
            "Iteration 371, loss = 1515508230.36127949\n",
            "Iteration 372, loss = 1515451433.54107070\n",
            "Iteration 373, loss = 1515394651.83045864\n",
            "Iteration 374, loss = 1515337440.73597431\n",
            "Iteration 375, loss = 1515280537.94676471\n",
            "Iteration 376, loss = 1515223641.22757339\n",
            "Iteration 377, loss = 1515166949.77145076\n",
            "Iteration 378, loss = 1515110142.28792357\n",
            "Iteration 379, loss = 1515053207.05280995\n",
            "Iteration 380, loss = 1514996159.76890111\n",
            "Iteration 381, loss = 1514939431.88992381\n",
            "Iteration 382, loss = 1514882433.09222651\n",
            "Iteration 383, loss = 1514825342.93083501\n",
            "Iteration 384, loss = 1514768567.16383529\n",
            "Iteration 385, loss = 1514711366.46928763\n",
            "Iteration 386, loss = 1514654344.67127633\n",
            "Iteration 387, loss = 1514597442.76444030\n",
            "Iteration 388, loss = 1514540364.02068138\n",
            "Iteration 389, loss = 1514483549.95627451\n",
            "Iteration 390, loss = 1514426351.19480085\n",
            "Iteration 391, loss = 1514369627.25371814\n",
            "Iteration 392, loss = 1514312373.74612188\n",
            "Iteration 393, loss = 1514255910.31396723\n",
            "Iteration 394, loss = 1514198772.38489485\n",
            "Iteration 395, loss = 1514141791.72558618\n",
            "Iteration 396, loss = 1514084877.49031711\n",
            "Iteration 397, loss = 1514027848.61783552\n",
            "Iteration 398, loss = 1513971059.96704507\n",
            "Iteration 399, loss = 1513913932.20628858\n",
            "Iteration 400, loss = 1513857098.58457136\n",
            "Iteration 401, loss = 1513800353.02553630\n",
            "Iteration 402, loss = 1513743157.21371603\n",
            "Iteration 403, loss = 1513686733.83751869\n",
            "Iteration 404, loss = 1513630072.60668135\n",
            "Iteration 405, loss = 1513573174.44853234\n",
            "Iteration 406, loss = 1513516994.60221457\n",
            "Iteration 407, loss = 1513460249.55242062\n",
            "Iteration 408, loss = 1513403801.57103848\n",
            "Iteration 409, loss = 1513347003.34175086\n",
            "Iteration 410, loss = 1513290805.22266674\n",
            "Iteration 411, loss = 1513234297.05619597\n",
            "Iteration 412, loss = 1513177745.28725576\n",
            "Iteration 413, loss = 1513121707.99897337\n",
            "Iteration 414, loss = 1513064884.51319289\n",
            "Iteration 415, loss = 1513008714.13354731\n",
            "Iteration 416, loss = 1512952599.46505046\n",
            "Iteration 417, loss = 1512896081.30284452\n",
            "Iteration 418, loss = 1512839667.82246947\n",
            "Iteration 419, loss = 1512783121.40729141\n",
            "Iteration 420, loss = 1512726762.70344543\n",
            "Iteration 421, loss = 1512670163.65847993\n",
            "Iteration 422, loss = 1512613722.61171222\n",
            "Iteration 423, loss = 1512556958.55745173\n",
            "Iteration 424, loss = 1512500674.59977913\n",
            "Iteration 425, loss = 1512444525.78777051\n",
            "Iteration 426, loss = 1512387793.90771031\n",
            "Iteration 427, loss = 1512331697.45655179\n",
            "Iteration 428, loss = 1512275667.04155898\n",
            "Iteration 429, loss = 1512219198.90815496\n",
            "Iteration 430, loss = 1512163295.04300380\n",
            "Iteration 431, loss = 1512107043.15763402\n",
            "Iteration 432, loss = 1512050786.96360183\n",
            "Iteration 433, loss = 1511994583.42921090\n",
            "Iteration 434, loss = 1511938499.44193792\n",
            "Iteration 435, loss = 1511882453.36144209\n",
            "Iteration 436, loss = 1511826102.16616178\n",
            "Iteration 437, loss = 1511769969.13774800\n",
            "Iteration 438, loss = 1511713768.67535520\n",
            "Iteration 439, loss = 1511657505.72470164\n",
            "Iteration 440, loss = 1511601165.19059992\n",
            "Iteration 441, loss = 1511545534.25222731\n",
            "Iteration 442, loss = 1511488751.14426684\n",
            "Iteration 443, loss = 1511432693.83268595\n",
            "Iteration 444, loss = 1511376783.31992650\n",
            "Iteration 445, loss = 1511319955.08574867\n",
            "Iteration 446, loss = 1511264250.55715513\n",
            "Iteration 447, loss = 1511208021.67542195\n",
            "Iteration 448, loss = 1511151859.49221849\n",
            "Iteration 449, loss = 1511095902.29217792\n",
            "Iteration 450, loss = 1511039349.70082736\n",
            "Iteration 451, loss = 1510983602.20037913\n",
            "Iteration 452, loss = 1510927528.62012553\n",
            "Iteration 453, loss = 1510871601.84952188\n",
            "Iteration 454, loss = 1510815413.34813547\n",
            "Iteration 455, loss = 1510759313.08155894\n",
            "Iteration 456, loss = 1510703601.04717207\n",
            "Iteration 457, loss = 1510647475.19418216\n",
            "Iteration 458, loss = 1510591805.20960689\n",
            "Iteration 459, loss = 1510535706.55994678\n",
            "Iteration 460, loss = 1510479770.00781608\n",
            "Iteration 461, loss = 1510424060.79535937\n",
            "Iteration 462, loss = 1510368284.53687191\n",
            "Iteration 463, loss = 1510312133.10035920\n",
            "Iteration 464, loss = 1510256520.50817418\n",
            "Iteration 465, loss = 1510200660.07805109\n",
            "Iteration 466, loss = 1510144763.32095981\n",
            "Iteration 467, loss = 1510088773.01331902\n",
            "Iteration 468, loss = 1510032869.55439353\n",
            "Iteration 469, loss = 1509976732.83623028\n",
            "Iteration 470, loss = 1509921197.52402973\n",
            "Iteration 471, loss = 1509864922.06109357\n",
            "Iteration 472, loss = 1509808820.69198942\n",
            "Iteration 473, loss = 1509752883.24200225\n",
            "Iteration 474, loss = 1509697198.33660054\n",
            "Iteration 475, loss = 1509640843.56049252\n",
            "Iteration 476, loss = 1509585037.21446180\n",
            "Iteration 477, loss = 1509529265.23037267\n",
            "Iteration 478, loss = 1509472940.08285499\n",
            "Iteration 479, loss = 1509416906.06619430\n",
            "Iteration 480, loss = 1509361209.11381745\n",
            "Iteration 481, loss = 1509304593.85862803\n",
            "Iteration 482, loss = 1509248367.22179008\n",
            "Iteration 483, loss = 1509192428.40497327\n",
            "Iteration 484, loss = 1509135809.34393525\n",
            "Iteration 485, loss = 1509079864.51902533\n",
            "Iteration 486, loss = 1509023803.49286771\n",
            "Iteration 487, loss = 1508967420.95403242\n",
            "Iteration 488, loss = 1508911597.63950944\n",
            "Iteration 489, loss = 1508855474.89533997\n",
            "Iteration 490, loss = 1508799678.47403073\n",
            "Iteration 491, loss = 1508743907.93694329\n",
            "Iteration 492, loss = 1508687979.24723053\n",
            "Iteration 493, loss = 1508632249.43958163\n",
            "Iteration 494, loss = 1508576203.78352857\n",
            "Iteration 495, loss = 1508520889.51837873\n",
            "Iteration 496, loss = 1508464658.41445494\n",
            "Iteration 497, loss = 1508408807.64393687\n",
            "Iteration 498, loss = 1508353027.75735426\n",
            "Iteration 499, loss = 1508296853.06458330\n",
            "Iteration 500, loss = 1508241178.25905108\n",
            "Iteration 501, loss = 1508184887.20739913\n",
            "Iteration 502, loss = 1508129050.77393937\n",
            "Iteration 503, loss = 1508073031.37449670\n",
            "Iteration 504, loss = 1508017039.81892848\n",
            "Iteration 505, loss = 1507960795.03132010\n",
            "Iteration 506, loss = 1507905147.41170192\n",
            "Iteration 507, loss = 1507848931.77617240\n",
            "Iteration 508, loss = 1507793352.30008912\n",
            "Iteration 509, loss = 1507737091.12611508\n",
            "Iteration 510, loss = 1507681180.25149655\n",
            "Iteration 511, loss = 1507625738.68595791\n",
            "Iteration 512, loss = 1507569830.85478139\n",
            "Iteration 513, loss = 1507513876.76467395\n",
            "Iteration 514, loss = 1507458576.12235284\n",
            "Iteration 515, loss = 1507402841.81450176\n",
            "Iteration 516, loss = 1507347288.82591987\n",
            "Iteration 517, loss = 1507291754.85841370\n",
            "Iteration 518, loss = 1507236336.24405217\n",
            "Iteration 519, loss = 1507180735.89672256\n",
            "Iteration 520, loss = 1507125486.29974174\n",
            "Iteration 521, loss = 1507069684.50094438\n",
            "Iteration 522, loss = 1507014546.05399847\n",
            "Iteration 523, loss = 1506959090.16275477\n",
            "Iteration 524, loss = 1506903823.96655416\n",
            "Iteration 525, loss = 1506848558.72945547\n",
            "Iteration 526, loss = 1506793216.70445991\n",
            "Iteration 527, loss = 1506737942.45680356\n",
            "Iteration 528, loss = 1506682898.04685950\n",
            "Iteration 529, loss = 1506627520.65600634\n",
            "Iteration 530, loss = 1506571916.78370023\n",
            "Iteration 531, loss = 1506516686.17111850\n",
            "Iteration 532, loss = 1506460978.00699139\n",
            "Iteration 533, loss = 1506405567.28595853\n",
            "Iteration 534, loss = 1506349853.10469961\n",
            "Iteration 535, loss = 1506294170.46129441\n",
            "Iteration 536, loss = 1506238906.04715347\n",
            "Iteration 537, loss = 1506183216.09336925\n",
            "Iteration 538, loss = 1506127862.61218286\n",
            "Iteration 539, loss = 1506072449.90260792\n",
            "Iteration 540, loss = 1506016801.73932171\n",
            "Iteration 541, loss = 1505961568.13013482\n",
            "Iteration 542, loss = 1505905760.87228465\n",
            "Iteration 543, loss = 1505850711.12892199\n",
            "Iteration 544, loss = 1505795563.92890692\n",
            "Iteration 545, loss = 1505739645.65898228\n",
            "Iteration 546, loss = 1505684690.68248606\n",
            "Iteration 547, loss = 1505629250.51546693\n",
            "Iteration 548, loss = 1505574042.77082777\n",
            "Iteration 549, loss = 1505518567.65773129\n",
            "Iteration 550, loss = 1505463389.16795278\n",
            "Iteration 551, loss = 1505407777.19995856\n",
            "Iteration 552, loss = 1505352353.48342657\n",
            "Iteration 553, loss = 1505297226.95440602\n",
            "Iteration 554, loss = 1505242098.43693995\n",
            "Iteration 555, loss = 1505186679.03216076\n",
            "Iteration 556, loss = 1505131743.24567056\n",
            "Iteration 557, loss = 1505076252.84513092\n",
            "Iteration 558, loss = 1505021244.34500718\n",
            "Iteration 559, loss = 1504965917.04043961\n",
            "Iteration 560, loss = 1504910889.43840528\n",
            "Iteration 561, loss = 1504855784.15049791\n",
            "Iteration 562, loss = 1504800374.86817861\n",
            "Iteration 563, loss = 1504745376.51072645\n",
            "Iteration 564, loss = 1504690359.12820959\n",
            "Iteration 565, loss = 1504635268.57853079\n",
            "Iteration 566, loss = 1504580248.45254874\n",
            "Iteration 567, loss = 1504525257.34732676\n",
            "Iteration 568, loss = 1504470349.97784638\n",
            "Iteration 569, loss = 1504415027.90333533\n",
            "Iteration 570, loss = 1504360020.25275016\n",
            "Iteration 571, loss = 1504304945.39149690\n",
            "Iteration 572, loss = 1504249201.90211225\n",
            "Iteration 573, loss = 1504194167.21029639\n",
            "Iteration 574, loss = 1504138765.25368881\n",
            "Iteration 575, loss = 1504083321.61397505\n",
            "Iteration 576, loss = 1504027880.09031630\n",
            "Iteration 577, loss = 1503972742.66278529\n",
            "Iteration 578, loss = 1503917634.75765085\n",
            "Iteration 579, loss = 1503861909.67235613\n",
            "Iteration 580, loss = 1503807065.98308730\n",
            "Iteration 581, loss = 1503751868.80148506\n",
            "Iteration 582, loss = 1503697276.55818224\n",
            "Iteration 583, loss = 1503641571.57335448\n",
            "Iteration 584, loss = 1503586949.75773454\n",
            "Iteration 585, loss = 1503531989.83865809\n",
            "Iteration 586, loss = 1503476804.69379377\n",
            "Iteration 587, loss = 1503422133.02635503\n",
            "Iteration 588, loss = 1503366829.72228765\n",
            "Iteration 589, loss = 1503312099.96055222\n",
            "Iteration 590, loss = 1503256923.21138978\n",
            "Iteration 591, loss = 1503201861.21012354\n",
            "Iteration 592, loss = 1503147004.75848508\n",
            "Iteration 593, loss = 1503091919.24218655\n",
            "Iteration 594, loss = 1503036771.22971773\n",
            "Iteration 595, loss = 1502981894.64864659\n",
            "Iteration 596, loss = 1502926578.55966997\n",
            "Iteration 597, loss = 1502871436.38017845\n",
            "Iteration 598, loss = 1502816571.93539143\n",
            "Iteration 599, loss = 1502761440.15561128\n",
            "Iteration 600, loss = 1502706245.20905256\n",
            "Iteration 601, loss = 1502651189.16244745\n",
            "Iteration 602, loss = 1502596417.73868299\n",
            "Iteration 603, loss = 1502541486.58498621\n",
            "Iteration 604, loss = 1502486716.62523055\n",
            "Iteration 605, loss = 1502431934.70520043\n",
            "Iteration 606, loss = 1502377329.47238946\n",
            "Iteration 607, loss = 1502322417.25801682\n",
            "Iteration 608, loss = 1502267821.78844905\n",
            "Iteration 609, loss = 1502212805.79891276\n",
            "Iteration 610, loss = 1502157956.69261336\n",
            "Iteration 611, loss = 1502102834.08101416\n",
            "Iteration 612, loss = 1502047996.96986508\n",
            "Iteration 613, loss = 1501992852.27285385\n",
            "Iteration 614, loss = 1501937829.85893393\n",
            "Iteration 615, loss = 1501883076.12864351\n",
            "Iteration 616, loss = 1501828077.41005278\n",
            "Iteration 617, loss = 1501773233.41999412\n",
            "Iteration 618, loss = 1501718324.96065116\n",
            "Iteration 619, loss = 1501663393.42846751\n",
            "Iteration 620, loss = 1501608442.93205452\n",
            "Iteration 621, loss = 1501553480.07596540\n",
            "Iteration 622, loss = 1501498600.24997497\n",
            "Iteration 623, loss = 1501443912.64238667\n",
            "Iteration 624, loss = 1501388428.08591080\n",
            "Iteration 625, loss = 1501333977.20318294\n",
            "Iteration 626, loss = 1501279467.89011979\n",
            "Iteration 627, loss = 1501224398.36693954\n",
            "Iteration 628, loss = 1501169742.97584319\n",
            "Iteration 629, loss = 1501114912.90833521\n",
            "Iteration 630, loss = 1501060401.40220451\n",
            "Iteration 631, loss = 1501005432.64374542\n",
            "Iteration 632, loss = 1500950590.38041592\n",
            "Iteration 633, loss = 1500895961.51128960\n",
            "Iteration 634, loss = 1500840902.28941846\n",
            "Iteration 635, loss = 1500786237.57963443\n",
            "Iteration 636, loss = 1500731450.19342303\n",
            "Iteration 637, loss = 1500676516.77065086\n",
            "Iteration 638, loss = 1500621914.36486626\n",
            "Iteration 639, loss = 1500566753.50974631\n",
            "Iteration 640, loss = 1500511813.34258723\n",
            "Iteration 641, loss = 1500457173.98403692\n",
            "Iteration 642, loss = 1500402198.12690735\n",
            "Iteration 643, loss = 1500347334.79154754\n",
            "Iteration 644, loss = 1500292294.12421155\n",
            "Iteration 645, loss = 1500237547.94731116\n",
            "Iteration 646, loss = 1500182792.11768413\n",
            "Iteration 647, loss = 1500127920.68197322\n",
            "Iteration 648, loss = 1500073238.63524437\n",
            "Iteration 649, loss = 1500018233.91505933\n",
            "Iteration 650, loss = 1499963503.61264229\n",
            "Iteration 651, loss = 1499908916.21852779\n",
            "Iteration 652, loss = 1499853851.12729216\n",
            "Iteration 653, loss = 1499799280.82914662\n",
            "Iteration 654, loss = 1499744059.62506080\n",
            "Iteration 655, loss = 1499689284.12231040\n",
            "Iteration 656, loss = 1499634672.18497777\n",
            "Iteration 657, loss = 1499579636.04018974\n",
            "Iteration 658, loss = 1499524700.66265702\n",
            "Iteration 659, loss = 1499470301.17300940\n",
            "Iteration 660, loss = 1499415054.33262968\n",
            "Iteration 661, loss = 1499360382.88809443\n",
            "Iteration 662, loss = 1499305559.14943218\n",
            "Iteration 663, loss = 1499251002.19806886\n",
            "Iteration 664, loss = 1499195959.66923666\n",
            "Iteration 665, loss = 1499141114.25690079\n",
            "Iteration 666, loss = 1499086967.02380300\n",
            "Iteration 667, loss = 1499031511.55159640\n",
            "Iteration 668, loss = 1498977241.49338388\n",
            "Iteration 669, loss = 1498922375.08472800\n",
            "Iteration 670, loss = 1498867727.99478602\n",
            "Iteration 671, loss = 1498812781.75598550\n",
            "Iteration 672, loss = 1498758277.36559534\n",
            "Iteration 673, loss = 1498702928.68714142\n",
            "Iteration 674, loss = 1498648568.36082625\n",
            "Iteration 675, loss = 1498593729.00068927\n",
            "Iteration 676, loss = 1498538830.69458961\n",
            "Iteration 677, loss = 1498484226.94848037\n",
            "Iteration 678, loss = 1498429887.40582299\n",
            "Iteration 679, loss = 1498375172.56508613\n",
            "Iteration 680, loss = 1498320351.89609170\n",
            "Iteration 681, loss = 1498265968.01291990\n",
            "Iteration 682, loss = 1498211435.62018633\n",
            "Iteration 683, loss = 1498156305.93303394\n",
            "Iteration 684, loss = 1498101682.43604922\n",
            "Iteration 685, loss = 1498046704.47315192\n",
            "Iteration 686, loss = 1497991978.27514172\n",
            "Iteration 687, loss = 1497936732.92088604\n",
            "Iteration 688, loss = 1497882096.65352154\n",
            "Iteration 689, loss = 1497827060.37086439\n",
            "Iteration 690, loss = 1497771941.51564932\n",
            "Iteration 691, loss = 1497716853.57437205\n",
            "Iteration 692, loss = 1497662248.41371894\n",
            "Iteration 693, loss = 1497607062.11313367\n",
            "Iteration 694, loss = 1497552345.24943423\n",
            "Iteration 695, loss = 1497497236.34984183\n",
            "Iteration 696, loss = 1497442585.40096545\n",
            "Iteration 697, loss = 1497388013.08345270\n",
            "Iteration 698, loss = 1497333371.69511676\n",
            "Iteration 699, loss = 1497279042.71803212\n",
            "Iteration 700, loss = 1497224606.40305710\n",
            "Iteration 701, loss = 1497170451.75742912\n",
            "Iteration 702, loss = 1497115528.98874354\n",
            "Iteration 703, loss = 1497061657.16200757\n",
            "Iteration 704, loss = 1497007300.78984118\n",
            "Iteration 705, loss = 1496952835.25125170\n",
            "Iteration 706, loss = 1496898360.16503835\n",
            "Iteration 707, loss = 1496844099.45063472\n",
            "Iteration 708, loss = 1496789469.06291199\n",
            "Iteration 709, loss = 1496735466.28008366\n",
            "Iteration 710, loss = 1496680913.27589417\n",
            "Iteration 711, loss = 1496626501.07600498\n",
            "Iteration 712, loss = 1496572378.74844432\n",
            "Iteration 713, loss = 1496517653.04196048\n",
            "Iteration 714, loss = 1496464068.20547318\n",
            "Iteration 715, loss = 1496409484.13585258\n",
            "Iteration 716, loss = 1496355448.93361545\n",
            "Iteration 717, loss = 1496301249.23728085\n",
            "Iteration 718, loss = 1496246794.59175467\n",
            "Iteration 719, loss = 1496192264.82846379\n",
            "Iteration 720, loss = 1496138123.80348992\n",
            "Iteration 721, loss = 1496083504.04664731\n",
            "Iteration 722, loss = 1496028926.80212665\n",
            "Iteration 723, loss = 1495974570.67368317\n",
            "Iteration 724, loss = 1495920239.73705649\n",
            "Iteration 725, loss = 1495865616.39822507\n",
            "Iteration 726, loss = 1495811365.96655369\n",
            "Iteration 727, loss = 1495757030.68287539\n",
            "Iteration 728, loss = 1495702542.83383870\n",
            "Iteration 729, loss = 1495647813.61317992\n",
            "Iteration 730, loss = 1495593813.42037463\n",
            "Iteration 731, loss = 1495538843.36255026\n",
            "Iteration 732, loss = 1495484474.44969797\n",
            "Iteration 733, loss = 1495429581.73370743\n",
            "Iteration 734, loss = 1495375635.30852866\n",
            "Iteration 735, loss = 1495320844.03748393\n",
            "Iteration 736, loss = 1495266769.55539942\n",
            "Iteration 737, loss = 1495212261.81866264\n",
            "Iteration 738, loss = 1495158055.90821195\n",
            "Iteration 739, loss = 1495103582.97045875\n",
            "Iteration 740, loss = 1495049651.04911995\n",
            "Iteration 741, loss = 1494994977.98893595\n",
            "Iteration 742, loss = 1494940818.85383749\n",
            "Iteration 743, loss = 1494886280.17714405\n",
            "Iteration 744, loss = 1494831931.83813524\n",
            "Iteration 745, loss = 1494777369.69546795\n",
            "Iteration 746, loss = 1494723236.37807059\n",
            "Iteration 747, loss = 1494668722.83882499\n",
            "Iteration 748, loss = 1494614456.96558642\n",
            "Iteration 749, loss = 1494559839.96161246\n",
            "Iteration 750, loss = 1494505917.57435846\n",
            "Iteration 751, loss = 1494451250.46648479\n",
            "Iteration 752, loss = 1494397045.11309481\n",
            "Iteration 753, loss = 1494342571.73685718\n",
            "Iteration 754, loss = 1494288200.76528072\n",
            "Iteration 755, loss = 1494233601.37881207\n",
            "Iteration 756, loss = 1494179223.65315390\n",
            "Iteration 757, loss = 1494124843.89434242\n",
            "Iteration 758, loss = 1494070583.10354185\n",
            "Iteration 759, loss = 1494015957.23489833\n",
            "Iteration 760, loss = 1493961958.20850062\n",
            "Iteration 761, loss = 1493907521.52722287\n",
            "Iteration 762, loss = 1493853163.70871043\n",
            "Iteration 763, loss = 1493799125.39879537\n",
            "Iteration 764, loss = 1493744674.35550523\n",
            "Iteration 765, loss = 1493690347.04889512\n",
            "Iteration 766, loss = 1493636085.54929733\n",
            "Iteration 767, loss = 1493582033.19328260\n",
            "Iteration 768, loss = 1493527458.41868186\n",
            "Iteration 769, loss = 1493472898.49009633\n",
            "Iteration 770, loss = 1493418982.25952578\n",
            "Iteration 771, loss = 1493364127.49577999\n",
            "Iteration 772, loss = 1493309803.13810635\n",
            "Iteration 773, loss = 1493255354.58697915\n",
            "Iteration 774, loss = 1493200708.32294369\n",
            "Iteration 775, loss = 1493146371.27942538\n",
            "Iteration 776, loss = 1493091983.45707154\n",
            "Iteration 777, loss = 1493037456.12344217\n",
            "Iteration 778, loss = 1492983070.51870584\n",
            "Iteration 779, loss = 1492928891.89673972\n",
            "Iteration 780, loss = 1492874577.39853406\n",
            "Iteration 781, loss = 1492819926.49854016\n",
            "Iteration 782, loss = 1492765786.03012419\n",
            "Iteration 783, loss = 1492711528.00343204\n",
            "Iteration 784, loss = 1492657013.91908622\n",
            "Iteration 785, loss = 1492602583.56538296\n",
            "Iteration 786, loss = 1492548346.45096612\n",
            "Iteration 787, loss = 1492493904.51455808\n",
            "Iteration 788, loss = 1492439357.74348235\n",
            "Iteration 789, loss = 1492385271.29666162\n",
            "Iteration 790, loss = 1492330448.14775848\n",
            "Iteration 791, loss = 1492276335.99501252\n",
            "Iteration 792, loss = 1492221710.83205891\n",
            "Iteration 793, loss = 1492167333.24666429\n",
            "Iteration 794, loss = 1492113074.88095117\n",
            "Iteration 795, loss = 1492058561.66818571\n",
            "Iteration 796, loss = 1492004251.36243367\n",
            "Iteration 797, loss = 1491950077.21479797\n",
            "Iteration 798, loss = 1491895613.58693910\n",
            "Iteration 799, loss = 1491841341.21171999\n",
            "Iteration 800, loss = 1491787497.37703776\n",
            "Iteration 801, loss = 1491733172.59287691\n",
            "Iteration 802, loss = 1491678825.56374478\n",
            "Iteration 803, loss = 1491624582.02466536\n",
            "Iteration 804, loss = 1491570300.78381276\n",
            "Iteration 805, loss = 1491516100.35604262\n",
            "Iteration 806, loss = 1491461822.83551145\n",
            "Iteration 807, loss = 1491407394.77841759\n",
            "Iteration 808, loss = 1491353085.97777295\n",
            "Iteration 809, loss = 1491298748.61247945\n",
            "Iteration 810, loss = 1491244374.04151225\n",
            "Iteration 811, loss = 1491190517.19690681\n",
            "Iteration 812, loss = 1491136111.43862128\n",
            "Iteration 813, loss = 1491081942.09294701\n",
            "Iteration 814, loss = 1491027993.84364176\n",
            "Iteration 815, loss = 1490973480.24698591\n",
            "Iteration 816, loss = 1490919581.14602137\n",
            "Iteration 817, loss = 1490865518.21837091\n",
            "Iteration 818, loss = 1490811000.87336254\n",
            "Iteration 819, loss = 1490756485.28495336\n",
            "Iteration 820, loss = 1490702377.15734625\n",
            "Iteration 821, loss = 1490647930.27727103\n",
            "Iteration 822, loss = 1490593678.28755927\n",
            "Iteration 823, loss = 1490539017.38452983\n",
            "Iteration 824, loss = 1490484959.02450585\n",
            "Iteration 825, loss = 1490430460.49994111\n",
            "Iteration 826, loss = 1490376574.73544240\n",
            "Iteration 827, loss = 1490322229.42793798\n",
            "Iteration 828, loss = 1490268072.30928564\n",
            "Iteration 829, loss = 1490213903.98980832\n",
            "Iteration 830, loss = 1490159962.55898452\n",
            "Iteration 831, loss = 1490105777.86075544\n",
            "Iteration 832, loss = 1490051641.41479373\n",
            "Iteration 833, loss = 1489997666.07671070\n",
            "Iteration 834, loss = 1489943433.71584034\n",
            "Iteration 835, loss = 1489889227.51976705\n",
            "Iteration 836, loss = 1489834757.72560835\n",
            "Iteration 837, loss = 1489780584.99560237\n",
            "Iteration 838, loss = 1489726313.42897749\n",
            "Iteration 839, loss = 1489671689.57663345\n",
            "Iteration 840, loss = 1489617693.57315707\n",
            "Iteration 841, loss = 1489563266.57514811\n",
            "Iteration 842, loss = 1489509057.77590966\n",
            "Iteration 843, loss = 1489454784.52802515\n",
            "Iteration 844, loss = 1489400359.21365452\n",
            "Iteration 845, loss = 1489346384.68570447\n",
            "Iteration 846, loss = 1489291832.33598423\n",
            "Iteration 847, loss = 1489237690.58483601\n",
            "Iteration 848, loss = 1489182854.82005072\n",
            "Iteration 849, loss = 1489129067.51176047\n",
            "Iteration 850, loss = 1489074491.02281666\n",
            "Iteration 851, loss = 1489020252.56705499\n",
            "Iteration 852, loss = 1488965875.01696539\n",
            "Iteration 853, loss = 1488911244.72912860\n",
            "Iteration 854, loss = 1488857112.53836250\n",
            "Iteration 855, loss = 1488802741.16714454\n",
            "Iteration 856, loss = 1488748425.83463025\n",
            "Iteration 857, loss = 1488694040.59392715\n",
            "Iteration 858, loss = 1488640065.68649650\n",
            "Iteration 859, loss = 1488585461.99050522\n",
            "Iteration 860, loss = 1488531307.08974767\n",
            "Iteration 861, loss = 1488477239.05247426\n",
            "Iteration 862, loss = 1488423279.26753712\n",
            "Iteration 863, loss = 1488368897.58894920\n",
            "Iteration 864, loss = 1488314912.83357143\n",
            "Iteration 865, loss = 1488261121.16611195\n",
            "Iteration 866, loss = 1488207007.41156149\n",
            "Iteration 867, loss = 1488152910.71315980\n",
            "Iteration 868, loss = 1488099245.89912271\n",
            "Iteration 869, loss = 1488045284.97661471\n",
            "Iteration 870, loss = 1487991211.35738206\n",
            "Iteration 871, loss = 1487937391.68425226\n",
            "Iteration 872, loss = 1487883322.46253538\n",
            "Iteration 873, loss = 1487829210.50040078\n",
            "Iteration 874, loss = 1487775662.28082442\n",
            "Iteration 875, loss = 1487721254.52104521\n",
            "Iteration 876, loss = 1487667223.98135829\n",
            "Iteration 877, loss = 1487613764.71824193\n",
            "Iteration 878, loss = 1487559573.72181749\n",
            "Iteration 879, loss = 1487505626.69393086\n",
            "Iteration 880, loss = 1487451794.60080838\n",
            "Iteration 881, loss = 1487397972.27356553\n",
            "Iteration 882, loss = 1487343996.19139838\n",
            "Iteration 883, loss = 1487290053.30719543\n",
            "Iteration 884, loss = 1487235664.18661165\n",
            "Iteration 885, loss = 1487181356.55615973\n",
            "Iteration 886, loss = 1487127299.37173223\n",
            "Iteration 887, loss = 1487072967.13498306\n",
            "Iteration 888, loss = 1487018539.77431107\n",
            "Iteration 889, loss = 1486964192.28023934\n",
            "Iteration 890, loss = 1486910103.74080992\n",
            "Iteration 891, loss = 1486855728.68069720\n",
            "Iteration 892, loss = 1486801796.48223329\n",
            "Iteration 893, loss = 1486747433.35050011\n",
            "Iteration 894, loss = 1486693565.32007170\n",
            "Iteration 895, loss = 1486639468.68990993\n",
            "Iteration 896, loss = 1486585364.32961392\n",
            "Iteration 897, loss = 1486531115.88050008\n",
            "Iteration 898, loss = 1486477123.01041579\n",
            "Iteration 899, loss = 1486423039.04782295\n",
            "Iteration 900, loss = 1486369135.62883592\n",
            "Iteration 901, loss = 1486314593.99249196\n",
            "Iteration 902, loss = 1486261348.51637697\n",
            "Iteration 903, loss = 1486206809.99206066\n",
            "Iteration 904, loss = 1486153160.15307713\n",
            "Iteration 905, loss = 1486099346.52938533\n",
            "Iteration 906, loss = 1486045500.99332976\n",
            "Iteration 907, loss = 1485991687.38706160\n",
            "Iteration 908, loss = 1485938007.74820709\n",
            "Iteration 909, loss = 1485884101.54342103\n",
            "Iteration 910, loss = 1485829893.31282115\n",
            "Iteration 911, loss = 1485776478.88764977\n",
            "Iteration 912, loss = 1485722227.31552649\n",
            "Iteration 913, loss = 1485668389.06681776\n",
            "Iteration 914, loss = 1485614318.72521091\n",
            "Iteration 915, loss = 1485560253.67123938\n",
            "Iteration 916, loss = 1485506280.88700938\n",
            "Iteration 917, loss = 1485452101.74741220\n",
            "Iteration 918, loss = 1485397821.26179743\n",
            "Iteration 919, loss = 1485343686.07132792\n",
            "Iteration 920, loss = 1485289605.58633089\n",
            "Iteration 921, loss = 1485235155.34430814\n",
            "Iteration 922, loss = 1485180931.49900055\n",
            "Iteration 923, loss = 1485126867.21060205\n",
            "Iteration 924, loss = 1485072773.44319367\n",
            "Iteration 925, loss = 1485018623.57574558\n",
            "Iteration 926, loss = 1484964668.63646603\n",
            "Iteration 927, loss = 1484910262.52455401\n",
            "Iteration 928, loss = 1484856779.26661277\n",
            "Iteration 929, loss = 1484802502.84083176\n",
            "Iteration 930, loss = 1484748924.73631549\n",
            "Iteration 931, loss = 1484695056.29299164\n",
            "Iteration 932, loss = 1484641008.16036749\n",
            "Iteration 933, loss = 1484587462.24630976\n",
            "Iteration 934, loss = 1484533213.19325948\n",
            "Iteration 935, loss = 1484479609.75114202\n",
            "Iteration 936, loss = 1484425809.86375356\n",
            "Iteration 937, loss = 1484371729.80791426\n",
            "Iteration 938, loss = 1484317911.62215304\n",
            "Iteration 939, loss = 1484263976.69538021\n",
            "Iteration 940, loss = 1484210370.77856684\n",
            "Iteration 941, loss = 1484156255.77083421\n",
            "Iteration 942, loss = 1484102802.17807364\n",
            "Iteration 943, loss = 1484048882.38836312\n",
            "Iteration 944, loss = 1483994953.39827514\n",
            "Iteration 945, loss = 1483941215.03106833\n",
            "Iteration 946, loss = 1483887252.83864975\n",
            "Iteration 947, loss = 1483833354.45285940\n",
            "Iteration 948, loss = 1483779413.41692328\n",
            "Iteration 949, loss = 1483725431.15413928\n",
            "Iteration 950, loss = 1483671435.80639338\n",
            "Iteration 951, loss = 1483617469.72802711\n",
            "Iteration 952, loss = 1483563618.66469407\n",
            "Iteration 953, loss = 1483509481.43688440\n",
            "Iteration 954, loss = 1483455411.93077374\n",
            "Iteration 955, loss = 1483401459.46144438\n",
            "Iteration 956, loss = 1483347021.25266385\n",
            "Iteration 957, loss = 1483293185.02625918\n",
            "Iteration 958, loss = 1483238793.02317190\n",
            "Iteration 959, loss = 1483184608.40239930\n",
            "Iteration 960, loss = 1483130921.34064436\n",
            "Iteration 961, loss = 1483076902.85916948\n",
            "Iteration 962, loss = 1483023094.05567455\n",
            "Iteration 963, loss = 1482969190.01803231\n",
            "Iteration 964, loss = 1482915998.68512535\n",
            "Iteration 965, loss = 1482862473.14255857\n",
            "Iteration 966, loss = 1482808820.88259268\n",
            "Iteration 967, loss = 1482755377.63959885\n",
            "Iteration 968, loss = 1482702018.19715285\n",
            "Iteration 969, loss = 1482648578.44679618\n",
            "Iteration 970, loss = 1482594625.87906313\n",
            "Iteration 971, loss = 1482541172.49731517\n",
            "Iteration 972, loss = 1482487770.22608185\n",
            "Iteration 973, loss = 1482433582.58817267\n",
            "Iteration 974, loss = 1482380050.15807819\n",
            "Iteration 975, loss = 1482326366.02269697\n",
            "Iteration 976, loss = 1482272444.64971209\n",
            "Iteration 977, loss = 1482218830.14868689\n",
            "Iteration 978, loss = 1482164865.13767481\n",
            "Iteration 979, loss = 1482110864.44996524\n",
            "Iteration 980, loss = 1482057241.90225530\n",
            "Iteration 981, loss = 1482003156.13146305\n",
            "Iteration 982, loss = 1481949256.03328538\n",
            "Iteration 983, loss = 1481895301.44384575\n",
            "Iteration 984, loss = 1481840926.91905570\n",
            "Iteration 985, loss = 1481786932.82608724\n",
            "Iteration 986, loss = 1481732454.14080381\n",
            "Iteration 987, loss = 1481678397.15488529\n",
            "Iteration 988, loss = 1481623932.62336707\n",
            "Iteration 989, loss = 1481569885.08999777\n",
            "Iteration 990, loss = 1481515361.73292565\n",
            "Iteration 991, loss = 1481461548.88096786\n",
            "Iteration 992, loss = 1481408013.09688330\n",
            "Iteration 993, loss = 1481354043.33901048\n",
            "Iteration 994, loss = 1481300401.90459943\n",
            "Iteration 995, loss = 1481247045.56003332\n",
            "Iteration 996, loss = 1481193782.12309742\n",
            "Iteration 997, loss = 1481140149.73477578\n",
            "Iteration 998, loss = 1481086815.07010436\n",
            "Iteration 999, loss = 1481033194.68333602\n",
            "Iteration 1000, loss = 1480979946.40247941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1409118138.55482244\n",
            "Iteration 2, loss = 1108544505.95962548\n",
            "Iteration 3, loss = 1035722743.63367665\n",
            "Iteration 4, loss = 699284193.48335755\n",
            "Iteration 5, loss = 402563367.40838271\n",
            "Iteration 6, loss = 225966042.99573502\n",
            "Iteration 7, loss = 104018284.76021703\n",
            "Iteration 8, loss = 33196717.09818035\n",
            "Iteration 9, loss = 20506566.94998876\n",
            "Iteration 10, loss = 31993610.09068898\n",
            "Iteration 11, loss = 51449722.88437179\n",
            "Iteration 12, loss = 66608807.23800784\n",
            "Iteration 13, loss = 71681317.32086170\n",
            "Iteration 14, loss = 67334630.14775960\n",
            "Iteration 15, loss = 56952385.03584523\n",
            "Iteration 16, loss = 44635758.39278957\n",
            "Iteration 17, loss = 33533918.23190054\n",
            "Iteration 18, loss = 24926483.62507360\n",
            "Iteration 19, loss = 19382671.18435527\n",
            "Iteration 20, loss = 16741311.45578059\n",
            "Iteration 21, loss = 16396791.81890767\n",
            "Iteration 22, loss = 17161750.86716025\n",
            "Iteration 23, loss = 18028750.88869029\n",
            "Iteration 24, loss = 18915913.40659894\n",
            "Iteration 25, loss = 19013312.86765589\n",
            "Iteration 26, loss = 18781803.93520901\n",
            "Iteration 27, loss = 18210288.87974511\n",
            "Iteration 28, loss = 17664667.28133291\n",
            "Iteration 29, loss = 17018790.65736550\n",
            "Iteration 30, loss = 16534718.87166794\n",
            "Iteration 31, loss = 16183920.15352236\n",
            "Iteration 32, loss = 16084907.90123017\n",
            "Iteration 33, loss = 16344351.28411744\n",
            "Iteration 34, loss = 16544023.24727802\n",
            "Iteration 35, loss = 16305892.52038811\n",
            "Iteration 36, loss = 16160021.99133850\n",
            "Iteration 37, loss = 16222967.39801074\n",
            "Iteration 38, loss = 16110467.90333561\n",
            "Iteration 39, loss = 16033223.64904346\n",
            "Iteration 40, loss = 16051293.25563905\n",
            "Iteration 41, loss = 15901835.48326651\n",
            "Iteration 42, loss = 15973631.24768592\n",
            "Iteration 43, loss = 15933594.98466716\n",
            "Iteration 44, loss = 15868746.24197049\n",
            "Iteration 45, loss = 15885189.06124157\n",
            "Iteration 46, loss = 15937531.10616964\n",
            "Iteration 47, loss = 15936115.45691843\n",
            "Iteration 48, loss = 15918453.72113623\n",
            "Iteration 49, loss = 16019521.66689210\n",
            "Iteration 50, loss = 16320657.97474301\n",
            "Iteration 51, loss = 16432041.06168645\n",
            "Iteration 52, loss = 16176823.90389056\n",
            "Iteration 53, loss = 15921915.68778022\n",
            "Iteration 54, loss = 16108519.29518136\n",
            "Iteration 55, loss = 16042722.45483153\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538805956.70465517\n",
            "Iteration 2, loss = 1538775691.64035797\n",
            "Iteration 3, loss = 1538745391.25778699\n",
            "Iteration 4, loss = 1538715434.87649441\n",
            "Iteration 5, loss = 1538684660.53735304\n",
            "Iteration 6, loss = 1538653783.76639676\n",
            "Iteration 7, loss = 1538622662.51267290\n",
            "Iteration 8, loss = 1538590769.31484795\n",
            "Iteration 9, loss = 1538558293.32827044\n",
            "Iteration 10, loss = 1538525054.77232695\n",
            "Iteration 11, loss = 1538491541.50736856\n",
            "Iteration 12, loss = 1538456963.92870736\n",
            "Iteration 13, loss = 1538421456.56214833\n",
            "Iteration 14, loss = 1538385359.79258966\n",
            "Iteration 15, loss = 1538348253.89925003\n",
            "Iteration 16, loss = 1538310604.71284223\n",
            "Iteration 17, loss = 1538271354.47155190\n",
            "Iteration 18, loss = 1538231793.12697458\n",
            "Iteration 19, loss = 1538191329.65420294\n",
            "Iteration 20, loss = 1538150238.88793492\n",
            "Iteration 21, loss = 1538106904.38645673\n",
            "Iteration 22, loss = 1538064068.48533702\n",
            "Iteration 23, loss = 1538019832.53600121\n",
            "Iteration 24, loss = 1537975328.56356549\n",
            "Iteration 25, loss = 1537928980.41149545\n",
            "Iteration 26, loss = 1537883007.40901518\n",
            "Iteration 27, loss = 1537835539.46187878\n",
            "Iteration 28, loss = 1537787825.10641527\n",
            "Iteration 29, loss = 1537739443.47222471\n",
            "Iteration 30, loss = 1537690690.62659121\n",
            "Iteration 31, loss = 1537642051.44086075\n",
            "Iteration 32, loss = 1537591672.83087683\n",
            "Iteration 33, loss = 1537541439.66265869\n",
            "Iteration 34, loss = 1537490771.25066137\n",
            "Iteration 35, loss = 1537440765.40563464\n",
            "Iteration 36, loss = 1537389320.41830969\n",
            "Iteration 37, loss = 1537336963.96353269\n",
            "Iteration 38, loss = 1537285419.20122004\n",
            "Iteration 39, loss = 1537233392.74177575\n",
            "Iteration 40, loss = 1537180324.09146309\n",
            "Iteration 41, loss = 1537127948.15833306\n",
            "Iteration 42, loss = 1537074843.99313807\n",
            "Iteration 43, loss = 1537020561.32370996\n",
            "Iteration 44, loss = 1536966223.82756162\n",
            "Iteration 45, loss = 1536911921.55878186\n",
            "Iteration 46, loss = 1536855678.88763475\n",
            "Iteration 47, loss = 1536799849.47865295\n",
            "Iteration 48, loss = 1536743081.91668916\n",
            "Iteration 49, loss = 1536685402.82453656\n",
            "Iteration 50, loss = 1536627083.55436420\n",
            "Iteration 51, loss = 1536567933.09322834\n",
            "Iteration 52, loss = 1536507888.13679481\n",
            "Iteration 53, loss = 1536447030.91696906\n",
            "Iteration 54, loss = 1536385422.95526338\n",
            "Iteration 55, loss = 1536322952.88565326\n",
            "Iteration 56, loss = 1536259395.89055967\n",
            "Iteration 57, loss = 1536194883.75467491\n",
            "Iteration 58, loss = 1536129345.92362833\n",
            "Iteration 59, loss = 1536063064.70784140\n",
            "Iteration 60, loss = 1535995604.66043401\n",
            "Iteration 61, loss = 1535927938.17055702\n",
            "Iteration 62, loss = 1535859034.36456871\n",
            "Iteration 63, loss = 1535789919.21965647\n",
            "Iteration 64, loss = 1535720132.17602086\n",
            "Iteration 65, loss = 1535649963.89302707\n",
            "Iteration 66, loss = 1535579354.10668159\n",
            "Iteration 67, loss = 1535508413.58845973\n",
            "Iteration 68, loss = 1535437225.20750356\n",
            "Iteration 69, loss = 1535365656.09919977\n",
            "Iteration 70, loss = 1535294069.35901618\n",
            "Iteration 71, loss = 1535222121.15209246\n",
            "Iteration 72, loss = 1535150204.15214944\n",
            "Iteration 73, loss = 1535078052.97593689\n",
            "Iteration 74, loss = 1535005822.45196700\n",
            "Iteration 75, loss = 1534933700.36425447\n",
            "Iteration 76, loss = 1534861089.20622396\n",
            "Iteration 77, loss = 1534788899.38062263\n",
            "Iteration 78, loss = 1534716225.92627263\n",
            "Iteration 79, loss = 1534643385.68967438\n",
            "Iteration 80, loss = 1534569567.85327387\n",
            "Iteration 81, loss = 1534496407.73504996\n",
            "Iteration 82, loss = 1534422938.94018531\n",
            "Iteration 83, loss = 1534349170.89804149\n",
            "Iteration 84, loss = 1534276232.70359564\n",
            "Iteration 85, loss = 1534203502.63288832\n",
            "Iteration 86, loss = 1534130369.11915326\n",
            "Iteration 87, loss = 1534057947.47141266\n",
            "Iteration 88, loss = 1533985702.32389855\n",
            "Iteration 89, loss = 1533913005.03567958\n",
            "Iteration 90, loss = 1533840995.34053731\n",
            "Iteration 91, loss = 1533769085.79830647\n",
            "Iteration 92, loss = 1533697190.57298303\n",
            "Iteration 93, loss = 1533625544.15386987\n",
            "Iteration 94, loss = 1533553866.93800020\n",
            "Iteration 95, loss = 1533482452.33193278\n",
            "Iteration 96, loss = 1533410540.47172260\n",
            "Iteration 97, loss = 1533339539.22601414\n",
            "Iteration 98, loss = 1533268296.81177330\n",
            "Iteration 99, loss = 1533196655.04933977\n",
            "Iteration 100, loss = 1533126023.70139527\n",
            "Iteration 101, loss = 1533054768.10565257\n",
            "Iteration 102, loss = 1532984555.63050079\n",
            "Iteration 103, loss = 1532913452.88059974\n",
            "Iteration 104, loss = 1532843254.12561822\n",
            "Iteration 105, loss = 1532772745.06718898\n",
            "Iteration 106, loss = 1532702404.17544079\n",
            "Iteration 107, loss = 1532632405.90713620\n",
            "Iteration 108, loss = 1532562354.08596063\n",
            "Iteration 109, loss = 1532492754.17589378\n",
            "Iteration 110, loss = 1532422861.00788426\n",
            "Iteration 111, loss = 1532353425.60977650\n",
            "Iteration 112, loss = 1532284066.22549891\n",
            "Iteration 113, loss = 1532214901.33465743\n",
            "Iteration 114, loss = 1532145959.14254498\n",
            "Iteration 115, loss = 1532076863.54176235\n",
            "Iteration 116, loss = 1532008086.24976373\n",
            "Iteration 117, loss = 1531939377.87789416\n",
            "Iteration 118, loss = 1531870119.21087885\n",
            "Iteration 119, loss = 1531801506.63765645\n",
            "Iteration 120, loss = 1531732285.14017439\n",
            "Iteration 121, loss = 1531664259.77752852\n",
            "Iteration 122, loss = 1531595699.37693310\n",
            "Iteration 123, loss = 1531526818.46031690\n",
            "Iteration 124, loss = 1531458633.68838692\n",
            "Iteration 125, loss = 1531390696.87186837\n",
            "Iteration 126, loss = 1531322471.17002320\n",
            "Iteration 127, loss = 1531254674.41749787\n",
            "Iteration 128, loss = 1531186568.11574435\n",
            "Iteration 129, loss = 1531119128.42711115\n",
            "Iteration 130, loss = 1531051585.57276249\n",
            "Iteration 131, loss = 1530984426.42229056\n",
            "Iteration 132, loss = 1530917294.54492331\n",
            "Iteration 133, loss = 1530850553.30350137\n",
            "Iteration 134, loss = 1530783655.94364119\n",
            "Iteration 135, loss = 1530717176.47053409\n",
            "Iteration 136, loss = 1530650744.82857323\n",
            "Iteration 137, loss = 1530584610.91376519\n",
            "Iteration 138, loss = 1530518104.22003484\n",
            "Iteration 139, loss = 1530452240.58702040\n",
            "Iteration 140, loss = 1530386027.04254436\n",
            "Iteration 141, loss = 1530320020.71301746\n",
            "Iteration 142, loss = 1530254538.81998134\n",
            "Iteration 143, loss = 1530188270.12800646\n",
            "Iteration 144, loss = 1530122537.59112525\n",
            "Iteration 145, loss = 1530056482.17606759\n",
            "Iteration 146, loss = 1529990517.35695553\n",
            "Iteration 147, loss = 1529925604.38775873\n",
            "Iteration 148, loss = 1529859282.09787989\n",
            "Iteration 149, loss = 1529793832.20728397\n",
            "Iteration 150, loss = 1529728620.07333398\n",
            "Iteration 151, loss = 1529663084.13853645\n",
            "Iteration 152, loss = 1529598365.62069464\n",
            "Iteration 153, loss = 1529533071.19139624\n",
            "Iteration 154, loss = 1529468454.90361309\n",
            "Iteration 155, loss = 1529403635.25787091\n",
            "Iteration 156, loss = 1529338840.79600668\n",
            "Iteration 157, loss = 1529274499.04683900\n",
            "Iteration 158, loss = 1529209700.13267779\n",
            "Iteration 159, loss = 1529145417.10201049\n",
            "Iteration 160, loss = 1529080558.01771712\n",
            "Iteration 161, loss = 1529016655.87658286\n",
            "Iteration 162, loss = 1528951906.17838883\n",
            "Iteration 163, loss = 1528888103.47473192\n",
            "Iteration 164, loss = 1528823939.57776117\n",
            "Iteration 165, loss = 1528759923.20550752\n",
            "Iteration 166, loss = 1528695657.17263246\n",
            "Iteration 167, loss = 1528632107.97283220\n",
            "Iteration 168, loss = 1528567642.75749874\n",
            "Iteration 169, loss = 1528503552.25497818\n",
            "Iteration 170, loss = 1528439493.42878151\n",
            "Iteration 171, loss = 1528375416.21658587\n",
            "Iteration 172, loss = 1528311275.09528852\n",
            "Iteration 173, loss = 1528247118.79674077\n",
            "Iteration 174, loss = 1528182978.81045485\n",
            "Iteration 175, loss = 1528119394.43941879\n",
            "Iteration 176, loss = 1528055516.38541746\n",
            "Iteration 177, loss = 1527991944.36319733\n",
            "Iteration 178, loss = 1527927956.48420024\n",
            "Iteration 179, loss = 1527864972.18513346\n",
            "Iteration 180, loss = 1527801369.75531173\n",
            "Iteration 181, loss = 1527738300.65114355\n",
            "Iteration 182, loss = 1527674936.37041950\n",
            "Iteration 183, loss = 1527611890.34255552\n",
            "Iteration 184, loss = 1527549020.92023540\n",
            "Iteration 185, loss = 1527485698.78615928\n",
            "Iteration 186, loss = 1527422651.52621984\n",
            "Iteration 187, loss = 1527360123.54335284\n",
            "Iteration 188, loss = 1527297227.61570644\n",
            "Iteration 189, loss = 1527234258.10497665\n",
            "Iteration 190, loss = 1527171833.17111993\n",
            "Iteration 191, loss = 1527109230.49465466\n",
            "Iteration 192, loss = 1527046329.81779480\n",
            "Iteration 193, loss = 1526984180.02734280\n",
            "Iteration 194, loss = 1526921270.11498642\n",
            "Iteration 195, loss = 1526858850.75247240\n",
            "Iteration 196, loss = 1526796458.74987936\n",
            "Iteration 197, loss = 1526734085.05161381\n",
            "Iteration 198, loss = 1526671339.88781357\n",
            "Iteration 199, loss = 1526608793.16876888\n",
            "Iteration 200, loss = 1526546530.02559686\n",
            "Iteration 201, loss = 1526484213.61741996\n",
            "Iteration 202, loss = 1526421170.49178433\n",
            "Iteration 203, loss = 1526359233.02015734\n",
            "Iteration 204, loss = 1526296855.17655993\n",
            "Iteration 205, loss = 1526234304.40734458\n",
            "Iteration 206, loss = 1526172129.83566642\n",
            "Iteration 207, loss = 1526109930.37556744\n",
            "Iteration 208, loss = 1526048251.20755315\n",
            "Iteration 209, loss = 1525986030.54836512\n",
            "Iteration 210, loss = 1525924333.74038363\n",
            "Iteration 211, loss = 1525862472.37885022\n",
            "Iteration 212, loss = 1525800810.80595350\n",
            "Iteration 213, loss = 1525739071.64317107\n",
            "Iteration 214, loss = 1525677592.54150772\n",
            "Iteration 215, loss = 1525615668.94174480\n",
            "Iteration 216, loss = 1525554446.75431323\n",
            "Iteration 217, loss = 1525493038.90920210\n",
            "Iteration 218, loss = 1525431333.84048605\n",
            "Iteration 219, loss = 1525370208.19421220\n",
            "Iteration 220, loss = 1525308982.88314319\n",
            "Iteration 221, loss = 1525247799.20174003\n",
            "Iteration 222, loss = 1525186630.20382929\n",
            "Iteration 223, loss = 1525125137.89226985\n",
            "Iteration 224, loss = 1525063972.75082183\n",
            "Iteration 225, loss = 1525002415.41812658\n",
            "Iteration 226, loss = 1524941548.45013142\n",
            "Iteration 227, loss = 1524879814.18468785\n",
            "Iteration 228, loss = 1524819046.07438612\n",
            "Iteration 229, loss = 1524757945.37455773\n",
            "Iteration 230, loss = 1524697378.94639158\n",
            "Iteration 231, loss = 1524635956.10025477\n",
            "Iteration 232, loss = 1524575800.23565745\n",
            "Iteration 233, loss = 1524515286.87971234\n",
            "Iteration 234, loss = 1524454487.92982554\n",
            "Iteration 235, loss = 1524394391.08417559\n",
            "Iteration 236, loss = 1524333648.43188286\n",
            "Iteration 237, loss = 1524273051.47450590\n",
            "Iteration 238, loss = 1524212385.72381186\n",
            "Iteration 239, loss = 1524151706.70278430\n",
            "Iteration 240, loss = 1524091019.80403829\n",
            "Iteration 241, loss = 1524030725.83348346\n",
            "Iteration 242, loss = 1523969950.21475911\n",
            "Iteration 243, loss = 1523909862.95911384\n",
            "Iteration 244, loss = 1523848923.03735185\n",
            "Iteration 245, loss = 1523789121.05969191\n",
            "Iteration 246, loss = 1523728825.15692925\n",
            "Iteration 247, loss = 1523669220.94688368\n",
            "Iteration 248, loss = 1523608838.37323833\n",
            "Iteration 249, loss = 1523548829.28854156\n",
            "Iteration 250, loss = 1523489328.31338716\n",
            "Iteration 251, loss = 1523429251.50101781\n",
            "Iteration 252, loss = 1523369457.38781285\n",
            "Iteration 253, loss = 1523309534.26879001\n",
            "Iteration 254, loss = 1523249415.02437615\n",
            "Iteration 255, loss = 1523189590.35893154\n",
            "Iteration 256, loss = 1523129141.80647135\n",
            "Iteration 257, loss = 1523069508.72943306\n",
            "Iteration 258, loss = 1523009211.06877470\n",
            "Iteration 259, loss = 1522949115.95471573\n",
            "Iteration 260, loss = 1522889040.28674865\n",
            "Iteration 261, loss = 1522828550.76634049\n",
            "Iteration 262, loss = 1522768745.59828782\n",
            "Iteration 263, loss = 1522708459.21516204\n",
            "Iteration 264, loss = 1522648602.89763188\n",
            "Iteration 265, loss = 1522588437.22252893\n",
            "Iteration 266, loss = 1522528553.39062810\n",
            "Iteration 267, loss = 1522469002.98508358\n",
            "Iteration 268, loss = 1522409044.12342548\n",
            "Iteration 269, loss = 1522349539.62754750\n",
            "Iteration 270, loss = 1522290219.71605515\n",
            "Iteration 271, loss = 1522230931.73122644\n",
            "Iteration 272, loss = 1522171373.33289504\n",
            "Iteration 273, loss = 1522112199.82598495\n",
            "Iteration 274, loss = 1522053150.65083146\n",
            "Iteration 275, loss = 1521993900.56728506\n",
            "Iteration 276, loss = 1521934691.15866756\n",
            "Iteration 277, loss = 1521875760.78751659\n",
            "Iteration 278, loss = 1521816225.97141957\n",
            "Iteration 279, loss = 1521757336.78850651\n",
            "Iteration 280, loss = 1521698095.69958210\n",
            "Iteration 281, loss = 1521638857.80329657\n",
            "Iteration 282, loss = 1521579638.22655392\n",
            "Iteration 283, loss = 1521520524.56017160\n",
            "Iteration 284, loss = 1521461787.18206453\n",
            "Iteration 285, loss = 1521402628.51859856\n",
            "Iteration 286, loss = 1521343469.81863952\n",
            "Iteration 287, loss = 1521284628.28149033\n",
            "Iteration 288, loss = 1521225903.63154507\n",
            "Iteration 289, loss = 1521166618.78769541\n",
            "Iteration 290, loss = 1521107555.03468060\n",
            "Iteration 291, loss = 1521048537.87415552\n",
            "Iteration 292, loss = 1520989319.56938672\n",
            "Iteration 293, loss = 1520930168.27508354\n",
            "Iteration 294, loss = 1520870707.71712899\n",
            "Iteration 295, loss = 1520811531.76123357\n",
            "Iteration 296, loss = 1520752494.57538438\n",
            "Iteration 297, loss = 1520692864.39044952\n",
            "Iteration 298, loss = 1520634041.08527899\n",
            "Iteration 299, loss = 1520574724.69958234\n",
            "Iteration 300, loss = 1520515438.33407021\n",
            "Iteration 301, loss = 1520456773.42556167\n",
            "Iteration 302, loss = 1520397957.94624114\n",
            "Iteration 303, loss = 1520338613.37275314\n",
            "Iteration 304, loss = 1520279962.36524081\n",
            "Iteration 305, loss = 1520221444.83511019\n",
            "Iteration 306, loss = 1520162566.66044950\n",
            "Iteration 307, loss = 1520103967.00296521\n",
            "Iteration 308, loss = 1520045330.58029914\n",
            "Iteration 309, loss = 1519986866.77834129\n",
            "Iteration 310, loss = 1519928256.87904930\n",
            "Iteration 311, loss = 1519869781.19991112\n",
            "Iteration 312, loss = 1519811255.90756679\n",
            "Iteration 313, loss = 1519752627.35091209\n",
            "Iteration 314, loss = 1519694364.91123343\n",
            "Iteration 315, loss = 1519635399.05021954\n",
            "Iteration 316, loss = 1519577314.26628757\n",
            "Iteration 317, loss = 1519518884.10639524\n",
            "Iteration 318, loss = 1519460141.65731716\n",
            "Iteration 319, loss = 1519402151.20969367\n",
            "Iteration 320, loss = 1519343656.21960545\n",
            "Iteration 321, loss = 1519285132.47680020\n",
            "Iteration 322, loss = 1519226871.90755177\n",
            "Iteration 323, loss = 1519168199.79630876\n",
            "Iteration 324, loss = 1519109836.62779403\n",
            "Iteration 325, loss = 1519051355.95695043\n",
            "Iteration 326, loss = 1518992919.65546203\n",
            "Iteration 327, loss = 1518934420.15425587\n",
            "Iteration 328, loss = 1518876144.84825826\n",
            "Iteration 329, loss = 1518817783.08391523\n",
            "Iteration 330, loss = 1518759355.63736224\n",
            "Iteration 331, loss = 1518701859.36014938\n",
            "Iteration 332, loss = 1518643022.03692937\n",
            "Iteration 333, loss = 1518584985.68512130\n",
            "Iteration 334, loss = 1518527129.35358119\n",
            "Iteration 335, loss = 1518468849.90109587\n",
            "Iteration 336, loss = 1518410657.13404346\n",
            "Iteration 337, loss = 1518352247.70025587\n",
            "Iteration 338, loss = 1518294681.10760164\n",
            "Iteration 339, loss = 1518236073.21851969\n",
            "Iteration 340, loss = 1518178279.57708430\n",
            "Iteration 341, loss = 1518120153.94807911\n",
            "Iteration 342, loss = 1518062273.15768218\n",
            "Iteration 343, loss = 1518004676.20821309\n",
            "Iteration 344, loss = 1517946776.75937748\n",
            "Iteration 345, loss = 1517888808.73082924\n",
            "Iteration 346, loss = 1517831518.55261970\n",
            "Iteration 347, loss = 1517773220.49952888\n",
            "Iteration 348, loss = 1517715994.13546634\n",
            "Iteration 349, loss = 1517658138.21362090\n",
            "Iteration 350, loss = 1517600665.02893090\n",
            "Iteration 351, loss = 1517542678.97862434\n",
            "Iteration 352, loss = 1517484828.37357545\n",
            "Iteration 353, loss = 1517427215.95790911\n",
            "Iteration 354, loss = 1517369652.14450645\n",
            "Iteration 355, loss = 1517311679.00396156\n",
            "Iteration 356, loss = 1517254129.28635049\n",
            "Iteration 357, loss = 1517196310.41710687\n",
            "Iteration 358, loss = 1517138812.15851283\n",
            "Iteration 359, loss = 1517081313.36552143\n",
            "Iteration 360, loss = 1517023403.99402928\n",
            "Iteration 361, loss = 1516966010.04392648\n",
            "Iteration 362, loss = 1516908361.22366095\n",
            "Iteration 363, loss = 1516850697.69992542\n",
            "Iteration 364, loss = 1516793041.68768406\n",
            "Iteration 365, loss = 1516735224.49544549\n",
            "Iteration 366, loss = 1516678058.22626233\n",
            "Iteration 367, loss = 1516620230.77931476\n",
            "Iteration 368, loss = 1516562941.13803983\n",
            "Iteration 369, loss = 1516505184.80736375\n",
            "Iteration 370, loss = 1516448215.73912978\n",
            "Iteration 371, loss = 1516390484.30305195\n",
            "Iteration 372, loss = 1516333096.41470194\n",
            "Iteration 373, loss = 1516275481.68226886\n",
            "Iteration 374, loss = 1516218326.54388857\n",
            "Iteration 375, loss = 1516160284.07568693\n",
            "Iteration 376, loss = 1516102761.66959453\n",
            "Iteration 377, loss = 1516045368.61031270\n",
            "Iteration 378, loss = 1515987682.14021254\n",
            "Iteration 379, loss = 1515930086.20600152\n",
            "Iteration 380, loss = 1515873096.76046586\n",
            "Iteration 381, loss = 1515815171.21096158\n",
            "Iteration 382, loss = 1515758161.66553020\n",
            "Iteration 383, loss = 1515700848.26527524\n",
            "Iteration 384, loss = 1515643265.14990377\n",
            "Iteration 385, loss = 1515586136.15707016\n",
            "Iteration 386, loss = 1515528915.04960585\n",
            "Iteration 387, loss = 1515471606.51783490\n",
            "Iteration 388, loss = 1515413823.57066584\n",
            "Iteration 389, loss = 1515356301.46518898\n",
            "Iteration 390, loss = 1515299314.13764787\n",
            "Iteration 391, loss = 1515241967.76130962\n",
            "Iteration 392, loss = 1515184494.18276167\n",
            "Iteration 393, loss = 1515127403.85845995\n",
            "Iteration 394, loss = 1515070425.16583800\n",
            "Iteration 395, loss = 1515013031.10341692\n",
            "Iteration 396, loss = 1514955854.68964291\n",
            "Iteration 397, loss = 1514898682.23620653\n",
            "Iteration 398, loss = 1514842059.02278900\n",
            "Iteration 399, loss = 1514784076.33527303\n",
            "Iteration 400, loss = 1514726947.71903491\n",
            "Iteration 401, loss = 1514669840.53176594\n",
            "Iteration 402, loss = 1514612634.61970758\n",
            "Iteration 403, loss = 1514555267.29857588\n",
            "Iteration 404, loss = 1514498479.95562434\n",
            "Iteration 405, loss = 1514441291.58926296\n",
            "Iteration 406, loss = 1514384071.62732720\n",
            "Iteration 407, loss = 1514327416.50089288\n",
            "Iteration 408, loss = 1514270518.57473826\n",
            "Iteration 409, loss = 1514213268.79334784\n",
            "Iteration 410, loss = 1514156717.38343859\n",
            "Iteration 411, loss = 1514099659.39069939\n",
            "Iteration 412, loss = 1514042656.64236879\n",
            "Iteration 413, loss = 1513986022.91670322\n",
            "Iteration 414, loss = 1513928913.68754768\n",
            "Iteration 415, loss = 1513871782.75842166\n",
            "Iteration 416, loss = 1513815297.63284898\n",
            "Iteration 417, loss = 1513758163.78785324\n",
            "Iteration 418, loss = 1513701165.33266282\n",
            "Iteration 419, loss = 1513644347.20252609\n",
            "Iteration 420, loss = 1513587516.26605773\n",
            "Iteration 421, loss = 1513530282.31448531\n",
            "Iteration 422, loss = 1513473618.92770433\n",
            "Iteration 423, loss = 1513416392.44932771\n",
            "Iteration 424, loss = 1513359504.27867913\n",
            "Iteration 425, loss = 1513302599.05761313\n",
            "Iteration 426, loss = 1513245895.24472809\n",
            "Iteration 427, loss = 1513188690.98689365\n",
            "Iteration 428, loss = 1513132500.93350935\n",
            "Iteration 429, loss = 1513075631.92924547\n",
            "Iteration 430, loss = 1513018788.17403769\n",
            "Iteration 431, loss = 1512962185.34112477\n",
            "Iteration 432, loss = 1512905972.84566808\n",
            "Iteration 433, loss = 1512849001.77762222\n",
            "Iteration 434, loss = 1512792825.33714056\n",
            "Iteration 435, loss = 1512735851.05141854\n",
            "Iteration 436, loss = 1512679220.62579250\n",
            "Iteration 437, loss = 1512622710.55898046\n",
            "Iteration 438, loss = 1512566086.77417207\n",
            "Iteration 439, loss = 1512509205.61968946\n",
            "Iteration 440, loss = 1512452909.60285830\n",
            "Iteration 441, loss = 1512395822.92968202\n",
            "Iteration 442, loss = 1512339533.76062083\n",
            "Iteration 443, loss = 1512282776.52913165\n",
            "Iteration 444, loss = 1512225960.11720824\n",
            "Iteration 445, loss = 1512169252.27266049\n",
            "Iteration 446, loss = 1512112549.75632763\n",
            "Iteration 447, loss = 1512055960.23516583\n",
            "Iteration 448, loss = 1511999068.99833250\n",
            "Iteration 449, loss = 1511942242.18770576\n",
            "Iteration 450, loss = 1511885994.81266856\n",
            "Iteration 451, loss = 1511829354.84699774\n",
            "Iteration 452, loss = 1511772361.13839555\n",
            "Iteration 453, loss = 1511715999.08031082\n",
            "Iteration 454, loss = 1511659554.05640316\n",
            "Iteration 455, loss = 1511602807.16905713\n",
            "Iteration 456, loss = 1511546021.22188544\n",
            "Iteration 457, loss = 1511489776.31781721\n",
            "Iteration 458, loss = 1511433086.45436525\n",
            "Iteration 459, loss = 1511376843.14759493\n",
            "Iteration 460, loss = 1511320331.52519941\n",
            "Iteration 461, loss = 1511264111.66886973\n",
            "Iteration 462, loss = 1511207408.38442922\n",
            "Iteration 463, loss = 1511151123.52824783\n",
            "Iteration 464, loss = 1511094834.49915504\n",
            "Iteration 465, loss = 1511038650.50153732\n",
            "Iteration 466, loss = 1510981757.26150322\n",
            "Iteration 467, loss = 1510925969.60098219\n",
            "Iteration 468, loss = 1510869337.11782503\n",
            "Iteration 469, loss = 1510813119.24443579\n",
            "Iteration 470, loss = 1510756917.19932914\n",
            "Iteration 471, loss = 1510700805.24365354\n",
            "Iteration 472, loss = 1510644473.67954659\n",
            "Iteration 473, loss = 1510588194.29508710\n",
            "Iteration 474, loss = 1510532270.39695168\n",
            "Iteration 475, loss = 1510475709.92505860\n",
            "Iteration 476, loss = 1510419597.41903424\n",
            "Iteration 477, loss = 1510363237.17825055\n",
            "Iteration 478, loss = 1510307092.19374490\n",
            "Iteration 479, loss = 1510250318.93362641\n",
            "Iteration 480, loss = 1510194413.88195062\n",
            "Iteration 481, loss = 1510137647.41979218\n",
            "Iteration 482, loss = 1510081484.94775653\n",
            "Iteration 483, loss = 1510024840.35058594\n",
            "Iteration 484, loss = 1509968525.29169679\n",
            "Iteration 485, loss = 1509912082.44329762\n",
            "Iteration 486, loss = 1509855828.33485937\n",
            "Iteration 487, loss = 1509799198.86750698\n",
            "Iteration 488, loss = 1509742986.04178429\n",
            "Iteration 489, loss = 1509686628.13793921\n",
            "Iteration 490, loss = 1509630709.03597093\n",
            "Iteration 491, loss = 1509574379.59523082\n",
            "Iteration 492, loss = 1509518117.20812845\n",
            "Iteration 493, loss = 1509462276.57511139\n",
            "Iteration 494, loss = 1509406485.27598238\n",
            "Iteration 495, loss = 1509350222.41699505\n",
            "Iteration 496, loss = 1509294364.58566880\n",
            "Iteration 497, loss = 1509238253.64236355\n",
            "Iteration 498, loss = 1509182321.07528138\n",
            "Iteration 499, loss = 1509125963.12250853\n",
            "Iteration 500, loss = 1509070257.19662452\n",
            "Iteration 501, loss = 1509013994.73112607\n",
            "Iteration 502, loss = 1508957814.06620383\n",
            "Iteration 503, loss = 1508901755.50232291\n",
            "Iteration 504, loss = 1508845633.07327294\n",
            "Iteration 505, loss = 1508790089.61103916\n",
            "Iteration 506, loss = 1508733933.65738821\n",
            "Iteration 507, loss = 1508678092.28224754\n",
            "Iteration 508, loss = 1508622527.86909771\n",
            "Iteration 509, loss = 1508566663.93673754\n",
            "Iteration 510, loss = 1508511146.18679094\n",
            "Iteration 511, loss = 1508455081.00277925\n",
            "Iteration 512, loss = 1508399452.13772988\n",
            "Iteration 513, loss = 1508343660.51956224\n",
            "Iteration 514, loss = 1508287577.67233372\n",
            "Iteration 515, loss = 1508231854.97650456\n",
            "Iteration 516, loss = 1508175960.88956594\n",
            "Iteration 517, loss = 1508119886.44520473\n",
            "Iteration 518, loss = 1508064042.26055264\n",
            "Iteration 519, loss = 1508008081.62867665\n",
            "Iteration 520, loss = 1507952064.22987366\n",
            "Iteration 521, loss = 1507896193.36566591\n",
            "Iteration 522, loss = 1507840058.09477401\n",
            "Iteration 523, loss = 1507783894.05407667\n",
            "Iteration 524, loss = 1507727645.88284016\n",
            "Iteration 525, loss = 1507671498.96517348\n",
            "Iteration 526, loss = 1507615490.51497245\n",
            "Iteration 527, loss = 1507559241.80633473\n",
            "Iteration 528, loss = 1507503215.76199436\n",
            "Iteration 529, loss = 1507446922.31876802\n",
            "Iteration 530, loss = 1507390737.99501801\n",
            "Iteration 531, loss = 1507334650.68294883\n",
            "Iteration 532, loss = 1507278676.63065267\n",
            "Iteration 533, loss = 1507222286.10765767\n",
            "Iteration 534, loss = 1507165770.51626658\n",
            "Iteration 535, loss = 1507110119.86821508\n",
            "Iteration 536, loss = 1507053557.22659111\n",
            "Iteration 537, loss = 1506997768.56428003\n",
            "Iteration 538, loss = 1506941056.75578451\n",
            "Iteration 539, loss = 1506885540.10489750\n",
            "Iteration 540, loss = 1506829432.87596178\n",
            "Iteration 541, loss = 1506773618.80611539\n",
            "Iteration 542, loss = 1506717850.77986336\n",
            "Iteration 543, loss = 1506661960.10378504\n",
            "Iteration 544, loss = 1506606261.69682384\n",
            "Iteration 545, loss = 1506550475.20462918\n",
            "Iteration 546, loss = 1506494988.62761116\n",
            "Iteration 547, loss = 1506439101.99963045\n",
            "Iteration 548, loss = 1506383481.10967755\n",
            "Iteration 549, loss = 1506327313.31941128\n",
            "Iteration 550, loss = 1506271441.91562939\n",
            "Iteration 551, loss = 1506215760.45908546\n",
            "Iteration 552, loss = 1506159766.54647660\n",
            "Iteration 553, loss = 1506103852.04802132\n",
            "Iteration 554, loss = 1506047955.99936295\n",
            "Iteration 555, loss = 1505992047.42141032\n",
            "Iteration 556, loss = 1505936016.04319239\n",
            "Iteration 557, loss = 1505880380.56704855\n",
            "Iteration 558, loss = 1505824532.97825527\n",
            "Iteration 559, loss = 1505768284.35083103\n",
            "Iteration 560, loss = 1505712778.00254703\n",
            "Iteration 561, loss = 1505657103.00372863\n",
            "Iteration 562, loss = 1505601381.04251933\n",
            "Iteration 563, loss = 1505545575.58481765\n",
            "Iteration 564, loss = 1505490555.78534985\n",
            "Iteration 565, loss = 1505435012.90514755\n",
            "Iteration 566, loss = 1505379626.38264012\n",
            "Iteration 567, loss = 1505323911.82401419\n",
            "Iteration 568, loss = 1505268537.25022960\n",
            "Iteration 569, loss = 1505213086.70131040\n",
            "Iteration 570, loss = 1505157801.36650848\n",
            "Iteration 571, loss = 1505102023.70737791\n",
            "Iteration 572, loss = 1505046459.70530200\n",
            "Iteration 573, loss = 1504991074.69159746\n",
            "Iteration 574, loss = 1504935702.65761852\n",
            "Iteration 575, loss = 1504880328.32634115\n",
            "Iteration 576, loss = 1504824703.39890957\n",
            "Iteration 577, loss = 1504769663.58433652\n",
            "Iteration 578, loss = 1504714559.41355515\n",
            "Iteration 579, loss = 1504659210.00238585\n",
            "Iteration 580, loss = 1504603945.95760036\n",
            "Iteration 581, loss = 1504548886.72173357\n",
            "Iteration 582, loss = 1504493635.53580284\n",
            "Iteration 583, loss = 1504438428.85166216\n",
            "Iteration 584, loss = 1504382600.90157032\n",
            "Iteration 585, loss = 1504327497.35568476\n",
            "Iteration 586, loss = 1504272095.37417459\n",
            "Iteration 587, loss = 1504216171.68417907\n",
            "Iteration 588, loss = 1504160964.42363930\n",
            "Iteration 589, loss = 1504105148.44544530\n",
            "Iteration 590, loss = 1504049722.33681345\n",
            "Iteration 591, loss = 1503994096.23872542\n",
            "Iteration 592, loss = 1503938636.97950268\n",
            "Iteration 593, loss = 1503883340.38699603\n",
            "Iteration 594, loss = 1503827724.76905131\n",
            "Iteration 595, loss = 1503772119.97513437\n",
            "Iteration 596, loss = 1503716952.80883431\n",
            "Iteration 597, loss = 1503661531.46283031\n",
            "Iteration 598, loss = 1503605927.29755378\n",
            "Iteration 599, loss = 1503550579.80251336\n",
            "Iteration 600, loss = 1503494955.77918983\n",
            "Iteration 601, loss = 1503440041.82403874\n",
            "Iteration 602, loss = 1503384172.63716626\n",
            "Iteration 603, loss = 1503328928.41579318\n",
            "Iteration 604, loss = 1503273707.10838056\n",
            "Iteration 605, loss = 1503218317.91210508\n",
            "Iteration 606, loss = 1503163420.55983305\n",
            "Iteration 607, loss = 1503107837.63549638\n",
            "Iteration 608, loss = 1503053083.93670106\n",
            "Iteration 609, loss = 1502998016.57096148\n",
            "Iteration 610, loss = 1502942985.35944438\n",
            "Iteration 611, loss = 1502888113.85983229\n",
            "Iteration 612, loss = 1502832941.45671368\n",
            "Iteration 613, loss = 1502777954.94091773\n",
            "Iteration 614, loss = 1502722875.52397633\n",
            "Iteration 615, loss = 1502667552.99266219\n",
            "Iteration 616, loss = 1502612746.48588991\n",
            "Iteration 617, loss = 1502557075.01003408\n",
            "Iteration 618, loss = 1502502285.93613148\n",
            "Iteration 619, loss = 1502447252.49058270\n",
            "Iteration 620, loss = 1502392201.63667393\n",
            "Iteration 621, loss = 1502337003.38886642\n",
            "Iteration 622, loss = 1502282433.67916226\n",
            "Iteration 623, loss = 1502227467.89823508\n",
            "Iteration 624, loss = 1502172451.49247932\n",
            "Iteration 625, loss = 1502117541.29968143\n",
            "Iteration 626, loss = 1502062483.72928596\n",
            "Iteration 627, loss = 1502007466.20363069\n",
            "Iteration 628, loss = 1501952264.50175643\n",
            "Iteration 629, loss = 1501896913.26062703\n",
            "Iteration 630, loss = 1501841792.58448625\n",
            "Iteration 631, loss = 1501786691.70265603\n",
            "Iteration 632, loss = 1501731168.10248017\n",
            "Iteration 633, loss = 1501676016.92405033\n",
            "Iteration 634, loss = 1501620685.31420302\n",
            "Iteration 635, loss = 1501565388.84904480\n",
            "Iteration 636, loss = 1501509640.60172796\n",
            "Iteration 637, loss = 1501454288.02173495\n",
            "Iteration 638, loss = 1501398561.30429673\n",
            "Iteration 639, loss = 1501342905.79909849\n",
            "Iteration 640, loss = 1501287235.94041371\n",
            "Iteration 641, loss = 1501231712.15186691\n",
            "Iteration 642, loss = 1501176214.29123902\n",
            "Iteration 643, loss = 1501121106.09588766\n",
            "Iteration 644, loss = 1501065600.23756385\n",
            "Iteration 645, loss = 1501010317.64833355\n",
            "Iteration 646, loss = 1500955445.85308337\n",
            "Iteration 647, loss = 1500900508.85292220\n",
            "Iteration 648, loss = 1500845188.67757869\n",
            "Iteration 649, loss = 1500790100.52863836\n",
            "Iteration 650, loss = 1500735248.94727445\n",
            "Iteration 651, loss = 1500680412.51674390\n",
            "Iteration 652, loss = 1500625682.41309309\n",
            "Iteration 653, loss = 1500570688.82436371\n",
            "Iteration 654, loss = 1500515713.22159171\n",
            "Iteration 655, loss = 1500461343.18229866\n",
            "Iteration 656, loss = 1500406093.15612841\n",
            "Iteration 657, loss = 1500351324.01691937\n",
            "Iteration 658, loss = 1500296060.59183812\n",
            "Iteration 659, loss = 1500241064.95002675\n",
            "Iteration 660, loss = 1500186020.57034755\n",
            "Iteration 661, loss = 1500131275.48396277\n",
            "Iteration 662, loss = 1500075911.85536599\n",
            "Iteration 663, loss = 1500021232.96407461\n",
            "Iteration 664, loss = 1499966156.78719831\n",
            "Iteration 665, loss = 1499911421.70538664\n",
            "Iteration 666, loss = 1499856736.57688642\n",
            "Iteration 667, loss = 1499801725.12726212\n",
            "Iteration 668, loss = 1499746722.58350039\n",
            "Iteration 669, loss = 1499692206.26434875\n",
            "Iteration 670, loss = 1499637140.78046703\n",
            "Iteration 671, loss = 1499582127.74740219\n",
            "Iteration 672, loss = 1499527933.35794210\n",
            "Iteration 673, loss = 1499472846.00606465\n",
            "Iteration 674, loss = 1499417899.68914533\n",
            "Iteration 675, loss = 1499363655.77082467\n",
            "Iteration 676, loss = 1499308431.02612042\n",
            "Iteration 677, loss = 1499253346.37755251\n",
            "Iteration 678, loss = 1499198529.73897290\n",
            "Iteration 679, loss = 1499143571.31572723\n",
            "Iteration 680, loss = 1499088359.49600005\n",
            "Iteration 681, loss = 1499033310.73147631\n",
            "Iteration 682, loss = 1498978218.01495433\n",
            "Iteration 683, loss = 1498922972.51397419\n",
            "Iteration 684, loss = 1498868030.37953568\n",
            "Iteration 685, loss = 1498813071.74866748\n",
            "Iteration 686, loss = 1498757853.18132997\n",
            "Iteration 687, loss = 1498702843.68394780\n",
            "Iteration 688, loss = 1498647831.27390790\n",
            "Iteration 689, loss = 1498592790.53999543\n",
            "Iteration 690, loss = 1498537940.17835045\n",
            "Iteration 691, loss = 1498483255.17935777\n",
            "Iteration 692, loss = 1498428059.90896511\n",
            "Iteration 693, loss = 1498373255.02758622\n",
            "Iteration 694, loss = 1498318629.48500729\n",
            "Iteration 695, loss = 1498263701.35364461\n",
            "Iteration 696, loss = 1498208702.51403570\n",
            "Iteration 697, loss = 1498154074.91408253\n",
            "Iteration 698, loss = 1498099369.23421049\n",
            "Iteration 699, loss = 1498044395.34233141\n",
            "Iteration 700, loss = 1497989672.06884885\n",
            "Iteration 701, loss = 1497934861.88038611\n",
            "Iteration 702, loss = 1497880504.78979445\n",
            "Iteration 703, loss = 1497825464.61458707\n",
            "Iteration 704, loss = 1497770730.65482950\n",
            "Iteration 705, loss = 1497715890.32922935\n",
            "Iteration 706, loss = 1497660547.95917845\n",
            "Iteration 707, loss = 1497606069.76848841\n",
            "Iteration 708, loss = 1497550401.85239172\n",
            "Iteration 709, loss = 1497495584.67562342\n",
            "Iteration 710, loss = 1497440442.86281610\n",
            "Iteration 711, loss = 1497385474.24932122\n",
            "Iteration 712, loss = 1497330411.80388856\n",
            "Iteration 713, loss = 1497275134.46940327\n",
            "Iteration 714, loss = 1497220326.85277390\n",
            "Iteration 715, loss = 1497165414.16571903\n",
            "Iteration 716, loss = 1497110190.91436410\n",
            "Iteration 717, loss = 1497055351.05535579\n",
            "Iteration 718, loss = 1497000302.84234548\n",
            "Iteration 719, loss = 1496945383.71790385\n",
            "Iteration 720, loss = 1496890368.49276114\n",
            "Iteration 721, loss = 1496835561.03695798\n",
            "Iteration 722, loss = 1496780649.75830626\n",
            "Iteration 723, loss = 1496725908.77294731\n",
            "Iteration 724, loss = 1496671129.30364776\n",
            "Iteration 725, loss = 1496616213.54414988\n",
            "Iteration 726, loss = 1496561860.30027199\n",
            "Iteration 727, loss = 1496507130.90569615\n",
            "Iteration 728, loss = 1496452185.09830713\n",
            "Iteration 729, loss = 1496397381.09012580\n",
            "Iteration 730, loss = 1496342971.44502759\n",
            "Iteration 731, loss = 1496288120.30518150\n",
            "Iteration 732, loss = 1496233208.53700662\n",
            "Iteration 733, loss = 1496178441.27084899\n",
            "Iteration 734, loss = 1496123768.89463162\n",
            "Iteration 735, loss = 1496069226.02328300\n",
            "Iteration 736, loss = 1496014359.48720241\n",
            "Iteration 737, loss = 1495959770.36527205\n",
            "Iteration 738, loss = 1495905119.34455705\n",
            "Iteration 739, loss = 1495850643.64550138\n",
            "Iteration 740, loss = 1495795628.98735213\n",
            "Iteration 741, loss = 1495740874.02214980\n",
            "Iteration 742, loss = 1495685995.09462690\n",
            "Iteration 743, loss = 1495631068.09295249\n",
            "Iteration 744, loss = 1495576453.93099785\n",
            "Iteration 745, loss = 1495520810.97534466\n",
            "Iteration 746, loss = 1495466307.81529951\n",
            "Iteration 747, loss = 1495411086.17984414\n",
            "Iteration 748, loss = 1495356456.71062589\n",
            "Iteration 749, loss = 1495301262.95924544\n",
            "Iteration 750, loss = 1495246444.32570171\n",
            "Iteration 751, loss = 1495191530.98550463\n",
            "Iteration 752, loss = 1495136791.58342552\n",
            "Iteration 753, loss = 1495082045.34055853\n",
            "Iteration 754, loss = 1495027357.99334502\n",
            "Iteration 755, loss = 1494972688.07284641\n",
            "Iteration 756, loss = 1494918141.79172754\n",
            "Iteration 757, loss = 1494863683.26627302\n",
            "Iteration 758, loss = 1494808969.21447182\n",
            "Iteration 759, loss = 1494754439.97686839\n",
            "Iteration 760, loss = 1494699723.47791958\n",
            "Iteration 761, loss = 1494645027.30812836\n",
            "Iteration 762, loss = 1494590485.60559559\n",
            "Iteration 763, loss = 1494535444.30165720\n",
            "Iteration 764, loss = 1494480370.83437634\n",
            "Iteration 765, loss = 1494426035.65489602\n",
            "Iteration 766, loss = 1494370848.46369267\n",
            "Iteration 767, loss = 1494316038.49907541\n",
            "Iteration 768, loss = 1494261052.95689273\n",
            "Iteration 769, loss = 1494205995.21727943\n",
            "Iteration 770, loss = 1494151522.21150494\n",
            "Iteration 771, loss = 1494096207.99025822\n",
            "Iteration 772, loss = 1494042007.67669368\n",
            "Iteration 773, loss = 1493986503.68781757\n",
            "Iteration 774, loss = 1493932446.77540398\n",
            "Iteration 775, loss = 1493877782.06258750\n",
            "Iteration 776, loss = 1493823618.13188386\n",
            "Iteration 777, loss = 1493768903.98737955\n",
            "Iteration 778, loss = 1493714922.27704978\n",
            "Iteration 779, loss = 1493660891.58262944\n",
            "Iteration 780, loss = 1493606561.60621715\n",
            "Iteration 781, loss = 1493552252.74343848\n",
            "Iteration 782, loss = 1493498081.32687902\n",
            "Iteration 783, loss = 1493443781.91697812\n",
            "Iteration 784, loss = 1493389169.33905578\n",
            "Iteration 785, loss = 1493334949.04804349\n",
            "Iteration 786, loss = 1493280284.20957994\n",
            "Iteration 787, loss = 1493225878.01716685\n",
            "Iteration 788, loss = 1493171582.50673199\n",
            "Iteration 789, loss = 1493116946.94961834\n",
            "Iteration 790, loss = 1493062483.40584850\n",
            "Iteration 791, loss = 1493008315.38030028\n",
            "Iteration 792, loss = 1492953916.33818460\n",
            "Iteration 793, loss = 1492899293.38672256\n",
            "Iteration 794, loss = 1492845229.46211338\n",
            "Iteration 795, loss = 1492791144.84476256\n",
            "Iteration 796, loss = 1492736339.32892871\n",
            "Iteration 797, loss = 1492682488.99172449\n",
            "Iteration 798, loss = 1492628348.93115520\n",
            "Iteration 799, loss = 1492574103.52230811\n",
            "Iteration 800, loss = 1492519616.45626092\n",
            "Iteration 801, loss = 1492465823.24094486\n",
            "Iteration 802, loss = 1492411622.23805475\n",
            "Iteration 803, loss = 1492357408.54813218\n",
            "Iteration 804, loss = 1492303171.10224271\n",
            "Iteration 805, loss = 1492248853.64894986\n",
            "Iteration 806, loss = 1492194758.37097573\n",
            "Iteration 807, loss = 1492140219.76341987\n",
            "Iteration 808, loss = 1492086318.28945661\n",
            "Iteration 809, loss = 1492031790.71401715\n",
            "Iteration 810, loss = 1491977652.51834488\n",
            "Iteration 811, loss = 1491923204.05948901\n",
            "Iteration 812, loss = 1491869010.56396198\n",
            "Iteration 813, loss = 1491814717.32578659\n",
            "Iteration 814, loss = 1491760332.11833310\n",
            "Iteration 815, loss = 1491705874.76814675\n",
            "Iteration 816, loss = 1491651758.75703716\n",
            "Iteration 817, loss = 1491597451.44115949\n",
            "Iteration 818, loss = 1491543162.08994269\n",
            "Iteration 819, loss = 1491488713.04026866\n",
            "Iteration 820, loss = 1491434380.99188066\n",
            "Iteration 821, loss = 1491380138.08188581\n",
            "Iteration 822, loss = 1491325977.73390770\n",
            "Iteration 823, loss = 1491271832.17420840\n",
            "Iteration 824, loss = 1491217261.29585075\n",
            "Iteration 825, loss = 1491163097.32319260\n",
            "Iteration 826, loss = 1491108719.51277828\n",
            "Iteration 827, loss = 1491054827.12373900\n",
            "Iteration 828, loss = 1491000706.70315909\n",
            "Iteration 829, loss = 1490946155.24609327\n",
            "Iteration 830, loss = 1490892022.99498272\n",
            "Iteration 831, loss = 1490837712.47487736\n",
            "Iteration 832, loss = 1490783283.13040066\n",
            "Iteration 833, loss = 1490729126.18615890\n",
            "Iteration 834, loss = 1490674824.12921548\n",
            "Iteration 835, loss = 1490620205.85689807\n",
            "Iteration 836, loss = 1490566134.42182922\n",
            "Iteration 837, loss = 1490512040.74561334\n",
            "Iteration 838, loss = 1490457245.24192929\n",
            "Iteration 839, loss = 1490403157.19113469\n",
            "Iteration 840, loss = 1490348548.20978045\n",
            "Iteration 841, loss = 1490294413.82806778\n",
            "Iteration 842, loss = 1490240053.44349504\n",
            "Iteration 843, loss = 1490185136.39971828\n",
            "Iteration 844, loss = 1490130745.60406232\n",
            "Iteration 845, loss = 1490076523.03567600\n",
            "Iteration 846, loss = 1490021817.43232512\n",
            "Iteration 847, loss = 1489967416.97771144\n",
            "Iteration 848, loss = 1489912819.29809499\n",
            "Iteration 849, loss = 1489858365.95525765\n",
            "Iteration 850, loss = 1489804121.50503445\n",
            "Iteration 851, loss = 1489749431.23776603\n",
            "Iteration 852, loss = 1489694929.73835921\n",
            "Iteration 853, loss = 1489640507.09210014\n",
            "Iteration 854, loss = 1489585712.57302785\n",
            "Iteration 855, loss = 1489531415.25404620\n",
            "Iteration 856, loss = 1489476602.47990584\n",
            "Iteration 857, loss = 1489421820.92410135\n",
            "Iteration 858, loss = 1489367236.79944491\n",
            "Iteration 859, loss = 1489312741.03287792\n",
            "Iteration 860, loss = 1489257920.66385484\n",
            "Iteration 861, loss = 1489203268.62442780\n",
            "Iteration 862, loss = 1489149233.52571511\n",
            "Iteration 863, loss = 1489094385.76136565\n",
            "Iteration 864, loss = 1489040241.29051185\n",
            "Iteration 865, loss = 1488986014.44512439\n",
            "Iteration 866, loss = 1488931693.75634694\n",
            "Iteration 867, loss = 1488877301.44857025\n",
            "Iteration 868, loss = 1488823003.51793098\n",
            "Iteration 869, loss = 1488768991.55498028\n",
            "Iteration 870, loss = 1488714477.01703811\n",
            "Iteration 871, loss = 1488660367.92257619\n",
            "Iteration 872, loss = 1488606344.39006424\n",
            "Iteration 873, loss = 1488552267.44804382\n",
            "Iteration 874, loss = 1488498086.89324760\n",
            "Iteration 875, loss = 1488444111.92513371\n",
            "Iteration 876, loss = 1488390055.56474495\n",
            "Iteration 877, loss = 1488336109.43699598\n",
            "Iteration 878, loss = 1488281795.24706960\n",
            "Iteration 879, loss = 1488227666.60637522\n",
            "Iteration 880, loss = 1488173570.57351851\n",
            "Iteration 881, loss = 1488119075.11546850\n",
            "Iteration 882, loss = 1488065054.12765789\n",
            "Iteration 883, loss = 1488011011.91390157\n",
            "Iteration 884, loss = 1487956632.10064101\n",
            "Iteration 885, loss = 1487902325.89386201\n",
            "Iteration 886, loss = 1487848314.80043745\n",
            "Iteration 887, loss = 1487794194.19877195\n",
            "Iteration 888, loss = 1487739632.89020538\n",
            "Iteration 889, loss = 1487685162.40054107\n",
            "Iteration 890, loss = 1487630853.20291877\n",
            "Iteration 891, loss = 1487576096.36315107\n",
            "Iteration 892, loss = 1487521358.11851120\n",
            "Iteration 893, loss = 1487466999.89673090\n",
            "Iteration 894, loss = 1487412193.89876223\n",
            "Iteration 895, loss = 1487357970.67445636\n",
            "Iteration 896, loss = 1487303333.36742735\n",
            "Iteration 897, loss = 1487249297.33764148\n",
            "Iteration 898, loss = 1487194925.99957514\n",
            "Iteration 899, loss = 1487140826.04588318\n",
            "Iteration 900, loss = 1487086590.14028645\n",
            "Iteration 901, loss = 1487032533.76628637\n",
            "Iteration 902, loss = 1486978300.45490956\n",
            "Iteration 903, loss = 1486924083.81259441\n",
            "Iteration 904, loss = 1486870069.58672714\n",
            "Iteration 905, loss = 1486815894.61949539\n",
            "Iteration 906, loss = 1486761929.02635646\n",
            "Iteration 907, loss = 1486707598.82348776\n",
            "Iteration 908, loss = 1486654016.07831097\n",
            "Iteration 909, loss = 1486599594.80264831\n",
            "Iteration 910, loss = 1486545584.67518044\n",
            "Iteration 911, loss = 1486491598.87490821\n",
            "Iteration 912, loss = 1486437748.71730494\n",
            "Iteration 913, loss = 1486383469.90010643\n",
            "Iteration 914, loss = 1486329323.97397327\n",
            "Iteration 915, loss = 1486275363.61174488\n",
            "Iteration 916, loss = 1486221140.24195838\n",
            "Iteration 917, loss = 1486166536.68043280\n",
            "Iteration 918, loss = 1486112683.46592307\n",
            "Iteration 919, loss = 1486058112.11150265\n",
            "Iteration 920, loss = 1486003963.63028502\n",
            "Iteration 921, loss = 1485949542.69896102\n",
            "Iteration 922, loss = 1485895699.32218266\n",
            "Iteration 923, loss = 1485841266.18877006\n",
            "Iteration 924, loss = 1485787572.61481404\n",
            "Iteration 925, loss = 1485733557.81865859\n",
            "Iteration 926, loss = 1485679443.73263359\n",
            "Iteration 927, loss = 1485625725.38856339\n",
            "Iteration 928, loss = 1485571497.07030463\n",
            "Iteration 929, loss = 1485517548.16432786\n",
            "Iteration 930, loss = 1485463090.59361053\n",
            "Iteration 931, loss = 1485409173.90821290\n",
            "Iteration 932, loss = 1485354230.77005339\n",
            "Iteration 933, loss = 1485300361.53286552\n",
            "Iteration 934, loss = 1485245630.57117081\n",
            "Iteration 935, loss = 1485191864.03089070\n",
            "Iteration 936, loss = 1485137216.83863521\n",
            "Iteration 937, loss = 1485083267.58073330\n",
            "Iteration 938, loss = 1485029053.04799032\n",
            "Iteration 939, loss = 1484975313.62635756\n",
            "Iteration 940, loss = 1484921018.36875582\n",
            "Iteration 941, loss = 1484867498.60621285\n",
            "Iteration 942, loss = 1484813437.13262439\n",
            "Iteration 943, loss = 1484759570.15915298\n",
            "Iteration 944, loss = 1484705352.25925827\n",
            "Iteration 945, loss = 1484652078.54907179\n",
            "Iteration 946, loss = 1484597723.91770244\n",
            "Iteration 947, loss = 1484543883.75051737\n",
            "Iteration 948, loss = 1484490186.71421218\n",
            "Iteration 949, loss = 1484436061.21688747\n",
            "Iteration 950, loss = 1484382063.01795506\n",
            "Iteration 951, loss = 1484328353.72841763\n",
            "Iteration 952, loss = 1484274396.43218875\n",
            "Iteration 953, loss = 1484220486.47682738\n",
            "Iteration 954, loss = 1484166924.05982494\n",
            "Iteration 955, loss = 1484112588.56463790\n",
            "Iteration 956, loss = 1484059265.56612229\n",
            "Iteration 957, loss = 1484004826.95393538\n",
            "Iteration 958, loss = 1483951210.70232892\n",
            "Iteration 959, loss = 1483897139.58688498\n",
            "Iteration 960, loss = 1483843459.45392895\n",
            "Iteration 961, loss = 1483788948.17031908\n",
            "Iteration 962, loss = 1483735442.42999196\n",
            "Iteration 963, loss = 1483681651.08594918\n",
            "Iteration 964, loss = 1483627781.94206238\n",
            "Iteration 965, loss = 1483574220.57304716\n",
            "Iteration 966, loss = 1483520108.35358882\n",
            "Iteration 967, loss = 1483466691.27765560\n",
            "Iteration 968, loss = 1483412933.39767385\n",
            "Iteration 969, loss = 1483359049.35346889\n",
            "Iteration 970, loss = 1483305127.71486473\n",
            "Iteration 971, loss = 1483251521.83549142\n",
            "Iteration 972, loss = 1483197672.99224663\n",
            "Iteration 973, loss = 1483144038.56377292\n",
            "Iteration 974, loss = 1483090002.82474542\n",
            "Iteration 975, loss = 1483036315.32925892\n",
            "Iteration 976, loss = 1482982795.34021139\n",
            "Iteration 977, loss = 1482928574.85980415\n",
            "Iteration 978, loss = 1482874898.33497453\n",
            "Iteration 979, loss = 1482820774.97914553\n",
            "Iteration 980, loss = 1482766687.42414188\n",
            "Iteration 981, loss = 1482712869.52686882\n",
            "Iteration 982, loss = 1482658475.23844552\n",
            "Iteration 983, loss = 1482604570.58954859\n",
            "Iteration 984, loss = 1482550209.19199562\n",
            "Iteration 985, loss = 1482496332.69791532\n",
            "Iteration 986, loss = 1482442344.48705578\n",
            "Iteration 987, loss = 1482387960.18088078\n",
            "Iteration 988, loss = 1482334060.62001038\n",
            "Iteration 989, loss = 1482279770.70126820\n",
            "Iteration 990, loss = 1482225807.15250802\n",
            "Iteration 991, loss = 1482171630.51878905\n",
            "Iteration 992, loss = 1482117419.86240268\n",
            "Iteration 993, loss = 1482063306.96614122\n",
            "Iteration 994, loss = 1482009438.19038367\n",
            "Iteration 995, loss = 1481955579.66866112\n",
            "Iteration 996, loss = 1481901309.21871638\n",
            "Iteration 997, loss = 1481847417.35258913\n",
            "Iteration 998, loss = 1481793410.39109588\n",
            "Iteration 999, loss = 1481739668.31994486\n",
            "Iteration 1000, loss = 1481685472.75325370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1415188105.73981428\n",
            "Iteration 2, loss = 1084334251.27776408\n",
            "Iteration 3, loss = 1069246759.03864789\n",
            "Iteration 4, loss = 764934991.88448524\n",
            "Iteration 5, loss = 491578526.07186371\n",
            "Iteration 6, loss = 332630678.29829037\n",
            "Iteration 7, loss = 195830236.14048275\n",
            "Iteration 8, loss = 102466012.64402565\n",
            "Iteration 9, loss = 56289421.15288897\n",
            "Iteration 10, loss = 40559491.46160852\n",
            "Iteration 11, loss = 38181327.52769110\n",
            "Iteration 12, loss = 45393657.41622561\n",
            "Iteration 13, loss = 52911607.22714911\n",
            "Iteration 14, loss = 57024714.10257408\n",
            "Iteration 15, loss = 55105504.18511914\n",
            "Iteration 16, loss = 49872495.86128704\n",
            "Iteration 17, loss = 41980002.99231049\n",
            "Iteration 18, loss = 34679505.03061669\n",
            "Iteration 19, loss = 28371385.10751761\n",
            "Iteration 20, loss = 23887261.68988302\n",
            "Iteration 21, loss = 21307166.16884045\n",
            "Iteration 22, loss = 20269159.69388701\n",
            "Iteration 23, loss = 19268377.42861530\n",
            "Iteration 24, loss = 15858069.12861151\n",
            "Iteration 25, loss = 16616975.23161442\n",
            "Iteration 26, loss = 17111678.68480371\n",
            "Iteration 27, loss = 17119883.92306381\n",
            "Iteration 28, loss = 16883833.22017042\n",
            "Iteration 29, loss = 16037639.73270608\n",
            "Iteration 30, loss = 15466598.52863579\n",
            "Iteration 31, loss = 15098403.54934235\n",
            "Iteration 32, loss = 14405501.41339407\n",
            "Iteration 33, loss = 13922148.16614592\n",
            "Iteration 34, loss = 13729733.99589705\n",
            "Iteration 35, loss = 13420968.75033742\n",
            "Iteration 36, loss = 13086873.85077632\n",
            "Iteration 37, loss = 12754348.61288291\n",
            "Iteration 38, loss = 12465996.86575944\n",
            "Iteration 39, loss = 12215964.69085646\n",
            "Iteration 40, loss = 12004604.41654649\n",
            "Iteration 41, loss = 11782055.04337571\n",
            "Iteration 42, loss = 11588674.24547299\n",
            "Iteration 43, loss = 11363570.89073521\n",
            "Iteration 44, loss = 11278594.62908630\n",
            "Iteration 45, loss = 11129212.48085393\n",
            "Iteration 46, loss = 10931508.78456728\n",
            "Iteration 47, loss = 10727815.07591797\n",
            "Iteration 48, loss = 10670427.26193173\n",
            "Iteration 49, loss = 10506657.30712111\n",
            "Iteration 50, loss = 10356013.77424720\n",
            "Iteration 51, loss = 10230835.12872751\n",
            "Iteration 52, loss = 10188508.78521481\n",
            "Iteration 53, loss = 10169059.17568232\n",
            "Iteration 54, loss = 9937626.83270706\n",
            "Iteration 55, loss = 9780401.95661907\n",
            "Iteration 56, loss = 9920005.57433474\n",
            "Iteration 57, loss = 9735701.03330246\n",
            "Iteration 58, loss = 9516093.16916692\n",
            "Iteration 59, loss = 9383320.39741994\n",
            "Iteration 60, loss = 9431098.89784813\n",
            "Iteration 61, loss = 9206118.66622286\n",
            "Iteration 62, loss = 9180872.58291764\n",
            "Iteration 63, loss = 9077694.12346971\n",
            "Iteration 64, loss = 8978598.14104264\n",
            "Iteration 65, loss = 8895917.32312671\n",
            "Iteration 66, loss = 8822464.48796492\n",
            "Iteration 67, loss = 8745888.82826566\n",
            "Iteration 68, loss = 8734955.75104923\n",
            "Iteration 69, loss = 8743537.60424384\n",
            "Iteration 70, loss = 8695760.87811011\n",
            "Iteration 71, loss = 8486173.85447299\n",
            "Iteration 72, loss = 8423465.70796221\n",
            "Iteration 73, loss = 8373186.84254822\n",
            "Iteration 74, loss = 8272683.72046217\n",
            "Iteration 75, loss = 8213833.85091063\n",
            "Iteration 76, loss = 8145881.34839959\n",
            "Iteration 77, loss = 8085551.46255713\n",
            "Iteration 78, loss = 8083281.10973278\n",
            "Iteration 79, loss = 7969697.78665974\n",
            "Iteration 80, loss = 7944569.16988328\n",
            "Iteration 81, loss = 7929645.20528208\n",
            "Iteration 82, loss = 7895545.98750105\n",
            "Iteration 83, loss = 7786809.93766287\n",
            "Iteration 84, loss = 7701638.38666403\n",
            "Iteration 85, loss = 7792380.27674855\n",
            "Iteration 86, loss = 7822903.39937825\n",
            "Iteration 87, loss = 7601057.72330976\n",
            "Iteration 88, loss = 7541780.98016914\n",
            "Iteration 89, loss = 7489710.60555739\n",
            "Iteration 90, loss = 7467391.38804250\n",
            "Iteration 91, loss = 7439722.16799531\n",
            "Iteration 92, loss = 7383723.88778507\n",
            "Iteration 93, loss = 7345355.69856816\n",
            "Iteration 94, loss = 7296439.47464053\n",
            "Iteration 95, loss = 7262336.43413696\n",
            "Iteration 96, loss = 7223342.80658375\n",
            "Iteration 97, loss = 7173260.73237262\n",
            "Iteration 98, loss = 7156987.90258972\n",
            "Iteration 99, loss = 7118847.80842972\n",
            "Iteration 100, loss = 7101951.02862725\n",
            "Iteration 101, loss = 7044833.71026021\n",
            "Iteration 102, loss = 7009137.03300241\n",
            "Iteration 103, loss = 6962002.40367213\n",
            "Iteration 104, loss = 6989489.95119599\n",
            "Iteration 105, loss = 6940676.20845894\n",
            "Iteration 106, loss = 6875950.24461633\n",
            "Iteration 107, loss = 6883427.12517409\n",
            "Iteration 108, loss = 6947517.06708976\n",
            "Iteration 109, loss = 6888344.57921049\n",
            "Iteration 110, loss = 6754450.02070399\n",
            "Iteration 111, loss = 6776592.01081569\n",
            "Iteration 112, loss = 6714293.51026523\n",
            "Iteration 113, loss = 6680697.07309063\n",
            "Iteration 114, loss = 6650169.67199539\n",
            "Iteration 115, loss = 6643853.73437439\n",
            "Iteration 116, loss = 6616998.58816335\n",
            "Iteration 117, loss = 6643300.68503086\n",
            "Iteration 118, loss = 6634649.19664140\n",
            "Iteration 119, loss = 6530987.23863160\n",
            "Iteration 120, loss = 6551430.04995602\n",
            "Iteration 121, loss = 6483877.11534575\n",
            "Iteration 122, loss = 6507257.87651735\n",
            "Iteration 123, loss = 6494421.55707561\n",
            "Iteration 124, loss = 6452761.43974488\n",
            "Iteration 125, loss = 6424714.34923512\n",
            "Iteration 126, loss = 6417393.81105360\n",
            "Iteration 127, loss = 6379959.33887006\n",
            "Iteration 128, loss = 6385479.40723280\n",
            "Iteration 129, loss = 6347764.28365799\n",
            "Iteration 130, loss = 6319508.92708336\n",
            "Iteration 131, loss = 6300450.17884403\n",
            "Iteration 132, loss = 6275633.68998422\n",
            "Iteration 133, loss = 6256158.95167195\n",
            "Iteration 134, loss = 6241492.35350084\n",
            "Iteration 135, loss = 6221407.90202954\n",
            "Iteration 136, loss = 6213761.02862497\n",
            "Iteration 137, loss = 6242917.64622183\n",
            "Iteration 138, loss = 6200430.44751656\n",
            "Iteration 139, loss = 6152674.19327295\n",
            "Iteration 140, loss = 6166016.30752868\n",
            "Iteration 141, loss = 6129080.79266189\n",
            "Iteration 142, loss = 6106836.33240103\n",
            "Iteration 143, loss = 6094809.72661024\n",
            "Iteration 144, loss = 6080833.11980492\n",
            "Iteration 145, loss = 6077749.50659360\n",
            "Iteration 146, loss = 6087424.69053191\n",
            "Iteration 147, loss = 6072195.46524822\n",
            "Iteration 148, loss = 6042225.27423722\n",
            "Iteration 149, loss = 6056884.34117033\n",
            "Iteration 150, loss = 6067877.17885493\n",
            "Iteration 151, loss = 6033950.20055541\n",
            "Iteration 152, loss = 6012944.83757294\n",
            "Iteration 153, loss = 6000765.14195955\n",
            "Iteration 154, loss = 5971352.36565521\n",
            "Iteration 155, loss = 5995348.79275973\n",
            "Iteration 156, loss = 6002584.83912246\n",
            "Iteration 157, loss = 5992776.47873602\n",
            "Iteration 158, loss = 5970167.06943819\n",
            "Iteration 159, loss = 5931063.99853887\n",
            "Iteration 160, loss = 5889323.26187261\n",
            "Iteration 161, loss = 5890983.80151282\n",
            "Iteration 162, loss = 5879519.11565750\n",
            "Iteration 163, loss = 5900662.53975569\n",
            "Iteration 164, loss = 5862342.56953814\n",
            "Iteration 165, loss = 5929599.85429203\n",
            "Iteration 166, loss = 5985048.69162528\n",
            "Iteration 167, loss = 5884580.79128790\n",
            "Iteration 168, loss = 5885212.07083415\n",
            "Iteration 169, loss = 5815332.45518685\n",
            "Iteration 170, loss = 5824380.83120640\n",
            "Iteration 171, loss = 5903045.83173819\n",
            "Iteration 172, loss = 5883910.76096940\n",
            "Iteration 173, loss = 5811658.60901702\n",
            "Iteration 174, loss = 5772047.94810741\n",
            "Iteration 175, loss = 5775799.43262987\n",
            "Iteration 176, loss = 5826949.62205998\n",
            "Iteration 177, loss = 5745002.34834565\n",
            "Iteration 178, loss = 5780582.52048001\n",
            "Iteration 179, loss = 5764221.14679307\n",
            "Iteration 180, loss = 5732508.15179162\n",
            "Iteration 181, loss = 5730860.32189723\n",
            "Iteration 182, loss = 5738481.28970197\n",
            "Iteration 183, loss = 5722504.18638346\n",
            "Iteration 184, loss = 5713711.67808264\n",
            "Iteration 185, loss = 5707263.35688830\n",
            "Iteration 186, loss = 5702197.34977549\n",
            "Iteration 187, loss = 5693466.28516796\n",
            "Iteration 188, loss = 5684162.69836752\n",
            "Iteration 189, loss = 5689750.03635438\n",
            "Iteration 190, loss = 5680411.98535153\n",
            "Iteration 191, loss = 5667031.55250440\n",
            "Iteration 192, loss = 5700449.95160393\n",
            "Iteration 193, loss = 5654064.31523023\n",
            "Iteration 194, loss = 5670938.47270079\n",
            "Iteration 195, loss = 5712825.91664942\n",
            "Iteration 196, loss = 5735037.13210129\n",
            "Iteration 197, loss = 5633349.93607120\n",
            "Iteration 198, loss = 5682973.38202148\n",
            "Iteration 199, loss = 5644326.23588713\n",
            "Iteration 200, loss = 5619892.33035172\n",
            "Iteration 201, loss = 5629861.46900656\n",
            "Iteration 202, loss = 5630962.65219531\n",
            "Iteration 203, loss = 5621673.97272838\n",
            "Iteration 204, loss = 5606716.16121742\n",
            "Iteration 205, loss = 5615908.84309905\n",
            "Iteration 206, loss = 5593766.22646358\n",
            "Iteration 207, loss = 5616595.24430735\n",
            "Iteration 208, loss = 5639711.71337322\n",
            "Iteration 209, loss = 5630724.96929337\n",
            "Iteration 210, loss = 5587937.37520084\n",
            "Iteration 211, loss = 5610463.24935174\n",
            "Iteration 212, loss = 5595848.10293344\n",
            "Iteration 213, loss = 5574796.49756056\n",
            "Iteration 214, loss = 5602846.80869010\n",
            "Iteration 215, loss = 5575012.49882812\n",
            "Iteration 216, loss = 5564834.34513153\n",
            "Iteration 217, loss = 5571588.79095100\n",
            "Iteration 218, loss = 5614753.22424022\n",
            "Iteration 219, loss = 5609191.42563176\n",
            "Iteration 220, loss = 5536321.33988228\n",
            "Iteration 221, loss = 5609598.89898356\n",
            "Iteration 222, loss = 5610082.79700039\n",
            "Iteration 223, loss = 5542315.12520651\n",
            "Iteration 224, loss = 5552214.03637767\n",
            "Iteration 225, loss = 5650083.20347902\n",
            "Iteration 226, loss = 5659606.42638373\n",
            "Iteration 227, loss = 5527112.29086508\n",
            "Iteration 228, loss = 5543208.79475567\n",
            "Iteration 229, loss = 5643909.21289727\n",
            "Iteration 230, loss = 5611827.15961000\n",
            "Iteration 231, loss = 5550180.47056622\n",
            "Iteration 232, loss = 5505907.42571807\n",
            "Iteration 233, loss = 5513350.49036570\n",
            "Iteration 234, loss = 5533520.64557317\n",
            "Iteration 235, loss = 5496463.43066262\n",
            "Iteration 236, loss = 5548414.76590069\n",
            "Iteration 237, loss = 5536554.91403097\n",
            "Iteration 238, loss = 5502492.99216880\n",
            "Iteration 239, loss = 5486258.01486335\n",
            "Iteration 240, loss = 5500742.96395669\n",
            "Iteration 241, loss = 5507637.93202071\n",
            "Iteration 242, loss = 5483720.07798794\n",
            "Iteration 243, loss = 5476969.25936189\n",
            "Iteration 244, loss = 5482053.57726152\n",
            "Iteration 245, loss = 5489582.91047897\n",
            "Iteration 246, loss = 5490007.45986281\n",
            "Iteration 247, loss = 5466022.96367564\n",
            "Iteration 248, loss = 5497740.02208327\n",
            "Iteration 249, loss = 5466996.84101868\n",
            "Iteration 250, loss = 5464344.33544526\n",
            "Iteration 251, loss = 5498094.20247865\n",
            "Iteration 252, loss = 5469724.20721631\n",
            "Iteration 253, loss = 5453701.33747284\n",
            "Iteration 254, loss = 5462395.14690213\n",
            "Iteration 255, loss = 5490745.92646418\n",
            "Iteration 256, loss = 5471271.55951815\n",
            "Iteration 257, loss = 5458339.92276758\n",
            "Iteration 258, loss = 5452070.10989094\n",
            "Iteration 259, loss = 5455256.03150634\n",
            "Iteration 260, loss = 5440604.81949163\n",
            "Iteration 261, loss = 5436851.68531712\n",
            "Iteration 262, loss = 5443511.71415814\n",
            "Iteration 263, loss = 5440829.67295934\n",
            "Iteration 264, loss = 5447019.65409773\n",
            "Iteration 265, loss = 5495365.98692389\n",
            "Iteration 266, loss = 5498437.10317704\n",
            "Iteration 267, loss = 5448658.22019168\n",
            "Iteration 268, loss = 5439910.43812456\n",
            "Iteration 269, loss = 5640157.89559061\n",
            "Iteration 270, loss = 5509818.40040703\n",
            "Iteration 271, loss = 5439099.47803530\n",
            "Iteration 272, loss = 5426723.77047152\n",
            "Iteration 273, loss = 5416679.48366297\n",
            "Iteration 274, loss = 5439071.57150562\n",
            "Iteration 275, loss = 5514937.07286376\n",
            "Iteration 276, loss = 5535076.62010416\n",
            "Iteration 277, loss = 5527359.15304484\n",
            "Iteration 278, loss = 5492650.20285016\n",
            "Iteration 279, loss = 5402070.76867851\n",
            "Iteration 280, loss = 5452279.65750947\n",
            "Iteration 281, loss = 5557645.11447061\n",
            "Iteration 282, loss = 5463650.50821542\n",
            "Iteration 283, loss = 5408827.61981574\n",
            "Iteration 284, loss = 5424753.80199795\n",
            "Iteration 285, loss = 5392667.48785049\n",
            "Iteration 286, loss = 5414396.79395351\n",
            "Iteration 287, loss = 5491238.92031887\n",
            "Iteration 288, loss = 5429226.23128384\n",
            "Iteration 289, loss = 5410774.93356858\n",
            "Iteration 290, loss = 5404829.76469670\n",
            "Iteration 291, loss = 5398460.34715980\n",
            "Iteration 292, loss = 5414908.92434195\n",
            "Iteration 293, loss = 5437529.45584970\n",
            "Iteration 294, loss = 5442255.78066745\n",
            "Iteration 295, loss = 5395286.82068335\n",
            "Iteration 296, loss = 5385219.14635049\n",
            "Iteration 297, loss = 5377891.63850752\n",
            "Iteration 298, loss = 5385312.79275472\n",
            "Iteration 299, loss = 5397682.12652550\n",
            "Iteration 300, loss = 5387341.53804171\n",
            "Iteration 301, loss = 5410264.32987761\n",
            "Iteration 302, loss = 5380348.99091473\n",
            "Iteration 303, loss = 5375840.96602549\n",
            "Iteration 304, loss = 5378579.24911648\n",
            "Iteration 305, loss = 5372266.42049746\n",
            "Iteration 306, loss = 5394198.81799585\n",
            "Iteration 307, loss = 5379813.83399641\n",
            "Iteration 308, loss = 5415462.77079624\n",
            "Iteration 309, loss = 5400916.14128682\n",
            "Iteration 310, loss = 5363186.47118693\n",
            "Iteration 311, loss = 5455652.22882376\n",
            "Iteration 312, loss = 5459608.37468513\n",
            "Iteration 313, loss = 5374770.46099941\n",
            "Iteration 314, loss = 5379607.97099681\n",
            "Iteration 315, loss = 5365578.31594969\n",
            "Iteration 316, loss = 5375310.70262209\n",
            "Iteration 317, loss = 5362784.99196573\n",
            "Iteration 318, loss = 5369765.74394361\n",
            "Iteration 319, loss = 5437216.12667791\n",
            "Iteration 320, loss = 5350860.11140158\n",
            "Iteration 321, loss = 5383739.70895099\n",
            "Iteration 322, loss = 5395820.90583128\n",
            "Iteration 323, loss = 5345383.38584356\n",
            "Iteration 324, loss = 5401619.95735185\n",
            "Iteration 325, loss = 5583002.28087689\n",
            "Iteration 326, loss = 5458484.40343578\n",
            "Iteration 327, loss = 5363868.14728649\n",
            "Iteration 328, loss = 5348266.39901385\n",
            "Iteration 329, loss = 5414090.11950312\n",
            "Iteration 330, loss = 5422476.80118241\n",
            "Iteration 331, loss = 5378923.17720581\n",
            "Iteration 332, loss = 5358779.64473912\n",
            "Iteration 333, loss = 5344975.28520298\n",
            "Iteration 334, loss = 5340829.33616746\n",
            "Iteration 335, loss = 5343262.27364214\n",
            "Iteration 336, loss = 5340874.97741505\n",
            "Iteration 337, loss = 5364236.93806291\n",
            "Iteration 338, loss = 5350514.51278200\n",
            "Iteration 339, loss = 5343582.93508369\n",
            "Iteration 340, loss = 5341290.37000155\n",
            "Iteration 341, loss = 5344241.56736438\n",
            "Iteration 342, loss = 5350569.32224351\n",
            "Iteration 343, loss = 5350588.46128584\n",
            "Iteration 344, loss = 5329619.55062294\n",
            "Iteration 345, loss = 5334534.71034199\n",
            "Iteration 346, loss = 5334767.63957874\n",
            "Iteration 347, loss = 5328285.52856550\n",
            "Iteration 348, loss = 5324531.59628604\n",
            "Iteration 349, loss = 5345408.41341047\n",
            "Iteration 350, loss = 5359193.84392072\n",
            "Iteration 351, loss = 5329162.35815295\n",
            "Iteration 352, loss = 5373741.53138928\n",
            "Iteration 353, loss = 5411087.83658132\n",
            "Iteration 354, loss = 5418625.78555282\n",
            "Iteration 355, loss = 5387676.99906607\n",
            "Iteration 356, loss = 5314987.69083641\n",
            "Iteration 357, loss = 5377894.96314310\n",
            "Iteration 358, loss = 5395652.18481221\n",
            "Iteration 359, loss = 5309874.26817970\n",
            "Iteration 360, loss = 5398027.73851814\n",
            "Iteration 361, loss = 5415058.27345648\n",
            "Iteration 362, loss = 5384238.19186279\n",
            "Iteration 363, loss = 5370954.65708186\n",
            "Iteration 364, loss = 5361653.12977525\n",
            "Iteration 365, loss = 5334620.23462073\n",
            "Iteration 366, loss = 5319490.68194745\n",
            "Iteration 367, loss = 5317515.45252325\n",
            "Iteration 368, loss = 5317050.44841832\n",
            "Iteration 369, loss = 5310825.79721364\n",
            "Iteration 370, loss = 5311898.00593870\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538824806.76381016\n",
            "Iteration 2, loss = 1538794884.05715632\n",
            "Iteration 3, loss = 1538764980.64346409\n",
            "Iteration 4, loss = 1538735110.29654002\n",
            "Iteration 5, loss = 1538705180.78248000\n",
            "Iteration 6, loss = 1538675013.66478467\n",
            "Iteration 7, loss = 1538643954.18589902\n",
            "Iteration 8, loss = 1538612674.38994074\n",
            "Iteration 9, loss = 1538580910.23307848\n",
            "Iteration 10, loss = 1538548240.94360566\n",
            "Iteration 11, loss = 1538514381.18849373\n",
            "Iteration 12, loss = 1538480077.52946281\n",
            "Iteration 13, loss = 1538444910.17139697\n",
            "Iteration 14, loss = 1538408612.20705152\n",
            "Iteration 15, loss = 1538371112.66826248\n",
            "Iteration 16, loss = 1538333174.42893267\n",
            "Iteration 17, loss = 1538294135.81559420\n",
            "Iteration 18, loss = 1538253509.37738109\n",
            "Iteration 19, loss = 1538213192.82821250\n",
            "Iteration 20, loss = 1538170020.55181932\n",
            "Iteration 21, loss = 1538127722.78700995\n",
            "Iteration 22, loss = 1538083528.49964666\n",
            "Iteration 23, loss = 1538039498.66956544\n",
            "Iteration 24, loss = 1537994258.77536321\n",
            "Iteration 25, loss = 1537947741.88239336\n",
            "Iteration 26, loss = 1537901980.56766415\n",
            "Iteration 27, loss = 1537854213.68391824\n",
            "Iteration 28, loss = 1537806724.71677947\n",
            "Iteration 29, loss = 1537757988.57423592\n",
            "Iteration 30, loss = 1537709989.07131910\n",
            "Iteration 31, loss = 1537660677.05042076\n",
            "Iteration 32, loss = 1537610676.53041553\n",
            "Iteration 33, loss = 1537560057.88323259\n",
            "Iteration 34, loss = 1537509783.60989237\n",
            "Iteration 35, loss = 1537459711.00201011\n",
            "Iteration 36, loss = 1537408019.55900812\n",
            "Iteration 37, loss = 1537355956.78800273\n",
            "Iteration 38, loss = 1537304466.45889688\n",
            "Iteration 39, loss = 1537251727.24831319\n",
            "Iteration 40, loss = 1537198971.24582291\n",
            "Iteration 41, loss = 1537145287.46392751\n",
            "Iteration 42, loss = 1537091346.12459970\n",
            "Iteration 43, loss = 1537036599.74063373\n",
            "Iteration 44, loss = 1536981909.14397359\n",
            "Iteration 45, loss = 1536926097.93681526\n",
            "Iteration 46, loss = 1536869701.04883981\n",
            "Iteration 47, loss = 1536812487.32455063\n",
            "Iteration 48, loss = 1536755011.43192577\n",
            "Iteration 49, loss = 1536696577.09969139\n",
            "Iteration 50, loss = 1536637236.62929416\n",
            "Iteration 51, loss = 1536577110.48830700\n",
            "Iteration 52, loss = 1536516087.63592649\n",
            "Iteration 53, loss = 1536454394.65354252\n",
            "Iteration 54, loss = 1536391682.47491622\n",
            "Iteration 55, loss = 1536328101.52294278\n",
            "Iteration 56, loss = 1536263495.68250537\n",
            "Iteration 57, loss = 1536198111.97361088\n",
            "Iteration 58, loss = 1536131830.01992869\n",
            "Iteration 59, loss = 1536064771.76115799\n",
            "Iteration 60, loss = 1535996840.84136367\n",
            "Iteration 61, loss = 1535928316.60859680\n",
            "Iteration 62, loss = 1535859215.15302014\n",
            "Iteration 63, loss = 1535789331.09377337\n",
            "Iteration 64, loss = 1535719216.00096655\n",
            "Iteration 65, loss = 1535648553.87216520\n",
            "Iteration 66, loss = 1535577614.63692069\n",
            "Iteration 67, loss = 1535506271.03653836\n",
            "Iteration 68, loss = 1535434932.63989806\n",
            "Iteration 69, loss = 1535363465.17615318\n",
            "Iteration 70, loss = 1535291663.23250747\n",
            "Iteration 71, loss = 1535219794.16778541\n",
            "Iteration 72, loss = 1535147612.20457959\n",
            "Iteration 73, loss = 1535075711.11659765\n",
            "Iteration 74, loss = 1535003587.05372405\n",
            "Iteration 75, loss = 1534931312.32691169\n",
            "Iteration 76, loss = 1534859281.52204514\n",
            "Iteration 77, loss = 1534787170.49348736\n",
            "Iteration 78, loss = 1534714742.20802760\n",
            "Iteration 79, loss = 1534642383.30970645\n",
            "Iteration 80, loss = 1534570326.53285623\n",
            "Iteration 81, loss = 1534497275.80287242\n",
            "Iteration 82, loss = 1534425120.23055744\n",
            "Iteration 83, loss = 1534352595.27806020\n",
            "Iteration 84, loss = 1534280247.90928006\n",
            "Iteration 85, loss = 1534207832.74197555\n",
            "Iteration 86, loss = 1534135694.80706263\n",
            "Iteration 87, loss = 1534063383.32854557\n",
            "Iteration 88, loss = 1533991332.65185332\n",
            "Iteration 89, loss = 1533919373.87882710\n",
            "Iteration 90, loss = 1533847658.49160480\n",
            "Iteration 91, loss = 1533776034.71910644\n",
            "Iteration 92, loss = 1533704144.14699197\n",
            "Iteration 93, loss = 1533632921.33142447\n",
            "Iteration 94, loss = 1533561447.01407433\n",
            "Iteration 95, loss = 1533490689.59137917\n",
            "Iteration 96, loss = 1533419255.98829007\n",
            "Iteration 97, loss = 1533348675.67903018\n",
            "Iteration 98, loss = 1533277535.87353325\n",
            "Iteration 99, loss = 1533206860.95107770\n",
            "Iteration 100, loss = 1533136245.91131568\n",
            "Iteration 101, loss = 1533065500.65857172\n",
            "Iteration 102, loss = 1532994826.71092153\n",
            "Iteration 103, loss = 1532924528.50164866\n",
            "Iteration 104, loss = 1532854803.15722322\n",
            "Iteration 105, loss = 1532784571.31349063\n",
            "Iteration 106, loss = 1532714250.27257800\n",
            "Iteration 107, loss = 1532644549.46318984\n",
            "Iteration 108, loss = 1532575150.39365816\n",
            "Iteration 109, loss = 1532505340.54484034\n",
            "Iteration 110, loss = 1532436042.78811026\n",
            "Iteration 111, loss = 1532366788.97703123\n",
            "Iteration 112, loss = 1532297459.49298954\n",
            "Iteration 113, loss = 1532228347.82193780\n",
            "Iteration 114, loss = 1532159394.71520066\n",
            "Iteration 115, loss = 1532090639.30493069\n",
            "Iteration 116, loss = 1532021393.24706292\n",
            "Iteration 117, loss = 1531952726.90614176\n",
            "Iteration 118, loss = 1531884361.64283466\n",
            "Iteration 119, loss = 1531815542.10383201\n",
            "Iteration 120, loss = 1531747354.60376644\n",
            "Iteration 121, loss = 1531678983.55553365\n",
            "Iteration 122, loss = 1531610853.06761813\n",
            "Iteration 123, loss = 1531542909.09081817\n",
            "Iteration 124, loss = 1531475086.49575663\n",
            "Iteration 125, loss = 1531407422.82846928\n",
            "Iteration 126, loss = 1531339511.45252275\n",
            "Iteration 127, loss = 1531272000.14145732\n",
            "Iteration 128, loss = 1531204997.52444267\n",
            "Iteration 129, loss = 1531137346.73176074\n",
            "Iteration 130, loss = 1531070486.41463518\n",
            "Iteration 131, loss = 1531003096.05953360\n",
            "Iteration 132, loss = 1530936251.96846199\n",
            "Iteration 133, loss = 1530869553.75421834\n",
            "Iteration 134, loss = 1530802768.78318572\n",
            "Iteration 135, loss = 1530735752.07620740\n",
            "Iteration 136, loss = 1530669301.18293333\n",
            "Iteration 137, loss = 1530602585.74906778\n",
            "Iteration 138, loss = 1530535976.63478875\n",
            "Iteration 139, loss = 1530469467.65661097\n",
            "Iteration 140, loss = 1530403441.20255160\n",
            "Iteration 141, loss = 1530336610.75957084\n",
            "Iteration 142, loss = 1530270771.23984385\n",
            "Iteration 143, loss = 1530204133.00695944\n",
            "Iteration 144, loss = 1530138493.22683787\n",
            "Iteration 145, loss = 1530072215.27554941\n",
            "Iteration 146, loss = 1530006006.93390036\n",
            "Iteration 147, loss = 1529940206.53542852\n",
            "Iteration 148, loss = 1529874618.31070352\n",
            "Iteration 149, loss = 1529808962.27840137\n",
            "Iteration 150, loss = 1529743160.47665381\n",
            "Iteration 151, loss = 1529677984.04070282\n",
            "Iteration 152, loss = 1529612684.99516439\n",
            "Iteration 153, loss = 1529547352.35312176\n",
            "Iteration 154, loss = 1529482292.17947197\n",
            "Iteration 155, loss = 1529417197.55820513\n",
            "Iteration 156, loss = 1529352212.85471010\n",
            "Iteration 157, loss = 1529287174.61856890\n",
            "Iteration 158, loss = 1529222214.12496400\n",
            "Iteration 159, loss = 1529157258.51973414\n",
            "Iteration 160, loss = 1529092760.14147711\n",
            "Iteration 161, loss = 1529028082.11938238\n",
            "Iteration 162, loss = 1528963036.08213735\n",
            "Iteration 163, loss = 1528898828.05431032\n",
            "Iteration 164, loss = 1528834177.52226710\n",
            "Iteration 165, loss = 1528770069.29569769\n",
            "Iteration 166, loss = 1528705489.06274748\n",
            "Iteration 167, loss = 1528641347.52208066\n",
            "Iteration 168, loss = 1528577707.10520601\n",
            "Iteration 169, loss = 1528513061.21708870\n",
            "Iteration 170, loss = 1528449466.84670830\n",
            "Iteration 171, loss = 1528385768.84163857\n",
            "Iteration 172, loss = 1528321512.09455919\n",
            "Iteration 173, loss = 1528257826.98818040\n",
            "Iteration 174, loss = 1528194095.03415298\n",
            "Iteration 175, loss = 1528130683.48886800\n",
            "Iteration 176, loss = 1528067220.30394506\n",
            "Iteration 177, loss = 1528003696.03221869\n",
            "Iteration 178, loss = 1527940275.10299993\n",
            "Iteration 179, loss = 1527877553.24313927\n",
            "Iteration 180, loss = 1527814165.17631388\n",
            "Iteration 181, loss = 1527751187.81361103\n",
            "Iteration 182, loss = 1527688755.59460115\n",
            "Iteration 183, loss = 1527625023.71210170\n",
            "Iteration 184, loss = 1527562455.51237726\n",
            "Iteration 185, loss = 1527499382.28715110\n",
            "Iteration 186, loss = 1527436543.29344821\n",
            "Iteration 187, loss = 1527373365.08893108\n",
            "Iteration 188, loss = 1527310788.72828221\n",
            "Iteration 189, loss = 1527247518.16587305\n",
            "Iteration 190, loss = 1527184926.93680716\n",
            "Iteration 191, loss = 1527122472.58522058\n",
            "Iteration 192, loss = 1527059105.93288875\n",
            "Iteration 193, loss = 1526996697.73119187\n",
            "Iteration 194, loss = 1526934074.95156765\n",
            "Iteration 195, loss = 1526872072.31328321\n",
            "Iteration 196, loss = 1526809199.94254684\n",
            "Iteration 197, loss = 1526746616.66420555\n",
            "Iteration 198, loss = 1526684472.66163254\n",
            "Iteration 199, loss = 1526622297.80434084\n",
            "Iteration 200, loss = 1526559836.08943534\n",
            "Iteration 201, loss = 1526497704.96488309\n",
            "Iteration 202, loss = 1526435323.89813113\n",
            "Iteration 203, loss = 1526373372.18279862\n",
            "Iteration 204, loss = 1526310924.71027160\n",
            "Iteration 205, loss = 1526248860.35403943\n",
            "Iteration 206, loss = 1526186760.39483690\n",
            "Iteration 207, loss = 1526124911.82033253\n",
            "Iteration 208, loss = 1526063086.78090096\n",
            "Iteration 209, loss = 1526001328.39072704\n",
            "Iteration 210, loss = 1525939549.95942879\n",
            "Iteration 211, loss = 1525878321.57152295\n",
            "Iteration 212, loss = 1525817041.35625434\n",
            "Iteration 213, loss = 1525755676.13525510\n",
            "Iteration 214, loss = 1525694923.26439381\n",
            "Iteration 215, loss = 1525633652.81932855\n",
            "Iteration 216, loss = 1525572810.71702147\n",
            "Iteration 217, loss = 1525511782.69984055\n",
            "Iteration 218, loss = 1525450714.08681512\n",
            "Iteration 219, loss = 1525389639.99250269\n",
            "Iteration 220, loss = 1525328667.95611024\n",
            "Iteration 221, loss = 1525267416.07697439\n",
            "Iteration 222, loss = 1525206165.03728151\n",
            "Iteration 223, loss = 1525144813.29738498\n",
            "Iteration 224, loss = 1525083860.96020627\n",
            "Iteration 225, loss = 1525022479.31603360\n",
            "Iteration 226, loss = 1524961496.27474999\n",
            "Iteration 227, loss = 1524900429.37084961\n",
            "Iteration 228, loss = 1524839538.48297691\n",
            "Iteration 229, loss = 1524778762.07599521\n",
            "Iteration 230, loss = 1524718139.78848052\n",
            "Iteration 231, loss = 1524657264.38351870\n",
            "Iteration 232, loss = 1524596955.17622232\n",
            "Iteration 233, loss = 1524536588.96248984\n",
            "Iteration 234, loss = 1524475995.93538308\n",
            "Iteration 235, loss = 1524415405.86397386\n",
            "Iteration 236, loss = 1524355472.59117365\n",
            "Iteration 237, loss = 1524294798.15182352\n",
            "Iteration 238, loss = 1524234474.44219017\n",
            "Iteration 239, loss = 1524174105.67075539\n",
            "Iteration 240, loss = 1524113973.37737727\n",
            "Iteration 241, loss = 1524053379.28540397\n",
            "Iteration 242, loss = 1523993335.64125252\n",
            "Iteration 243, loss = 1523933220.23795104\n",
            "Iteration 244, loss = 1523872713.29623437\n",
            "Iteration 245, loss = 1523812725.61775136\n",
            "Iteration 246, loss = 1523752322.22619915\n",
            "Iteration 247, loss = 1523692041.37494111\n",
            "Iteration 248, loss = 1523632211.79479885\n",
            "Iteration 249, loss = 1523571785.38612175\n",
            "Iteration 250, loss = 1523511690.66354537\n",
            "Iteration 251, loss = 1523451772.01647210\n",
            "Iteration 252, loss = 1523391570.66401672\n",
            "Iteration 253, loss = 1523331642.67866898\n",
            "Iteration 254, loss = 1523271694.31988120\n",
            "Iteration 255, loss = 1523211839.02130532\n",
            "Iteration 256, loss = 1523151995.07542038\n",
            "Iteration 257, loss = 1523092239.32701850\n",
            "Iteration 258, loss = 1523032584.76862907\n",
            "Iteration 259, loss = 1522973193.34708977\n",
            "Iteration 260, loss = 1522913427.74643040\n",
            "Iteration 261, loss = 1522854046.40683174\n",
            "Iteration 262, loss = 1522794602.14010000\n",
            "Iteration 263, loss = 1522735244.60666227\n",
            "Iteration 264, loss = 1522675863.03333926\n",
            "Iteration 265, loss = 1522616302.21716070\n",
            "Iteration 266, loss = 1522556991.82177806\n",
            "Iteration 267, loss = 1522497792.12306452\n",
            "Iteration 268, loss = 1522438075.35965633\n",
            "Iteration 269, loss = 1522378554.82402086\n",
            "Iteration 270, loss = 1522319628.91385818\n",
            "Iteration 271, loss = 1522259761.56145883\n",
            "Iteration 272, loss = 1522200432.75490427\n",
            "Iteration 273, loss = 1522140654.24760962\n",
            "Iteration 274, loss = 1522081388.99835634\n",
            "Iteration 275, loss = 1522021695.52422714\n",
            "Iteration 276, loss = 1521962415.68171501\n",
            "Iteration 277, loss = 1521902908.39681721\n",
            "Iteration 278, loss = 1521843457.11812019\n",
            "Iteration 279, loss = 1521784048.95460558\n",
            "Iteration 280, loss = 1521724996.81902170\n",
            "Iteration 281, loss = 1521665496.62053585\n",
            "Iteration 282, loss = 1521606444.17012858\n",
            "Iteration 283, loss = 1521546920.79567432\n",
            "Iteration 284, loss = 1521488034.37674475\n",
            "Iteration 285, loss = 1521428983.98872805\n",
            "Iteration 286, loss = 1521369687.59904623\n",
            "Iteration 287, loss = 1521310581.96551394\n",
            "Iteration 288, loss = 1521251866.28775239\n",
            "Iteration 289, loss = 1521192849.99093556\n",
            "Iteration 290, loss = 1521133540.52959847\n",
            "Iteration 291, loss = 1521074681.07928395\n",
            "Iteration 292, loss = 1521015677.73298311\n",
            "Iteration 293, loss = 1520956574.58664370\n",
            "Iteration 294, loss = 1520897621.01793718\n",
            "Iteration 295, loss = 1520838636.00943375\n",
            "Iteration 296, loss = 1520779468.95561075\n",
            "Iteration 297, loss = 1520720422.78702736\n",
            "Iteration 298, loss = 1520661305.56909943\n",
            "Iteration 299, loss = 1520602563.72921228\n",
            "Iteration 300, loss = 1520543247.46393323\n",
            "Iteration 301, loss = 1520484211.22673106\n",
            "Iteration 302, loss = 1520425077.43316317\n",
            "Iteration 303, loss = 1520365827.22363973\n",
            "Iteration 304, loss = 1520306869.87660694\n",
            "Iteration 305, loss = 1520248133.40384078\n",
            "Iteration 306, loss = 1520188863.77029467\n",
            "Iteration 307, loss = 1520130085.22834158\n",
            "Iteration 308, loss = 1520071307.47330022\n",
            "Iteration 309, loss = 1520012587.44215751\n",
            "Iteration 310, loss = 1519953808.15811062\n",
            "Iteration 311, loss = 1519895230.67790318\n",
            "Iteration 312, loss = 1519836995.11418390\n",
            "Iteration 313, loss = 1519778521.65563774\n",
            "Iteration 314, loss = 1519720167.09269357\n",
            "Iteration 315, loss = 1519661746.87799883\n",
            "Iteration 316, loss = 1519603710.18670201\n",
            "Iteration 317, loss = 1519545516.00670743\n",
            "Iteration 318, loss = 1519487197.88789988\n",
            "Iteration 319, loss = 1519429152.21063542\n",
            "Iteration 320, loss = 1519370497.09622264\n",
            "Iteration 321, loss = 1519312486.39589882\n",
            "Iteration 322, loss = 1519254414.95032024\n",
            "Iteration 323, loss = 1519196021.26897812\n",
            "Iteration 324, loss = 1519138169.21379209\n",
            "Iteration 325, loss = 1519079608.61936593\n",
            "Iteration 326, loss = 1519021943.96135378\n",
            "Iteration 327, loss = 1518963931.74752259\n",
            "Iteration 328, loss = 1518905784.06699109\n",
            "Iteration 329, loss = 1518847840.48306584\n",
            "Iteration 330, loss = 1518789740.37488055\n",
            "Iteration 331, loss = 1518732184.28956819\n",
            "Iteration 332, loss = 1518674215.46812224\n",
            "Iteration 333, loss = 1518616484.93245578\n",
            "Iteration 334, loss = 1518559086.09550643\n",
            "Iteration 335, loss = 1518501025.57399678\n",
            "Iteration 336, loss = 1518443124.58692932\n",
            "Iteration 337, loss = 1518385651.68942547\n",
            "Iteration 338, loss = 1518327774.10190940\n",
            "Iteration 339, loss = 1518269405.88988876\n",
            "Iteration 340, loss = 1518211679.91590762\n",
            "Iteration 341, loss = 1518153623.13880181\n",
            "Iteration 342, loss = 1518095585.10708642\n",
            "Iteration 343, loss = 1518037740.61265230\n",
            "Iteration 344, loss = 1517979722.08927035\n",
            "Iteration 345, loss = 1517921653.29355550\n",
            "Iteration 346, loss = 1517863950.29165030\n",
            "Iteration 347, loss = 1517806103.27830672\n",
            "Iteration 348, loss = 1517748233.61010385\n",
            "Iteration 349, loss = 1517691015.34327722\n",
            "Iteration 350, loss = 1517632782.22851038\n",
            "Iteration 351, loss = 1517575416.16268182\n",
            "Iteration 352, loss = 1517517654.63163733\n",
            "Iteration 353, loss = 1517460269.72970796\n",
            "Iteration 354, loss = 1517402297.07098770\n",
            "Iteration 355, loss = 1517344550.68583679\n",
            "Iteration 356, loss = 1517286866.21356034\n",
            "Iteration 357, loss = 1517229194.78772068\n",
            "Iteration 358, loss = 1517171794.26542258\n",
            "Iteration 359, loss = 1517113921.68362403\n",
            "Iteration 360, loss = 1517056913.37609148\n",
            "Iteration 361, loss = 1516998989.22094393\n",
            "Iteration 362, loss = 1516941521.73590875\n",
            "Iteration 363, loss = 1516884470.12546349\n",
            "Iteration 364, loss = 1516826667.16216087\n",
            "Iteration 365, loss = 1516769788.87112594\n",
            "Iteration 366, loss = 1516712130.28188062\n",
            "Iteration 367, loss = 1516655231.27132607\n",
            "Iteration 368, loss = 1516597783.45068693\n",
            "Iteration 369, loss = 1516540802.35710001\n",
            "Iteration 370, loss = 1516483502.74455118\n",
            "Iteration 371, loss = 1516426318.09285092\n",
            "Iteration 372, loss = 1516369533.81761432\n",
            "Iteration 373, loss = 1516312037.52495027\n",
            "Iteration 374, loss = 1516254824.15248227\n",
            "Iteration 375, loss = 1516197639.25466943\n",
            "Iteration 376, loss = 1516140276.65160441\n",
            "Iteration 377, loss = 1516083274.89460206\n",
            "Iteration 378, loss = 1516025846.22800565\n",
            "Iteration 379, loss = 1515968748.74343491\n",
            "Iteration 380, loss = 1515911146.76546001\n",
            "Iteration 381, loss = 1515853972.53989530\n",
            "Iteration 382, loss = 1515796562.77345419\n",
            "Iteration 383, loss = 1515739446.91850853\n",
            "Iteration 384, loss = 1515681982.35597563\n",
            "Iteration 385, loss = 1515624522.92860579\n",
            "Iteration 386, loss = 1515567226.85428691\n",
            "Iteration 387, loss = 1515509947.08828497\n",
            "Iteration 388, loss = 1515452408.48620296\n",
            "Iteration 389, loss = 1515395163.70911145\n",
            "Iteration 390, loss = 1515338097.42327356\n",
            "Iteration 391, loss = 1515280171.93329263\n",
            "Iteration 392, loss = 1515223441.84717989\n",
            "Iteration 393, loss = 1515165727.58976746\n",
            "Iteration 394, loss = 1515108865.92524266\n",
            "Iteration 395, loss = 1515051620.32420516\n",
            "Iteration 396, loss = 1514994727.17918587\n",
            "Iteration 397, loss = 1514937140.11310887\n",
            "Iteration 398, loss = 1514880308.91641879\n",
            "Iteration 399, loss = 1514823105.09195876\n",
            "Iteration 400, loss = 1514766354.10174203\n",
            "Iteration 401, loss = 1514708962.03073335\n",
            "Iteration 402, loss = 1514652329.49360585\n",
            "Iteration 403, loss = 1514595481.30759954\n",
            "Iteration 404, loss = 1514538622.90942097\n",
            "Iteration 405, loss = 1514481821.56149650\n",
            "Iteration 406, loss = 1514425610.15713930\n",
            "Iteration 407, loss = 1514368504.14960122\n",
            "Iteration 408, loss = 1514312050.07377362\n",
            "Iteration 409, loss = 1514254889.41596389\n",
            "Iteration 410, loss = 1514198220.76996279\n",
            "Iteration 411, loss = 1514141177.06736588\n",
            "Iteration 412, loss = 1514084214.82140517\n",
            "Iteration 413, loss = 1514027174.88329959\n",
            "Iteration 414, loss = 1513969962.47196865\n",
            "Iteration 415, loss = 1513913078.90761638\n",
            "Iteration 416, loss = 1513856132.16815329\n",
            "Iteration 417, loss = 1513799020.13965154\n",
            "Iteration 418, loss = 1513741666.95140004\n",
            "Iteration 419, loss = 1513685155.07157922\n",
            "Iteration 420, loss = 1513628621.23142624\n",
            "Iteration 421, loss = 1513571475.59886026\n",
            "Iteration 422, loss = 1513515026.82345128\n",
            "Iteration 423, loss = 1513458086.22905993\n",
            "Iteration 424, loss = 1513401608.28219557\n",
            "Iteration 425, loss = 1513344741.01335621\n",
            "Iteration 426, loss = 1513287869.46341205\n",
            "Iteration 427, loss = 1513231012.47007871\n",
            "Iteration 428, loss = 1513174264.93731427\n",
            "Iteration 429, loss = 1513117478.26577544\n",
            "Iteration 430, loss = 1513060370.06367040\n",
            "Iteration 431, loss = 1513003633.10670376\n",
            "Iteration 432, loss = 1512946737.13694596\n",
            "Iteration 433, loss = 1512889793.14626503\n",
            "Iteration 434, loss = 1512832859.01340556\n",
            "Iteration 435, loss = 1512775723.33824730\n",
            "Iteration 436, loss = 1512719036.79097033\n",
            "Iteration 437, loss = 1512661929.69100547\n",
            "Iteration 438, loss = 1512605177.83348346\n",
            "Iteration 439, loss = 1512548275.73789430\n",
            "Iteration 440, loss = 1512491693.58071589\n",
            "Iteration 441, loss = 1512435047.90371394\n",
            "Iteration 442, loss = 1512378240.04319143\n",
            "Iteration 443, loss = 1512321547.05059361\n",
            "Iteration 444, loss = 1512265056.99961472\n",
            "Iteration 445, loss = 1512208156.88455415\n",
            "Iteration 446, loss = 1512151499.30879998\n",
            "Iteration 447, loss = 1512094420.32731724\n",
            "Iteration 448, loss = 1512038137.31867766\n",
            "Iteration 449, loss = 1511981092.05922818\n",
            "Iteration 450, loss = 1511924263.57199788\n",
            "Iteration 451, loss = 1511867465.19931793\n",
            "Iteration 452, loss = 1511810649.65009212\n",
            "Iteration 453, loss = 1511753614.53602123\n",
            "Iteration 454, loss = 1511697150.61091185\n",
            "Iteration 455, loss = 1511640646.68546033\n",
            "Iteration 456, loss = 1511583431.72431588\n",
            "Iteration 457, loss = 1511527123.72607660\n",
            "Iteration 458, loss = 1511470272.74217105\n",
            "Iteration 459, loss = 1511413810.36883950\n",
            "Iteration 460, loss = 1511357433.59942818\n",
            "Iteration 461, loss = 1511300823.57505035\n",
            "Iteration 462, loss = 1511244474.80409813\n",
            "Iteration 463, loss = 1511187654.97954774\n",
            "Iteration 464, loss = 1511131459.20390153\n",
            "Iteration 465, loss = 1511075051.48931289\n",
            "Iteration 466, loss = 1511018620.80593228\n",
            "Iteration 467, loss = 1510961790.19242573\n",
            "Iteration 468, loss = 1510905388.36187768\n",
            "Iteration 469, loss = 1510848879.09465551\n",
            "Iteration 470, loss = 1510792574.02288556\n",
            "Iteration 471, loss = 1510736188.32589388\n",
            "Iteration 472, loss = 1510679758.41042376\n",
            "Iteration 473, loss = 1510623314.11887598\n",
            "Iteration 474, loss = 1510567409.29409313\n",
            "Iteration 475, loss = 1510510922.58112597\n",
            "Iteration 476, loss = 1510454802.34851384\n",
            "Iteration 477, loss = 1510398674.05323648\n",
            "Iteration 478, loss = 1510342257.87793946\n",
            "Iteration 479, loss = 1510286018.33236575\n",
            "Iteration 480, loss = 1510229532.32976937\n",
            "Iteration 481, loss = 1510173190.17671275\n",
            "Iteration 482, loss = 1510117120.13128233\n",
            "Iteration 483, loss = 1510060679.97714472\n",
            "Iteration 484, loss = 1510004505.32990837\n",
            "Iteration 485, loss = 1509948627.51363015\n",
            "Iteration 486, loss = 1509892471.62037230\n",
            "Iteration 487, loss = 1509836574.01266956\n",
            "Iteration 488, loss = 1509780650.44620728\n",
            "Iteration 489, loss = 1509725426.99040318\n",
            "Iteration 490, loss = 1509669216.74684310\n",
            "Iteration 491, loss = 1509613856.32063365\n",
            "Iteration 492, loss = 1509558086.13185048\n",
            "Iteration 493, loss = 1509502394.62056041\n",
            "Iteration 494, loss = 1509446971.02303100\n",
            "Iteration 495, loss = 1509391340.53208494\n",
            "Iteration 496, loss = 1509335681.40528202\n",
            "Iteration 497, loss = 1509280152.23132658\n",
            "Iteration 498, loss = 1509224642.39334393\n",
            "Iteration 499, loss = 1509168962.77891946\n",
            "Iteration 500, loss = 1509113465.40101099\n",
            "Iteration 501, loss = 1509057847.32240343\n",
            "Iteration 502, loss = 1509002336.04367352\n",
            "Iteration 503, loss = 1508946509.54755688\n",
            "Iteration 504, loss = 1508890928.14349747\n",
            "Iteration 505, loss = 1508834807.02131748\n",
            "Iteration 506, loss = 1508779114.14998865\n",
            "Iteration 507, loss = 1508723188.55909491\n",
            "Iteration 508, loss = 1508666909.17928338\n",
            "Iteration 509, loss = 1508610925.59866762\n",
            "Iteration 510, loss = 1508554910.24659061\n",
            "Iteration 511, loss = 1508498870.51286554\n",
            "Iteration 512, loss = 1508442716.01179433\n",
            "Iteration 513, loss = 1508386667.12803173\n",
            "Iteration 514, loss = 1508330582.23921013\n",
            "Iteration 515, loss = 1508274590.34399962\n",
            "Iteration 516, loss = 1508218427.88183355\n",
            "Iteration 517, loss = 1508162719.94417906\n",
            "Iteration 518, loss = 1508106503.41960096\n",
            "Iteration 519, loss = 1508050909.21800160\n",
            "Iteration 520, loss = 1507994804.81192994\n",
            "Iteration 521, loss = 1507938935.56605077\n",
            "Iteration 522, loss = 1507883522.28313947\n",
            "Iteration 523, loss = 1507827461.58131671\n",
            "Iteration 524, loss = 1507771410.06516433\n",
            "Iteration 525, loss = 1507715869.06715512\n",
            "Iteration 526, loss = 1507660176.26131725\n",
            "Iteration 527, loss = 1507604268.94640326\n",
            "Iteration 528, loss = 1507548973.12156558\n",
            "Iteration 529, loss = 1507492905.76100564\n",
            "Iteration 530, loss = 1507437731.81795335\n",
            "Iteration 531, loss = 1507382244.93570971\n",
            "Iteration 532, loss = 1507326626.27964997\n",
            "Iteration 533, loss = 1507271069.56326270\n",
            "Iteration 534, loss = 1507215331.27258039\n",
            "Iteration 535, loss = 1507159406.43535089\n",
            "Iteration 536, loss = 1507103882.44576693\n",
            "Iteration 537, loss = 1507047752.30083466\n",
            "Iteration 538, loss = 1506991978.37933874\n",
            "Iteration 539, loss = 1506936205.21015716\n",
            "Iteration 540, loss = 1506879847.65363574\n",
            "Iteration 541, loss = 1506824225.40359354\n",
            "Iteration 542, loss = 1506768553.11416197\n",
            "Iteration 543, loss = 1506712313.98397732\n",
            "Iteration 544, loss = 1506656692.53488421\n",
            "Iteration 545, loss = 1506600725.03589058\n",
            "Iteration 546, loss = 1506544813.55868793\n",
            "Iteration 547, loss = 1506488857.57090759\n",
            "Iteration 548, loss = 1506433085.79833961\n",
            "Iteration 549, loss = 1506377054.29751444\n",
            "Iteration 550, loss = 1506321316.73726869\n",
            "Iteration 551, loss = 1506265188.45495033\n",
            "Iteration 552, loss = 1506209382.57753587\n",
            "Iteration 553, loss = 1506154014.19509387\n",
            "Iteration 554, loss = 1506097814.24942279\n",
            "Iteration 555, loss = 1506042305.87363529\n",
            "Iteration 556, loss = 1505986937.25340366\n",
            "Iteration 557, loss = 1505931314.64351368\n",
            "Iteration 558, loss = 1505875504.73448777\n",
            "Iteration 559, loss = 1505820395.23472166\n",
            "Iteration 560, loss = 1505764757.38774395\n",
            "Iteration 561, loss = 1505709571.35455489\n",
            "Iteration 562, loss = 1505653895.45629978\n",
            "Iteration 563, loss = 1505598300.70324278\n",
            "Iteration 564, loss = 1505542850.13465858\n",
            "Iteration 565, loss = 1505487344.84741759\n",
            "Iteration 566, loss = 1505431398.44575024\n",
            "Iteration 567, loss = 1505376141.44216967\n",
            "Iteration 568, loss = 1505319780.87514138\n",
            "Iteration 569, loss = 1505264544.88169122\n",
            "Iteration 570, loss = 1505208687.99591923\n",
            "Iteration 571, loss = 1505152837.17266798\n",
            "Iteration 572, loss = 1505097078.62854838\n",
            "Iteration 573, loss = 1505041537.66599584\n",
            "Iteration 574, loss = 1504985992.59848189\n",
            "Iteration 575, loss = 1504930540.42092514\n",
            "Iteration 576, loss = 1504874590.98301125\n",
            "Iteration 577, loss = 1504819796.59782171\n",
            "Iteration 578, loss = 1504764087.41075253\n",
            "Iteration 579, loss = 1504708420.16384721\n",
            "Iteration 580, loss = 1504652740.83161259\n",
            "Iteration 581, loss = 1504597448.17723584\n",
            "Iteration 582, loss = 1504541355.18443847\n",
            "Iteration 583, loss = 1504485494.59499836\n",
            "Iteration 584, loss = 1504429900.93868160\n",
            "Iteration 585, loss = 1504373536.64305234\n",
            "Iteration 586, loss = 1504318224.42884970\n",
            "Iteration 587, loss = 1504262118.06941962\n",
            "Iteration 588, loss = 1504206480.71149397\n",
            "Iteration 589, loss = 1504150772.79021120\n",
            "Iteration 590, loss = 1504095509.36029720\n",
            "Iteration 591, loss = 1504039847.41550636\n",
            "Iteration 592, loss = 1503984365.64012957\n",
            "Iteration 593, loss = 1503928915.38514161\n",
            "Iteration 594, loss = 1503873708.74579167\n",
            "Iteration 595, loss = 1503818141.45886135\n",
            "Iteration 596, loss = 1503762716.53616714\n",
            "Iteration 597, loss = 1503707695.17188764\n",
            "Iteration 598, loss = 1503651775.25669432\n",
            "Iteration 599, loss = 1503596928.86924863\n",
            "Iteration 600, loss = 1503541226.88019681\n",
            "Iteration 601, loss = 1503486051.35525370\n",
            "Iteration 602, loss = 1503430740.59750175\n",
            "Iteration 603, loss = 1503375416.16499043\n",
            "Iteration 604, loss = 1503320088.85538697\n",
            "Iteration 605, loss = 1503264692.01776624\n",
            "Iteration 606, loss = 1503209243.90124607\n",
            "Iteration 607, loss = 1503153766.31346774\n",
            "Iteration 608, loss = 1503098505.15385914\n",
            "Iteration 609, loss = 1503042827.49557328\n",
            "Iteration 610, loss = 1502987308.31357479\n",
            "Iteration 611, loss = 1502931925.72198415\n",
            "Iteration 612, loss = 1502876387.10129285\n",
            "Iteration 613, loss = 1502820825.29014516\n",
            "Iteration 614, loss = 1502765642.32033777\n",
            "Iteration 615, loss = 1502710432.79975605\n",
            "Iteration 616, loss = 1502655219.99176526\n",
            "Iteration 617, loss = 1502600070.37726378\n",
            "Iteration 618, loss = 1502545251.23757172\n",
            "Iteration 619, loss = 1502490161.72281575\n",
            "Iteration 620, loss = 1502435294.08605361\n",
            "Iteration 621, loss = 1502380524.05247378\n",
            "Iteration 622, loss = 1502325534.42847395\n",
            "Iteration 623, loss = 1502270459.27328920\n",
            "Iteration 624, loss = 1502215216.06884241\n",
            "Iteration 625, loss = 1502160494.93242931\n",
            "Iteration 626, loss = 1502105194.04886079\n",
            "Iteration 627, loss = 1502049652.14848375\n",
            "Iteration 628, loss = 1501994365.88448858\n",
            "Iteration 629, loss = 1501938951.36100411\n",
            "Iteration 630, loss = 1501883369.38368678\n",
            "Iteration 631, loss = 1501827799.80974150\n",
            "Iteration 632, loss = 1501772169.94968748\n",
            "Iteration 633, loss = 1501716534.55494905\n",
            "Iteration 634, loss = 1501661091.52695966\n",
            "Iteration 635, loss = 1501605392.68133354\n",
            "Iteration 636, loss = 1501549905.09017825\n",
            "Iteration 637, loss = 1501494167.10200071\n",
            "Iteration 638, loss = 1501438787.24254942\n",
            "Iteration 639, loss = 1501383696.94129944\n",
            "Iteration 640, loss = 1501328128.20040441\n",
            "Iteration 641, loss = 1501272675.19804692\n",
            "Iteration 642, loss = 1501217442.56863165\n",
            "Iteration 643, loss = 1501162637.48829770\n",
            "Iteration 644, loss = 1501107260.88439202\n",
            "Iteration 645, loss = 1501052206.84472966\n",
            "Iteration 646, loss = 1500997296.06530690\n",
            "Iteration 647, loss = 1500942084.69355392\n",
            "Iteration 648, loss = 1500887209.89332795\n",
            "Iteration 649, loss = 1500831887.58975983\n",
            "Iteration 650, loss = 1500776904.80475330\n",
            "Iteration 651, loss = 1500721524.45437288\n",
            "Iteration 652, loss = 1500666495.35875988\n",
            "Iteration 653, loss = 1500610846.22320580\n",
            "Iteration 654, loss = 1500556040.31106758\n",
            "Iteration 655, loss = 1500500503.63643956\n",
            "Iteration 656, loss = 1500445155.84631610\n",
            "Iteration 657, loss = 1500390410.49263287\n",
            "Iteration 658, loss = 1500335343.30985904\n",
            "Iteration 659, loss = 1500280387.41745758\n",
            "Iteration 660, loss = 1500225265.46061373\n",
            "Iteration 661, loss = 1500170443.86363435\n",
            "Iteration 662, loss = 1500115737.64153671\n",
            "Iteration 663, loss = 1500060625.36957431\n",
            "Iteration 664, loss = 1500006138.85119724\n",
            "Iteration 665, loss = 1499950894.43307686\n",
            "Iteration 666, loss = 1499896049.76055765\n",
            "Iteration 667, loss = 1499841148.67637539\n",
            "Iteration 668, loss = 1499786171.69054365\n",
            "Iteration 669, loss = 1499731604.90547013\n",
            "Iteration 670, loss = 1499676290.96337414\n",
            "Iteration 671, loss = 1499621625.98998928\n",
            "Iteration 672, loss = 1499567031.15221810\n",
            "Iteration 673, loss = 1499512029.28528309\n",
            "Iteration 674, loss = 1499457273.74303484\n",
            "Iteration 675, loss = 1499402309.19923997\n",
            "Iteration 676, loss = 1499347852.48028469\n",
            "Iteration 677, loss = 1499292788.23261833\n",
            "Iteration 678, loss = 1499237976.30277872\n",
            "Iteration 679, loss = 1499183078.51880312\n",
            "Iteration 680, loss = 1499128669.47889352\n",
            "Iteration 681, loss = 1499073441.71375060\n",
            "Iteration 682, loss = 1499018818.12719679\n",
            "Iteration 683, loss = 1498964017.66026688\n",
            "Iteration 684, loss = 1498909545.90068817\n",
            "Iteration 685, loss = 1498854612.41527653\n",
            "Iteration 686, loss = 1498799840.18201256\n",
            "Iteration 687, loss = 1498745219.64628816\n",
            "Iteration 688, loss = 1498690455.41117477\n",
            "Iteration 689, loss = 1498635535.86447716\n",
            "Iteration 690, loss = 1498580551.52882195\n",
            "Iteration 691, loss = 1498526097.10301805\n",
            "Iteration 692, loss = 1498470987.02132463\n",
            "Iteration 693, loss = 1498416179.77542019\n",
            "Iteration 694, loss = 1498361214.79882836\n",
            "Iteration 695, loss = 1498305889.22036171\n",
            "Iteration 696, loss = 1498251288.12658024\n",
            "Iteration 697, loss = 1498195962.98583102\n",
            "Iteration 698, loss = 1498140909.64951658\n",
            "Iteration 699, loss = 1498086069.45723057\n",
            "Iteration 700, loss = 1498030815.94342136\n",
            "Iteration 701, loss = 1497975926.39183354\n",
            "Iteration 702, loss = 1497920844.16490197\n",
            "Iteration 703, loss = 1497866060.10971451\n",
            "Iteration 704, loss = 1497811321.90523505\n",
            "Iteration 705, loss = 1497756289.58373332\n",
            "Iteration 706, loss = 1497700988.93612409\n",
            "Iteration 707, loss = 1497646395.32313871\n",
            "Iteration 708, loss = 1497591341.91446161\n",
            "Iteration 709, loss = 1497535951.73865724\n",
            "Iteration 710, loss = 1497481555.05385494\n",
            "Iteration 711, loss = 1497426585.09300637\n",
            "Iteration 712, loss = 1497371374.36503506\n",
            "Iteration 713, loss = 1497316608.62898421\n",
            "Iteration 714, loss = 1497261975.94808459\n",
            "Iteration 715, loss = 1497206821.39872885\n",
            "Iteration 716, loss = 1497152080.45520329\n",
            "Iteration 717, loss = 1497097213.62945008\n",
            "Iteration 718, loss = 1497042513.95744205\n",
            "Iteration 719, loss = 1496987264.79880738\n",
            "Iteration 720, loss = 1496932450.04241180\n",
            "Iteration 721, loss = 1496877871.22476411\n",
            "Iteration 722, loss = 1496823066.95740843\n",
            "Iteration 723, loss = 1496768261.69063544\n",
            "Iteration 724, loss = 1496713420.49517226\n",
            "Iteration 725, loss = 1496658664.96163058\n",
            "Iteration 726, loss = 1496604352.15315413\n",
            "Iteration 727, loss = 1496549653.44749665\n",
            "Iteration 728, loss = 1496494813.27339625\n",
            "Iteration 729, loss = 1496440570.06159592\n",
            "Iteration 730, loss = 1496385796.89004230\n",
            "Iteration 731, loss = 1496331184.30200338\n",
            "Iteration 732, loss = 1496276772.02478480\n",
            "Iteration 733, loss = 1496221983.40839529\n",
            "Iteration 734, loss = 1496167556.43572617\n",
            "Iteration 735, loss = 1496112827.70852232\n",
            "Iteration 736, loss = 1496058713.81026793\n",
            "Iteration 737, loss = 1496003742.28177476\n",
            "Iteration 738, loss = 1495949680.99601388\n",
            "Iteration 739, loss = 1495895257.56941867\n",
            "Iteration 740, loss = 1495840610.03588128\n",
            "Iteration 741, loss = 1495785729.91115379\n",
            "Iteration 742, loss = 1495731969.92021537\n",
            "Iteration 743, loss = 1495677047.19362926\n",
            "Iteration 744, loss = 1495622320.08805490\n",
            "Iteration 745, loss = 1495568158.10317254\n",
            "Iteration 746, loss = 1495513199.36928272\n",
            "Iteration 747, loss = 1495459076.12869358\n",
            "Iteration 748, loss = 1495404381.58879948\n",
            "Iteration 749, loss = 1495349960.26967573\n",
            "Iteration 750, loss = 1495295200.30496931\n",
            "Iteration 751, loss = 1495240318.90517497\n",
            "Iteration 752, loss = 1495185878.48934054\n",
            "Iteration 753, loss = 1495131136.56589818\n",
            "Iteration 754, loss = 1495076462.74743152\n",
            "Iteration 755, loss = 1495021571.27508283\n",
            "Iteration 756, loss = 1494966989.22083473\n",
            "Iteration 757, loss = 1494912544.72636056\n",
            "Iteration 758, loss = 1494857649.01166868\n",
            "Iteration 759, loss = 1494802989.37008643\n",
            "Iteration 760, loss = 1494748483.95622683\n",
            "Iteration 761, loss = 1494693961.87599325\n",
            "Iteration 762, loss = 1494639432.19864845\n",
            "Iteration 763, loss = 1494584818.51725316\n",
            "Iteration 764, loss = 1494530053.61048388\n",
            "Iteration 765, loss = 1494475838.13316298\n",
            "Iteration 766, loss = 1494421112.54362321\n",
            "Iteration 767, loss = 1494366610.44906759\n",
            "Iteration 768, loss = 1494311525.09567285\n",
            "Iteration 769, loss = 1494257261.03916883\n",
            "Iteration 770, loss = 1494202621.25357008\n",
            "Iteration 771, loss = 1494147794.20601439\n",
            "Iteration 772, loss = 1494093573.52754760\n",
            "Iteration 773, loss = 1494039047.74624515\n",
            "Iteration 774, loss = 1493984598.64190078\n",
            "Iteration 775, loss = 1493930729.65972161\n",
            "Iteration 776, loss = 1493875889.05173469\n",
            "Iteration 777, loss = 1493821850.79990864\n",
            "Iteration 778, loss = 1493767593.58689785\n",
            "Iteration 779, loss = 1493713281.06784391\n",
            "Iteration 780, loss = 1493659199.09619570\n",
            "Iteration 781, loss = 1493604640.88233662\n",
            "Iteration 782, loss = 1493550526.72228408\n",
            "Iteration 783, loss = 1493495997.00192666\n",
            "Iteration 784, loss = 1493442008.46422768\n",
            "Iteration 785, loss = 1493387681.34554958\n",
            "Iteration 786, loss = 1493333166.30035734\n",
            "Iteration 787, loss = 1493278997.57121420\n",
            "Iteration 788, loss = 1493224408.09923577\n",
            "Iteration 789, loss = 1493169887.25944233\n",
            "Iteration 790, loss = 1493115360.97324872\n",
            "Iteration 791, loss = 1493061210.28416896\n",
            "Iteration 792, loss = 1493006352.71466732\n",
            "Iteration 793, loss = 1492951882.07699847\n",
            "Iteration 794, loss = 1492897420.58828211\n",
            "Iteration 795, loss = 1492842529.84369278\n",
            "Iteration 796, loss = 1492788268.21820569\n",
            "Iteration 797, loss = 1492733421.70250058\n",
            "Iteration 798, loss = 1492678813.08088017\n",
            "Iteration 799, loss = 1492624207.98864603\n",
            "Iteration 800, loss = 1492569618.98238301\n",
            "Iteration 801, loss = 1492515290.19408417\n",
            "Iteration 802, loss = 1492460546.91179132\n",
            "Iteration 803, loss = 1492405800.11492968\n",
            "Iteration 804, loss = 1492351545.27550149\n",
            "Iteration 805, loss = 1492297387.66323185\n",
            "Iteration 806, loss = 1492242231.13251877\n",
            "Iteration 807, loss = 1492188043.97394490\n",
            "Iteration 808, loss = 1492133754.58641553\n",
            "Iteration 809, loss = 1492078925.67755222\n",
            "Iteration 810, loss = 1492024195.55980802\n",
            "Iteration 811, loss = 1491970373.51727891\n",
            "Iteration 812, loss = 1491915300.38563538\n",
            "Iteration 813, loss = 1491861150.87835169\n",
            "Iteration 814, loss = 1491806576.89941740\n",
            "Iteration 815, loss = 1491752128.29962158\n",
            "Iteration 816, loss = 1491697574.18913484\n",
            "Iteration 817, loss = 1491642943.88212657\n",
            "Iteration 818, loss = 1491588628.36784363\n",
            "Iteration 819, loss = 1491534383.54778719\n",
            "Iteration 820, loss = 1491479793.67435169\n",
            "Iteration 821, loss = 1491425370.31842589\n",
            "Iteration 822, loss = 1491371155.57134414\n",
            "Iteration 823, loss = 1491316753.98990512\n",
            "Iteration 824, loss = 1491262597.49497771\n",
            "Iteration 825, loss = 1491208553.56797886\n",
            "Iteration 826, loss = 1491153700.45600891\n",
            "Iteration 827, loss = 1491099547.92150140\n",
            "Iteration 828, loss = 1491045109.00872207\n",
            "Iteration 829, loss = 1490990666.27329803\n",
            "Iteration 830, loss = 1490936385.34206152\n",
            "Iteration 831, loss = 1490881991.31213379\n",
            "Iteration 832, loss = 1490827683.17277670\n",
            "Iteration 833, loss = 1490773225.86791635\n",
            "Iteration 834, loss = 1490719261.66802073\n",
            "Iteration 835, loss = 1490664845.30385447\n",
            "Iteration 836, loss = 1490610509.88587499\n",
            "Iteration 837, loss = 1490556389.87400222\n",
            "Iteration 838, loss = 1490502230.71842718\n",
            "Iteration 839, loss = 1490448095.86501312\n",
            "Iteration 840, loss = 1490393678.15448451\n",
            "Iteration 841, loss = 1490339408.88025260\n",
            "Iteration 842, loss = 1490285347.48675108\n",
            "Iteration 843, loss = 1490231286.97298241\n",
            "Iteration 844, loss = 1490176956.05556822\n",
            "Iteration 845, loss = 1490123221.27412844\n",
            "Iteration 846, loss = 1490068789.70480537\n",
            "Iteration 847, loss = 1490014803.52663279\n",
            "Iteration 848, loss = 1489960673.99501967\n",
            "Iteration 849, loss = 1489906686.38717937\n",
            "Iteration 850, loss = 1489852508.99967194\n",
            "Iteration 851, loss = 1489798048.88052773\n",
            "Iteration 852, loss = 1489743770.68903065\n",
            "Iteration 853, loss = 1489689185.33405924\n",
            "Iteration 854, loss = 1489634752.77251148\n",
            "Iteration 855, loss = 1489580482.00025463\n",
            "Iteration 856, loss = 1489526056.80629539\n",
            "Iteration 857, loss = 1489471536.14350462\n",
            "Iteration 858, loss = 1489417486.95118690\n",
            "Iteration 859, loss = 1489362914.07522106\n",
            "Iteration 860, loss = 1489308978.84143257\n",
            "Iteration 861, loss = 1489254574.08997989\n",
            "Iteration 862, loss = 1489200175.95796108\n",
            "Iteration 863, loss = 1489146114.51982284\n",
            "Iteration 864, loss = 1489091804.96929741\n",
            "Iteration 865, loss = 1489037864.86240435\n",
            "Iteration 866, loss = 1488983760.29190493\n",
            "Iteration 867, loss = 1488929745.02044749\n",
            "Iteration 868, loss = 1488875628.16328621\n",
            "Iteration 869, loss = 1488821659.95552993\n",
            "Iteration 870, loss = 1488767669.29227424\n",
            "Iteration 871, loss = 1488713515.81721187\n",
            "Iteration 872, loss = 1488659295.85336947\n",
            "Iteration 873, loss = 1488604797.21952963\n",
            "Iteration 874, loss = 1488550778.39407873\n",
            "Iteration 875, loss = 1488496523.42485642\n",
            "Iteration 876, loss = 1488442121.17790318\n",
            "Iteration 877, loss = 1488387861.49728537\n",
            "Iteration 878, loss = 1488333463.13655281\n",
            "Iteration 879, loss = 1488279241.73427463\n",
            "Iteration 880, loss = 1488224754.69598079\n",
            "Iteration 881, loss = 1488170696.08600187\n",
            "Iteration 882, loss = 1488115856.73674822\n",
            "Iteration 883, loss = 1488061999.14577484\n",
            "Iteration 884, loss = 1488007007.93782973\n",
            "Iteration 885, loss = 1487952703.35677934\n",
            "Iteration 886, loss = 1487898442.79720950\n",
            "Iteration 887, loss = 1487844235.09517074\n",
            "Iteration 888, loss = 1487789354.92061687\n",
            "Iteration 889, loss = 1487735688.31973147\n",
            "Iteration 890, loss = 1487681211.82636261\n",
            "Iteration 891, loss = 1487627201.26830673\n",
            "Iteration 892, loss = 1487573063.08840537\n",
            "Iteration 893, loss = 1487518708.02232194\n",
            "Iteration 894, loss = 1487465114.49707031\n",
            "Iteration 895, loss = 1487410553.83085060\n",
            "Iteration 896, loss = 1487356851.18557096\n",
            "Iteration 897, loss = 1487302780.60841346\n",
            "Iteration 898, loss = 1487248582.27930951\n",
            "Iteration 899, loss = 1487194569.01618314\n",
            "Iteration 900, loss = 1487140469.76109481\n",
            "Iteration 901, loss = 1487086782.13287520\n",
            "Iteration 902, loss = 1487032734.64396381\n",
            "Iteration 903, loss = 1486978674.53384042\n",
            "Iteration 904, loss = 1486924933.11912012\n",
            "Iteration 905, loss = 1486870990.63690233\n",
            "Iteration 906, loss = 1486816957.74848199\n",
            "Iteration 907, loss = 1486763262.19190645\n",
            "Iteration 908, loss = 1486709028.74584842\n",
            "Iteration 909, loss = 1486655267.05947113\n",
            "Iteration 910, loss = 1486600970.49335074\n",
            "Iteration 911, loss = 1486547043.26101160\n",
            "Iteration 912, loss = 1486493018.23822618\n",
            "Iteration 913, loss = 1486438694.16010714\n",
            "Iteration 914, loss = 1486384512.14169645\n",
            "Iteration 915, loss = 1486330293.02541924\n",
            "Iteration 916, loss = 1486276125.60028052\n",
            "Iteration 917, loss = 1486222021.26217794\n",
            "Iteration 918, loss = 1486168066.26947236\n",
            "Iteration 919, loss = 1486113610.34879136\n",
            "Iteration 920, loss = 1486059839.89094901\n",
            "Iteration 921, loss = 1486005739.40035582\n",
            "Iteration 922, loss = 1485951467.14728594\n",
            "Iteration 923, loss = 1485897367.30929351\n",
            "Iteration 924, loss = 1485843256.01795006\n",
            "Iteration 925, loss = 1485788904.11108255\n",
            "Iteration 926, loss = 1485734856.98396397\n",
            "Iteration 927, loss = 1485680719.67436218\n",
            "Iteration 928, loss = 1485626572.90939188\n",
            "Iteration 929, loss = 1485572448.88524485\n",
            "Iteration 930, loss = 1485518438.35095191\n",
            "Iteration 931, loss = 1485464393.99764323\n",
            "Iteration 932, loss = 1485410531.35481477\n",
            "Iteration 933, loss = 1485356820.93843484\n",
            "Iteration 934, loss = 1485302689.09435844\n",
            "Iteration 935, loss = 1485248873.82614565\n",
            "Iteration 936, loss = 1485194844.50599313\n",
            "Iteration 937, loss = 1485141010.85545182\n",
            "Iteration 938, loss = 1485087060.90650582\n",
            "Iteration 939, loss = 1485032897.55960488\n",
            "Iteration 940, loss = 1484978758.89574385\n",
            "Iteration 941, loss = 1484924628.23407435\n",
            "Iteration 942, loss = 1484870450.03457594\n",
            "Iteration 943, loss = 1484815860.58536601\n",
            "Iteration 944, loss = 1484762040.89982891\n",
            "Iteration 945, loss = 1484707234.85655332\n",
            "Iteration 946, loss = 1484653103.98748016\n",
            "Iteration 947, loss = 1484599000.01117992\n",
            "Iteration 948, loss = 1484544370.05218625\n",
            "Iteration 949, loss = 1484490418.39466810\n",
            "Iteration 950, loss = 1484436051.07247448\n",
            "Iteration 951, loss = 1484382217.26954699\n",
            "Iteration 952, loss = 1484327919.36825061\n",
            "Iteration 953, loss = 1484273705.06018329\n",
            "Iteration 954, loss = 1484219797.02422929\n",
            "Iteration 955, loss = 1484165540.28788495\n",
            "Iteration 956, loss = 1484111381.24822688\n",
            "Iteration 957, loss = 1484057107.97766972\n",
            "Iteration 958, loss = 1484003080.76371670\n",
            "Iteration 959, loss = 1483949078.22966194\n",
            "Iteration 960, loss = 1483894735.42111588\n",
            "Iteration 961, loss = 1483840900.25159526\n",
            "Iteration 962, loss = 1483787153.59114623\n",
            "Iteration 963, loss = 1483733373.94849396\n",
            "Iteration 964, loss = 1483679270.89987159\n",
            "Iteration 965, loss = 1483625760.88046670\n",
            "Iteration 966, loss = 1483571826.48821807\n",
            "Iteration 967, loss = 1483518295.55248094\n",
            "Iteration 968, loss = 1483464304.41244054\n",
            "Iteration 969, loss = 1483410583.38890433\n",
            "Iteration 970, loss = 1483356728.97458792\n",
            "Iteration 971, loss = 1483303391.30156970\n",
            "Iteration 972, loss = 1483249631.80877137\n",
            "Iteration 973, loss = 1483195529.96110749\n",
            "Iteration 974, loss = 1483142268.89783597\n",
            "Iteration 975, loss = 1483088316.96243930\n",
            "Iteration 976, loss = 1483034472.45010233\n",
            "Iteration 977, loss = 1482980780.47507668\n",
            "Iteration 978, loss = 1482927014.01591372\n",
            "Iteration 979, loss = 1482873079.00386119\n",
            "Iteration 980, loss = 1482819666.79188752\n",
            "Iteration 981, loss = 1482765459.83343172\n",
            "Iteration 982, loss = 1482711934.68853617\n",
            "Iteration 983, loss = 1482658338.68029547\n",
            "Iteration 984, loss = 1482604320.85387397\n",
            "Iteration 985, loss = 1482550287.76473451\n",
            "Iteration 986, loss = 1482496362.21703625\n",
            "Iteration 987, loss = 1482442321.71088696\n",
            "Iteration 988, loss = 1482388092.69870758\n",
            "Iteration 989, loss = 1482334080.17642832\n",
            "Iteration 990, loss = 1482279167.25212574\n",
            "Iteration 991, loss = 1482225544.32611179\n",
            "Iteration 992, loss = 1482170587.43736100\n",
            "Iteration 993, loss = 1482116811.64202714\n",
            "Iteration 994, loss = 1482062116.07843256\n",
            "Iteration 995, loss = 1482008266.41377902\n",
            "Iteration 996, loss = 1481953897.72244430\n",
            "Iteration 997, loss = 1481899326.83758783\n",
            "Iteration 998, loss = 1481845406.17778134\n",
            "Iteration 999, loss = 1481791216.93244457\n",
            "Iteration 1000, loss = 1481736946.18143678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1398000219.68475795\n",
            "Iteration 2, loss = 1092021464.78232741\n",
            "Iteration 3, loss = 1033434415.58116317\n",
            "Iteration 4, loss = 677480069.96418381\n",
            "Iteration 5, loss = 396035749.61779338\n",
            "Iteration 6, loss = 245405663.79452819\n",
            "Iteration 7, loss = 124718216.01992720\n",
            "Iteration 8, loss = 54246197.44480134\n",
            "Iteration 9, loss = 31091415.62054221\n",
            "Iteration 10, loss = 30961277.38689053\n",
            "Iteration 11, loss = 42272814.16386349\n",
            "Iteration 12, loss = 56537313.32721031\n",
            "Iteration 13, loss = 66520458.17575989\n",
            "Iteration 14, loss = 69935265.41607049\n",
            "Iteration 15, loss = 66467275.42512569\n",
            "Iteration 16, loss = 59543240.57253573\n",
            "Iteration 17, loss = 50994556.78417017\n",
            "Iteration 18, loss = 42377835.69245428\n",
            "Iteration 19, loss = 35457870.74642707\n",
            "Iteration 20, loss = 30209799.00266864\n",
            "Iteration 21, loss = 26977908.46180995\n",
            "Iteration 22, loss = 25622143.69056559\n",
            "Iteration 23, loss = 25004543.25728192\n",
            "Iteration 24, loss = 25082262.15714409\n",
            "Iteration 25, loss = 25551564.02852315\n",
            "Iteration 26, loss = 25923612.59513319\n",
            "Iteration 27, loss = 26157916.19299161\n",
            "Iteration 28, loss = 25934587.55027734\n",
            "Iteration 29, loss = 25487507.47003024\n",
            "Iteration 30, loss = 25046620.52897282\n",
            "Iteration 31, loss = 24661107.11659639\n",
            "Iteration 32, loss = 24305840.19528916\n",
            "Iteration 33, loss = 23833561.75780265\n",
            "Iteration 34, loss = 23577241.85018467\n",
            "Iteration 35, loss = 23314192.75933919\n",
            "Iteration 36, loss = 23194316.01049837\n",
            "Iteration 37, loss = 23057024.41433549\n",
            "Iteration 38, loss = 23013533.51531327\n",
            "Iteration 39, loss = 23010657.46465040\n",
            "Iteration 40, loss = 22917714.68527770\n",
            "Iteration 41, loss = 22787309.79154974\n",
            "Iteration 42, loss = 22801897.05344309\n",
            "Iteration 43, loss = 22763090.93870472\n",
            "Iteration 44, loss = 22867876.18305806\n",
            "Iteration 45, loss = 22474450.40127126\n",
            "Iteration 46, loss = 22410996.94226553\n",
            "Iteration 47, loss = 22359038.52443054\n",
            "Iteration 48, loss = 22553254.89076078\n",
            "Iteration 49, loss = 22269305.65861452\n",
            "Iteration 50, loss = 22018976.99508364\n",
            "Iteration 51, loss = 22141938.89426754\n",
            "Iteration 52, loss = 21925710.40840473\n",
            "Iteration 53, loss = 21828544.52178372\n",
            "Iteration 54, loss = 21851157.46042183\n",
            "Iteration 55, loss = 21708749.47118354\n",
            "Iteration 56, loss = 21696722.95941652\n",
            "Iteration 57, loss = 21651672.55156277\n",
            "Iteration 58, loss = 21555874.25217820\n",
            "Iteration 59, loss = 21523142.52019810\n",
            "Iteration 60, loss = 21461617.71603300\n",
            "Iteration 61, loss = 21405495.25219318\n",
            "Iteration 62, loss = 21427928.35284299\n",
            "Iteration 63, loss = 21532986.31414730\n",
            "Iteration 64, loss = 21581302.99379526\n",
            "Iteration 65, loss = 21298307.59340114\n",
            "Iteration 66, loss = 21196739.72870165\n",
            "Iteration 67, loss = 21197476.57975457\n",
            "Iteration 68, loss = 21174229.01009580\n",
            "Iteration 69, loss = 21081028.96263308\n",
            "Iteration 70, loss = 21030972.27584501\n",
            "Iteration 71, loss = 21015502.55472603\n",
            "Iteration 72, loss = 20963239.82395972\n",
            "Iteration 73, loss = 20920685.44609756\n",
            "Iteration 74, loss = 20857799.47730106\n",
            "Iteration 75, loss = 20815104.45372562\n",
            "Iteration 76, loss = 20796876.26079125\n",
            "Iteration 77, loss = 20805757.91793612\n",
            "Iteration 78, loss = 20739605.29982559\n",
            "Iteration 79, loss = 20697246.56400051\n",
            "Iteration 80, loss = 20686570.20789870\n",
            "Iteration 81, loss = 20711182.08374543\n",
            "Iteration 82, loss = 20722812.78664239\n",
            "Iteration 83, loss = 20590041.11175197\n",
            "Iteration 84, loss = 20620189.12611046\n",
            "Iteration 85, loss = 20596526.26666459\n",
            "Iteration 86, loss = 20585132.81989470\n",
            "Iteration 87, loss = 20597026.12991188\n",
            "Iteration 88, loss = 20508412.36404235\n",
            "Iteration 89, loss = 20444791.87509168\n",
            "Iteration 90, loss = 20433780.49842880\n",
            "Iteration 91, loss = 20464132.26987120\n",
            "Iteration 92, loss = 20613522.17242669\n",
            "Iteration 93, loss = 20443763.20119958\n",
            "Iteration 94, loss = 20379727.49294266\n",
            "Iteration 95, loss = 20353673.40484288\n",
            "Iteration 96, loss = 20323215.83663879\n",
            "Iteration 97, loss = 20358117.46976842\n",
            "Iteration 98, loss = 20316550.53485414\n",
            "Iteration 99, loss = 20271681.38005590\n",
            "Iteration 100, loss = 20220061.28754291\n",
            "Iteration 101, loss = 20255474.42941817\n",
            "Iteration 102, loss = 20174191.65125655\n",
            "Iteration 103, loss = 20247082.67025248\n",
            "Iteration 104, loss = 20156132.18528755\n",
            "Iteration 105, loss = 20209741.38655889\n",
            "Iteration 106, loss = 20399872.29205225\n",
            "Iteration 107, loss = 20194424.28157726\n",
            "Iteration 108, loss = 20218645.15453799\n",
            "Iteration 109, loss = 20228034.92189875\n",
            "Iteration 110, loss = 20201239.03255863\n",
            "Iteration 111, loss = 20081542.60327181\n",
            "Iteration 112, loss = 20019033.69883400\n",
            "Iteration 113, loss = 20057446.68879455\n",
            "Iteration 114, loss = 20048286.37964471\n",
            "Iteration 115, loss = 19979351.72693116\n",
            "Iteration 116, loss = 19975638.23268380\n",
            "Iteration 117, loss = 19948037.26560655\n",
            "Iteration 118, loss = 19966365.72071711\n",
            "Iteration 119, loss = 19983856.39710605\n",
            "Iteration 120, loss = 19962288.98483051\n",
            "Iteration 121, loss = 19894003.12278640\n",
            "Iteration 122, loss = 19939863.55280373\n",
            "Iteration 123, loss = 19968086.18583829\n",
            "Iteration 124, loss = 19974122.30014606\n",
            "Iteration 125, loss = 19963553.07114639\n",
            "Iteration 126, loss = 19888666.40126388\n",
            "Iteration 127, loss = 19834745.47235140\n",
            "Iteration 128, loss = 19849421.31380236\n",
            "Iteration 129, loss = 19831294.05962437\n",
            "Iteration 130, loss = 19853510.31085877\n",
            "Iteration 131, loss = 19900253.59237259\n",
            "Iteration 132, loss = 19861026.49960755\n",
            "Iteration 133, loss = 19791724.72764970\n",
            "Iteration 134, loss = 19779893.89893202\n",
            "Iteration 135, loss = 19817098.64007540\n",
            "Iteration 136, loss = 19761123.60063957\n",
            "Iteration 137, loss = 19870828.37688240\n",
            "Iteration 138, loss = 19804112.65771243\n",
            "Iteration 139, loss = 19769320.90114915\n",
            "Iteration 140, loss = 19728552.79078037\n",
            "Iteration 141, loss = 19729438.17530249\n",
            "Iteration 142, loss = 19541655.62644743\n",
            "Iteration 143, loss = 19659980.93744875\n",
            "Iteration 144, loss = 19592424.15740772\n",
            "Iteration 145, loss = 19545078.11536963\n",
            "Iteration 146, loss = 19574333.14812980\n",
            "Iteration 147, loss = 19564123.67730261\n",
            "Iteration 148, loss = 19524652.28833831\n",
            "Iteration 149, loss = 19508417.96841089\n",
            "Iteration 150, loss = 19508214.71804928\n",
            "Iteration 151, loss = 19545821.96663506\n",
            "Iteration 152, loss = 19470629.94925212\n",
            "Iteration 153, loss = 19535265.54237886\n",
            "Iteration 154, loss = 19468552.08780921\n",
            "Iteration 155, loss = 19478865.07668516\n",
            "Iteration 156, loss = 19516295.47151279\n",
            "Iteration 157, loss = 19454421.26445804\n",
            "Iteration 158, loss = 19466685.68466379\n",
            "Iteration 159, loss = 19450420.04871414\n",
            "Iteration 160, loss = 19510390.20578806\n",
            "Iteration 161, loss = 19473740.64832260\n",
            "Iteration 162, loss = 19443349.65303497\n",
            "Iteration 163, loss = 19425963.64536621\n",
            "Iteration 164, loss = 19419697.94337592\n",
            "Iteration 165, loss = 19401126.44573594\n",
            "Iteration 166, loss = 19444122.18637740\n",
            "Iteration 167, loss = 19489039.05199257\n",
            "Iteration 168, loss = 19390320.90411086\n",
            "Iteration 169, loss = 19416116.03795523\n",
            "Iteration 170, loss = 19396829.44712589\n",
            "Iteration 171, loss = 19403720.44837787\n",
            "Iteration 172, loss = 19520627.30757755\n",
            "Iteration 173, loss = 19473156.18242123\n",
            "Iteration 174, loss = 19357497.79156054\n",
            "Iteration 175, loss = 19475416.09201417\n",
            "Iteration 176, loss = 19360912.28417327\n",
            "Iteration 177, loss = 19432726.17778033\n",
            "Iteration 178, loss = 19394758.07048518\n",
            "Iteration 179, loss = 19371493.17199804\n",
            "Iteration 180, loss = 19367062.80858872\n",
            "Iteration 181, loss = 19347029.62240329\n",
            "Iteration 182, loss = 19393594.76972883\n",
            "Iteration 183, loss = 19405826.80015288\n",
            "Iteration 184, loss = 19507149.90798202\n",
            "Iteration 185, loss = 19400760.82950605\n",
            "Iteration 186, loss = 19322314.23509547\n",
            "Iteration 187, loss = 19341913.76170968\n",
            "Iteration 188, loss = 19311062.13866122\n",
            "Iteration 189, loss = 19343361.26689265\n",
            "Iteration 190, loss = 19309962.00200431\n",
            "Iteration 191, loss = 19339495.20166964\n",
            "Iteration 192, loss = 19394096.92337484\n",
            "Iteration 193, loss = 19326847.45951619\n",
            "Iteration 194, loss = 19301915.89160931\n",
            "Iteration 195, loss = 19294697.11170039\n",
            "Iteration 196, loss = 19284913.80325201\n",
            "Iteration 197, loss = 19299763.95557946\n",
            "Iteration 198, loss = 19287842.99607400\n",
            "Iteration 199, loss = 19306912.57935955\n",
            "Iteration 200, loss = 19320297.04542725\n",
            "Iteration 201, loss = 19339898.67022370\n",
            "Iteration 202, loss = 19250922.54704724\n",
            "Iteration 203, loss = 19491590.26452053\n",
            "Iteration 204, loss = 19516775.00515055\n",
            "Iteration 205, loss = 19477139.14979542\n",
            "Iteration 206, loss = 19514400.44281114\n",
            "Iteration 207, loss = 19613402.27536258\n",
            "Iteration 208, loss = 19552308.55790584\n",
            "Iteration 209, loss = 19530428.24216714\n",
            "Iteration 210, loss = 19568583.26906173\n",
            "Iteration 211, loss = 19670372.11422894\n",
            "Iteration 212, loss = 19805498.58728724\n",
            "Iteration 213, loss = 19542832.08214912\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538817418.15169692\n",
            "Iteration 2, loss = 1538787301.10344577\n",
            "Iteration 3, loss = 1538757318.90927529\n",
            "Iteration 4, loss = 1538726871.94067883\n",
            "Iteration 5, loss = 1538696648.49169040\n",
            "Iteration 6, loss = 1538665832.95806885\n",
            "Iteration 7, loss = 1538634973.07503176\n",
            "Iteration 8, loss = 1538603661.13576102\n",
            "Iteration 9, loss = 1538571536.88712263\n",
            "Iteration 10, loss = 1538539338.14362574\n",
            "Iteration 11, loss = 1538506454.74470186\n",
            "Iteration 12, loss = 1538472414.77093720\n",
            "Iteration 13, loss = 1538438042.93239450\n",
            "Iteration 14, loss = 1538402526.94893003\n",
            "Iteration 15, loss = 1538366676.42466617\n",
            "Iteration 16, loss = 1538329425.28503036\n",
            "Iteration 17, loss = 1538291069.20449543\n",
            "Iteration 18, loss = 1538252169.88482499\n",
            "Iteration 19, loss = 1538212075.13880134\n",
            "Iteration 20, loss = 1538171169.73764014\n",
            "Iteration 21, loss = 1538128795.59350944\n",
            "Iteration 22, loss = 1538086063.13493681\n",
            "Iteration 23, loss = 1538041429.02105927\n",
            "Iteration 24, loss = 1537997844.78901958\n",
            "Iteration 25, loss = 1537951143.87084126\n",
            "Iteration 26, loss = 1537904833.90915442\n",
            "Iteration 27, loss = 1537857730.30887008\n",
            "Iteration 28, loss = 1537810358.82037258\n",
            "Iteration 29, loss = 1537761932.84799886\n",
            "Iteration 30, loss = 1537711945.62823129\n",
            "Iteration 31, loss = 1537662914.93391967\n",
            "Iteration 32, loss = 1537613470.80254602\n",
            "Iteration 33, loss = 1537563488.49000072\n",
            "Iteration 34, loss = 1537512495.25781107\n",
            "Iteration 35, loss = 1537461785.76671505\n",
            "Iteration 36, loss = 1537410233.96165657\n",
            "Iteration 37, loss = 1537359939.82935309\n",
            "Iteration 38, loss = 1537307441.69795513\n",
            "Iteration 39, loss = 1537255172.33660412\n",
            "Iteration 40, loss = 1537202917.43753934\n",
            "Iteration 41, loss = 1537149679.23229623\n",
            "Iteration 42, loss = 1537095911.16017270\n",
            "Iteration 43, loss = 1537041947.69983292\n",
            "Iteration 44, loss = 1536987252.90168905\n",
            "Iteration 45, loss = 1536932714.21961045\n",
            "Iteration 46, loss = 1536876849.77795959\n",
            "Iteration 47, loss = 1536820540.64418364\n",
            "Iteration 48, loss = 1536764055.94829845\n",
            "Iteration 49, loss = 1536706560.00433397\n",
            "Iteration 50, loss = 1536648385.40571856\n",
            "Iteration 51, loss = 1536589464.84697199\n",
            "Iteration 52, loss = 1536529631.70508575\n",
            "Iteration 53, loss = 1536469177.22295403\n",
            "Iteration 54, loss = 1536407625.80616283\n",
            "Iteration 55, loss = 1536345148.78637457\n",
            "Iteration 56, loss = 1536281529.27035594\n",
            "Iteration 57, loss = 1536217072.13573194\n",
            "Iteration 58, loss = 1536151193.11300397\n",
            "Iteration 59, loss = 1536084846.65205789\n",
            "Iteration 60, loss = 1536017403.03323746\n",
            "Iteration 61, loss = 1535949193.92425990\n",
            "Iteration 62, loss = 1535880102.52616501\n",
            "Iteration 63, loss = 1535810639.23816204\n",
            "Iteration 64, loss = 1535740822.14163017\n",
            "Iteration 65, loss = 1535670027.17452192\n",
            "Iteration 66, loss = 1535598969.09401703\n",
            "Iteration 67, loss = 1535527486.71940660\n",
            "Iteration 68, loss = 1535455946.65886354\n",
            "Iteration 69, loss = 1535384033.78848910\n",
            "Iteration 70, loss = 1535311765.46188140\n",
            "Iteration 71, loss = 1535239333.38968062\n",
            "Iteration 72, loss = 1535166727.21220589\n",
            "Iteration 73, loss = 1535093645.23049784\n",
            "Iteration 74, loss = 1535020974.75683522\n",
            "Iteration 75, loss = 1534947430.13363814\n",
            "Iteration 76, loss = 1534874285.35070562\n",
            "Iteration 77, loss = 1534801184.97812510\n",
            "Iteration 78, loss = 1534728456.14061236\n",
            "Iteration 79, loss = 1534655746.74361205\n",
            "Iteration 80, loss = 1534582935.67484498\n",
            "Iteration 81, loss = 1534510602.64876890\n",
            "Iteration 82, loss = 1534438123.09723163\n",
            "Iteration 83, loss = 1534365262.59312582\n",
            "Iteration 84, loss = 1534292418.92162895\n",
            "Iteration 85, loss = 1534219523.85327291\n",
            "Iteration 86, loss = 1534146169.37108994\n",
            "Iteration 87, loss = 1534073768.29142141\n",
            "Iteration 88, loss = 1534000745.81443739\n",
            "Iteration 89, loss = 1533928158.45624423\n",
            "Iteration 90, loss = 1533855888.59878302\n",
            "Iteration 91, loss = 1533783492.14978552\n",
            "Iteration 92, loss = 1533711249.29466987\n",
            "Iteration 93, loss = 1533639002.12425447\n",
            "Iteration 94, loss = 1533567333.03559375\n",
            "Iteration 95, loss = 1533495078.28832769\n",
            "Iteration 96, loss = 1533423522.82190728\n",
            "Iteration 97, loss = 1533352134.57487726\n",
            "Iteration 98, loss = 1533280288.56518149\n",
            "Iteration 99, loss = 1533209054.65050578\n",
            "Iteration 100, loss = 1533137751.83733940\n",
            "Iteration 101, loss = 1533066305.12972355\n",
            "Iteration 102, loss = 1532994998.45659161\n",
            "Iteration 103, loss = 1532924146.21852040\n",
            "Iteration 104, loss = 1532852948.84306002\n",
            "Iteration 105, loss = 1532782449.58601785\n",
            "Iteration 106, loss = 1532711793.75475860\n",
            "Iteration 107, loss = 1532641224.01868606\n",
            "Iteration 108, loss = 1532570799.28023171\n",
            "Iteration 109, loss = 1532500840.96212745\n",
            "Iteration 110, loss = 1532431041.26239419\n",
            "Iteration 111, loss = 1532361302.84413362\n",
            "Iteration 112, loss = 1532291482.28655434\n",
            "Iteration 113, loss = 1532222028.43089318\n",
            "Iteration 114, loss = 1532152683.77208495\n",
            "Iteration 115, loss = 1532082616.60261154\n",
            "Iteration 116, loss = 1532013532.66240025\n",
            "Iteration 117, loss = 1531944038.74673033\n",
            "Iteration 118, loss = 1531874563.65047097\n",
            "Iteration 119, loss = 1531805445.87379265\n",
            "Iteration 120, loss = 1531736637.29516006\n",
            "Iteration 121, loss = 1531667552.18156862\n",
            "Iteration 122, loss = 1531598993.83150935\n",
            "Iteration 123, loss = 1531530188.07798648\n",
            "Iteration 124, loss = 1531461618.34903431\n",
            "Iteration 125, loss = 1531393578.59558797\n",
            "Iteration 126, loss = 1531325301.67149377\n",
            "Iteration 127, loss = 1531257140.98046899\n",
            "Iteration 128, loss = 1531189589.78109050\n",
            "Iteration 129, loss = 1531121623.08022523\n",
            "Iteration 130, loss = 1531054752.88444567\n",
            "Iteration 131, loss = 1530986826.14829063\n",
            "Iteration 132, loss = 1530919914.90018487\n",
            "Iteration 133, loss = 1530852592.35717034\n",
            "Iteration 134, loss = 1530786104.10809445\n",
            "Iteration 135, loss = 1530718746.65517759\n",
            "Iteration 136, loss = 1530652415.09080672\n",
            "Iteration 137, loss = 1530585809.84428263\n",
            "Iteration 138, loss = 1530519137.48816705\n",
            "Iteration 139, loss = 1530452455.15842342\n",
            "Iteration 140, loss = 1530386447.54235268\n",
            "Iteration 141, loss = 1530319848.60312295\n",
            "Iteration 142, loss = 1530253181.65094256\n",
            "Iteration 143, loss = 1530186660.30177212\n",
            "Iteration 144, loss = 1530120134.21547627\n",
            "Iteration 145, loss = 1530054246.34834623\n",
            "Iteration 146, loss = 1529988068.26465821\n",
            "Iteration 147, loss = 1529921866.09327793\n",
            "Iteration 148, loss = 1529855728.89612770\n",
            "Iteration 149, loss = 1529790005.59305811\n",
            "Iteration 150, loss = 1529724203.34870553\n",
            "Iteration 151, loss = 1529658918.49528933\n",
            "Iteration 152, loss = 1529593178.19250274\n",
            "Iteration 153, loss = 1529528223.79853702\n",
            "Iteration 154, loss = 1529462897.80506563\n",
            "Iteration 155, loss = 1529397773.94952607\n",
            "Iteration 156, loss = 1529332870.45212197\n",
            "Iteration 157, loss = 1529267401.94931602\n",
            "Iteration 158, loss = 1529202780.79206038\n",
            "Iteration 159, loss = 1529137035.02498102\n",
            "Iteration 160, loss = 1529072256.54880047\n",
            "Iteration 161, loss = 1529007154.49131393\n",
            "Iteration 162, loss = 1528941882.00707936\n",
            "Iteration 163, loss = 1528877289.00309658\n",
            "Iteration 164, loss = 1528812437.63919592\n",
            "Iteration 165, loss = 1528747190.48426938\n",
            "Iteration 166, loss = 1528683186.02204061\n",
            "Iteration 167, loss = 1528618240.66095972\n",
            "Iteration 168, loss = 1528553562.76346755\n",
            "Iteration 169, loss = 1528489063.56564426\n",
            "Iteration 170, loss = 1528424771.30794454\n",
            "Iteration 171, loss = 1528360074.55125046\n",
            "Iteration 172, loss = 1528296045.52848911\n",
            "Iteration 173, loss = 1528231833.11657572\n",
            "Iteration 174, loss = 1528167645.90600204\n",
            "Iteration 175, loss = 1528104000.57436872\n",
            "Iteration 176, loss = 1528040579.51101542\n",
            "Iteration 177, loss = 1527976773.44182444\n",
            "Iteration 178, loss = 1527913693.21363854\n",
            "Iteration 179, loss = 1527850655.49890375\n",
            "Iteration 180, loss = 1527787301.35918236\n",
            "Iteration 181, loss = 1527723950.31197214\n",
            "Iteration 182, loss = 1527661016.12256050\n",
            "Iteration 183, loss = 1527597371.50250840\n",
            "Iteration 184, loss = 1527534225.10812259\n",
            "Iteration 185, loss = 1527470722.42955899\n",
            "Iteration 186, loss = 1527407709.24199533\n",
            "Iteration 187, loss = 1527344605.91181350\n",
            "Iteration 188, loss = 1527281653.23675847\n",
            "Iteration 189, loss = 1527218564.45068717\n",
            "Iteration 190, loss = 1527155540.76868057\n",
            "Iteration 191, loss = 1527093015.51707435\n",
            "Iteration 192, loss = 1527029815.77496266\n",
            "Iteration 193, loss = 1526967258.54299688\n",
            "Iteration 194, loss = 1526904394.31502175\n",
            "Iteration 195, loss = 1526841553.48452330\n",
            "Iteration 196, loss = 1526779224.26360273\n",
            "Iteration 197, loss = 1526716037.84312344\n",
            "Iteration 198, loss = 1526653421.50090694\n",
            "Iteration 199, loss = 1526591041.39808130\n",
            "Iteration 200, loss = 1526528320.68421316\n",
            "Iteration 201, loss = 1526465863.91349578\n",
            "Iteration 202, loss = 1526403409.51108789\n",
            "Iteration 203, loss = 1526340810.26408267\n",
            "Iteration 204, loss = 1526279045.03303981\n",
            "Iteration 205, loss = 1526216447.29449916\n",
            "Iteration 206, loss = 1526154660.32690740\n",
            "Iteration 207, loss = 1526092508.97227836\n",
            "Iteration 208, loss = 1526030652.68805742\n",
            "Iteration 209, loss = 1525968871.26487350\n",
            "Iteration 210, loss = 1525907023.84277225\n",
            "Iteration 211, loss = 1525845075.83699393\n",
            "Iteration 212, loss = 1525783874.32096744\n",
            "Iteration 213, loss = 1525722043.33482957\n",
            "Iteration 214, loss = 1525661027.80354643\n",
            "Iteration 215, loss = 1525599177.06712151\n",
            "Iteration 216, loss = 1525538169.00630069\n",
            "Iteration 217, loss = 1525477267.32330418\n",
            "Iteration 218, loss = 1525415933.26347208\n",
            "Iteration 219, loss = 1525354885.92659211\n",
            "Iteration 220, loss = 1525294570.66584754\n",
            "Iteration 221, loss = 1525233232.40284348\n",
            "Iteration 222, loss = 1525172269.26686049\n",
            "Iteration 223, loss = 1525111648.41073513\n",
            "Iteration 224, loss = 1525050467.23895979\n",
            "Iteration 225, loss = 1524989416.28522539\n",
            "Iteration 226, loss = 1524929094.19564199\n",
            "Iteration 227, loss = 1524867697.26841259\n",
            "Iteration 228, loss = 1524806673.87009645\n",
            "Iteration 229, loss = 1524745706.20232964\n",
            "Iteration 230, loss = 1524684899.23236990\n",
            "Iteration 231, loss = 1524624357.52668238\n",
            "Iteration 232, loss = 1524563404.66921425\n",
            "Iteration 233, loss = 1524502661.77035069\n",
            "Iteration 234, loss = 1524441948.92362738\n",
            "Iteration 235, loss = 1524381194.64990568\n",
            "Iteration 236, loss = 1524320880.36624384\n",
            "Iteration 237, loss = 1524260002.17884374\n",
            "Iteration 238, loss = 1524199108.36320591\n",
            "Iteration 239, loss = 1524138681.59506750\n",
            "Iteration 240, loss = 1524077824.85005403\n",
            "Iteration 241, loss = 1524017219.04591537\n",
            "Iteration 242, loss = 1523956642.23524213\n",
            "Iteration 243, loss = 1523896071.09956312\n",
            "Iteration 244, loss = 1523835031.93873382\n",
            "Iteration 245, loss = 1523774925.77766776\n",
            "Iteration 246, loss = 1523714143.06451321\n",
            "Iteration 247, loss = 1523654265.38059711\n",
            "Iteration 248, loss = 1523593315.24512100\n",
            "Iteration 249, loss = 1523533161.59765530\n",
            "Iteration 250, loss = 1523473177.52990127\n",
            "Iteration 251, loss = 1523412768.72592711\n",
            "Iteration 252, loss = 1523352815.69506836\n",
            "Iteration 253, loss = 1523292883.25273204\n",
            "Iteration 254, loss = 1523232920.27094364\n",
            "Iteration 255, loss = 1523172935.82972622\n",
            "Iteration 256, loss = 1523113059.73826027\n",
            "Iteration 257, loss = 1523053181.48669481\n",
            "Iteration 258, loss = 1522993317.24760866\n",
            "Iteration 259, loss = 1522933545.41531301\n",
            "Iteration 260, loss = 1522873356.45683908\n",
            "Iteration 261, loss = 1522813905.74399638\n",
            "Iteration 262, loss = 1522753533.01480007\n",
            "Iteration 263, loss = 1522694111.15462565\n",
            "Iteration 264, loss = 1522633897.30314851\n",
            "Iteration 265, loss = 1522574096.84696221\n",
            "Iteration 266, loss = 1522514234.57304120\n",
            "Iteration 267, loss = 1522454435.85864973\n",
            "Iteration 268, loss = 1522394596.11014366\n",
            "Iteration 269, loss = 1522334880.68129086\n",
            "Iteration 270, loss = 1522275371.68350434\n",
            "Iteration 271, loss = 1522215510.51314592\n",
            "Iteration 272, loss = 1522155935.55392241\n",
            "Iteration 273, loss = 1522096030.32669044\n",
            "Iteration 274, loss = 1522036687.01844835\n",
            "Iteration 275, loss = 1521977160.73935795\n",
            "Iteration 276, loss = 1521917612.44761181\n",
            "Iteration 277, loss = 1521857956.46440196\n",
            "Iteration 278, loss = 1521798428.66607141\n",
            "Iteration 279, loss = 1521739485.96540833\n",
            "Iteration 280, loss = 1521679886.55914521\n",
            "Iteration 281, loss = 1521620637.70024705\n",
            "Iteration 282, loss = 1521561499.07136774\n",
            "Iteration 283, loss = 1521502014.61727667\n",
            "Iteration 284, loss = 1521442740.36806560\n",
            "Iteration 285, loss = 1521383422.66336012\n",
            "Iteration 286, loss = 1521324128.67466021\n",
            "Iteration 287, loss = 1521264741.93567038\n",
            "Iteration 288, loss = 1521205658.44793367\n",
            "Iteration 289, loss = 1521146240.32095027\n",
            "Iteration 290, loss = 1521086945.73938799\n",
            "Iteration 291, loss = 1521027971.39293361\n",
            "Iteration 292, loss = 1520968620.09825873\n",
            "Iteration 293, loss = 1520909897.35196042\n",
            "Iteration 294, loss = 1520850717.73533106\n",
            "Iteration 295, loss = 1520791718.02474904\n",
            "Iteration 296, loss = 1520732727.13456368\n",
            "Iteration 297, loss = 1520673911.32409477\n",
            "Iteration 298, loss = 1520615454.58447266\n",
            "Iteration 299, loss = 1520556268.41868472\n",
            "Iteration 300, loss = 1520497260.18753934\n",
            "Iteration 301, loss = 1520438734.51095414\n",
            "Iteration 302, loss = 1520379995.02515578\n",
            "Iteration 303, loss = 1520321160.23652649\n",
            "Iteration 304, loss = 1520262470.25120044\n",
            "Iteration 305, loss = 1520203701.06076813\n",
            "Iteration 306, loss = 1520144914.39293432\n",
            "Iteration 307, loss = 1520086258.50257444\n",
            "Iteration 308, loss = 1520027577.85903788\n",
            "Iteration 309, loss = 1519968742.39946055\n",
            "Iteration 310, loss = 1519910247.62007332\n",
            "Iteration 311, loss = 1519850832.51758027\n",
            "Iteration 312, loss = 1519792560.04544783\n",
            "Iteration 313, loss = 1519733855.30459714\n",
            "Iteration 314, loss = 1519674889.44100428\n",
            "Iteration 315, loss = 1519616422.10755277\n",
            "Iteration 316, loss = 1519557935.69601059\n",
            "Iteration 317, loss = 1519498864.86425304\n",
            "Iteration 318, loss = 1519440569.05054283\n",
            "Iteration 319, loss = 1519381891.37435985\n",
            "Iteration 320, loss = 1519323487.00844741\n",
            "Iteration 321, loss = 1519265050.52026796\n",
            "Iteration 322, loss = 1519206531.15694880\n",
            "Iteration 323, loss = 1519148361.52227998\n",
            "Iteration 324, loss = 1519089774.18235230\n",
            "Iteration 325, loss = 1519031730.60821271\n",
            "Iteration 326, loss = 1518973521.96776152\n",
            "Iteration 327, loss = 1518914901.97622848\n",
            "Iteration 328, loss = 1518856927.08882952\n",
            "Iteration 329, loss = 1518798352.13687992\n",
            "Iteration 330, loss = 1518740493.54534626\n",
            "Iteration 331, loss = 1518681842.44973850\n",
            "Iteration 332, loss = 1518623560.65760875\n",
            "Iteration 333, loss = 1518565202.89433932\n",
            "Iteration 334, loss = 1518506499.96513939\n",
            "Iteration 335, loss = 1518448574.72504449\n",
            "Iteration 336, loss = 1518389918.19822359\n",
            "Iteration 337, loss = 1518331323.94774580\n",
            "Iteration 338, loss = 1518273352.49609637\n",
            "Iteration 339, loss = 1518215011.23717880\n",
            "Iteration 340, loss = 1518156994.84267855\n",
            "Iteration 341, loss = 1518099111.34358931\n",
            "Iteration 342, loss = 1518041149.10313892\n",
            "Iteration 343, loss = 1517983553.35660601\n",
            "Iteration 344, loss = 1517925351.45610785\n",
            "Iteration 345, loss = 1517868042.40317392\n",
            "Iteration 346, loss = 1517809763.77407694\n",
            "Iteration 347, loss = 1517751948.78661871\n",
            "Iteration 348, loss = 1517694112.89473176\n",
            "Iteration 349, loss = 1517635855.85157657\n",
            "Iteration 350, loss = 1517577874.65501952\n",
            "Iteration 351, loss = 1517519736.71537185\n",
            "Iteration 352, loss = 1517461365.08273053\n",
            "Iteration 353, loss = 1517403871.32923603\n",
            "Iteration 354, loss = 1517345526.77778435\n",
            "Iteration 355, loss = 1517288079.34546781\n",
            "Iteration 356, loss = 1517229707.51914883\n",
            "Iteration 357, loss = 1517172097.64959598\n",
            "Iteration 358, loss = 1517114285.66658163\n",
            "Iteration 359, loss = 1517057068.16302276\n",
            "Iteration 360, loss = 1516999099.86745548\n",
            "Iteration 361, loss = 1516941587.89004660\n",
            "Iteration 362, loss = 1516884168.96594000\n",
            "Iteration 363, loss = 1516826688.73163581\n",
            "Iteration 364, loss = 1516769283.48439860\n",
            "Iteration 365, loss = 1516711838.93451285\n",
            "Iteration 366, loss = 1516653886.91400027\n",
            "Iteration 367, loss = 1516596671.95450020\n",
            "Iteration 368, loss = 1516538806.10541868\n",
            "Iteration 369, loss = 1516481319.77702236\n",
            "Iteration 370, loss = 1516423478.75477004\n",
            "Iteration 371, loss = 1516365738.02805734\n",
            "Iteration 372, loss = 1516308049.57055640\n",
            "Iteration 373, loss = 1516250690.03165507\n",
            "Iteration 374, loss = 1516192743.57221675\n",
            "Iteration 375, loss = 1516135127.28627348\n",
            "Iteration 376, loss = 1516077879.63363004\n",
            "Iteration 377, loss = 1516020051.41534305\n",
            "Iteration 378, loss = 1515963137.35189891\n",
            "Iteration 379, loss = 1515905421.08658314\n",
            "Iteration 380, loss = 1515848372.01950312\n",
            "Iteration 381, loss = 1515791344.77717972\n",
            "Iteration 382, loss = 1515733951.32552290\n",
            "Iteration 383, loss = 1515676669.87852025\n",
            "Iteration 384, loss = 1515619438.90214348\n",
            "Iteration 385, loss = 1515562062.15420341\n",
            "Iteration 386, loss = 1515504509.08384895\n",
            "Iteration 387, loss = 1515447787.69708323\n",
            "Iteration 388, loss = 1515389709.92251205\n",
            "Iteration 389, loss = 1515332680.33998632\n",
            "Iteration 390, loss = 1515275050.77067351\n",
            "Iteration 391, loss = 1515217850.20560074\n",
            "Iteration 392, loss = 1515160291.42984509\n",
            "Iteration 393, loss = 1515102651.30972457\n",
            "Iteration 394, loss = 1515045340.64695811\n",
            "Iteration 395, loss = 1514987271.74540830\n",
            "Iteration 396, loss = 1514930165.78908515\n",
            "Iteration 397, loss = 1514872637.02168822\n",
            "Iteration 398, loss = 1514815076.56824303\n",
            "Iteration 399, loss = 1514757276.59933400\n",
            "Iteration 400, loss = 1514700224.36052084\n",
            "Iteration 401, loss = 1514642681.32828879\n",
            "Iteration 402, loss = 1514585141.35331774\n",
            "Iteration 403, loss = 1514527886.22785592\n",
            "Iteration 404, loss = 1514470518.61522746\n",
            "Iteration 405, loss = 1514413426.39532089\n",
            "Iteration 406, loss = 1514355850.00790453\n",
            "Iteration 407, loss = 1514298580.55893230\n",
            "Iteration 408, loss = 1514241294.63944721\n",
            "Iteration 409, loss = 1514184363.93535900\n",
            "Iteration 410, loss = 1514126889.74458456\n",
            "Iteration 411, loss = 1514069613.35800934\n",
            "Iteration 412, loss = 1514012664.63748932\n",
            "Iteration 413, loss = 1513955353.95518565\n",
            "Iteration 414, loss = 1513898346.33645153\n",
            "Iteration 415, loss = 1513841283.69190502\n",
            "Iteration 416, loss = 1513784095.04512310\n",
            "Iteration 417, loss = 1513727464.90426993\n",
            "Iteration 418, loss = 1513670584.98295188\n",
            "Iteration 419, loss = 1513614016.69220686\n",
            "Iteration 420, loss = 1513557229.42884278\n",
            "Iteration 421, loss = 1513500587.93769264\n",
            "Iteration 422, loss = 1513443925.00412655\n",
            "Iteration 423, loss = 1513387234.73874593\n",
            "Iteration 424, loss = 1513330548.96921921\n",
            "Iteration 425, loss = 1513273779.55689311\n",
            "Iteration 426, loss = 1513217345.44854355\n",
            "Iteration 427, loss = 1513160418.45494390\n",
            "Iteration 428, loss = 1513103936.66759062\n",
            "Iteration 429, loss = 1513047350.73166656\n",
            "Iteration 430, loss = 1512990688.72281766\n",
            "Iteration 431, loss = 1512933966.76070833\n",
            "Iteration 432, loss = 1512877525.59331346\n",
            "Iteration 433, loss = 1512820852.77846789\n",
            "Iteration 434, loss = 1512764188.55281425\n",
            "Iteration 435, loss = 1512707546.04028225\n",
            "Iteration 436, loss = 1512650690.83953500\n",
            "Iteration 437, loss = 1512594173.19874072\n",
            "Iteration 438, loss = 1512537407.78062797\n",
            "Iteration 439, loss = 1512480668.38708043\n",
            "Iteration 440, loss = 1512423838.14029431\n",
            "Iteration 441, loss = 1512367245.73575997\n",
            "Iteration 442, loss = 1512310305.84145784\n",
            "Iteration 443, loss = 1512253719.35514379\n",
            "Iteration 444, loss = 1512196662.84248161\n",
            "Iteration 445, loss = 1512139937.89796352\n",
            "Iteration 446, loss = 1512083245.43170381\n",
            "Iteration 447, loss = 1512025996.44398665\n",
            "Iteration 448, loss = 1511969407.47814202\n",
            "Iteration 449, loss = 1511912346.03585672\n",
            "Iteration 450, loss = 1511855814.59177136\n",
            "Iteration 451, loss = 1511798942.84190249\n",
            "Iteration 452, loss = 1511742337.67544365\n",
            "Iteration 453, loss = 1511685327.29014421\n",
            "Iteration 454, loss = 1511628934.88738346\n",
            "Iteration 455, loss = 1511571927.38738060\n",
            "Iteration 456, loss = 1511515525.00795960\n",
            "Iteration 457, loss = 1511458576.94531608\n",
            "Iteration 458, loss = 1511402203.57182264\n",
            "Iteration 459, loss = 1511345519.92100739\n",
            "Iteration 460, loss = 1511289270.34624124\n",
            "Iteration 461, loss = 1511232336.66417599\n",
            "Iteration 462, loss = 1511176039.21555471\n",
            "Iteration 463, loss = 1511119671.89122558\n",
            "Iteration 464, loss = 1511062663.08054996\n",
            "Iteration 465, loss = 1511006552.02314401\n",
            "Iteration 466, loss = 1510949832.22617507\n",
            "Iteration 467, loss = 1510893031.36545944\n",
            "Iteration 468, loss = 1510836464.35621476\n",
            "Iteration 469, loss = 1510780318.40832424\n",
            "Iteration 470, loss = 1510723272.38411093\n",
            "Iteration 471, loss = 1510666916.14293170\n",
            "Iteration 472, loss = 1510609943.78718853\n",
            "Iteration 473, loss = 1510553346.51704788\n",
            "Iteration 474, loss = 1510497206.03778124\n",
            "Iteration 475, loss = 1510440178.03321004\n",
            "Iteration 476, loss = 1510383774.03035665\n",
            "Iteration 477, loss = 1510327211.16624618\n",
            "Iteration 478, loss = 1510270959.92313981\n",
            "Iteration 479, loss = 1510214420.47912884\n",
            "Iteration 480, loss = 1510157698.64921618\n",
            "Iteration 481, loss = 1510101340.96519542\n",
            "Iteration 482, loss = 1510044567.20332980\n",
            "Iteration 483, loss = 1509988389.31311703\n",
            "Iteration 484, loss = 1509931762.01222730\n",
            "Iteration 485, loss = 1509875200.06366038\n",
            "Iteration 486, loss = 1509818907.80673027\n",
            "Iteration 487, loss = 1509763064.38558936\n",
            "Iteration 488, loss = 1509706333.86353183\n",
            "Iteration 489, loss = 1509650741.95006537\n",
            "Iteration 490, loss = 1509594058.95367980\n",
            "Iteration 491, loss = 1509537986.11268497\n",
            "Iteration 492, loss = 1509481681.80772734\n",
            "Iteration 493, loss = 1509425507.61842585\n",
            "Iteration 494, loss = 1509368750.76250029\n",
            "Iteration 495, loss = 1509312558.49993610\n",
            "Iteration 496, loss = 1509256209.28186035\n",
            "Iteration 497, loss = 1509199688.13085246\n",
            "Iteration 498, loss = 1509144035.68986320\n",
            "Iteration 499, loss = 1509087531.59833670\n",
            "Iteration 500, loss = 1509031785.25741410\n",
            "Iteration 501, loss = 1508975892.63015389\n",
            "Iteration 502, loss = 1508919959.11099029\n",
            "Iteration 503, loss = 1508864167.62188721\n",
            "Iteration 504, loss = 1508807897.44424009\n",
            "Iteration 505, loss = 1508752184.42047453\n",
            "Iteration 506, loss = 1508696106.83449984\n",
            "Iteration 507, loss = 1508639957.37232471\n",
            "Iteration 508, loss = 1508583937.72325110\n",
            "Iteration 509, loss = 1508527930.42260599\n",
            "Iteration 510, loss = 1508472092.70787740\n",
            "Iteration 511, loss = 1508415972.52337146\n",
            "Iteration 512, loss = 1508360282.64067578\n",
            "Iteration 513, loss = 1508304297.24061441\n",
            "Iteration 514, loss = 1508248561.21258855\n",
            "Iteration 515, loss = 1508192333.37894440\n",
            "Iteration 516, loss = 1508136196.46478033\n",
            "Iteration 517, loss = 1508080737.67775536\n",
            "Iteration 518, loss = 1508024361.99684048\n",
            "Iteration 519, loss = 1507967995.35889363\n",
            "Iteration 520, loss = 1507912372.05648613\n",
            "Iteration 521, loss = 1507855772.46795249\n",
            "Iteration 522, loss = 1507799813.47004080\n",
            "Iteration 523, loss = 1507743525.10120893\n",
            "Iteration 524, loss = 1507687532.61148810\n",
            "Iteration 525, loss = 1507631425.44917178\n",
            "Iteration 526, loss = 1507575543.31644130\n",
            "Iteration 527, loss = 1507519219.54523969\n",
            "Iteration 528, loss = 1507463358.41265011\n",
            "Iteration 529, loss = 1507408030.75065231\n",
            "Iteration 530, loss = 1507351823.76897407\n",
            "Iteration 531, loss = 1507296092.13208842\n",
            "Iteration 532, loss = 1507240391.02860522\n",
            "Iteration 533, loss = 1507184677.99825120\n",
            "Iteration 534, loss = 1507129209.45567751\n",
            "Iteration 535, loss = 1507073274.48004818\n",
            "Iteration 536, loss = 1507017607.62346339\n",
            "Iteration 537, loss = 1506961759.09889340\n",
            "Iteration 538, loss = 1506906000.97888780\n",
            "Iteration 539, loss = 1506850327.63558865\n",
            "Iteration 540, loss = 1506794484.81828690\n",
            "Iteration 541, loss = 1506738434.94828105\n",
            "Iteration 542, loss = 1506682374.43624306\n",
            "Iteration 543, loss = 1506626482.60361481\n",
            "Iteration 544, loss = 1506570583.85336494\n",
            "Iteration 545, loss = 1506514033.96319842\n",
            "Iteration 546, loss = 1506458051.39401913\n",
            "Iteration 547, loss = 1506401783.51563621\n",
            "Iteration 548, loss = 1506345674.12352538\n",
            "Iteration 549, loss = 1506289669.54941821\n",
            "Iteration 550, loss = 1506233451.20790720\n",
            "Iteration 551, loss = 1506177467.25940228\n",
            "Iteration 552, loss = 1506121634.06009078\n",
            "Iteration 553, loss = 1506065594.28197384\n",
            "Iteration 554, loss = 1506010045.25841045\n",
            "Iteration 555, loss = 1505953750.34991717\n",
            "Iteration 556, loss = 1505898082.50371313\n",
            "Iteration 557, loss = 1505842439.56319499\n",
            "Iteration 558, loss = 1505786905.27097011\n",
            "Iteration 559, loss = 1505730929.25774884\n",
            "Iteration 560, loss = 1505675778.65369534\n",
            "Iteration 561, loss = 1505619942.34514594\n",
            "Iteration 562, loss = 1505564354.14242029\n",
            "Iteration 563, loss = 1505509297.55683708\n",
            "Iteration 564, loss = 1505453742.42211246\n",
            "Iteration 565, loss = 1505397933.53803968\n",
            "Iteration 566, loss = 1505342314.94308114\n",
            "Iteration 567, loss = 1505287167.26499891\n",
            "Iteration 568, loss = 1505231321.29911804\n",
            "Iteration 569, loss = 1505175570.64247012\n",
            "Iteration 570, loss = 1505119617.49187136\n",
            "Iteration 571, loss = 1505064130.33808231\n",
            "Iteration 572, loss = 1505008113.27443814\n",
            "Iteration 573, loss = 1504952328.41549158\n",
            "Iteration 574, loss = 1504896617.11320567\n",
            "Iteration 575, loss = 1504840995.96475768\n",
            "Iteration 576, loss = 1504785213.32524347\n",
            "Iteration 577, loss = 1504729668.79746199\n",
            "Iteration 578, loss = 1504674226.83606482\n",
            "Iteration 579, loss = 1504618426.33147645\n",
            "Iteration 580, loss = 1504562989.26131654\n",
            "Iteration 581, loss = 1504507557.15679336\n",
            "Iteration 582, loss = 1504452276.26341343\n",
            "Iteration 583, loss = 1504396429.21503496\n",
            "Iteration 584, loss = 1504341197.73402333\n",
            "Iteration 585, loss = 1504285910.19457555\n",
            "Iteration 586, loss = 1504230449.46530628\n",
            "Iteration 587, loss = 1504175306.31689310\n",
            "Iteration 588, loss = 1504119992.95397568\n",
            "Iteration 589, loss = 1504064525.90130377\n",
            "Iteration 590, loss = 1504009436.33805513\n",
            "Iteration 591, loss = 1503954110.36612988\n",
            "Iteration 592, loss = 1503898734.61132979\n",
            "Iteration 593, loss = 1503843599.65480280\n",
            "Iteration 594, loss = 1503787786.27431679\n",
            "Iteration 595, loss = 1503732900.74016142\n",
            "Iteration 596, loss = 1503677256.45446491\n",
            "Iteration 597, loss = 1503621997.59406710\n",
            "Iteration 598, loss = 1503566342.97277260\n",
            "Iteration 599, loss = 1503511165.43824768\n",
            "Iteration 600, loss = 1503455699.12067199\n",
            "Iteration 601, loss = 1503400426.17865443\n",
            "Iteration 602, loss = 1503344800.36703539\n",
            "Iteration 603, loss = 1503289353.30516839\n",
            "Iteration 604, loss = 1503233919.88314486\n",
            "Iteration 605, loss = 1503178440.01797748\n",
            "Iteration 606, loss = 1503122740.57067585\n",
            "Iteration 607, loss = 1503067016.75203061\n",
            "Iteration 608, loss = 1503011622.39723325\n",
            "Iteration 609, loss = 1502955714.69567680\n",
            "Iteration 610, loss = 1502900181.32923198\n",
            "Iteration 611, loss = 1502844472.05832624\n",
            "Iteration 612, loss = 1502788911.77389097\n",
            "Iteration 613, loss = 1502733327.35168624\n",
            "Iteration 614, loss = 1502677672.31840944\n",
            "Iteration 615, loss = 1502622344.25084686\n",
            "Iteration 616, loss = 1502566637.65633321\n",
            "Iteration 617, loss = 1502511477.59387708\n",
            "Iteration 618, loss = 1502455982.16408300\n",
            "Iteration 619, loss = 1502400454.23298836\n",
            "Iteration 620, loss = 1502345142.21665931\n",
            "Iteration 621, loss = 1502289657.72746539\n",
            "Iteration 622, loss = 1502234105.92231870\n",
            "Iteration 623, loss = 1502178455.14705539\n",
            "Iteration 624, loss = 1502123411.60900235\n",
            "Iteration 625, loss = 1502067682.03565192\n",
            "Iteration 626, loss = 1502011997.59838319\n",
            "Iteration 627, loss = 1501957176.07728052\n",
            "Iteration 628, loss = 1501901531.27290678\n",
            "Iteration 629, loss = 1501846290.87752676\n",
            "Iteration 630, loss = 1501791358.35064459\n",
            "Iteration 631, loss = 1501735898.57956743\n",
            "Iteration 632, loss = 1501681101.66305590\n",
            "Iteration 633, loss = 1501626051.16349196\n",
            "Iteration 634, loss = 1501571084.20672584\n",
            "Iteration 635, loss = 1501515644.51113272\n",
            "Iteration 636, loss = 1501460877.62827015\n",
            "Iteration 637, loss = 1501405752.17470288\n",
            "Iteration 638, loss = 1501350827.74455476\n",
            "Iteration 639, loss = 1501295640.81187725\n",
            "Iteration 640, loss = 1501240301.85084176\n",
            "Iteration 641, loss = 1501185244.83687472\n",
            "Iteration 642, loss = 1501129995.72691655\n",
            "Iteration 643, loss = 1501074745.59024739\n",
            "Iteration 644, loss = 1501019363.64057922\n",
            "Iteration 645, loss = 1500963983.38088822\n",
            "Iteration 646, loss = 1500908266.82432914\n",
            "Iteration 647, loss = 1500853032.37715220\n",
            "Iteration 648, loss = 1500797685.19572568\n",
            "Iteration 649, loss = 1500741837.11619878\n",
            "Iteration 650, loss = 1500686470.86532331\n",
            "Iteration 651, loss = 1500631423.99890804\n",
            "Iteration 652, loss = 1500575470.28457952\n",
            "Iteration 653, loss = 1500520241.99049091\n",
            "Iteration 654, loss = 1500464741.62613273\n",
            "Iteration 655, loss = 1500409464.27036476\n",
            "Iteration 656, loss = 1500354106.25734305\n",
            "Iteration 657, loss = 1500298947.38201356\n",
            "Iteration 658, loss = 1500243422.01666236\n",
            "Iteration 659, loss = 1500188274.53858733\n",
            "Iteration 660, loss = 1500133358.31717753\n",
            "Iteration 661, loss = 1500077940.69520783\n",
            "Iteration 662, loss = 1500023142.45277834\n",
            "Iteration 663, loss = 1499967806.47195029\n",
            "Iteration 664, loss = 1499912915.55286384\n",
            "Iteration 665, loss = 1499857603.52022696\n",
            "Iteration 666, loss = 1499802799.46332049\n",
            "Iteration 667, loss = 1499747454.00445795\n",
            "Iteration 668, loss = 1499692522.27900529\n",
            "Iteration 669, loss = 1499637131.29811358\n",
            "Iteration 670, loss = 1499582266.52057695\n",
            "Iteration 671, loss = 1499526949.42767191\n",
            "Iteration 672, loss = 1499471883.29677200\n",
            "Iteration 673, loss = 1499416781.30620193\n",
            "Iteration 674, loss = 1499361838.98707533\n",
            "Iteration 675, loss = 1499306773.31049967\n",
            "Iteration 676, loss = 1499251989.18817949\n",
            "Iteration 677, loss = 1499196858.13271046\n",
            "Iteration 678, loss = 1499141851.14801073\n",
            "Iteration 679, loss = 1499086958.31339836\n",
            "Iteration 680, loss = 1499031836.64475679\n",
            "Iteration 681, loss = 1498976654.46965170\n",
            "Iteration 682, loss = 1498921822.29155016\n",
            "Iteration 683, loss = 1498866440.25887585\n",
            "Iteration 684, loss = 1498811533.81132460\n",
            "Iteration 685, loss = 1498756543.18904519\n",
            "Iteration 686, loss = 1498701708.12104273\n",
            "Iteration 687, loss = 1498646399.08028340\n",
            "Iteration 688, loss = 1498591870.61201501\n",
            "Iteration 689, loss = 1498536739.49821234\n",
            "Iteration 690, loss = 1498481973.16547871\n",
            "Iteration 691, loss = 1498427006.05757380\n",
            "Iteration 692, loss = 1498372008.06266093\n",
            "Iteration 693, loss = 1498317290.21550918\n",
            "Iteration 694, loss = 1498262263.75404787\n",
            "Iteration 695, loss = 1498207825.23898149\n",
            "Iteration 696, loss = 1498152976.93857098\n",
            "Iteration 697, loss = 1498098458.35008049\n",
            "Iteration 698, loss = 1498043592.88088942\n",
            "Iteration 699, loss = 1497989578.02907658\n",
            "Iteration 700, loss = 1497934808.24006391\n",
            "Iteration 701, loss = 1497880351.06229901\n",
            "Iteration 702, loss = 1497825561.29298091\n",
            "Iteration 703, loss = 1497771398.12602043\n",
            "Iteration 704, loss = 1497716835.99149799\n",
            "Iteration 705, loss = 1497661841.21446562\n",
            "Iteration 706, loss = 1497607548.86219716\n",
            "Iteration 707, loss = 1497552814.43807244\n",
            "Iteration 708, loss = 1497498414.08884573\n",
            "Iteration 709, loss = 1497443631.08574271\n",
            "Iteration 710, loss = 1497389227.84223676\n",
            "Iteration 711, loss = 1497334336.85610986\n",
            "Iteration 712, loss = 1497279517.36410213\n",
            "Iteration 713, loss = 1497224856.01579022\n",
            "Iteration 714, loss = 1497170003.47826910\n",
            "Iteration 715, loss = 1497114963.58154249\n",
            "Iteration 716, loss = 1497059869.66605067\n",
            "Iteration 717, loss = 1497004836.76558161\n",
            "Iteration 718, loss = 1496950149.20505285\n",
            "Iteration 719, loss = 1496894878.86704493\n",
            "Iteration 720, loss = 1496839489.19800591\n",
            "Iteration 721, loss = 1496784547.69299555\n",
            "Iteration 722, loss = 1496729608.21322227\n",
            "Iteration 723, loss = 1496674116.52701306\n",
            "Iteration 724, loss = 1496619412.61576962\n",
            "Iteration 725, loss = 1496564404.56388378\n",
            "Iteration 726, loss = 1496509474.57038140\n",
            "Iteration 727, loss = 1496454483.31027722\n",
            "Iteration 728, loss = 1496399931.69722891\n",
            "Iteration 729, loss = 1496345246.47717762\n",
            "Iteration 730, loss = 1496290547.18478179\n",
            "Iteration 731, loss = 1496236068.49193931\n",
            "Iteration 732, loss = 1496181152.50557327\n",
            "Iteration 733, loss = 1496126873.16441441\n",
            "Iteration 734, loss = 1496072020.26196933\n",
            "Iteration 735, loss = 1496017438.63562012\n",
            "Iteration 736, loss = 1495962528.61081648\n",
            "Iteration 737, loss = 1495907804.25207639\n",
            "Iteration 738, loss = 1495852837.81027627\n",
            "Iteration 739, loss = 1495797574.04289341\n",
            "Iteration 740, loss = 1495743296.85004807\n",
            "Iteration 741, loss = 1495688176.96593833\n",
            "Iteration 742, loss = 1495633734.26656985\n",
            "Iteration 743, loss = 1495578837.71190000\n",
            "Iteration 744, loss = 1495524085.60157871\n",
            "Iteration 745, loss = 1495470099.23157954\n",
            "Iteration 746, loss = 1495415739.48657680\n",
            "Iteration 747, loss = 1495361218.65769053\n",
            "Iteration 748, loss = 1495306815.20079041\n",
            "Iteration 749, loss = 1495252539.53465247\n",
            "Iteration 750, loss = 1495198260.39251614\n",
            "Iteration 751, loss = 1495143913.02117205\n",
            "Iteration 752, loss = 1495089258.55520058\n",
            "Iteration 753, loss = 1495034946.91871977\n",
            "Iteration 754, loss = 1494980198.00531864\n",
            "Iteration 755, loss = 1494925777.06942725\n",
            "Iteration 756, loss = 1494870962.09184647\n",
            "Iteration 757, loss = 1494816562.59097123\n",
            "Iteration 758, loss = 1494761817.91387439\n",
            "Iteration 759, loss = 1494707141.03751397\n",
            "Iteration 760, loss = 1494652897.92039728\n",
            "Iteration 761, loss = 1494597973.72483778\n",
            "Iteration 762, loss = 1494543484.76725984\n",
            "Iteration 763, loss = 1494488733.47876811\n",
            "Iteration 764, loss = 1494434323.72072458\n",
            "Iteration 765, loss = 1494379431.33368587\n",
            "Iteration 766, loss = 1494324487.42602396\n",
            "Iteration 767, loss = 1494270045.34726405\n",
            "Iteration 768, loss = 1494215069.55273461\n",
            "Iteration 769, loss = 1494160617.58639884\n",
            "Iteration 770, loss = 1494105694.30194998\n",
            "Iteration 771, loss = 1494051318.26643085\n",
            "Iteration 772, loss = 1493996572.32603455\n",
            "Iteration 773, loss = 1493942711.40792537\n",
            "Iteration 774, loss = 1493887608.04239726\n",
            "Iteration 775, loss = 1493833887.04753780\n",
            "Iteration 776, loss = 1493779512.58834028\n",
            "Iteration 777, loss = 1493724940.76588035\n",
            "Iteration 778, loss = 1493670769.09281325\n",
            "Iteration 779, loss = 1493616577.05048418\n",
            "Iteration 780, loss = 1493561931.18745279\n",
            "Iteration 781, loss = 1493507696.95522571\n",
            "Iteration 782, loss = 1493453005.95811534\n",
            "Iteration 783, loss = 1493398831.20382452\n",
            "Iteration 784, loss = 1493344199.89215350\n",
            "Iteration 785, loss = 1493289712.84749436\n",
            "Iteration 786, loss = 1493235192.18084502\n",
            "Iteration 787, loss = 1493180512.53779459\n",
            "Iteration 788, loss = 1493125907.01227665\n",
            "Iteration 789, loss = 1493071589.59950876\n",
            "Iteration 790, loss = 1493016973.02218080\n",
            "Iteration 791, loss = 1492962520.85353422\n",
            "Iteration 792, loss = 1492908180.46524191\n",
            "Iteration 793, loss = 1492853744.53581429\n",
            "Iteration 794, loss = 1492799316.88841271\n",
            "Iteration 795, loss = 1492745032.19974113\n",
            "Iteration 796, loss = 1492690977.84970474\n",
            "Iteration 797, loss = 1492636294.68431258\n",
            "Iteration 798, loss = 1492582379.44475126\n",
            "Iteration 799, loss = 1492527803.65610886\n",
            "Iteration 800, loss = 1492473647.12426543\n",
            "Iteration 801, loss = 1492419747.98229766\n",
            "Iteration 802, loss = 1492365543.93956327\n",
            "Iteration 803, loss = 1492311298.09554887\n",
            "Iteration 804, loss = 1492257149.37338686\n",
            "Iteration 805, loss = 1492203211.30165052\n",
            "Iteration 806, loss = 1492149052.33719468\n",
            "Iteration 807, loss = 1492094793.69256258\n",
            "Iteration 808, loss = 1492040573.51437140\n",
            "Iteration 809, loss = 1491986187.55504012\n",
            "Iteration 810, loss = 1491932117.31315875\n",
            "Iteration 811, loss = 1491877380.08175898\n",
            "Iteration 812, loss = 1491823191.03148866\n",
            "Iteration 813, loss = 1491769060.51965523\n",
            "Iteration 814, loss = 1491714525.88069177\n",
            "Iteration 815, loss = 1491660260.94253421\n",
            "Iteration 816, loss = 1491605866.69249368\n",
            "Iteration 817, loss = 1491551615.71172905\n",
            "Iteration 818, loss = 1491497366.66092467\n",
            "Iteration 819, loss = 1491443305.08283353\n",
            "Iteration 820, loss = 1491388666.31015253\n",
            "Iteration 821, loss = 1491334889.81514859\n",
            "Iteration 822, loss = 1491280103.47655010\n",
            "Iteration 823, loss = 1491226237.95653129\n",
            "Iteration 824, loss = 1491172134.47845125\n",
            "Iteration 825, loss = 1491117391.66424060\n",
            "Iteration 826, loss = 1491063410.68847799\n",
            "Iteration 827, loss = 1491009163.59194303\n",
            "Iteration 828, loss = 1490954899.40614533\n",
            "Iteration 829, loss = 1490900909.22632933\n",
            "Iteration 830, loss = 1490846353.52953243\n",
            "Iteration 831, loss = 1490792246.00621343\n",
            "Iteration 832, loss = 1490738074.17473650\n",
            "Iteration 833, loss = 1490683700.58346796\n",
            "Iteration 834, loss = 1490629622.35486770\n",
            "Iteration 835, loss = 1490575301.38569641\n",
            "Iteration 836, loss = 1490520860.89080739\n",
            "Iteration 837, loss = 1490466651.02066350\n",
            "Iteration 838, loss = 1490412297.51606131\n",
            "Iteration 839, loss = 1490358331.51972294\n",
            "Iteration 840, loss = 1490303824.37766266\n",
            "Iteration 841, loss = 1490249407.66395020\n",
            "Iteration 842, loss = 1490195593.05317140\n",
            "Iteration 843, loss = 1490140990.14835191\n",
            "Iteration 844, loss = 1490086706.64047718\n",
            "Iteration 845, loss = 1490032097.76934290\n",
            "Iteration 846, loss = 1489978177.40937591\n",
            "Iteration 847, loss = 1489923621.24092746\n",
            "Iteration 848, loss = 1489869726.39639783\n",
            "Iteration 849, loss = 1489815235.65129566\n",
            "Iteration 850, loss = 1489761314.25727248\n",
            "Iteration 851, loss = 1489707303.72741604\n",
            "Iteration 852, loss = 1489653047.33517337\n",
            "Iteration 853, loss = 1489599253.55548096\n",
            "Iteration 854, loss = 1489545164.19512200\n",
            "Iteration 855, loss = 1489490970.23096561\n",
            "Iteration 856, loss = 1489436980.85197091\n",
            "Iteration 857, loss = 1489382741.62076211\n",
            "Iteration 858, loss = 1489328381.65380216\n",
            "Iteration 859, loss = 1489274336.13941741\n",
            "Iteration 860, loss = 1489219857.66706562\n",
            "Iteration 861, loss = 1489165651.68937469\n",
            "Iteration 862, loss = 1489111181.50388122\n",
            "Iteration 863, loss = 1489056856.57941318\n",
            "Iteration 864, loss = 1489002371.85827255\n",
            "Iteration 865, loss = 1488948144.42982936\n",
            "Iteration 866, loss = 1488893840.06056070\n",
            "Iteration 867, loss = 1488839418.49423862\n",
            "Iteration 868, loss = 1488785436.67937469\n",
            "Iteration 869, loss = 1488731066.78018069\n",
            "Iteration 870, loss = 1488676867.35549212\n",
            "Iteration 871, loss = 1488622927.70450616\n",
            "Iteration 872, loss = 1488568674.06619477\n",
            "Iteration 873, loss = 1488514316.34378600\n",
            "Iteration 874, loss = 1488460285.06080890\n",
            "Iteration 875, loss = 1488406229.57268023\n",
            "Iteration 876, loss = 1488351734.41538382\n",
            "Iteration 877, loss = 1488297434.42898154\n",
            "Iteration 878, loss = 1488243044.10321093\n",
            "Iteration 879, loss = 1488189061.21093726\n",
            "Iteration 880, loss = 1488134223.70155025\n",
            "Iteration 881, loss = 1488080023.77204990\n",
            "Iteration 882, loss = 1488025550.03682852\n",
            "Iteration 883, loss = 1487971216.55957174\n",
            "Iteration 884, loss = 1487916837.75384188\n",
            "Iteration 885, loss = 1487862491.47475481\n",
            "Iteration 886, loss = 1487808198.85771918\n",
            "Iteration 887, loss = 1487753887.65962315\n",
            "Iteration 888, loss = 1487699534.48922276\n",
            "Iteration 889, loss = 1487645454.56684184\n",
            "Iteration 890, loss = 1487590833.23559451\n",
            "Iteration 891, loss = 1487536661.76553988\n",
            "Iteration 892, loss = 1487482719.80093026\n",
            "Iteration 893, loss = 1487427867.09171343\n",
            "Iteration 894, loss = 1487373841.16869164\n",
            "Iteration 895, loss = 1487319472.47848010\n",
            "Iteration 896, loss = 1487265386.89455032\n",
            "Iteration 897, loss = 1487211050.05614257\n",
            "Iteration 898, loss = 1487157161.81792355\n",
            "Iteration 899, loss = 1487102750.67687750\n",
            "Iteration 900, loss = 1487048783.79207420\n",
            "Iteration 901, loss = 1486994482.19124460\n",
            "Iteration 902, loss = 1486940534.41109514\n",
            "Iteration 903, loss = 1486886323.35070014\n",
            "Iteration 904, loss = 1486832110.35118985\n",
            "Iteration 905, loss = 1486777953.54368472\n",
            "Iteration 906, loss = 1486723339.10125780\n",
            "Iteration 907, loss = 1486669696.55575705\n",
            "Iteration 908, loss = 1486615420.45837712\n",
            "Iteration 909, loss = 1486560709.92729425\n",
            "Iteration 910, loss = 1486507215.94206285\n",
            "Iteration 911, loss = 1486452662.29153609\n",
            "Iteration 912, loss = 1486398993.22462273\n",
            "Iteration 913, loss = 1486345009.13459873\n",
            "Iteration 914, loss = 1486290801.11870289\n",
            "Iteration 915, loss = 1486236978.90542197\n",
            "Iteration 916, loss = 1486182946.57381845\n",
            "Iteration 917, loss = 1486129182.34907103\n",
            "Iteration 918, loss = 1486075115.50634098\n",
            "Iteration 919, loss = 1486021322.53008747\n",
            "Iteration 920, loss = 1485967043.78322792\n",
            "Iteration 921, loss = 1485913448.94169259\n",
            "Iteration 922, loss = 1485859509.79193044\n",
            "Iteration 923, loss = 1485805143.66016603\n",
            "Iteration 924, loss = 1485751436.20950341\n",
            "Iteration 925, loss = 1485697280.85179353\n",
            "Iteration 926, loss = 1485643346.22732043\n",
            "Iteration 927, loss = 1485589266.35084128\n",
            "Iteration 928, loss = 1485535099.88324738\n",
            "Iteration 929, loss = 1485480970.99999356\n",
            "Iteration 930, loss = 1485426962.35716581\n",
            "Iteration 931, loss = 1485372724.72166300\n",
            "Iteration 932, loss = 1485318585.41402221\n",
            "Iteration 933, loss = 1485264506.26900935\n",
            "Iteration 934, loss = 1485209802.14757991\n",
            "Iteration 935, loss = 1485155616.21463752\n",
            "Iteration 936, loss = 1485101507.18567920\n",
            "Iteration 937, loss = 1485047109.11356521\n",
            "Iteration 938, loss = 1484992660.07606912\n",
            "Iteration 939, loss = 1484938764.62442756\n",
            "Iteration 940, loss = 1484884518.64547563\n",
            "Iteration 941, loss = 1484830590.51432252\n",
            "Iteration 942, loss = 1484776418.33255053\n",
            "Iteration 943, loss = 1484722496.13007259\n",
            "Iteration 944, loss = 1484668207.57722354\n",
            "Iteration 945, loss = 1484614273.64373183\n",
            "Iteration 946, loss = 1484560328.80116343\n",
            "Iteration 947, loss = 1484506438.81541657\n",
            "Iteration 948, loss = 1484451987.42239690\n",
            "Iteration 949, loss = 1484398228.71089792\n",
            "Iteration 950, loss = 1484343990.41331649\n",
            "Iteration 951, loss = 1484290448.83408928\n",
            "Iteration 952, loss = 1484235892.61078668\n",
            "Iteration 953, loss = 1484181924.13051915\n",
            "Iteration 954, loss = 1484127917.60271907\n",
            "Iteration 955, loss = 1484073625.44513154\n",
            "Iteration 956, loss = 1484019493.30227566\n",
            "Iteration 957, loss = 1483965032.32693052\n",
            "Iteration 958, loss = 1483911096.49873638\n",
            "Iteration 959, loss = 1483856677.33874893\n",
            "Iteration 960, loss = 1483802526.19459748\n",
            "Iteration 961, loss = 1483748536.96595550\n",
            "Iteration 962, loss = 1483694225.52149940\n",
            "Iteration 963, loss = 1483640325.40640950\n",
            "Iteration 964, loss = 1483586125.27514958\n",
            "Iteration 965, loss = 1483532254.72627997\n",
            "Iteration 966, loss = 1483478212.19354224\n",
            "Iteration 967, loss = 1483424379.38442945\n",
            "Iteration 968, loss = 1483370612.02036643\n",
            "Iteration 969, loss = 1483316682.87512994\n",
            "Iteration 970, loss = 1483263048.82064247\n",
            "Iteration 971, loss = 1483209359.79806828\n",
            "Iteration 972, loss = 1483156059.20328426\n",
            "Iteration 973, loss = 1483101936.30646896\n",
            "Iteration 974, loss = 1483048371.07947683\n",
            "Iteration 975, loss = 1482994777.78632426\n",
            "Iteration 976, loss = 1482941057.42264128\n",
            "Iteration 977, loss = 1482887156.26534486\n",
            "Iteration 978, loss = 1482833574.05305147\n",
            "Iteration 979, loss = 1482779527.47238946\n",
            "Iteration 980, loss = 1482725747.32557893\n",
            "Iteration 981, loss = 1482671835.57349801\n",
            "Iteration 982, loss = 1482617919.27536345\n",
            "Iteration 983, loss = 1482563702.13628316\n",
            "Iteration 984, loss = 1482509758.08015275\n",
            "Iteration 985, loss = 1482455631.31608081\n",
            "Iteration 986, loss = 1482401857.29905176\n",
            "Iteration 987, loss = 1482347323.04831266\n",
            "Iteration 988, loss = 1482293591.66515422\n",
            "Iteration 989, loss = 1482239488.94246697\n",
            "Iteration 990, loss = 1482185317.01952028\n",
            "Iteration 991, loss = 1482131668.86567211\n",
            "Iteration 992, loss = 1482077492.42585683\n",
            "Iteration 993, loss = 1482023721.61544442\n",
            "Iteration 994, loss = 1481969762.12496734\n",
            "Iteration 995, loss = 1481916041.87636209\n",
            "Iteration 996, loss = 1481862167.61699414\n",
            "Iteration 997, loss = 1481808356.09379745\n",
            "Iteration 998, loss = 1481754472.12581515\n",
            "Iteration 999, loss = 1481700558.79838848\n",
            "Iteration 1000, loss = 1481646602.79954910\n",
            "Iteration 1, loss = 84430330748.78099060\n",
            "Iteration 2, loss = 1887885882338407765472359436069425393018312458421523288042466531051061356003328.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:127: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (100,), relu, 0.0001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538801985.61017132\n",
            "Iteration 2, loss = 1538771067.09903908\n",
            "Iteration 3, loss = 1538739216.41605783\n",
            "Iteration 4, loss = 1538704321.39512920\n",
            "Iteration 5, loss = 1538665311.84345007\n",
            "Iteration 6, loss = 1538622187.41127014\n",
            "Iteration 7, loss = 1538572449.53917432\n",
            "Iteration 8, loss = 1538516713.35829639\n",
            "Iteration 9, loss = 1538454521.61695457\n",
            "Iteration 10, loss = 1538384498.84678125\n",
            "Iteration 11, loss = 1538305937.51185822\n",
            "Iteration 12, loss = 1538221346.55048108\n",
            "Iteration 13, loss = 1538124257.12165737\n",
            "Iteration 14, loss = 1538021266.14666700\n",
            "Iteration 15, loss = 1537905739.51526213\n",
            "Iteration 16, loss = 1537782636.81585717\n",
            "Iteration 17, loss = 1537647611.48234749\n",
            "Iteration 18, loss = 1537500206.87964106\n",
            "Iteration 19, loss = 1537343382.77418756\n",
            "Iteration 20, loss = 1537175001.83315969\n",
            "Iteration 21, loss = 1536995024.43358612\n",
            "Iteration 22, loss = 1536799500.76887035\n",
            "Iteration 23, loss = 1536594609.86303687\n",
            "Iteration 24, loss = 1536375824.64544535\n",
            "Iteration 25, loss = 1536146182.00199604\n",
            "Iteration 26, loss = 1535900001.39270496\n",
            "Iteration 27, loss = 1535641648.11657119\n",
            "Iteration 28, loss = 1535367390.27445650\n",
            "Iteration 29, loss = 1535083452.24650598\n",
            "Iteration 30, loss = 1534778030.44462633\n",
            "Iteration 31, loss = 1534465059.27168489\n",
            "Iteration 32, loss = 1534131670.32361579\n",
            "Iteration 33, loss = 1533786015.73750782\n",
            "Iteration 34, loss = 1533423793.18979216\n",
            "Iteration 35, loss = 1533046060.91670942\n",
            "Iteration 36, loss = 1532652103.37950039\n",
            "Iteration 37, loss = 1532246677.99826074\n",
            "Iteration 38, loss = 1531819052.17511582\n",
            "Iteration 39, loss = 1531378844.60606480\n",
            "Iteration 40, loss = 1530919801.27126455\n",
            "Iteration 41, loss = 1530444547.14672375\n",
            "Iteration 42, loss = 1529958020.67548823\n",
            "Iteration 43, loss = 1529450878.79044032\n",
            "Iteration 44, loss = 1528917979.66328692\n",
            "Iteration 45, loss = 1528387171.01430845\n",
            "Iteration 46, loss = 1527830539.00732613\n",
            "Iteration 47, loss = 1527261607.44415355\n",
            "Iteration 48, loss = 1526676915.48998904\n",
            "Iteration 49, loss = 1526077238.87700152\n",
            "Iteration 50, loss = 1525461946.24014235\n",
            "Iteration 51, loss = 1524826631.44206190\n",
            "Iteration 52, loss = 1524184566.49051523\n",
            "Iteration 53, loss = 1523518665.82021070\n",
            "Iteration 54, loss = 1522829474.89446425\n",
            "Iteration 55, loss = 1522134128.52327752\n",
            "Iteration 56, loss = 1521410992.58155012\n",
            "Iteration 57, loss = 1520672145.39570761\n",
            "Iteration 58, loss = 1519929822.29339719\n",
            "Iteration 59, loss = 1519151914.42430782\n",
            "Iteration 60, loss = 1518362499.02538252\n",
            "Iteration 61, loss = 1517561198.03291678\n",
            "Iteration 62, loss = 1516744690.24211359\n",
            "Iteration 63, loss = 1515897143.59403753\n",
            "Iteration 64, loss = 1515044199.18711424\n",
            "Iteration 65, loss = 1514176150.71164632\n",
            "Iteration 66, loss = 1513283297.11748123\n",
            "Iteration 67, loss = 1512380279.77167058\n",
            "Iteration 68, loss = 1511464249.90608239\n",
            "Iteration 69, loss = 1510522120.10592985\n",
            "Iteration 70, loss = 1509571494.93167591\n",
            "Iteration 71, loss = 1508606832.32897687\n",
            "Iteration 72, loss = 1507633353.92826748\n",
            "Iteration 73, loss = 1506622539.57189012\n",
            "Iteration 74, loss = 1505612504.51653528\n",
            "Iteration 75, loss = 1504591807.08510804\n",
            "Iteration 76, loss = 1503535320.28343797\n",
            "Iteration 77, loss = 1502477193.29544234\n",
            "Iteration 78, loss = 1501401695.08883739\n",
            "Iteration 79, loss = 1500313611.59295917\n",
            "Iteration 80, loss = 1499201174.16334748\n",
            "Iteration 81, loss = 1498072198.36626744\n",
            "Iteration 82, loss = 1496940260.91773129\n",
            "Iteration 83, loss = 1495785614.13120532\n",
            "Iteration 84, loss = 1494623733.16388416\n",
            "Iteration 85, loss = 1493438922.17804384\n",
            "Iteration 86, loss = 1492246691.36620593\n",
            "Iteration 87, loss = 1491028250.58306170\n",
            "Iteration 88, loss = 1489806367.30492377\n",
            "Iteration 89, loss = 1488573404.56076479\n",
            "Iteration 90, loss = 1487309889.32028556\n",
            "Iteration 91, loss = 1486034143.35005951\n",
            "Iteration 92, loss = 1484742585.48511577\n",
            "Iteration 93, loss = 1483435578.91571259\n",
            "Iteration 94, loss = 1482109925.02806020\n",
            "Iteration 95, loss = 1480764286.51512027\n",
            "Iteration 96, loss = 1479408688.65413737\n",
            "Iteration 97, loss = 1478033264.12465072\n",
            "Iteration 98, loss = 1476659185.58991909\n",
            "Iteration 99, loss = 1475241960.97659159\n",
            "Iteration 100, loss = 1473826745.40683913\n",
            "Iteration 101, loss = 1472396336.95968986\n",
            "Iteration 102, loss = 1470958814.15092516\n",
            "Iteration 103, loss = 1469488838.83106446\n",
            "Iteration 104, loss = 1468028362.13506126\n",
            "Iteration 105, loss = 1466535694.49897504\n",
            "Iteration 106, loss = 1465026309.48735237\n",
            "Iteration 107, loss = 1463525486.72296906\n",
            "Iteration 108, loss = 1461988679.00678515\n",
            "Iteration 109, loss = 1460453847.39105868\n",
            "Iteration 110, loss = 1458884981.79640961\n",
            "Iteration 111, loss = 1457318686.46129012\n",
            "Iteration 112, loss = 1455723757.85439920\n",
            "Iteration 113, loss = 1454117867.00333762\n",
            "Iteration 114, loss = 1452489471.88826752\n",
            "Iteration 115, loss = 1450851326.87262225\n",
            "Iteration 116, loss = 1449195044.10078287\n",
            "Iteration 117, loss = 1447532651.28564119\n",
            "Iteration 118, loss = 1445854084.10952640\n",
            "Iteration 119, loss = 1444134097.80768299\n",
            "Iteration 120, loss = 1442448906.82585812\n",
            "Iteration 121, loss = 1440736910.24153399\n",
            "Iteration 122, loss = 1438994018.86881828\n",
            "Iteration 123, loss = 1437269164.97011662\n",
            "Iteration 124, loss = 1435511979.63097143\n",
            "Iteration 125, loss = 1433755034.50452113\n",
            "Iteration 126, loss = 1431963416.76572013\n",
            "Iteration 127, loss = 1430182155.19164395\n",
            "Iteration 128, loss = 1428363306.54699421\n",
            "Iteration 129, loss = 1426537833.67768788\n",
            "Iteration 130, loss = 1424685760.74738073\n",
            "Iteration 131, loss = 1422801431.09595156\n",
            "Iteration 132, loss = 1420943257.36802077\n",
            "Iteration 133, loss = 1419040555.44662094\n",
            "Iteration 134, loss = 1417122139.43987560\n",
            "Iteration 135, loss = 1415180601.15187550\n",
            "Iteration 136, loss = 1413259181.77098155\n",
            "Iteration 137, loss = 1411306140.98352408\n",
            "Iteration 138, loss = 1409335173.16008592\n",
            "Iteration 139, loss = 1407372947.95477509\n",
            "Iteration 140, loss = 1405374356.92933917\n",
            "Iteration 141, loss = 1403401813.24105668\n",
            "Iteration 142, loss = 1401377580.25009632\n",
            "Iteration 143, loss = 1399370779.56414890\n",
            "Iteration 144, loss = 1397341336.83793402\n",
            "Iteration 145, loss = 1395304655.02399731\n",
            "Iteration 146, loss = 1393268925.17875838\n",
            "Iteration 147, loss = 1391184692.61167192\n",
            "Iteration 148, loss = 1389131965.79593372\n",
            "Iteration 149, loss = 1387026141.90951037\n",
            "Iteration 150, loss = 1384924611.99706340\n",
            "Iteration 151, loss = 1382803482.90337753\n",
            "Iteration 152, loss = 1380707716.94963002\n",
            "Iteration 153, loss = 1378514933.47627378\n",
            "Iteration 154, loss = 1376374485.95623851\n",
            "Iteration 155, loss = 1374197871.45895052\n",
            "Iteration 156, loss = 1371992040.86922789\n",
            "Iteration 157, loss = 1369811346.49443626\n",
            "Iteration 158, loss = 1367581702.48249149\n",
            "Iteration 159, loss = 1365387869.73160291\n",
            "Iteration 160, loss = 1363154895.58351159\n",
            "Iteration 161, loss = 1360898125.47925520\n",
            "Iteration 162, loss = 1358685262.10024834\n",
            "Iteration 163, loss = 1356442617.23078370\n",
            "Iteration 164, loss = 1354202188.03522277\n",
            "Iteration 165, loss = 1351929352.39693236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 166, loss = 1349677295.84157133\n",
            "Iteration 167, loss = 1347366669.28333426\n",
            "Iteration 168, loss = 1345098845.58581305\n",
            "Iteration 169, loss = 1342801438.05325413\n",
            "Iteration 170, loss = 1340475252.36822414\n",
            "Iteration 171, loss = 1338136302.40444660\n",
            "Iteration 172, loss = 1335807206.40071130\n",
            "Iteration 173, loss = 1333487596.06048751\n",
            "Iteration 174, loss = 1331099943.29478908\n",
            "Iteration 175, loss = 1328763166.23944473\n",
            "Iteration 176, loss = 1326385942.04221678\n",
            "Iteration 177, loss = 1324008094.24693894\n",
            "Iteration 178, loss = 1321595619.16199875\n",
            "Iteration 179, loss = 1319213550.07638049\n",
            "Iteration 180, loss = 1316761646.75640821\n",
            "Iteration 181, loss = 1314384017.02806377\n",
            "Iteration 182, loss = 1311928714.81972861\n",
            "Iteration 183, loss = 1309478221.88783932\n",
            "Iteration 184, loss = 1307061695.27288175\n",
            "Iteration 185, loss = 1304623993.61118340\n",
            "Iteration 186, loss = 1302140458.70853257\n",
            "Iteration 187, loss = 1299689680.80953765\n",
            "Iteration 188, loss = 1297188356.46360588\n",
            "Iteration 189, loss = 1294725415.44587803\n",
            "Iteration 190, loss = 1292194896.04163313\n",
            "Iteration 191, loss = 1289671400.96742415\n",
            "Iteration 192, loss = 1287144174.69626141\n",
            "Iteration 193, loss = 1284623788.20631504\n",
            "Iteration 194, loss = 1282067617.22003388\n",
            "Iteration 195, loss = 1279516798.52413630\n",
            "Iteration 196, loss = 1276964498.22418094\n",
            "Iteration 197, loss = 1274438454.53573394\n",
            "Iteration 198, loss = 1271871808.74786663\n",
            "Iteration 199, loss = 1269294544.10534191\n",
            "Iteration 200, loss = 1266748891.42221308\n",
            "Iteration 201, loss = 1264181131.15896535\n",
            "Iteration 202, loss = 1261620181.24336219\n",
            "Iteration 203, loss = 1259034480.32793736\n",
            "Iteration 204, loss = 1256449129.34053063\n",
            "Iteration 205, loss = 1253844080.76996851\n",
            "Iteration 206, loss = 1251247578.37128687\n",
            "Iteration 207, loss = 1248626007.63029861\n",
            "Iteration 208, loss = 1245968357.85082436\n",
            "Iteration 209, loss = 1243324198.53393412\n",
            "Iteration 210, loss = 1240659335.27349305\n",
            "Iteration 211, loss = 1237952701.74107623\n",
            "Iteration 212, loss = 1235265709.28914070\n",
            "Iteration 213, loss = 1232587251.93182850\n",
            "Iteration 214, loss = 1229841275.45763898\n",
            "Iteration 215, loss = 1227155077.28053689\n",
            "Iteration 216, loss = 1224427267.29679370\n",
            "Iteration 217, loss = 1221716843.41795659\n",
            "Iteration 218, loss = 1219015611.93757629\n",
            "Iteration 219, loss = 1216298952.99022913\n",
            "Iteration 220, loss = 1213550263.14168406\n",
            "Iteration 221, loss = 1210807181.99673319\n",
            "Iteration 222, loss = 1208093671.65885973\n",
            "Iteration 223, loss = 1205323014.43954325\n",
            "Iteration 224, loss = 1202592944.36574793\n",
            "Iteration 225, loss = 1199799696.85895324\n",
            "Iteration 226, loss = 1197042502.70980144\n",
            "Iteration 227, loss = 1194240044.40240026\n",
            "Iteration 228, loss = 1191505426.61045384\n",
            "Iteration 229, loss = 1188713903.94504905\n",
            "Iteration 230, loss = 1185905957.43442273\n",
            "Iteration 231, loss = 1183118767.09540510\n",
            "Iteration 232, loss = 1180349679.77419257\n",
            "Iteration 233, loss = 1177562026.49833107\n",
            "Iteration 234, loss = 1174741828.00311542\n",
            "Iteration 235, loss = 1171954809.11290193\n",
            "Iteration 236, loss = 1169120938.35918546\n",
            "Iteration 237, loss = 1166354064.01440406\n",
            "Iteration 238, loss = 1163483562.01263213\n",
            "Iteration 239, loss = 1160689103.61788249\n",
            "Iteration 240, loss = 1157834799.03191018\n",
            "Iteration 241, loss = 1155059366.22690105\n",
            "Iteration 242, loss = 1152192735.48538733\n",
            "Iteration 243, loss = 1149360465.29023361\n",
            "Iteration 244, loss = 1146510073.67031431\n",
            "Iteration 245, loss = 1143657889.13963890\n",
            "Iteration 246, loss = 1140779642.59664965\n",
            "Iteration 247, loss = 1137862564.32625604\n",
            "Iteration 248, loss = 1134980047.14565134\n",
            "Iteration 249, loss = 1132073618.56504297\n",
            "Iteration 250, loss = 1129162027.95762610\n",
            "Iteration 251, loss = 1126250611.45342946\n",
            "Iteration 252, loss = 1123367273.68837786\n",
            "Iteration 253, loss = 1120452693.38485789\n",
            "Iteration 254, loss = 1117561142.82339334\n",
            "Iteration 255, loss = 1114619476.80096579\n",
            "Iteration 256, loss = 1111728230.02050805\n",
            "Iteration 257, loss = 1108758997.01040459\n",
            "Iteration 258, loss = 1105832035.20784664\n",
            "Iteration 259, loss = 1102897674.23321033\n",
            "Iteration 260, loss = 1099906676.05436301\n",
            "Iteration 261, loss = 1096963822.08644748\n",
            "Iteration 262, loss = 1094005439.25111437\n",
            "Iteration 263, loss = 1091023851.02387118\n",
            "Iteration 264, loss = 1088068800.93978405\n",
            "Iteration 265, loss = 1085131961.64598322\n",
            "Iteration 266, loss = 1082139669.35667038\n",
            "Iteration 267, loss = 1079154085.15416932\n",
            "Iteration 268, loss = 1076180846.15101862\n",
            "Iteration 269, loss = 1073270284.70314491\n",
            "Iteration 270, loss = 1070218619.45492017\n",
            "Iteration 271, loss = 1067296243.26096380\n",
            "Iteration 272, loss = 1064246204.85856235\n",
            "Iteration 273, loss = 1061270778.85226429\n",
            "Iteration 274, loss = 1058288327.11415660\n",
            "Iteration 275, loss = 1055344572.05733514\n",
            "Iteration 276, loss = 1052263222.69203413\n",
            "Iteration 277, loss = 1049277668.71150196\n",
            "Iteration 278, loss = 1046325445.12119734\n",
            "Iteration 279, loss = 1043278252.40298474\n",
            "Iteration 280, loss = 1040310034.90005672\n",
            "Iteration 281, loss = 1037263286.54484820\n",
            "Iteration 282, loss = 1034274711.30949366\n",
            "Iteration 283, loss = 1031251858.66410136\n",
            "Iteration 284, loss = 1028260010.58663797\n",
            "Iteration 285, loss = 1025246409.86582279\n",
            "Iteration 286, loss = 1022258197.31474447\n",
            "Iteration 287, loss = 1019220858.38125491\n",
            "Iteration 288, loss = 1016239529.74214935\n",
            "Iteration 289, loss = 1013254042.55027342\n",
            "Iteration 290, loss = 1010208108.47932529\n",
            "Iteration 291, loss = 1007166341.65718400\n",
            "Iteration 292, loss = 1004181137.51027358\n",
            "Iteration 293, loss = 1001136937.38965428\n",
            "Iteration 294, loss = 998069146.54372752\n",
            "Iteration 295, loss = 995058018.47177839\n",
            "Iteration 296, loss = 992000894.99444735\n",
            "Iteration 297, loss = 988956885.94806206\n",
            "Iteration 298, loss = 985889940.57337570\n",
            "Iteration 299, loss = 982834271.77316105\n",
            "Iteration 300, loss = 979782860.44869173\n",
            "Iteration 301, loss = 976733619.32641900\n",
            "Iteration 302, loss = 973674013.49325967\n",
            "Iteration 303, loss = 970638940.14553952\n",
            "Iteration 304, loss = 967584408.93247485\n",
            "Iteration 305, loss = 964566547.10819244\n",
            "Iteration 306, loss = 961492506.21940506\n",
            "Iteration 307, loss = 958463024.53984344\n",
            "Iteration 308, loss = 955407833.40146101\n",
            "Iteration 309, loss = 952345152.82233799\n",
            "Iteration 310, loss = 949324932.61380851\n",
            "Iteration 311, loss = 946211576.19275248\n",
            "Iteration 312, loss = 943188428.81770408\n",
            "Iteration 313, loss = 940163050.54912674\n",
            "Iteration 314, loss = 937101567.57827365\n",
            "Iteration 315, loss = 934051478.01164973\n",
            "Iteration 316, loss = 931039408.84459066\n",
            "Iteration 317, loss = 928027789.40913320\n",
            "Iteration 318, loss = 924988050.49347627\n",
            "Iteration 319, loss = 921947573.21071231\n",
            "Iteration 320, loss = 918902489.83751059\n",
            "Iteration 321, loss = 915905879.58358693\n",
            "Iteration 322, loss = 912883609.03807843\n",
            "Iteration 323, loss = 909870795.45415723\n",
            "Iteration 324, loss = 906825143.45353913\n",
            "Iteration 325, loss = 903837757.88248837\n",
            "Iteration 326, loss = 900806844.82362628\n",
            "Iteration 327, loss = 897810781.43713248\n",
            "Iteration 328, loss = 894790536.85734582\n",
            "Iteration 329, loss = 891781600.06093419\n",
            "Iteration 330, loss = 888750512.77024424\n",
            "Iteration 331, loss = 885739577.12524903\n",
            "Iteration 332, loss = 882737400.63947761\n",
            "Iteration 333, loss = 879713419.15802431\n",
            "Iteration 334, loss = 876730758.12855375\n",
            "Iteration 335, loss = 873741070.06599557\n",
            "Iteration 336, loss = 870732764.93041301\n",
            "Iteration 337, loss = 867766150.33528495\n",
            "Iteration 338, loss = 864720374.49355853\n",
            "Iteration 339, loss = 861799841.71443117\n",
            "Iteration 340, loss = 858793551.31755555\n",
            "Iteration 341, loss = 855797220.34635520\n",
            "Iteration 342, loss = 852793661.22302139\n",
            "Iteration 343, loss = 849812599.55988503\n",
            "Iteration 344, loss = 846791202.11446035\n",
            "Iteration 345, loss = 843835693.06608880\n",
            "Iteration 346, loss = 840786654.04400659\n",
            "Iteration 347, loss = 837815825.58113742\n",
            "Iteration 348, loss = 834777208.22033548\n",
            "Iteration 349, loss = 831775914.47360349\n",
            "Iteration 350, loss = 828764938.32016945\n",
            "Iteration 351, loss = 825803560.73548293\n",
            "Iteration 352, loss = 822737641.98647821\n",
            "Iteration 353, loss = 819790793.64819014\n",
            "Iteration 354, loss = 816782455.06607509\n",
            "Iteration 355, loss = 813865226.45154560\n",
            "Iteration 356, loss = 810876868.07348859\n",
            "Iteration 357, loss = 807932277.63699472\n",
            "Iteration 358, loss = 804986583.10260582\n",
            "Iteration 359, loss = 802060750.64006495\n",
            "Iteration 360, loss = 799136910.90751529\n",
            "Iteration 361, loss = 796201370.46982563\n",
            "Iteration 362, loss = 793260522.25169218\n",
            "Iteration 363, loss = 790317090.73911524\n",
            "Iteration 364, loss = 787419106.57457829\n",
            "Iteration 365, loss = 784506528.88259709\n",
            "Iteration 366, loss = 781567829.33765209\n",
            "Iteration 367, loss = 778656998.59834123\n",
            "Iteration 368, loss = 775724597.58565152\n",
            "Iteration 369, loss = 772812331.53980756\n",
            "Iteration 370, loss = 769858061.44599366\n",
            "Iteration 371, loss = 766991746.30262017\n",
            "Iteration 372, loss = 764020462.05604053\n",
            "Iteration 373, loss = 761139041.75542891\n",
            "Iteration 374, loss = 758245233.51156056\n",
            "Iteration 375, loss = 755347125.64987671\n",
            "Iteration 376, loss = 752469654.77381957\n",
            "Iteration 377, loss = 749597994.74798632\n",
            "Iteration 378, loss = 746735181.02275658\n",
            "Iteration 379, loss = 743894177.40464616\n",
            "Iteration 380, loss = 740989917.66428947\n",
            "Iteration 381, loss = 738158363.51115072\n",
            "Iteration 382, loss = 735287358.71907878\n",
            "Iteration 383, loss = 732400035.79396832\n",
            "Iteration 384, loss = 729528836.74610388\n",
            "Iteration 385, loss = 726631299.60408854\n",
            "Iteration 386, loss = 723764570.95302892\n",
            "Iteration 387, loss = 720891267.41965902\n",
            "Iteration 388, loss = 718004832.78482080\n",
            "Iteration 389, loss = 715119369.86818790\n",
            "Iteration 390, loss = 712281477.63004911\n",
            "Iteration 391, loss = 709416038.70929623\n",
            "Iteration 392, loss = 706587586.45611334\n",
            "Iteration 393, loss = 703711216.47754407\n",
            "Iteration 394, loss = 700859559.37093318\n",
            "Iteration 395, loss = 698078307.71528304\n",
            "Iteration 396, loss = 695232178.78155351\n",
            "Iteration 397, loss = 692413047.22290230\n",
            "Iteration 398, loss = 689598049.37592947\n",
            "Iteration 399, loss = 686765493.08540940\n",
            "Iteration 400, loss = 683965283.81128013\n",
            "Iteration 401, loss = 681136504.56399190\n",
            "Iteration 402, loss = 678352920.90535021\n",
            "Iteration 403, loss = 675554055.54895914\n",
            "Iteration 404, loss = 672750273.29246926\n",
            "Iteration 405, loss = 669960864.12755644\n",
            "Iteration 406, loss = 667233712.23859251\n",
            "Iteration 407, loss = 664433339.07985628\n",
            "Iteration 408, loss = 661711241.98991835\n",
            "Iteration 409, loss = 658952136.77707112\n",
            "Iteration 410, loss = 656239804.76321125\n",
            "Iteration 411, loss = 653516706.58800042\n",
            "Iteration 412, loss = 650781244.28278613\n",
            "Iteration 413, loss = 648078443.32440817\n",
            "Iteration 414, loss = 645360156.04356003\n",
            "Iteration 415, loss = 642659004.52566230\n",
            "Iteration 416, loss = 639978614.28859973\n",
            "Iteration 417, loss = 637277686.83384407\n",
            "Iteration 418, loss = 634581927.72346067\n",
            "Iteration 419, loss = 631883689.76576555\n",
            "Iteration 420, loss = 629223748.26012373\n",
            "Iteration 421, loss = 626531776.43784142\n",
            "Iteration 422, loss = 623865903.64094937\n",
            "Iteration 423, loss = 621232578.45306015\n",
            "Iteration 424, loss = 618588980.69109571\n",
            "Iteration 425, loss = 615906733.01805782\n",
            "Iteration 426, loss = 613316424.35774887\n",
            "Iteration 427, loss = 610660479.22975147\n",
            "Iteration 428, loss = 608074368.11404145\n",
            "Iteration 429, loss = 605430170.80729854\n",
            "Iteration 430, loss = 602834630.99322391\n",
            "Iteration 431, loss = 600225178.30720353\n",
            "Iteration 432, loss = 597643034.34789693\n",
            "Iteration 433, loss = 595060657.30158079\n",
            "Iteration 434, loss = 592484361.18377197\n",
            "Iteration 435, loss = 589916607.84991074\n",
            "Iteration 436, loss = 587371218.04027569\n",
            "Iteration 437, loss = 584818369.37198734\n",
            "Iteration 438, loss = 582300905.27590072\n",
            "Iteration 439, loss = 579747580.06300521\n",
            "Iteration 440, loss = 577210873.63506961\n",
            "Iteration 441, loss = 574720474.36415684\n",
            "Iteration 442, loss = 572162473.40412915\n",
            "Iteration 443, loss = 569645126.40874207\n",
            "Iteration 444, loss = 567120524.95532715\n",
            "Iteration 445, loss = 564600853.74991500\n",
            "Iteration 446, loss = 562114715.91142190\n",
            "Iteration 447, loss = 559587497.05320477\n",
            "Iteration 448, loss = 557114821.47055233\n",
            "Iteration 449, loss = 554575223.91342866\n",
            "Iteration 450, loss = 552139083.67263150\n",
            "Iteration 451, loss = 549631737.51969445\n",
            "Iteration 452, loss = 547175711.27940464\n",
            "Iteration 453, loss = 544717456.87874162\n",
            "Iteration 454, loss = 542239310.53827286\n",
            "Iteration 455, loss = 539821337.52314115\n",
            "Iteration 456, loss = 537359788.65328681\n",
            "Iteration 457, loss = 534919901.99626082\n",
            "Iteration 458, loss = 532435012.74470454\n",
            "Iteration 459, loss = 530005204.04703355\n",
            "Iteration 460, loss = 527540536.28992981\n",
            "Iteration 461, loss = 525099469.96568400\n",
            "Iteration 462, loss = 522632231.51316649\n",
            "Iteration 463, loss = 520233722.58639908\n",
            "Iteration 464, loss = 517824832.09646022\n",
            "Iteration 465, loss = 515409180.97902673\n",
            "Iteration 466, loss = 513017245.08764488\n",
            "Iteration 467, loss = 510661787.19919729\n",
            "Iteration 468, loss = 508294502.82872015\n",
            "Iteration 469, loss = 505959870.69091392\n",
            "Iteration 470, loss = 503597264.07297450\n",
            "Iteration 471, loss = 501306638.40806580\n",
            "Iteration 472, loss = 498944288.06904638\n",
            "Iteration 473, loss = 496641454.16353065\n",
            "Iteration 474, loss = 494374692.87131274\n",
            "Iteration 475, loss = 492073293.17485136\n",
            "Iteration 476, loss = 489796278.02547652\n",
            "Iteration 477, loss = 487513212.00332588\n",
            "Iteration 478, loss = 485249565.19826627\n",
            "Iteration 479, loss = 482998665.50420314\n",
            "Iteration 480, loss = 480790792.10372937\n",
            "Iteration 481, loss = 478504118.12432134\n",
            "Iteration 482, loss = 476296771.49159157\n",
            "Iteration 483, loss = 474049407.36232579\n",
            "Iteration 484, loss = 471860183.83372855\n",
            "Iteration 485, loss = 469607697.09348190\n",
            "Iteration 486, loss = 467423422.29216796\n",
            "Iteration 487, loss = 465234959.42586255\n",
            "Iteration 488, loss = 463020221.46622992\n",
            "Iteration 489, loss = 460855655.00641322\n",
            "Iteration 490, loss = 458652784.09079236\n",
            "Iteration 491, loss = 456503399.02545178\n",
            "Iteration 492, loss = 454320765.34382516\n",
            "Iteration 493, loss = 452169856.78136402\n",
            "Iteration 494, loss = 449987123.56094384\n",
            "Iteration 495, loss = 447838744.41361493\n",
            "Iteration 496, loss = 445669892.49556637\n",
            "Iteration 497, loss = 443511418.93185461\n",
            "Iteration 498, loss = 441338714.78026760\n",
            "Iteration 499, loss = 439222354.91290063\n",
            "Iteration 500, loss = 437061532.62420762\n",
            "Iteration 501, loss = 434966603.58966172\n",
            "Iteration 502, loss = 432833435.96221054\n",
            "Iteration 503, loss = 430747807.12435400\n",
            "Iteration 504, loss = 428664763.27064866\n",
            "Iteration 505, loss = 426584291.04349756\n",
            "Iteration 506, loss = 424498747.80193228\n",
            "Iteration 507, loss = 422461764.78232431\n",
            "Iteration 508, loss = 420399431.85737830\n",
            "Iteration 509, loss = 418360716.61272669\n",
            "Iteration 510, loss = 416318773.27899253\n",
            "Iteration 511, loss = 414284987.21247530\n",
            "Iteration 512, loss = 412257403.19959432\n",
            "Iteration 513, loss = 410266714.39001030\n",
            "Iteration 514, loss = 408266440.81700313\n",
            "Iteration 515, loss = 406290173.86804926\n",
            "Iteration 516, loss = 404335512.62229323\n",
            "Iteration 517, loss = 402358010.40116853\n",
            "Iteration 518, loss = 400444619.25750601\n",
            "Iteration 519, loss = 398516485.30763942\n",
            "Iteration 520, loss = 396559106.29405719\n",
            "Iteration 521, loss = 394695277.48646295\n",
            "Iteration 522, loss = 392760956.88794702\n",
            "Iteration 523, loss = 390845602.28138787\n",
            "Iteration 524, loss = 388958702.93546045\n",
            "Iteration 525, loss = 387071946.15184563\n",
            "Iteration 526, loss = 385162434.63568169\n",
            "Iteration 527, loss = 383301165.02274656\n",
            "Iteration 528, loss = 381416124.49346131\n",
            "Iteration 529, loss = 379540745.35787731\n",
            "Iteration 530, loss = 377658515.85646087\n",
            "Iteration 531, loss = 375821739.69391757\n",
            "Iteration 532, loss = 373974721.25651968\n",
            "Iteration 533, loss = 372139807.43741763\n",
            "Iteration 534, loss = 370295485.73952013\n",
            "Iteration 535, loss = 368491558.94504535\n",
            "Iteration 536, loss = 366695253.22139996\n",
            "Iteration 537, loss = 364879317.18592304\n",
            "Iteration 538, loss = 363098983.34051931\n",
            "Iteration 539, loss = 361326002.85654175\n",
            "Iteration 540, loss = 359526588.22494721\n",
            "Iteration 541, loss = 357731564.78528887\n",
            "Iteration 542, loss = 355991129.32257104\n",
            "Iteration 543, loss = 354204270.60103381\n",
            "Iteration 544, loss = 352440041.64128476\n",
            "Iteration 545, loss = 350733525.54998946\n",
            "Iteration 546, loss = 348955336.50010520\n",
            "Iteration 547, loss = 347282706.39388680\n",
            "Iteration 548, loss = 345587552.18275553\n",
            "Iteration 549, loss = 343879781.99402183\n",
            "Iteration 550, loss = 342185784.99685985\n",
            "Iteration 551, loss = 340532255.99388546\n",
            "Iteration 552, loss = 338842398.51960891\n",
            "Iteration 553, loss = 337207594.14481878\n",
            "Iteration 554, loss = 335538385.47207052\n",
            "Iteration 555, loss = 333923005.35273105\n",
            "Iteration 556, loss = 332277587.55425882\n",
            "Iteration 557, loss = 330674258.03947759\n",
            "Iteration 558, loss = 329036905.78831273\n",
            "Iteration 559, loss = 327431014.59707350\n",
            "Iteration 560, loss = 325838756.07741588\n",
            "Iteration 561, loss = 324233190.02051753\n",
            "Iteration 562, loss = 322624685.96365464\n",
            "Iteration 563, loss = 321054489.49908423\n",
            "Iteration 564, loss = 319471082.44825035\n",
            "Iteration 565, loss = 317875407.01267004\n",
            "Iteration 566, loss = 316324175.42062843\n",
            "Iteration 567, loss = 314772505.18371010\n",
            "Iteration 568, loss = 313205393.60361648\n",
            "Iteration 569, loss = 311648017.17937523\n",
            "Iteration 570, loss = 310119348.78294402\n",
            "Iteration 571, loss = 308576985.01638001\n",
            "Iteration 572, loss = 307050421.36470556\n",
            "Iteration 573, loss = 305508805.86862016\n",
            "Iteration 574, loss = 303989542.34445548\n",
            "Iteration 575, loss = 302474056.70180291\n",
            "Iteration 576, loss = 300936968.22750503\n",
            "Iteration 577, loss = 299452829.10530418\n",
            "Iteration 578, loss = 297933341.50473273\n",
            "Iteration 579, loss = 296479996.20998967\n",
            "Iteration 580, loss = 294951248.12465262\n",
            "Iteration 581, loss = 293502650.19909167\n",
            "Iteration 582, loss = 292026190.82927793\n",
            "Iteration 583, loss = 290578414.36737978\n",
            "Iteration 584, loss = 289128755.55290103\n",
            "Iteration 585, loss = 287662274.45281678\n",
            "Iteration 586, loss = 286259376.23197609\n",
            "Iteration 587, loss = 284809916.49922061\n",
            "Iteration 588, loss = 283424952.53427863\n",
            "Iteration 589, loss = 282012875.99642533\n",
            "Iteration 590, loss = 280632743.62535316\n",
            "Iteration 591, loss = 279260705.41969162\n",
            "Iteration 592, loss = 277907682.75784343\n",
            "Iteration 593, loss = 276552928.11870593\n",
            "Iteration 594, loss = 275203007.21314716\n",
            "Iteration 595, loss = 273896683.04464680\n",
            "Iteration 596, loss = 272571272.82664675\n",
            "Iteration 597, loss = 271236786.13771981\n",
            "Iteration 598, loss = 269944690.68569130\n",
            "Iteration 599, loss = 268614599.58657080\n",
            "Iteration 600, loss = 267337968.00399062\n",
            "Iteration 601, loss = 266024292.55325305\n",
            "Iteration 602, loss = 264726067.88214743\n",
            "Iteration 603, loss = 263455344.07753867\n",
            "Iteration 604, loss = 262151010.51945972\n",
            "Iteration 605, loss = 260906072.38628045\n",
            "Iteration 606, loss = 259588484.03985727\n",
            "Iteration 607, loss = 258364034.09733385\n",
            "Iteration 608, loss = 257089375.86761519\n",
            "Iteration 609, loss = 255853707.57558411\n",
            "Iteration 610, loss = 254617853.09775093\n",
            "Iteration 611, loss = 253375695.51324111\n",
            "Iteration 612, loss = 252185267.60008091\n",
            "Iteration 613, loss = 250947889.15233362\n",
            "Iteration 614, loss = 249763122.35799295\n",
            "Iteration 615, loss = 248559866.28957278\n",
            "Iteration 616, loss = 247399471.50603607\n",
            "Iteration 617, loss = 246205268.74598435\n",
            "Iteration 618, loss = 245048116.18569490\n",
            "Iteration 619, loss = 243889344.92342725\n",
            "Iteration 620, loss = 242737971.69970259\n",
            "Iteration 621, loss = 241583601.32481125\n",
            "Iteration 622, loss = 240445438.63358420\n",
            "Iteration 623, loss = 239307075.80435282\n",
            "Iteration 624, loss = 238180415.96496513\n",
            "Iteration 625, loss = 237056742.21089259\n",
            "Iteration 626, loss = 235922565.50721624\n",
            "Iteration 627, loss = 234823987.36322758\n",
            "Iteration 628, loss = 233722161.06883964\n",
            "Iteration 629, loss = 232612898.14973241\n",
            "Iteration 630, loss = 231526886.56013775\n",
            "Iteration 631, loss = 230456299.78409198\n",
            "Iteration 632, loss = 229373130.36851037\n",
            "Iteration 633, loss = 228315567.67172897\n",
            "Iteration 634, loss = 227260620.04388422\n",
            "Iteration 635, loss = 226201545.86681241\n",
            "Iteration 636, loss = 225161659.28423050\n",
            "Iteration 637, loss = 224127650.90833950\n",
            "Iteration 638, loss = 223097802.49842656\n",
            "Iteration 639, loss = 222067942.68850139\n",
            "Iteration 640, loss = 221046506.74022782\n",
            "Iteration 641, loss = 220052133.04385427\n",
            "Iteration 642, loss = 219034312.84423521\n",
            "Iteration 643, loss = 218047522.29474470\n",
            "Iteration 644, loss = 217052171.35081446\n",
            "Iteration 645, loss = 216060946.92618227\n",
            "Iteration 646, loss = 215100390.58798102\n",
            "Iteration 647, loss = 214123236.40730011\n",
            "Iteration 648, loss = 213168295.59012881\n",
            "Iteration 649, loss = 212218174.81102768\n",
            "Iteration 650, loss = 211296200.39646122\n",
            "Iteration 651, loss = 210335484.72101498\n",
            "Iteration 652, loss = 209432979.56535408\n",
            "Iteration 653, loss = 208499983.74565923\n",
            "Iteration 654, loss = 207580970.83393234\n",
            "Iteration 655, loss = 206671851.76304695\n",
            "Iteration 656, loss = 205736279.37898397\n",
            "Iteration 657, loss = 204854530.07286587\n",
            "Iteration 658, loss = 203936024.61610320\n",
            "Iteration 659, loss = 203055908.06100139\n",
            "Iteration 660, loss = 202169919.81698713\n",
            "Iteration 661, loss = 201296925.35130328\n",
            "Iteration 662, loss = 200442326.67581829\n",
            "Iteration 663, loss = 199575879.16088498\n",
            "Iteration 664, loss = 198737654.11245614\n",
            "Iteration 665, loss = 197904621.34781551\n",
            "Iteration 666, loss = 197075350.75237897\n",
            "Iteration 667, loss = 196247276.37094724\n",
            "Iteration 668, loss = 195420129.95042530\n",
            "Iteration 669, loss = 194620432.14595470\n",
            "Iteration 670, loss = 193788156.27434441\n",
            "Iteration 671, loss = 192978868.45800689\n",
            "Iteration 672, loss = 192170690.75272366\n",
            "Iteration 673, loss = 191371664.22167337\n",
            "Iteration 674, loss = 190558466.55159172\n",
            "Iteration 675, loss = 189794941.61432165\n",
            "Iteration 676, loss = 188991646.89205155\n",
            "Iteration 677, loss = 188221044.68390378\n",
            "Iteration 678, loss = 187450163.47873989\n",
            "Iteration 679, loss = 186692672.32763621\n",
            "Iteration 680, loss = 185933713.48744354\n",
            "Iteration 681, loss = 185182684.64906567\n",
            "Iteration 682, loss = 184420045.58406857\n",
            "Iteration 683, loss = 183694420.94368079\n",
            "Iteration 684, loss = 182951727.26612258\n",
            "Iteration 685, loss = 182211053.22691086\n",
            "Iteration 686, loss = 181506916.28718534\n",
            "Iteration 687, loss = 180776449.35680613\n",
            "Iteration 688, loss = 180065535.43033794\n",
            "Iteration 689, loss = 179345778.28364059\n",
            "Iteration 690, loss = 178647612.65034124\n",
            "Iteration 691, loss = 177939181.13977692\n",
            "Iteration 692, loss = 177249866.20852074\n",
            "Iteration 693, loss = 176542036.32567868\n",
            "Iteration 694, loss = 175854515.50698596\n",
            "Iteration 695, loss = 175188406.68046007\n",
            "Iteration 696, loss = 174502349.13731384\n",
            "Iteration 697, loss = 173838357.53554729\n",
            "Iteration 698, loss = 173170812.51693827\n",
            "Iteration 699, loss = 172511895.46398810\n",
            "Iteration 700, loss = 171856444.72754517\n",
            "Iteration 701, loss = 171227120.17725667\n",
            "Iteration 702, loss = 170572837.73650604\n",
            "Iteration 703, loss = 169947849.10990548\n",
            "Iteration 704, loss = 169300278.94873807\n",
            "Iteration 705, loss = 168677519.02532336\n",
            "Iteration 706, loss = 168068822.53074044\n",
            "Iteration 707, loss = 167440330.62493280\n",
            "Iteration 708, loss = 166824572.53375891\n",
            "Iteration 709, loss = 166216524.38891974\n",
            "Iteration 710, loss = 165612458.09683329\n",
            "Iteration 711, loss = 165009170.55351564\n",
            "Iteration 712, loss = 164417176.03755838\n",
            "Iteration 713, loss = 163823413.24982724\n",
            "Iteration 714, loss = 163239258.03630507\n",
            "Iteration 715, loss = 162671400.69044119\n",
            "Iteration 716, loss = 162082183.16623986\n",
            "Iteration 717, loss = 161524272.61448640\n",
            "Iteration 718, loss = 160956867.85015383\n",
            "Iteration 719, loss = 160396807.92500323\n",
            "Iteration 720, loss = 159823246.95485187\n",
            "Iteration 721, loss = 159278442.99266726\n",
            "Iteration 722, loss = 158725103.42526886\n",
            "Iteration 723, loss = 158171261.28622878\n",
            "Iteration 724, loss = 157613248.36902025\n",
            "Iteration 725, loss = 157069664.37448463\n",
            "Iteration 726, loss = 156528120.07586071\n",
            "Iteration 727, loss = 155988116.37559372\n",
            "Iteration 728, loss = 155446648.92775503\n",
            "Iteration 729, loss = 154913312.50743997\n",
            "Iteration 730, loss = 154389419.84095225\n",
            "Iteration 731, loss = 153866010.37264755\n",
            "Iteration 732, loss = 153344278.99325591\n",
            "Iteration 733, loss = 152839093.62045470\n",
            "Iteration 734, loss = 152333240.27969012\n",
            "Iteration 735, loss = 151820899.01709127\n",
            "Iteration 736, loss = 151340293.99804524\n",
            "Iteration 737, loss = 150839662.97850165\n",
            "Iteration 738, loss = 150339613.39493448\n",
            "Iteration 739, loss = 149871236.07471558\n",
            "Iteration 740, loss = 149381281.54649228\n",
            "Iteration 741, loss = 148906772.11223951\n",
            "Iteration 742, loss = 148429515.64626127\n",
            "Iteration 743, loss = 147958225.17323115\n",
            "Iteration 744, loss = 147489194.82140541\n",
            "Iteration 745, loss = 147035595.02398747\n",
            "Iteration 746, loss = 146565522.30417907\n",
            "Iteration 747, loss = 146118034.20902890\n",
            "Iteration 748, loss = 145675148.36964560\n",
            "Iteration 749, loss = 145234829.30128533\n",
            "Iteration 750, loss = 144796849.15839547\n",
            "Iteration 751, loss = 144369046.97517198\n",
            "Iteration 752, loss = 143947052.35429609\n",
            "Iteration 753, loss = 143529237.80693915\n",
            "Iteration 754, loss = 143101321.93521738\n",
            "Iteration 755, loss = 142700228.70579502\n",
            "Iteration 756, loss = 142297577.87101004\n",
            "Iteration 757, loss = 141892064.41488400\n",
            "Iteration 758, loss = 141481376.07728520\n",
            "Iteration 759, loss = 141094473.25641483\n",
            "Iteration 760, loss = 140693083.09402350\n",
            "Iteration 761, loss = 140299326.89281964\n",
            "Iteration 762, loss = 139900448.39155564\n",
            "Iteration 763, loss = 139512116.25936303\n",
            "Iteration 764, loss = 139132691.28440857\n",
            "Iteration 765, loss = 138728421.59801620\n",
            "Iteration 766, loss = 138357196.67921782\n",
            "Iteration 767, loss = 137978853.69722393\n",
            "Iteration 768, loss = 137598166.54685000\n",
            "Iteration 769, loss = 137231502.72596517\n",
            "Iteration 770, loss = 136856305.38407740\n",
            "Iteration 771, loss = 136486746.41350812\n",
            "Iteration 772, loss = 136128857.90582651\n",
            "Iteration 773, loss = 135767829.69225261\n",
            "Iteration 774, loss = 135405348.64635870\n",
            "Iteration 775, loss = 135046117.04989019\n",
            "Iteration 776, loss = 134703212.37154168\n",
            "Iteration 777, loss = 134349646.45300606\n",
            "Iteration 778, loss = 134008009.31659435\n",
            "Iteration 779, loss = 133668591.97285952\n",
            "Iteration 780, loss = 133320641.87025030\n",
            "Iteration 781, loss = 132990063.31792404\n",
            "Iteration 782, loss = 132649879.37311880\n",
            "Iteration 783, loss = 132307372.88376974\n",
            "Iteration 784, loss = 131991492.72881779\n",
            "Iteration 785, loss = 131662692.45256728\n",
            "Iteration 786, loss = 131336110.38527331\n",
            "Iteration 787, loss = 131019199.77898516\n",
            "Iteration 788, loss = 130690440.57697566\n",
            "Iteration 789, loss = 130390905.37416486\n",
            "Iteration 790, loss = 130073197.81439158\n",
            "Iteration 791, loss = 129756164.90095343\n",
            "Iteration 792, loss = 129450128.73459361\n",
            "Iteration 793, loss = 129138887.17055345\n",
            "Iteration 794, loss = 128842098.33945979\n",
            "Iteration 795, loss = 128536677.09339084\n",
            "Iteration 796, loss = 128243856.15991925\n",
            "Iteration 797, loss = 127943545.78783248\n",
            "Iteration 798, loss = 127650791.42589019\n",
            "Iteration 799, loss = 127359094.04820402\n",
            "Iteration 800, loss = 127067689.02885057\n",
            "Iteration 801, loss = 126780803.45623647\n",
            "Iteration 802, loss = 126486946.26191705\n",
            "Iteration 803, loss = 126202856.71311641\n",
            "Iteration 804, loss = 125924370.85293104\n",
            "Iteration 805, loss = 125636016.94962201\n",
            "Iteration 806, loss = 125361200.77389961\n",
            "Iteration 807, loss = 125081898.57343991\n",
            "Iteration 808, loss = 124814649.90267947\n",
            "Iteration 809, loss = 124540824.31123382\n",
            "Iteration 810, loss = 124277011.46383809\n",
            "Iteration 811, loss = 124012700.14287512\n",
            "Iteration 812, loss = 123754644.15728535\n",
            "Iteration 813, loss = 123487944.01607744\n",
            "Iteration 814, loss = 123234844.85248432\n",
            "Iteration 815, loss = 122987639.06862642\n",
            "Iteration 816, loss = 122730384.03659073\n",
            "Iteration 817, loss = 122481802.86151728\n",
            "Iteration 818, loss = 122232838.18615237\n",
            "Iteration 819, loss = 121992535.14888442\n",
            "Iteration 820, loss = 121743230.77518889\n",
            "Iteration 821, loss = 121510564.51795718\n",
            "Iteration 822, loss = 121265718.15563253\n",
            "Iteration 823, loss = 121028228.22627249\n",
            "Iteration 824, loss = 120785800.94255573\n",
            "Iteration 825, loss = 120557270.18494116\n",
            "Iteration 826, loss = 120328454.70824385\n",
            "Iteration 827, loss = 120101115.67693053\n",
            "Iteration 828, loss = 119868667.92421098\n",
            "Iteration 829, loss = 119638769.27592672\n",
            "Iteration 830, loss = 119417080.59938076\n",
            "Iteration 831, loss = 119193753.42286530\n",
            "Iteration 832, loss = 118965822.10693210\n",
            "Iteration 833, loss = 118749188.80738460\n",
            "Iteration 834, loss = 118516488.91662185\n",
            "Iteration 835, loss = 118301425.17081343\n",
            "Iteration 836, loss = 118071528.82237200\n",
            "Iteration 837, loss = 117864560.71715616\n",
            "Iteration 838, loss = 117636803.27136353\n",
            "Iteration 839, loss = 117434349.34610114\n",
            "Iteration 840, loss = 117218336.27365337\n",
            "Iteration 841, loss = 117010981.38572627\n",
            "Iteration 842, loss = 116813342.09272689\n",
            "Iteration 843, loss = 116612500.33327320\n",
            "Iteration 844, loss = 116405804.57706252\n",
            "Iteration 845, loss = 116224156.73297705\n",
            "Iteration 846, loss = 116023106.78920878\n",
            "Iteration 847, loss = 115825752.73873673\n",
            "Iteration 848, loss = 115631286.46434277\n",
            "Iteration 849, loss = 115444034.72188175\n",
            "Iteration 850, loss = 115252472.87912127\n",
            "Iteration 851, loss = 115050137.40651113\n",
            "Iteration 852, loss = 114860373.42287207\n",
            "Iteration 853, loss = 114671962.83756962\n",
            "Iteration 854, loss = 114479796.16738592\n",
            "Iteration 855, loss = 114292157.56009899\n",
            "Iteration 856, loss = 114101732.12120502\n",
            "Iteration 857, loss = 113912784.79689643\n",
            "Iteration 858, loss = 113730111.62129901\n",
            "Iteration 859, loss = 113550554.45781495\n",
            "Iteration 860, loss = 113361251.98315074\n",
            "Iteration 861, loss = 113179786.18860929\n",
            "Iteration 862, loss = 113004606.94264090\n",
            "Iteration 863, loss = 112818084.54233941\n",
            "Iteration 864, loss = 112644319.16258664\n",
            "Iteration 865, loss = 112469074.97693689\n",
            "Iteration 866, loss = 112287714.27217142\n",
            "Iteration 867, loss = 112109890.92292140\n",
            "Iteration 868, loss = 111945774.00779197\n",
            "Iteration 869, loss = 111775429.95604724\n",
            "Iteration 870, loss = 111601938.30025049\n",
            "Iteration 871, loss = 111436984.78689013\n",
            "Iteration 872, loss = 111280814.52586108\n",
            "Iteration 873, loss = 111120991.88628888\n",
            "Iteration 874, loss = 110952374.71076925\n",
            "Iteration 875, loss = 110796524.93524833\n",
            "Iteration 876, loss = 110635703.37932698\n",
            "Iteration 877, loss = 110483332.93883769\n",
            "Iteration 878, loss = 110326709.83761342\n",
            "Iteration 879, loss = 110164484.15098237\n",
            "Iteration 880, loss = 110014467.51278871\n",
            "Iteration 881, loss = 109856126.55237119\n",
            "Iteration 882, loss = 109704459.54657964\n",
            "Iteration 883, loss = 109553138.45723316\n",
            "Iteration 884, loss = 109396194.18863638\n",
            "Iteration 885, loss = 109249164.62627903\n",
            "Iteration 886, loss = 109094294.61818117\n",
            "Iteration 887, loss = 108939986.81168225\n",
            "Iteration 888, loss = 108801739.38829634\n",
            "Iteration 889, loss = 108643808.58665386\n",
            "Iteration 890, loss = 108496117.41633175\n",
            "Iteration 891, loss = 108346003.45308273\n",
            "Iteration 892, loss = 108204227.61747165\n",
            "Iteration 893, loss = 108059815.79882754\n",
            "Iteration 894, loss = 107910970.59610420\n",
            "Iteration 895, loss = 107772144.91882429\n",
            "Iteration 896, loss = 107632730.09646823\n",
            "Iteration 897, loss = 107503099.74962707\n",
            "Iteration 898, loss = 107367266.51715748\n",
            "Iteration 899, loss = 107238919.30946916\n",
            "Iteration 900, loss = 107111185.48280492\n",
            "Iteration 901, loss = 106984958.89340723\n",
            "Iteration 902, loss = 106863180.97772512\n",
            "Iteration 903, loss = 106738254.09435025\n",
            "Iteration 904, loss = 106616241.65833355\n",
            "Iteration 905, loss = 106488843.46281238\n",
            "Iteration 906, loss = 106365045.21477126\n",
            "Iteration 907, loss = 106238340.11067700\n",
            "Iteration 908, loss = 106113590.63167267\n",
            "Iteration 909, loss = 105981936.92144156\n",
            "Iteration 910, loss = 105859872.04681292\n",
            "Iteration 911, loss = 105726943.11120526\n",
            "Iteration 912, loss = 105602013.61544316\n",
            "Iteration 913, loss = 105478584.21237443\n",
            "Iteration 914, loss = 105357776.36571325\n",
            "Iteration 915, loss = 105235908.96706879\n",
            "Iteration 916, loss = 105111620.06495406\n",
            "Iteration 917, loss = 104994928.60494624\n",
            "Iteration 918, loss = 104874924.45252040\n",
            "Iteration 919, loss = 104761844.11397178\n",
            "Iteration 920, loss = 104645300.81825620\n",
            "Iteration 921, loss = 104533038.47398847\n",
            "Iteration 922, loss = 104410804.39119852\n",
            "Iteration 923, loss = 104298958.42551568\n",
            "Iteration 924, loss = 104183442.15968584\n",
            "Iteration 925, loss = 104062699.96215750\n",
            "Iteration 926, loss = 103948021.35159633\n",
            "Iteration 927, loss = 103829152.19924596\n",
            "Iteration 928, loss = 103711267.40366752\n",
            "Iteration 929, loss = 103590641.00580080\n",
            "Iteration 930, loss = 103472517.45039116\n",
            "Iteration 931, loss = 103350034.86218703\n",
            "Iteration 932, loss = 103234771.89921540\n",
            "Iteration 933, loss = 103115649.40763761\n",
            "Iteration 934, loss = 102998221.53919488\n",
            "Iteration 935, loss = 102880371.26693614\n",
            "Iteration 936, loss = 102766585.92639752\n",
            "Iteration 937, loss = 102654794.69041221\n",
            "Iteration 938, loss = 102542516.15885729\n",
            "Iteration 939, loss = 102432991.56537427\n",
            "Iteration 940, loss = 102328017.48143235\n",
            "Iteration 941, loss = 102209575.98388574\n",
            "Iteration 942, loss = 102112309.48308463\n",
            "Iteration 943, loss = 101991166.48020230\n",
            "Iteration 944, loss = 101885264.38793167\n",
            "Iteration 945, loss = 101767974.91503350\n",
            "Iteration 946, loss = 101658428.92375699\n",
            "Iteration 947, loss = 101543628.40969688\n",
            "Iteration 948, loss = 101429646.43908229\n",
            "Iteration 949, loss = 101316429.73650822\n",
            "Iteration 950, loss = 101199336.33869925\n",
            "Iteration 951, loss = 101092955.02350277\n",
            "Iteration 952, loss = 100983745.28806809\n",
            "Iteration 953, loss = 100862277.77677938\n",
            "Iteration 954, loss = 100756045.91946644\n",
            "Iteration 955, loss = 100639841.95223051\n",
            "Iteration 956, loss = 100532950.06419361\n",
            "Iteration 957, loss = 100414055.75843436\n",
            "Iteration 958, loss = 100307418.55670513\n",
            "Iteration 959, loss = 100192830.84329538\n",
            "Iteration 960, loss = 100084347.18353046\n",
            "Iteration 961, loss = 99977289.31761758\n",
            "Iteration 962, loss = 99873030.85698749\n",
            "Iteration 963, loss = 99763629.09946494\n",
            "Iteration 964, loss = 99659891.20952506\n",
            "Iteration 965, loss = 99560129.21664608\n",
            "Iteration 966, loss = 99452634.80707364\n",
            "Iteration 967, loss = 99348688.67875211\n",
            "Iteration 968, loss = 99253463.56523775\n",
            "Iteration 969, loss = 99146987.44905221\n",
            "Iteration 970, loss = 99047759.71725251\n",
            "Iteration 971, loss = 98945385.93226236\n",
            "Iteration 972, loss = 98846999.05492310\n",
            "Iteration 973, loss = 98746709.10206838\n",
            "Iteration 974, loss = 98647943.14836738\n",
            "Iteration 975, loss = 98550321.98728684\n",
            "Iteration 976, loss = 98446450.94661900\n",
            "Iteration 977, loss = 98344828.50853702\n",
            "Iteration 978, loss = 98251861.92345150\n",
            "Iteration 979, loss = 98152259.38781832\n",
            "Iteration 980, loss = 98054956.44186853\n",
            "Iteration 981, loss = 97956256.19212443\n",
            "Iteration 982, loss = 97861135.64651489\n",
            "Iteration 983, loss = 97763077.60117365\n",
            "Iteration 984, loss = 97666025.13565230\n",
            "Iteration 985, loss = 97565330.27015710\n",
            "Iteration 986, loss = 97463424.98249781\n",
            "Iteration 987, loss = 97368861.96290287\n",
            "Iteration 988, loss = 97264920.98047636\n",
            "Iteration 989, loss = 97168434.62086323\n",
            "Iteration 990, loss = 97066846.04617526\n",
            "Iteration 991, loss = 96972615.40686546\n",
            "Iteration 992, loss = 96873686.01334280\n",
            "Iteration 993, loss = 96777885.38285545\n",
            "Iteration 994, loss = 96679769.15397590\n",
            "Iteration 995, loss = 96584246.58794053\n",
            "Iteration 996, loss = 96481560.49916467\n",
            "Iteration 997, loss = 96388483.57333739\n",
            "Iteration 998, loss = 96283313.70851348\n",
            "Iteration 999, loss = 96186114.61738522\n",
            "Iteration 1000, loss = 96084170.50178239\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 36381769573.64955902\n",
            "Iteration 2, loss = 56852028597257976635713490756903863048398509826089118488360253221800771584.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (100,), relu, 0.001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538811872.71608210\n",
            "Iteration 2, loss = 1538779931.00043130\n",
            "Iteration 3, loss = 1538746389.24638200\n",
            "Iteration 4, loss = 1538711792.83397198\n",
            "Iteration 5, loss = 1538672988.21097422\n",
            "Iteration 6, loss = 1538631155.67251134\n",
            "Iteration 7, loss = 1538585248.52118635\n",
            "Iteration 8, loss = 1538532378.91406417\n",
            "Iteration 9, loss = 1538475755.94592094\n",
            "Iteration 10, loss = 1538411934.43836403\n",
            "Iteration 11, loss = 1538341420.79744363\n",
            "Iteration 12, loss = 1538262966.27621698\n",
            "Iteration 13, loss = 1538179068.23511171\n",
            "Iteration 14, loss = 1538085099.77107477\n",
            "Iteration 15, loss = 1537984848.20520830\n",
            "Iteration 16, loss = 1537872377.27392125\n",
            "Iteration 17, loss = 1537754961.72728848\n",
            "Iteration 18, loss = 1537624985.77224159\n",
            "Iteration 19, loss = 1537487726.57415748\n",
            "Iteration 20, loss = 1537336805.73051095\n",
            "Iteration 21, loss = 1537179340.47499895\n",
            "Iteration 22, loss = 1537011730.81253600\n",
            "Iteration 23, loss = 1536826655.90896273\n",
            "Iteration 24, loss = 1536633772.54530835\n",
            "Iteration 25, loss = 1536429270.76339459\n",
            "Iteration 26, loss = 1536210690.42713666\n",
            "Iteration 27, loss = 1535977837.17901707\n",
            "Iteration 28, loss = 1535730860.31647658\n",
            "Iteration 29, loss = 1535468739.17873907\n",
            "Iteration 30, loss = 1535195931.13624167\n",
            "Iteration 31, loss = 1534902786.34217763\n",
            "Iteration 32, loss = 1534600184.11434197\n",
            "Iteration 33, loss = 1534275542.28839278\n",
            "Iteration 34, loss = 1533943282.03083467\n",
            "Iteration 35, loss = 1533590734.12050748\n",
            "Iteration 36, loss = 1533223605.77362847\n",
            "Iteration 37, loss = 1532840231.28329253\n",
            "Iteration 38, loss = 1532441353.59990382\n",
            "Iteration 39, loss = 1532029799.32632160\n",
            "Iteration 40, loss = 1531596006.62618947\n",
            "Iteration 41, loss = 1531151052.01355314\n",
            "Iteration 42, loss = 1530685965.45550632\n",
            "Iteration 43, loss = 1530211918.72701502\n",
            "Iteration 44, loss = 1529712385.62772059\n",
            "Iteration 45, loss = 1529194188.14479136\n",
            "Iteration 46, loss = 1528666475.28545117\n",
            "Iteration 47, loss = 1528110038.70590162\n",
            "Iteration 48, loss = 1527545709.94890666\n",
            "Iteration 49, loss = 1526963916.92005658\n",
            "Iteration 50, loss = 1526358278.45788145\n",
            "Iteration 51, loss = 1525734620.27948999\n",
            "Iteration 52, loss = 1525110173.51905179\n",
            "Iteration 53, loss = 1524460021.03005767\n",
            "Iteration 54, loss = 1523786727.44852805\n",
            "Iteration 55, loss = 1523109547.99402595\n",
            "Iteration 56, loss = 1522408893.96557307\n",
            "Iteration 57, loss = 1521700935.17849827\n",
            "Iteration 58, loss = 1520954456.46783185\n",
            "Iteration 59, loss = 1520218405.90818858\n",
            "Iteration 60, loss = 1519448725.56919050\n",
            "Iteration 61, loss = 1518665009.38177609\n",
            "Iteration 62, loss = 1517869326.40542245\n",
            "Iteration 63, loss = 1517050357.75694203\n",
            "Iteration 64, loss = 1516217241.49164939\n",
            "Iteration 65, loss = 1515372788.64424396\n",
            "Iteration 66, loss = 1514509790.54664779\n",
            "Iteration 67, loss = 1513620953.85290360\n",
            "Iteration 68, loss = 1512722706.69566655\n",
            "Iteration 69, loss = 1511804944.91606593\n",
            "Iteration 70, loss = 1510870995.39282441\n",
            "Iteration 71, loss = 1509919614.43708301\n",
            "Iteration 72, loss = 1508958824.40590191\n",
            "Iteration 73, loss = 1507968127.37792969\n",
            "Iteration 74, loss = 1506984684.59033656\n",
            "Iteration 75, loss = 1505965299.78529000\n",
            "Iteration 76, loss = 1504937521.23864174\n",
            "Iteration 77, loss = 1503899499.39951396\n",
            "Iteration 78, loss = 1502858296.60376287\n",
            "Iteration 79, loss = 1501764802.56569481\n",
            "Iteration 80, loss = 1500674468.63647223\n",
            "Iteration 81, loss = 1499575550.71785069\n",
            "Iteration 82, loss = 1498444099.85586166\n",
            "Iteration 83, loss = 1497301537.31957531\n",
            "Iteration 84, loss = 1496129320.41824293\n",
            "Iteration 85, loss = 1494945629.31091261\n",
            "Iteration 86, loss = 1493761517.30906844\n",
            "Iteration 87, loss = 1492536358.51199555\n",
            "Iteration 88, loss = 1491309814.16582704\n",
            "Iteration 89, loss = 1490055571.34210372\n",
            "Iteration 90, loss = 1488798894.22438836\n",
            "Iteration 91, loss = 1487528346.91329718\n",
            "Iteration 92, loss = 1486229743.01875067\n",
            "Iteration 93, loss = 1484932223.55550408\n",
            "Iteration 94, loss = 1483614310.92573261\n",
            "Iteration 95, loss = 1482270161.91310835\n",
            "Iteration 96, loss = 1480934989.05003643\n",
            "Iteration 97, loss = 1479539931.49009919\n",
            "Iteration 98, loss = 1478173932.76623011\n",
            "Iteration 99, loss = 1476787681.33419228\n",
            "Iteration 100, loss = 1475366766.26438951\n",
            "Iteration 101, loss = 1473947052.65402269\n",
            "Iteration 102, loss = 1472496714.33008170\n",
            "Iteration 103, loss = 1471060951.22854972\n",
            "Iteration 104, loss = 1469577156.58037949\n",
            "Iteration 105, loss = 1468109088.25355911\n",
            "Iteration 106, loss = 1466582987.84473419\n",
            "Iteration 107, loss = 1465080172.49305511\n",
            "Iteration 108, loss = 1463550341.57676864\n",
            "Iteration 109, loss = 1461987560.61027050\n",
            "Iteration 110, loss = 1460441293.86380720\n",
            "Iteration 111, loss = 1458865087.62249494\n",
            "Iteration 112, loss = 1457273485.16274834\n",
            "Iteration 113, loss = 1455674593.65398145\n",
            "Iteration 114, loss = 1454065180.88628960\n",
            "Iteration 115, loss = 1452441710.83525133\n",
            "Iteration 116, loss = 1450806475.70702195\n",
            "Iteration 117, loss = 1449147723.98137164\n",
            "Iteration 118, loss = 1447485390.52305341\n",
            "Iteration 119, loss = 1445804179.11616468\n",
            "Iteration 120, loss = 1444109366.44177508\n",
            "Iteration 121, loss = 1442405898.67930675\n",
            "Iteration 122, loss = 1440667906.41322541\n",
            "Iteration 123, loss = 1438930691.06333804\n",
            "Iteration 124, loss = 1437184119.19258666\n",
            "Iteration 125, loss = 1435395667.17928600\n",
            "Iteration 126, loss = 1433626491.32328653\n",
            "Iteration 127, loss = 1431831292.73683333\n",
            "Iteration 128, loss = 1430022610.91351891\n",
            "Iteration 129, loss = 1428203240.81684399\n",
            "Iteration 130, loss = 1426364082.30409813\n",
            "Iteration 131, loss = 1424543709.59611654\n",
            "Iteration 132, loss = 1422664356.06284857\n",
            "Iteration 133, loss = 1420818352.42992806\n",
            "Iteration 134, loss = 1418917676.01818466\n",
            "Iteration 135, loss = 1417006006.42150712\n",
            "Iteration 136, loss = 1415125071.83423591\n",
            "Iteration 137, loss = 1413178823.45722413\n",
            "Iteration 138, loss = 1411253628.34701109\n",
            "Iteration 139, loss = 1409302358.69540262\n",
            "Iteration 140, loss = 1407346124.14002204\n",
            "Iteration 141, loss = 1405379540.88914967\n",
            "Iteration 142, loss = 1403412239.40249801\n",
            "Iteration 143, loss = 1401410105.01334667\n",
            "Iteration 144, loss = 1399404797.79572034\n",
            "Iteration 145, loss = 1397391912.42439342\n",
            "Iteration 146, loss = 1395380244.95998335\n",
            "Iteration 147, loss = 1393340393.39167643\n",
            "Iteration 148, loss = 1391271631.94519854\n",
            "Iteration 149, loss = 1389222318.13716555\n",
            "Iteration 150, loss = 1387179906.91752768\n",
            "Iteration 151, loss = 1385092325.01497936\n",
            "Iteration 152, loss = 1383009433.49794245\n",
            "Iteration 153, loss = 1380906579.73576570\n",
            "Iteration 154, loss = 1378814275.27417827\n",
            "Iteration 155, loss = 1376699806.72720480\n",
            "Iteration 156, loss = 1374558456.49951959\n",
            "Iteration 157, loss = 1372439282.44195175\n",
            "Iteration 158, loss = 1370265862.16073322\n",
            "Iteration 159, loss = 1368108980.06022501\n",
            "Iteration 160, loss = 1365941629.61778569\n",
            "Iteration 161, loss = 1363748311.25141358\n",
            "Iteration 162, loss = 1361542770.50926256\n",
            "Iteration 163, loss = 1359327426.63742185\n",
            "Iteration 164, loss = 1357121692.73973751\n",
            "Iteration 165, loss = 1354873866.92352557\n",
            "Iteration 166, loss = 1352631745.81803131\n",
            "Iteration 167, loss = 1350373296.14672375\n",
            "Iteration 168, loss = 1348108726.56853080\n",
            "Iteration 169, loss = 1345810221.26854205\n",
            "Iteration 170, loss = 1343501520.05499935\n",
            "Iteration 171, loss = 1341193349.65220451\n",
            "Iteration 172, loss = 1338865983.66746664\n",
            "Iteration 173, loss = 1336512074.20842052\n",
            "Iteration 174, loss = 1334107186.47608137\n",
            "Iteration 175, loss = 1331785233.83103466\n",
            "Iteration 176, loss = 1329358366.73517776\n",
            "Iteration 177, loss = 1326975964.62079072\n",
            "Iteration 178, loss = 1324588079.38130760\n",
            "Iteration 179, loss = 1322165049.75074506\n",
            "Iteration 180, loss = 1319768861.69776368\n",
            "Iteration 181, loss = 1317349516.98459339\n",
            "Iteration 182, loss = 1314946503.16957116\n",
            "Iteration 183, loss = 1312506386.49566293\n",
            "Iteration 184, loss = 1310072390.37829590\n",
            "Iteration 185, loss = 1307635774.80234265\n",
            "Iteration 186, loss = 1305167147.47149110\n",
            "Iteration 187, loss = 1302737831.85900116\n",
            "Iteration 188, loss = 1300252569.03998017\n",
            "Iteration 189, loss = 1297802357.91459608\n",
            "Iteration 190, loss = 1295328312.12991428\n",
            "Iteration 191, loss = 1292827347.84152937\n",
            "Iteration 192, loss = 1290382613.81999755\n",
            "Iteration 193, loss = 1287862975.99383807\n",
            "Iteration 194, loss = 1285362512.69585371\n",
            "Iteration 195, loss = 1282877040.08717895\n",
            "Iteration 196, loss = 1280347551.08556652\n",
            "Iteration 197, loss = 1277810045.56059217\n",
            "Iteration 198, loss = 1275272135.24189711\n",
            "Iteration 199, loss = 1272684263.72434044\n",
            "Iteration 200, loss = 1270112309.13414526\n",
            "Iteration 201, loss = 1267518072.05847812\n",
            "Iteration 202, loss = 1264890056.57794356\n",
            "Iteration 203, loss = 1262266682.33262372\n",
            "Iteration 204, loss = 1259657942.63722467\n",
            "Iteration 205, loss = 1256997958.54976869\n",
            "Iteration 206, loss = 1254380445.48018813\n",
            "Iteration 207, loss = 1251779808.41579151\n",
            "Iteration 208, loss = 1249137537.53851509\n",
            "Iteration 209, loss = 1246496695.80071616\n",
            "Iteration 210, loss = 1243882096.21064639\n",
            "Iteration 211, loss = 1241231568.22644877\n",
            "Iteration 212, loss = 1238605166.02192092\n",
            "Iteration 213, loss = 1235933668.80149770\n",
            "Iteration 214, loss = 1233271203.15783167\n",
            "Iteration 215, loss = 1230587010.98764515\n",
            "Iteration 216, loss = 1227861695.48457861\n",
            "Iteration 217, loss = 1225182627.66038227\n",
            "Iteration 218, loss = 1222472788.01503086\n",
            "Iteration 219, loss = 1219727818.93287539\n",
            "Iteration 220, loss = 1216988509.95792937\n",
            "Iteration 221, loss = 1214237470.50790906\n",
            "Iteration 222, loss = 1211505595.65955734\n",
            "Iteration 223, loss = 1208756648.34704733\n",
            "Iteration 224, loss = 1205982357.01995611\n",
            "Iteration 225, loss = 1203263667.41738629\n",
            "Iteration 226, loss = 1200508706.53189516\n",
            "Iteration 227, loss = 1197726015.85436487\n",
            "Iteration 228, loss = 1194996052.06903934\n",
            "Iteration 229, loss = 1192244844.43276000\n",
            "Iteration 230, loss = 1189469244.18492961\n",
            "Iteration 231, loss = 1186696395.98442602\n",
            "Iteration 232, loss = 1183949116.68492889\n",
            "Iteration 233, loss = 1181120957.86238050\n",
            "Iteration 234, loss = 1178352215.03178048\n",
            "Iteration 235, loss = 1175535866.95199633\n",
            "Iteration 236, loss = 1172733130.08282065\n",
            "Iteration 237, loss = 1169881188.25841951\n",
            "Iteration 238, loss = 1167092981.30358982\n",
            "Iteration 239, loss = 1164227344.37684512\n",
            "Iteration 240, loss = 1161422819.73110771\n",
            "Iteration 241, loss = 1158591478.10656619\n",
            "Iteration 242, loss = 1155747497.98514628\n",
            "Iteration 243, loss = 1152932382.61178041\n",
            "Iteration 244, loss = 1150078367.28749371\n",
            "Iteration 245, loss = 1147256360.82142234\n",
            "Iteration 246, loss = 1144375065.18183517\n",
            "Iteration 247, loss = 1141521408.50010896\n",
            "Iteration 248, loss = 1138686848.71849656\n",
            "Iteration 249, loss = 1135783649.35674024\n",
            "Iteration 250, loss = 1132896750.31914759\n",
            "Iteration 251, loss = 1130005921.15736747\n",
            "Iteration 252, loss = 1127119635.68993711\n",
            "Iteration 253, loss = 1124218796.62264919\n",
            "Iteration 254, loss = 1121284605.33036065\n",
            "Iteration 255, loss = 1118387513.35492158\n",
            "Iteration 256, loss = 1115448756.24486089\n",
            "Iteration 257, loss = 1112529933.11463094\n",
            "Iteration 258, loss = 1109563631.26207161\n",
            "Iteration 259, loss = 1106628639.67543507\n",
            "Iteration 260, loss = 1103690467.68046093\n",
            "Iteration 261, loss = 1100747900.02047539\n",
            "Iteration 262, loss = 1097745810.82784081\n",
            "Iteration 263, loss = 1094824866.67912030\n",
            "Iteration 264, loss = 1091849872.52642488\n",
            "Iteration 265, loss = 1088886022.47710538\n",
            "Iteration 266, loss = 1085957753.68856263\n",
            "Iteration 267, loss = 1082968628.52098942\n",
            "Iteration 268, loss = 1080005135.89321852\n",
            "Iteration 269, loss = 1077064086.34573507\n",
            "Iteration 270, loss = 1074079185.38392138\n",
            "Iteration 271, loss = 1071151586.26775074\n",
            "Iteration 272, loss = 1068127537.40106428\n",
            "Iteration 273, loss = 1065197683.61937964\n",
            "Iteration 274, loss = 1062229699.34868956\n",
            "Iteration 275, loss = 1059287902.16604316\n",
            "Iteration 276, loss = 1056310538.23590052\n",
            "Iteration 277, loss = 1053343681.24819767\n",
            "Iteration 278, loss = 1050377124.96593428\n",
            "Iteration 279, loss = 1047401260.66615558\n",
            "Iteration 280, loss = 1044429613.44772422\n",
            "Iteration 281, loss = 1041433501.83068383\n",
            "Iteration 282, loss = 1038454868.50687587\n",
            "Iteration 283, loss = 1035466878.50615644\n",
            "Iteration 284, loss = 1032471126.99843180\n",
            "Iteration 285, loss = 1029475873.47997975\n",
            "Iteration 286, loss = 1026486465.28056610\n",
            "Iteration 287, loss = 1023488471.91797304\n",
            "Iteration 288, loss = 1020490725.71004510\n",
            "Iteration 289, loss = 1017493007.48961365\n",
            "Iteration 290, loss = 1014423359.16438663\n",
            "Iteration 291, loss = 1011466736.14562917\n",
            "Iteration 292, loss = 1008395514.28345668\n",
            "Iteration 293, loss = 1005421894.76262343\n",
            "Iteration 294, loss = 1002360093.16483295\n",
            "Iteration 295, loss = 999343767.18351662\n",
            "Iteration 296, loss = 996306514.60089564\n",
            "Iteration 297, loss = 993268833.84103417\n",
            "Iteration 298, loss = 990243049.42991328\n",
            "Iteration 299, loss = 987225846.29324126\n",
            "Iteration 300, loss = 984202881.29055345\n",
            "Iteration 301, loss = 981159577.64473891\n",
            "Iteration 302, loss = 978166388.13257277\n",
            "Iteration 303, loss = 975147289.37905431\n",
            "Iteration 304, loss = 972138663.50797927\n",
            "Iteration 305, loss = 969127230.91828597\n",
            "Iteration 306, loss = 966091712.88644350\n",
            "Iteration 307, loss = 963064333.97695744\n",
            "Iteration 308, loss = 960059863.24752331\n",
            "Iteration 309, loss = 957034913.78480470\n",
            "Iteration 310, loss = 954031582.52924716\n",
            "Iteration 311, loss = 951022681.97703612\n",
            "Iteration 312, loss = 948023494.17216456\n",
            "Iteration 313, loss = 945000470.91337872\n",
            "Iteration 314, loss = 942062965.23621917\n",
            "Iteration 315, loss = 939033808.68046200\n",
            "Iteration 316, loss = 936054101.57832515\n",
            "Iteration 317, loss = 933025791.95546854\n",
            "Iteration 318, loss = 930062370.79141188\n",
            "Iteration 319, loss = 927044032.49676716\n",
            "Iteration 320, loss = 924037285.05929422\n",
            "Iteration 321, loss = 921093609.46199369\n",
            "Iteration 322, loss = 918071743.03026509\n",
            "Iteration 323, loss = 915043382.30485630\n",
            "Iteration 324, loss = 912116831.53328300\n",
            "Iteration 325, loss = 909123288.06300926\n",
            "Iteration 326, loss = 906144860.56865716\n",
            "Iteration 327, loss = 903163133.76137412\n",
            "Iteration 328, loss = 900179427.68826270\n",
            "Iteration 329, loss = 897218656.31838274\n",
            "Iteration 330, loss = 894256258.51361501\n",
            "Iteration 331, loss = 891287711.02235711\n",
            "Iteration 332, loss = 888286694.75858331\n",
            "Iteration 333, loss = 885318136.54791117\n",
            "Iteration 334, loss = 882349839.96445036\n",
            "Iteration 335, loss = 879391523.39461219\n",
            "Iteration 336, loss = 876368415.34621012\n",
            "Iteration 337, loss = 873406439.10654771\n",
            "Iteration 338, loss = 870438699.26253855\n",
            "Iteration 339, loss = 867435028.09612179\n",
            "Iteration 340, loss = 864484085.52635908\n",
            "Iteration 341, loss = 861476388.14768064\n",
            "Iteration 342, loss = 858483481.84725976\n",
            "Iteration 343, loss = 855516629.02469397\n",
            "Iteration 344, loss = 852556130.73775852\n",
            "Iteration 345, loss = 849564458.12992811\n",
            "Iteration 346, loss = 846606944.80455494\n",
            "Iteration 347, loss = 843620966.56255138\n",
            "Iteration 348, loss = 840663325.71322393\n",
            "Iteration 349, loss = 837696226.70953548\n",
            "Iteration 350, loss = 834738899.82105124\n",
            "Iteration 351, loss = 831767526.74910176\n",
            "Iteration 352, loss = 828800158.07385445\n",
            "Iteration 353, loss = 825867781.48239195\n",
            "Iteration 354, loss = 822871750.19023049\n",
            "Iteration 355, loss = 819924444.72372329\n",
            "Iteration 356, loss = 816956785.75226009\n",
            "Iteration 357, loss = 814027658.45437551\n",
            "Iteration 358, loss = 811089180.89399672\n",
            "Iteration 359, loss = 808135846.91584253\n",
            "Iteration 360, loss = 805209113.46046913\n",
            "Iteration 361, loss = 802276773.62706256\n",
            "Iteration 362, loss = 799361536.26141977\n",
            "Iteration 363, loss = 796436224.30749249\n",
            "Iteration 364, loss = 793550249.63274455\n",
            "Iteration 365, loss = 790630797.82063854\n",
            "Iteration 366, loss = 787708142.84459352\n",
            "Iteration 367, loss = 784855987.67991602\n",
            "Iteration 368, loss = 781928296.33113468\n",
            "Iteration 369, loss = 779051172.56410909\n",
            "Iteration 370, loss = 776184826.70669615\n",
            "Iteration 371, loss = 773297315.38502824\n",
            "Iteration 372, loss = 770391318.64349461\n",
            "Iteration 373, loss = 767520328.06594038\n",
            "Iteration 374, loss = 764655144.56905460\n",
            "Iteration 375, loss = 761754851.24640477\n",
            "Iteration 376, loss = 758890135.28529632\n",
            "Iteration 377, loss = 755976148.10715115\n",
            "Iteration 378, loss = 753155531.42055285\n",
            "Iteration 379, loss = 750261882.21066999\n",
            "Iteration 380, loss = 747342399.13538468\n",
            "Iteration 381, loss = 744519284.60612535\n",
            "Iteration 382, loss = 741633081.88220537\n",
            "Iteration 383, loss = 738803960.90081465\n",
            "Iteration 384, loss = 735917544.89511514\n",
            "Iteration 385, loss = 733075311.96426868\n",
            "Iteration 386, loss = 730261655.34659171\n",
            "Iteration 387, loss = 727407893.27718890\n",
            "Iteration 388, loss = 724618583.42593539\n",
            "Iteration 389, loss = 721805526.35508430\n",
            "Iteration 390, loss = 718999434.01024830\n",
            "Iteration 391, loss = 716191421.89121878\n",
            "Iteration 392, loss = 713413257.31859148\n",
            "Iteration 393, loss = 710649921.25313067\n",
            "Iteration 394, loss = 707842549.33331704\n",
            "Iteration 395, loss = 705041577.87806869\n",
            "Iteration 396, loss = 702296248.73918331\n",
            "Iteration 397, loss = 699493061.73991370\n",
            "Iteration 398, loss = 696717276.24506009\n",
            "Iteration 399, loss = 693956706.14135480\n",
            "Iteration 400, loss = 691182266.52528000\n",
            "Iteration 401, loss = 688441762.66559458\n",
            "Iteration 402, loss = 685655993.18953001\n",
            "Iteration 403, loss = 682905842.79794896\n",
            "Iteration 404, loss = 680174359.46954811\n",
            "Iteration 405, loss = 677453262.96172380\n",
            "Iteration 406, loss = 674717158.95645416\n",
            "Iteration 407, loss = 672008103.81038260\n",
            "Iteration 408, loss = 669264861.33921218\n",
            "Iteration 409, loss = 666566435.38027406\n",
            "Iteration 410, loss = 663855044.82813084\n",
            "Iteration 411, loss = 661132356.99938917\n",
            "Iteration 412, loss = 658433329.56614816\n",
            "Iteration 413, loss = 655716611.52527142\n",
            "Iteration 414, loss = 653030544.92318988\n",
            "Iteration 415, loss = 650354190.09397221\n",
            "Iteration 416, loss = 647652243.64929569\n",
            "Iteration 417, loss = 645016023.42161810\n",
            "Iteration 418, loss = 642367434.88532329\n",
            "Iteration 419, loss = 639727257.80755317\n",
            "Iteration 420, loss = 637108495.66265368\n",
            "Iteration 421, loss = 634463632.68973017\n",
            "Iteration 422, loss = 631845435.72127128\n",
            "Iteration 423, loss = 629247401.85720491\n",
            "Iteration 424, loss = 626627120.63289845\n",
            "Iteration 425, loss = 624013704.46066189\n",
            "Iteration 426, loss = 621418990.41894364\n",
            "Iteration 427, loss = 618837323.33098090\n",
            "Iteration 428, loss = 616254804.23765326\n",
            "Iteration 429, loss = 613685838.64847028\n",
            "Iteration 430, loss = 611067962.74328196\n",
            "Iteration 431, loss = 608507422.72405577\n",
            "Iteration 432, loss = 605943888.99888885\n",
            "Iteration 433, loss = 603387788.54368436\n",
            "Iteration 434, loss = 600784918.92509317\n",
            "Iteration 435, loss = 598231592.50619471\n",
            "Iteration 436, loss = 595704180.92214715\n",
            "Iteration 437, loss = 593152148.20011628\n",
            "Iteration 438, loss = 590606100.54646420\n",
            "Iteration 439, loss = 588079676.53076863\n",
            "Iteration 440, loss = 585548607.50412118\n",
            "Iteration 441, loss = 583015020.65946805\n",
            "Iteration 442, loss = 580555239.50047076\n",
            "Iteration 443, loss = 578026780.56078267\n",
            "Iteration 444, loss = 575555894.72359335\n",
            "Iteration 445, loss = 573053851.19460201\n",
            "Iteration 446, loss = 570611003.86372232\n",
            "Iteration 447, loss = 568138677.61115038\n",
            "Iteration 448, loss = 565674399.42945766\n",
            "Iteration 449, loss = 563218488.20023882\n",
            "Iteration 450, loss = 560764197.70974815\n",
            "Iteration 451, loss = 558330777.47386563\n",
            "Iteration 452, loss = 555872788.56211483\n",
            "Iteration 453, loss = 553445860.88121879\n",
            "Iteration 454, loss = 551033538.17843032\n",
            "Iteration 455, loss = 548579962.97840726\n",
            "Iteration 456, loss = 546169051.62868595\n",
            "Iteration 457, loss = 543745881.66486847\n",
            "Iteration 458, loss = 541324809.75074244\n",
            "Iteration 459, loss = 538961061.77502823\n",
            "Iteration 460, loss = 536526465.90144885\n",
            "Iteration 461, loss = 534121790.30162740\n",
            "Iteration 462, loss = 531768466.26691926\n",
            "Iteration 463, loss = 529415273.34351641\n",
            "Iteration 464, loss = 527038375.77178848\n",
            "Iteration 465, loss = 524739921.11398041\n",
            "Iteration 466, loss = 522370630.68507594\n",
            "Iteration 467, loss = 520088268.41973525\n",
            "Iteration 468, loss = 517738748.91059941\n",
            "Iteration 469, loss = 515478064.02930695\n",
            "Iteration 470, loss = 513179428.92911041\n",
            "Iteration 471, loss = 510894424.46057081\n",
            "Iteration 472, loss = 508584176.89896542\n",
            "Iteration 473, loss = 506360961.35248315\n",
            "Iteration 474, loss = 504089951.42580861\n",
            "Iteration 475, loss = 501814319.00699264\n",
            "Iteration 476, loss = 499610074.89685196\n",
            "Iteration 477, loss = 497315565.28784144\n",
            "Iteration 478, loss = 495122411.40488625\n",
            "Iteration 479, loss = 492902657.19490373\n",
            "Iteration 480, loss = 490651212.85172772\n",
            "Iteration 481, loss = 488439083.93060207\n",
            "Iteration 482, loss = 486255160.29788172\n",
            "Iteration 483, loss = 484026322.46336323\n",
            "Iteration 484, loss = 481862210.68591702\n",
            "Iteration 485, loss = 479687672.66025233\n",
            "Iteration 486, loss = 477492103.68250120\n",
            "Iteration 487, loss = 475316271.97625089\n",
            "Iteration 488, loss = 473188288.79559213\n",
            "Iteration 489, loss = 471021826.24061882\n",
            "Iteration 490, loss = 468871772.41478997\n",
            "Iteration 491, loss = 466688488.92635185\n",
            "Iteration 492, loss = 464563041.54408073\n",
            "Iteration 493, loss = 462429888.66760033\n",
            "Iteration 494, loss = 460279588.78104645\n",
            "Iteration 495, loss = 458157662.79595596\n",
            "Iteration 496, loss = 456066786.89576995\n",
            "Iteration 497, loss = 453912641.22685200\n",
            "Iteration 498, loss = 451851479.84129447\n",
            "Iteration 499, loss = 449752316.72568691\n",
            "Iteration 500, loss = 447682229.07510024\n",
            "Iteration 501, loss = 445612839.10849005\n",
            "Iteration 502, loss = 443539536.23681098\n",
            "Iteration 503, loss = 441472992.64283007\n",
            "Iteration 504, loss = 439400754.57783306\n",
            "Iteration 505, loss = 437360041.39300060\n",
            "Iteration 506, loss = 435309788.74521893\n",
            "Iteration 507, loss = 433288031.99282062\n",
            "Iteration 508, loss = 431258379.93867594\n",
            "Iteration 509, loss = 429255743.43636662\n",
            "Iteration 510, loss = 427231376.28100282\n",
            "Iteration 511, loss = 425215251.94955629\n",
            "Iteration 512, loss = 423264432.97735840\n",
            "Iteration 513, loss = 421274723.55985230\n",
            "Iteration 514, loss = 419303369.09791142\n",
            "Iteration 515, loss = 417319366.52590108\n",
            "Iteration 516, loss = 415380050.00518507\n",
            "Iteration 517, loss = 413422166.34471488\n",
            "Iteration 518, loss = 411471290.83076084\n",
            "Iteration 519, loss = 409518877.55235773\n",
            "Iteration 520, loss = 407557361.52145791\n",
            "Iteration 521, loss = 405615339.83924508\n",
            "Iteration 522, loss = 403627819.39118516\n",
            "Iteration 523, loss = 401692955.67185748\n",
            "Iteration 524, loss = 399742975.13414598\n",
            "Iteration 525, loss = 397817785.51437467\n",
            "Iteration 526, loss = 395878578.51103449\n",
            "Iteration 527, loss = 394017237.21911508\n",
            "Iteration 528, loss = 392069420.52152956\n",
            "Iteration 529, loss = 390195118.62418962\n",
            "Iteration 530, loss = 388353157.02331370\n",
            "Iteration 531, loss = 386484313.48512834\n",
            "Iteration 532, loss = 384631253.14360893\n",
            "Iteration 533, loss = 382805417.32737041\n",
            "Iteration 534, loss = 380988007.10020465\n",
            "Iteration 535, loss = 379182119.69059831\n",
            "Iteration 536, loss = 377352017.81854242\n",
            "Iteration 537, loss = 375584763.46875453\n",
            "Iteration 538, loss = 373764662.20748675\n",
            "Iteration 539, loss = 371996929.98711139\n",
            "Iteration 540, loss = 370213999.85933357\n",
            "Iteration 541, loss = 368425118.86430973\n",
            "Iteration 542, loss = 366652977.70748985\n",
            "Iteration 543, loss = 364910021.96715468\n",
            "Iteration 544, loss = 363155365.69746745\n",
            "Iteration 545, loss = 361393022.37227499\n",
            "Iteration 546, loss = 359717592.25373244\n",
            "Iteration 547, loss = 357939817.64797902\n",
            "Iteration 548, loss = 356266859.85647655\n",
            "Iteration 549, loss = 354565247.53126580\n",
            "Iteration 550, loss = 352842698.44373727\n",
            "Iteration 551, loss = 351201108.02107441\n",
            "Iteration 552, loss = 349492603.53462225\n",
            "Iteration 553, loss = 347845741.04315782\n",
            "Iteration 554, loss = 346211163.41821200\n",
            "Iteration 555, loss = 344559538.98116010\n",
            "Iteration 556, loss = 342931999.49496597\n",
            "Iteration 557, loss = 341327028.56347108\n",
            "Iteration 558, loss = 339686540.59546608\n",
            "Iteration 559, loss = 338121747.91000783\n",
            "Iteration 560, loss = 336467444.15762985\n",
            "Iteration 561, loss = 334874077.18903089\n",
            "Iteration 562, loss = 333297388.14109701\n",
            "Iteration 563, loss = 331668327.57186329\n",
            "Iteration 564, loss = 330080078.84488022\n",
            "Iteration 565, loss = 328497457.93884146\n",
            "Iteration 566, loss = 326914153.61580509\n",
            "Iteration 567, loss = 325352823.68609786\n",
            "Iteration 568, loss = 323781036.47855800\n",
            "Iteration 569, loss = 322258580.77337873\n",
            "Iteration 570, loss = 320687786.28201538\n",
            "Iteration 571, loss = 319179094.65655899\n",
            "Iteration 572, loss = 317664443.52346325\n",
            "Iteration 573, loss = 316141497.83397365\n",
            "Iteration 574, loss = 314618007.11277431\n",
            "Iteration 575, loss = 313145980.83437234\n",
            "Iteration 576, loss = 311653191.05685794\n",
            "Iteration 577, loss = 310144059.76394749\n",
            "Iteration 578, loss = 308678534.64813256\n",
            "Iteration 579, loss = 307214143.42573601\n",
            "Iteration 580, loss = 305752084.30634630\n",
            "Iteration 581, loss = 304278695.09739155\n",
            "Iteration 582, loss = 302859974.28500134\n",
            "Iteration 583, loss = 301395543.91722631\n",
            "Iteration 584, loss = 299955299.00690621\n",
            "Iteration 585, loss = 298520262.32451850\n",
            "Iteration 586, loss = 297120790.30794662\n",
            "Iteration 587, loss = 295678288.79877234\n",
            "Iteration 588, loss = 294264551.79538280\n",
            "Iteration 589, loss = 292865302.06223959\n",
            "Iteration 590, loss = 291477076.77485102\n",
            "Iteration 591, loss = 290062891.92350215\n",
            "Iteration 592, loss = 288688266.49999607\n",
            "Iteration 593, loss = 287304909.38337171\n",
            "Iteration 594, loss = 285938269.53431487\n",
            "Iteration 595, loss = 284571612.09733319\n",
            "Iteration 596, loss = 283212707.79178560\n",
            "Iteration 597, loss = 281864616.95869410\n",
            "Iteration 598, loss = 280529450.26556289\n",
            "Iteration 599, loss = 279186145.64417678\n",
            "Iteration 600, loss = 277863572.43500453\n",
            "Iteration 601, loss = 276518556.78236336\n",
            "Iteration 602, loss = 275193626.94653183\n",
            "Iteration 603, loss = 273875478.79059130\n",
            "Iteration 604, loss = 272554945.70230806\n",
            "Iteration 605, loss = 271237242.96811187\n",
            "Iteration 606, loss = 269928321.76069361\n",
            "Iteration 607, loss = 268641838.37764496\n",
            "Iteration 608, loss = 267363518.83716378\n",
            "Iteration 609, loss = 266095077.23129237\n",
            "Iteration 610, loss = 264832053.62654391\n",
            "Iteration 611, loss = 263576156.54705349\n",
            "Iteration 612, loss = 262343649.57024896\n",
            "Iteration 613, loss = 261137693.00359288\n",
            "Iteration 614, loss = 259886524.16283038\n",
            "Iteration 615, loss = 258691599.93541035\n",
            "Iteration 616, loss = 257507499.55158517\n",
            "Iteration 617, loss = 256307012.38383022\n",
            "Iteration 618, loss = 255121461.27370983\n",
            "Iteration 619, loss = 253922535.39861867\n",
            "Iteration 620, loss = 252772166.25576904\n",
            "Iteration 621, loss = 251588605.13909674\n",
            "Iteration 622, loss = 250430220.87709007\n",
            "Iteration 623, loss = 249259046.47042486\n",
            "Iteration 624, loss = 248116708.49943566\n",
            "Iteration 625, loss = 246969396.84629318\n",
            "Iteration 626, loss = 245828700.04630926\n",
            "Iteration 627, loss = 244711734.26009646\n",
            "Iteration 628, loss = 243571609.54897171\n",
            "Iteration 629, loss = 242463494.72695911\n",
            "Iteration 630, loss = 241335977.95980415\n",
            "Iteration 631, loss = 240242070.03696436\n",
            "Iteration 632, loss = 239151785.50884849\n",
            "Iteration 633, loss = 238054005.18936864\n",
            "Iteration 634, loss = 236972777.52990705\n",
            "Iteration 635, loss = 235897941.40291402\n",
            "Iteration 636, loss = 234821596.76292643\n",
            "Iteration 637, loss = 233765022.56703225\n",
            "Iteration 638, loss = 232706713.06099260\n",
            "Iteration 639, loss = 231643333.09545851\n",
            "Iteration 640, loss = 230601075.59383002\n",
            "Iteration 641, loss = 229575978.00672176\n",
            "Iteration 642, loss = 228530706.41501614\n",
            "Iteration 643, loss = 227519386.26269940\n",
            "Iteration 644, loss = 226498440.61256424\n",
            "Iteration 645, loss = 225478418.10087958\n",
            "Iteration 646, loss = 224482576.95829588\n",
            "Iteration 647, loss = 223500735.40975165\n",
            "Iteration 648, loss = 222484823.18280914\n",
            "Iteration 649, loss = 221503205.74238202\n",
            "Iteration 650, loss = 220513687.35858923\n",
            "Iteration 651, loss = 219545513.59412265\n",
            "Iteration 652, loss = 218570787.55208901\n",
            "Iteration 653, loss = 217606856.38095567\n",
            "Iteration 654, loss = 216602186.13833466\n",
            "Iteration 655, loss = 215678651.44288310\n",
            "Iteration 656, loss = 214709187.51853836\n",
            "Iteration 657, loss = 213770925.01188296\n",
            "Iteration 658, loss = 212813287.13565743\n",
            "Iteration 659, loss = 211880690.35674950\n",
            "Iteration 660, loss = 210962925.92034116\n",
            "Iteration 661, loss = 210025392.07955056\n",
            "Iteration 662, loss = 209112807.26451918\n",
            "Iteration 663, loss = 208210370.46862513\n",
            "Iteration 664, loss = 207276308.14781964\n",
            "Iteration 665, loss = 206380081.85719091\n",
            "Iteration 666, loss = 205505197.86411422\n",
            "Iteration 667, loss = 204596703.00919983\n",
            "Iteration 668, loss = 203705510.85942268\n",
            "Iteration 669, loss = 202827083.03879744\n",
            "Iteration 670, loss = 201932447.56635755\n",
            "Iteration 671, loss = 201066814.21185514\n",
            "Iteration 672, loss = 200161270.75038823\n",
            "Iteration 673, loss = 199291295.08126035\n",
            "Iteration 674, loss = 198418131.71619004\n",
            "Iteration 675, loss = 197540088.57674018\n",
            "Iteration 676, loss = 196681168.33163470\n",
            "Iteration 677, loss = 195835622.71335211\n",
            "Iteration 678, loss = 194959714.78980222\n",
            "Iteration 679, loss = 194131484.73824039\n",
            "Iteration 680, loss = 193309364.98988238\n",
            "Iteration 681, loss = 192461775.54848030\n",
            "Iteration 682, loss = 191643507.81651628\n",
            "Iteration 683, loss = 190820159.59529805\n",
            "Iteration 684, loss = 190018054.38968134\n",
            "Iteration 685, loss = 189215735.80405208\n",
            "Iteration 686, loss = 188392768.67116427\n",
            "Iteration 687, loss = 187610127.71848556\n",
            "Iteration 688, loss = 186834570.22699484\n",
            "Iteration 689, loss = 186048189.03369942\n",
            "Iteration 690, loss = 185282706.39063662\n",
            "Iteration 691, loss = 184506994.55093288\n",
            "Iteration 692, loss = 183749708.54939508\n",
            "Iteration 693, loss = 182995162.19454646\n",
            "Iteration 694, loss = 182247790.94847617\n",
            "Iteration 695, loss = 181499706.05057013\n",
            "Iteration 696, loss = 180777016.97046605\n",
            "Iteration 697, loss = 180036473.50500056\n",
            "Iteration 698, loss = 179324539.17565697\n",
            "Iteration 699, loss = 178603332.85389271\n",
            "Iteration 700, loss = 177891150.53123900\n",
            "Iteration 701, loss = 177167202.17110717\n",
            "Iteration 702, loss = 176481681.32631212\n",
            "Iteration 703, loss = 175772821.44709200\n",
            "Iteration 704, loss = 175065918.91999140\n",
            "Iteration 705, loss = 174372462.05693159\n",
            "Iteration 706, loss = 173682952.47377822\n",
            "Iteration 707, loss = 173003551.96404421\n",
            "Iteration 708, loss = 172306721.00793859\n",
            "Iteration 709, loss = 171621770.05007538\n",
            "Iteration 710, loss = 170950334.90237355\n",
            "Iteration 711, loss = 170271964.53404853\n",
            "Iteration 712, loss = 169618138.99187493\n",
            "Iteration 713, loss = 168954801.16322687\n",
            "Iteration 714, loss = 168296380.24744445\n",
            "Iteration 715, loss = 167641015.74620157\n",
            "Iteration 716, loss = 167013749.02760133\n",
            "Iteration 717, loss = 166369457.57642141\n",
            "Iteration 718, loss = 165736788.29052845\n",
            "Iteration 719, loss = 165090155.51636043\n",
            "Iteration 720, loss = 164473249.61103901\n",
            "Iteration 721, loss = 163840781.71183899\n",
            "Iteration 722, loss = 163217725.72465435\n",
            "Iteration 723, loss = 162588754.50755569\n",
            "Iteration 724, loss = 161978946.64047122\n",
            "Iteration 725, loss = 161370068.19041255\n",
            "Iteration 726, loss = 160752556.95518622\n",
            "Iteration 727, loss = 160167608.98763055\n",
            "Iteration 728, loss = 159562012.53732124\n",
            "Iteration 729, loss = 158965643.77712649\n",
            "Iteration 730, loss = 158389521.22653899\n",
            "Iteration 731, loss = 157803108.28691909\n",
            "Iteration 732, loss = 157228017.22568154\n",
            "Iteration 733, loss = 156659415.08551055\n",
            "Iteration 734, loss = 156085903.66548982\n",
            "Iteration 735, loss = 155528303.43614659\n",
            "Iteration 736, loss = 154973991.91932771\n",
            "Iteration 737, loss = 154411590.35876581\n",
            "Iteration 738, loss = 153881503.61542550\n",
            "Iteration 739, loss = 153338829.14471349\n",
            "Iteration 740, loss = 152786639.93090832\n",
            "Iteration 741, loss = 152272712.72281986\n",
            "Iteration 742, loss = 151743165.74897465\n",
            "Iteration 743, loss = 151220310.96551353\n",
            "Iteration 744, loss = 150704040.91628411\n",
            "Iteration 745, loss = 150192245.96022004\n",
            "Iteration 746, loss = 149691567.94477016\n",
            "Iteration 747, loss = 149178556.75352299\n",
            "Iteration 748, loss = 148681084.38357598\n",
            "Iteration 749, loss = 148184896.66769710\n",
            "Iteration 750, loss = 147698644.65513477\n",
            "Iteration 751, loss = 147202012.64619121\n",
            "Iteration 752, loss = 146720838.82451802\n",
            "Iteration 753, loss = 146238862.46062857\n",
            "Iteration 754, loss = 145772011.75408426\n",
            "Iteration 755, loss = 145294442.07248941\n",
            "Iteration 756, loss = 144825152.31868687\n",
            "Iteration 757, loss = 144362936.06872672\n",
            "Iteration 758, loss = 143896225.14690033\n",
            "Iteration 759, loss = 143436313.20135316\n",
            "Iteration 760, loss = 142981810.50631043\n",
            "Iteration 761, loss = 142513532.55496463\n",
            "Iteration 762, loss = 142067851.61317837\n",
            "Iteration 763, loss = 141620089.96577907\n",
            "Iteration 764, loss = 141181883.48454547\n",
            "Iteration 765, loss = 140742959.06565377\n",
            "Iteration 766, loss = 140313544.80527505\n",
            "Iteration 767, loss = 139873967.69970968\n",
            "Iteration 768, loss = 139458248.21011764\n",
            "Iteration 769, loss = 139024376.00327504\n",
            "Iteration 770, loss = 138604602.50778687\n",
            "Iteration 771, loss = 138177866.67983842\n",
            "Iteration 772, loss = 137742800.18671274\n",
            "Iteration 773, loss = 137335726.60153326\n",
            "Iteration 774, loss = 136913449.54125187\n",
            "Iteration 775, loss = 136493779.45699042\n",
            "Iteration 776, loss = 136080088.61902210\n",
            "Iteration 777, loss = 135670159.10706514\n",
            "Iteration 778, loss = 135274038.77480432\n",
            "Iteration 779, loss = 134875743.59402311\n",
            "Iteration 780, loss = 134476283.86906821\n",
            "Iteration 781, loss = 134078157.11112304\n",
            "Iteration 782, loss = 133692131.39154381\n",
            "Iteration 783, loss = 133304324.59628679\n",
            "Iteration 784, loss = 132918079.22231776\n",
            "Iteration 785, loss = 132541850.93997677\n",
            "Iteration 786, loss = 132159300.32277538\n",
            "Iteration 787, loss = 131782562.87045282\n",
            "Iteration 788, loss = 131417457.64748782\n",
            "Iteration 789, loss = 131039750.58535762\n",
            "Iteration 790, loss = 130674712.66163106\n",
            "Iteration 791, loss = 130295895.98114643\n",
            "Iteration 792, loss = 129941309.11776108\n",
            "Iteration 793, loss = 129581669.64250879\n",
            "Iteration 794, loss = 129217586.06695715\n",
            "Iteration 795, loss = 128864388.10358605\n",
            "Iteration 796, loss = 128509228.26006329\n",
            "Iteration 797, loss = 128167954.79200698\n",
            "Iteration 798, loss = 127827650.69062200\n",
            "Iteration 799, loss = 127490325.33982830\n",
            "Iteration 800, loss = 127159385.67890106\n",
            "Iteration 801, loss = 126826567.63227800\n",
            "Iteration 802, loss = 126499344.13847981\n",
            "Iteration 803, loss = 126180907.30843660\n",
            "Iteration 804, loss = 125864813.91805570\n",
            "Iteration 805, loss = 125542660.87576348\n",
            "Iteration 806, loss = 125215123.40510239\n",
            "Iteration 807, loss = 124913885.29430974\n",
            "Iteration 808, loss = 124591388.43713962\n",
            "Iteration 809, loss = 124280728.45687562\n",
            "Iteration 810, loss = 123969614.08264583\n",
            "Iteration 811, loss = 123665211.83100046\n",
            "Iteration 812, loss = 123352639.44948944\n",
            "Iteration 813, loss = 123050721.15309180\n",
            "Iteration 814, loss = 122742716.65115769\n",
            "Iteration 815, loss = 122446657.85444105\n",
            "Iteration 816, loss = 122149039.57767615\n",
            "Iteration 817, loss = 121845291.08648179\n",
            "Iteration 818, loss = 121551961.97493041\n",
            "Iteration 819, loss = 121259108.89570566\n",
            "Iteration 820, loss = 120967167.95102479\n",
            "Iteration 821, loss = 120682905.10909511\n",
            "Iteration 822, loss = 120390079.76915623\n",
            "Iteration 823, loss = 120113504.10984337\n",
            "Iteration 824, loss = 119823630.97245926\n",
            "Iteration 825, loss = 119544207.84205014\n",
            "Iteration 826, loss = 119272438.71625002\n",
            "Iteration 827, loss = 118992697.87319866\n",
            "Iteration 828, loss = 118723748.88913989\n",
            "Iteration 829, loss = 118445123.33642085\n",
            "Iteration 830, loss = 118180162.32298785\n",
            "Iteration 831, loss = 117904813.87704939\n",
            "Iteration 832, loss = 117647007.19876266\n",
            "Iteration 833, loss = 117375129.32142332\n",
            "Iteration 834, loss = 117111366.71971516\n",
            "Iteration 835, loss = 116847089.05804360\n",
            "Iteration 836, loss = 116583745.78412300\n",
            "Iteration 837, loss = 116329610.66090900\n",
            "Iteration 838, loss = 116067763.93816112\n",
            "Iteration 839, loss = 115815986.56374460\n",
            "Iteration 840, loss = 115568749.16416088\n",
            "Iteration 841, loss = 115325932.59405982\n",
            "Iteration 842, loss = 115079371.40310952\n",
            "Iteration 843, loss = 114843318.75737831\n",
            "Iteration 844, loss = 114602644.83460076\n",
            "Iteration 845, loss = 114371178.28151430\n",
            "Iteration 846, loss = 114133907.38745818\n",
            "Iteration 847, loss = 113905360.92896545\n",
            "Iteration 848, loss = 113672799.59755065\n",
            "Iteration 849, loss = 113445759.34300816\n",
            "Iteration 850, loss = 113207484.95088084\n",
            "Iteration 851, loss = 112975692.86770436\n",
            "Iteration 852, loss = 112753140.86492977\n",
            "Iteration 853, loss = 112515436.88087633\n",
            "Iteration 854, loss = 112295905.86152755\n",
            "Iteration 855, loss = 112061661.76823047\n",
            "Iteration 856, loss = 111838944.37078248\n",
            "Iteration 857, loss = 111618097.48843929\n",
            "Iteration 858, loss = 111394958.46515231\n",
            "Iteration 859, loss = 111177121.25188571\n",
            "Iteration 860, loss = 110962920.99288604\n",
            "Iteration 861, loss = 110743164.51519369\n",
            "Iteration 862, loss = 110526322.94361073\n",
            "Iteration 863, loss = 110317346.11902867\n",
            "Iteration 864, loss = 110106956.54786041\n",
            "Iteration 865, loss = 109893766.53307962\n",
            "Iteration 866, loss = 109684445.89531374\n",
            "Iteration 867, loss = 109477715.10374504\n",
            "Iteration 868, loss = 109278545.82751536\n",
            "Iteration 869, loss = 109068802.15490672\n",
            "Iteration 870, loss = 108872434.89498334\n",
            "Iteration 871, loss = 108675408.77592304\n",
            "Iteration 872, loss = 108475049.71427986\n",
            "Iteration 873, loss = 108285721.51725668\n",
            "Iteration 874, loss = 108089548.43653198\n",
            "Iteration 875, loss = 107900625.09939185\n",
            "Iteration 876, loss = 107707149.24035177\n",
            "Iteration 877, loss = 107516041.36945875\n",
            "Iteration 878, loss = 107330705.10801797\n",
            "Iteration 879, loss = 107136165.97207566\n",
            "Iteration 880, loss = 106949718.23398143\n",
            "Iteration 881, loss = 106760941.03873074\n",
            "Iteration 882, loss = 106584557.99071038\n",
            "Iteration 883, loss = 106399963.95247526\n",
            "Iteration 884, loss = 106215681.62192234\n",
            "Iteration 885, loss = 106036331.74809860\n",
            "Iteration 886, loss = 105867232.66793486\n",
            "Iteration 887, loss = 105681495.04818083\n",
            "Iteration 888, loss = 105513501.69394863\n",
            "Iteration 889, loss = 105336657.22726645\n",
            "Iteration 890, loss = 105161141.31495145\n",
            "Iteration 891, loss = 104985026.50715625\n",
            "Iteration 892, loss = 104808116.10178089\n",
            "Iteration 893, loss = 104637122.15855753\n",
            "Iteration 894, loss = 104463124.52237064\n",
            "Iteration 895, loss = 104284604.85476840\n",
            "Iteration 896, loss = 104110239.21137497\n",
            "Iteration 897, loss = 103938931.37325723\n",
            "Iteration 898, loss = 103769997.53158586\n",
            "Iteration 899, loss = 103596371.31334814\n",
            "Iteration 900, loss = 103422295.30515501\n",
            "Iteration 901, loss = 103261839.64989473\n",
            "Iteration 902, loss = 103080131.43289667\n",
            "Iteration 903, loss = 102919428.38770752\n",
            "Iteration 904, loss = 102751516.65494426\n",
            "Iteration 905, loss = 102583187.81404664\n",
            "Iteration 906, loss = 102417918.41107513\n",
            "Iteration 907, loss = 102252688.60448579\n",
            "Iteration 908, loss = 102099618.92242815\n",
            "Iteration 909, loss = 101928377.89712828\n",
            "Iteration 910, loss = 101771151.79513082\n",
            "Iteration 911, loss = 101615378.50282767\n",
            "Iteration 912, loss = 101448663.72093605\n",
            "Iteration 913, loss = 101300257.78009468\n",
            "Iteration 914, loss = 101140232.81440906\n",
            "Iteration 915, loss = 100982230.53095208\n",
            "Iteration 916, loss = 100826214.76407446\n",
            "Iteration 917, loss = 100668878.31787707\n",
            "Iteration 918, loss = 100508517.79721469\n",
            "Iteration 919, loss = 100347677.90522072\n",
            "Iteration 920, loss = 100191620.23832610\n",
            "Iteration 921, loss = 100027503.82127884\n",
            "Iteration 922, loss = 99866372.11987224\n",
            "Iteration 923, loss = 99711907.47360361\n",
            "Iteration 924, loss = 99552850.60632627\n",
            "Iteration 925, loss = 99391488.34121464\n",
            "Iteration 926, loss = 99238080.42490530\n",
            "Iteration 927, loss = 99080328.83849420\n",
            "Iteration 928, loss = 98921868.29785487\n",
            "Iteration 929, loss = 98771371.76616234\n",
            "Iteration 930, loss = 98610279.54371925\n",
            "Iteration 931, loss = 98463379.19213849\n",
            "Iteration 932, loss = 98305342.54580216\n",
            "Iteration 933, loss = 98156005.44474709\n",
            "Iteration 934, loss = 98009966.94792573\n",
            "Iteration 935, loss = 97854804.75698082\n",
            "Iteration 936, loss = 97703806.79356411\n",
            "Iteration 937, loss = 97560190.72222422\n",
            "Iteration 938, loss = 97412880.16734859\n",
            "Iteration 939, loss = 97263035.68651526\n",
            "Iteration 940, loss = 97119030.03579441\n",
            "Iteration 941, loss = 96973812.27843913\n",
            "Iteration 942, loss = 96833000.15899016\n",
            "Iteration 943, loss = 96689020.01194207\n",
            "Iteration 944, loss = 96545928.25793371\n",
            "Iteration 945, loss = 96405730.44823109\n",
            "Iteration 946, loss = 96267020.40935415\n",
            "Iteration 947, loss = 96123857.17892143\n",
            "Iteration 948, loss = 95987635.66546190\n",
            "Iteration 949, loss = 95847764.59917718\n",
            "Iteration 950, loss = 95711989.41387911\n",
            "Iteration 951, loss = 95568238.12888613\n",
            "Iteration 952, loss = 95436449.84476925\n",
            "Iteration 953, loss = 95292580.44787106\n",
            "Iteration 954, loss = 95155092.96507190\n",
            "Iteration 955, loss = 95019019.82967149\n",
            "Iteration 956, loss = 94873339.43433401\n",
            "Iteration 957, loss = 94737179.36108564\n",
            "Iteration 958, loss = 94592432.23622683\n",
            "Iteration 959, loss = 94451537.85035555\n",
            "Iteration 960, loss = 94311343.41149794\n",
            "Iteration 961, loss = 94169755.07324874\n",
            "Iteration 962, loss = 94022564.26234029\n",
            "Iteration 963, loss = 93879510.54446645\n",
            "Iteration 964, loss = 93733915.45125426\n",
            "Iteration 965, loss = 93591284.90088169\n",
            "Iteration 966, loss = 93447216.86414458\n",
            "Iteration 967, loss = 93301032.20524608\n",
            "Iteration 968, loss = 93164900.85247730\n",
            "Iteration 969, loss = 93021962.11399782\n",
            "Iteration 970, loss = 92888347.48278736\n",
            "Iteration 971, loss = 92751067.36862446\n",
            "Iteration 972, loss = 92608639.90036342\n",
            "Iteration 973, loss = 92478163.56282848\n",
            "Iteration 974, loss = 92341580.81812078\n",
            "Iteration 975, loss = 92202511.72063768\n",
            "Iteration 976, loss = 92065818.41303594\n",
            "Iteration 977, loss = 91927177.00277735\n",
            "Iteration 978, loss = 91783181.00506772\n",
            "Iteration 979, loss = 91646864.16195253\n",
            "Iteration 980, loss = 91509849.85163359\n",
            "Iteration 981, loss = 91365414.44573455\n",
            "Iteration 982, loss = 91228521.09575960\n",
            "Iteration 983, loss = 91086081.37104808\n",
            "Iteration 984, loss = 90944915.23560631\n",
            "Iteration 985, loss = 90806907.11180387\n",
            "Iteration 986, loss = 90667091.26107813\n",
            "Iteration 987, loss = 90527254.04010050\n",
            "Iteration 988, loss = 90386928.64151417\n",
            "Iteration 989, loss = 90248274.31056188\n",
            "Iteration 990, loss = 90109705.18625830\n",
            "Iteration 991, loss = 89968260.10662369\n",
            "Iteration 992, loss = 89828200.01310357\n",
            "Iteration 993, loss = 89686745.46965460\n",
            "Iteration 994, loss = 89542747.98618661\n",
            "Iteration 995, loss = 89413115.54385087\n",
            "Iteration 996, loss = 89264481.91767229\n",
            "Iteration 997, loss = 89126669.43211134\n",
            "Iteration 998, loss = 88989942.81489298\n",
            "Iteration 999, loss = 88855716.54881169\n",
            "Iteration 1000, loss = 88721708.90333408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 52783266921.26831055\n",
            "Iteration 2, loss = 687451931626862868622097858014097760987560231687314829184765171324313141248.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (100,), relu, 0.01, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538833954.97694421\n",
            "Iteration 2, loss = 1538804823.30092955\n",
            "Iteration 3, loss = 1538775304.92999363\n",
            "Iteration 4, loss = 1538743891.68804502\n",
            "Iteration 5, loss = 1538709500.29565525\n",
            "Iteration 6, loss = 1538671090.94687366\n",
            "Iteration 7, loss = 1538628032.98420739\n",
            "Iteration 8, loss = 1538579769.73492670\n",
            "Iteration 9, loss = 1538525299.97655392\n",
            "Iteration 10, loss = 1538464799.32110190\n",
            "Iteration 11, loss = 1538396372.80940652\n",
            "Iteration 12, loss = 1538320455.76585507\n",
            "Iteration 13, loss = 1538236049.16157150\n",
            "Iteration 14, loss = 1538144078.39154387\n",
            "Iteration 15, loss = 1538041035.66304874\n",
            "Iteration 16, loss = 1537929777.77285480\n",
            "Iteration 17, loss = 1537806786.82473135\n",
            "Iteration 18, loss = 1537675040.53968167\n",
            "Iteration 19, loss = 1537532720.43222713\n",
            "Iteration 20, loss = 1537377254.48830867\n",
            "Iteration 21, loss = 1537211969.82775617\n",
            "Iteration 22, loss = 1537033395.77238107\n",
            "Iteration 23, loss = 1536844054.48559904\n",
            "Iteration 24, loss = 1536640111.15356684\n",
            "Iteration 25, loss = 1536425658.91372037\n",
            "Iteration 26, loss = 1536197979.12274528\n",
            "Iteration 27, loss = 1535955771.12247896\n",
            "Iteration 28, loss = 1535699605.44499636\n",
            "Iteration 29, loss = 1535430203.31683755\n",
            "Iteration 30, loss = 1535149553.52678251\n",
            "Iteration 31, loss = 1534852329.44741869\n",
            "Iteration 32, loss = 1534540737.20407319\n",
            "Iteration 33, loss = 1534213668.78820944\n",
            "Iteration 34, loss = 1533870542.56439042\n",
            "Iteration 35, loss = 1533515307.69952583\n",
            "Iteration 36, loss = 1533142407.08184409\n",
            "Iteration 37, loss = 1532755240.40994287\n",
            "Iteration 38, loss = 1532350373.01238418\n",
            "Iteration 39, loss = 1531929258.51614785\n",
            "Iteration 40, loss = 1531495110.57670736\n",
            "Iteration 41, loss = 1531042100.81126857\n",
            "Iteration 42, loss = 1530575207.64435172\n",
            "Iteration 43, loss = 1530093975.46507668\n",
            "Iteration 44, loss = 1529593194.29441428\n",
            "Iteration 45, loss = 1529077585.96547937\n",
            "Iteration 46, loss = 1528550678.33911562\n",
            "Iteration 47, loss = 1528001395.32622290\n",
            "Iteration 48, loss = 1527444006.33526802\n",
            "Iteration 49, loss = 1526864486.60453415\n",
            "Iteration 50, loss = 1526271520.76373482\n",
            "Iteration 51, loss = 1525655768.22041440\n",
            "Iteration 52, loss = 1525033931.13383055\n",
            "Iteration 53, loss = 1524391261.21519637\n",
            "Iteration 54, loss = 1523721670.80922484\n",
            "Iteration 55, loss = 1523050469.50176406\n",
            "Iteration 56, loss = 1522355386.88509321\n",
            "Iteration 57, loss = 1521646149.39491463\n",
            "Iteration 58, loss = 1520920583.69659328\n",
            "Iteration 59, loss = 1520176150.80368900\n",
            "Iteration 60, loss = 1519421087.09068441\n",
            "Iteration 61, loss = 1518648748.08902287\n",
            "Iteration 62, loss = 1517860909.70579839\n",
            "Iteration 63, loss = 1517054265.49452591\n",
            "Iteration 64, loss = 1516235303.32453918\n",
            "Iteration 65, loss = 1515402768.44208264\n",
            "Iteration 66, loss = 1514552174.24725795\n",
            "Iteration 67, loss = 1513690245.76002574\n",
            "Iteration 68, loss = 1512804530.81882215\n",
            "Iteration 69, loss = 1511918478.30094981\n",
            "Iteration 70, loss = 1511006304.09158969\n",
            "Iteration 71, loss = 1510080294.61183381\n",
            "Iteration 72, loss = 1509134628.31994987\n",
            "Iteration 73, loss = 1508182017.38062596\n",
            "Iteration 74, loss = 1507209673.77412271\n",
            "Iteration 75, loss = 1506214784.41976857\n",
            "Iteration 76, loss = 1505211155.37070274\n",
            "Iteration 77, loss = 1504192072.39865255\n",
            "Iteration 78, loss = 1503146486.76860380\n",
            "Iteration 79, loss = 1502097040.50797033\n",
            "Iteration 80, loss = 1501035111.40806866\n",
            "Iteration 81, loss = 1499947824.44297576\n",
            "Iteration 82, loss = 1498847807.07400155\n",
            "Iteration 83, loss = 1497739707.98262954\n",
            "Iteration 84, loss = 1496621720.16965055\n",
            "Iteration 85, loss = 1495472791.08947206\n",
            "Iteration 86, loss = 1494320248.06551814\n",
            "Iteration 87, loss = 1493143533.54782867\n",
            "Iteration 88, loss = 1491959947.16996527\n",
            "Iteration 89, loss = 1490759598.74276614\n",
            "Iteration 90, loss = 1489538460.24098229\n",
            "Iteration 91, loss = 1488298648.72001457\n",
            "Iteration 92, loss = 1487045763.33977509\n",
            "Iteration 93, loss = 1485779721.49390364\n",
            "Iteration 94, loss = 1484498260.65005374\n",
            "Iteration 95, loss = 1483197594.65147281\n",
            "Iteration 96, loss = 1481880823.82528377\n",
            "Iteration 97, loss = 1480551598.34922886\n",
            "Iteration 98, loss = 1479210015.64567995\n",
            "Iteration 99, loss = 1477856480.55060697\n",
            "Iteration 100, loss = 1476473543.68774509\n",
            "Iteration 101, loss = 1475085599.01487541\n",
            "Iteration 102, loss = 1473682902.72251964\n",
            "Iteration 103, loss = 1472265111.01923084\n",
            "Iteration 104, loss = 1470835112.44874930\n",
            "Iteration 105, loss = 1469384737.49374771\n",
            "Iteration 106, loss = 1467915549.26291323\n",
            "Iteration 107, loss = 1466436904.91780806\n",
            "Iteration 108, loss = 1464962506.92586350\n",
            "Iteration 109, loss = 1463438282.30663204\n",
            "Iteration 110, loss = 1461928891.89978075\n",
            "Iteration 111, loss = 1460398529.03550005\n",
            "Iteration 112, loss = 1458835111.83069658\n",
            "Iteration 113, loss = 1457300736.21748471\n",
            "Iteration 114, loss = 1455713210.57971621\n",
            "Iteration 115, loss = 1454128222.95780587\n",
            "Iteration 116, loss = 1452514817.30446696\n",
            "Iteration 117, loss = 1450903567.01725483\n",
            "Iteration 118, loss = 1449277645.49446630\n",
            "Iteration 119, loss = 1447626289.81461072\n",
            "Iteration 120, loss = 1445963209.04436016\n",
            "Iteration 121, loss = 1444292749.21785808\n",
            "Iteration 122, loss = 1442601607.57927966\n",
            "Iteration 123, loss = 1440902223.12999916\n",
            "Iteration 124, loss = 1439195403.58143735\n",
            "Iteration 125, loss = 1437477304.70160913\n",
            "Iteration 126, loss = 1435732273.80102777\n",
            "Iteration 127, loss = 1433995113.30281091\n",
            "Iteration 128, loss = 1432224580.18225026\n",
            "Iteration 129, loss = 1430465495.59109044\n",
            "Iteration 130, loss = 1428679296.54424381\n",
            "Iteration 131, loss = 1426877942.00326967\n",
            "Iteration 132, loss = 1425065659.71016955\n",
            "Iteration 133, loss = 1423238354.70981097\n",
            "Iteration 134, loss = 1421391481.31920576\n",
            "Iteration 135, loss = 1419571443.44479156\n",
            "Iteration 136, loss = 1417686823.01569963\n",
            "Iteration 137, loss = 1415815985.93429136\n",
            "Iteration 138, loss = 1413941637.59812880\n",
            "Iteration 139, loss = 1412045235.48281741\n",
            "Iteration 140, loss = 1410138663.27355313\n",
            "Iteration 141, loss = 1408203888.61362410\n",
            "Iteration 142, loss = 1406282049.94182301\n",
            "Iteration 143, loss = 1404318778.17242694\n",
            "Iteration 144, loss = 1402374181.37365365\n",
            "Iteration 145, loss = 1400396190.17439413\n",
            "Iteration 146, loss = 1398399788.33836722\n",
            "Iteration 147, loss = 1396420877.16337252\n",
            "Iteration 148, loss = 1394424098.29396272\n",
            "Iteration 149, loss = 1392410704.29813790\n",
            "Iteration 150, loss = 1390398766.36355734\n",
            "Iteration 151, loss = 1388362112.09137297\n",
            "Iteration 152, loss = 1386326299.54362082\n",
            "Iteration 153, loss = 1384268033.45120859\n",
            "Iteration 154, loss = 1382206485.72087145\n",
            "Iteration 155, loss = 1380144429.05011535\n",
            "Iteration 156, loss = 1378053190.14802170\n",
            "Iteration 157, loss = 1375950430.20879674\n",
            "Iteration 158, loss = 1373867300.98394108\n",
            "Iteration 159, loss = 1371724052.40603709\n",
            "Iteration 160, loss = 1369613425.66074371\n",
            "Iteration 161, loss = 1367477924.65246177\n",
            "Iteration 162, loss = 1365340327.69585705\n",
            "Iteration 163, loss = 1363177687.84501028\n",
            "Iteration 164, loss = 1361018199.36519361\n",
            "Iteration 165, loss = 1358852971.55715084\n",
            "Iteration 166, loss = 1356673443.24822569\n",
            "Iteration 167, loss = 1354486047.60252595\n",
            "Iteration 168, loss = 1352305295.21446967\n",
            "Iteration 169, loss = 1350079728.55452132\n",
            "Iteration 170, loss = 1347878153.19825745\n",
            "Iteration 171, loss = 1345625653.86927390\n",
            "Iteration 172, loss = 1343413977.14205694\n",
            "Iteration 173, loss = 1341143952.65728974\n",
            "Iteration 174, loss = 1338891892.99206233\n",
            "Iteration 175, loss = 1336609713.50938940\n",
            "Iteration 176, loss = 1334320016.79920268\n",
            "Iteration 177, loss = 1332020678.10382938\n",
            "Iteration 178, loss = 1329717818.43834043\n",
            "Iteration 179, loss = 1327413698.38807511\n",
            "Iteration 180, loss = 1325070786.38022423\n",
            "Iteration 181, loss = 1322751491.49157405\n",
            "Iteration 182, loss = 1320402234.09769583\n",
            "Iteration 183, loss = 1318071970.50296903\n",
            "Iteration 184, loss = 1315699149.25696993\n",
            "Iteration 185, loss = 1313355949.86684036\n",
            "Iteration 186, loss = 1310985254.98132634\n",
            "Iteration 187, loss = 1308599618.66059613\n",
            "Iteration 188, loss = 1306216747.69667888\n",
            "Iteration 189, loss = 1303837802.14225030\n",
            "Iteration 190, loss = 1301418746.57482767\n",
            "Iteration 191, loss = 1299022253.30947495\n",
            "Iteration 192, loss = 1296593248.68796611\n",
            "Iteration 193, loss = 1294166183.10376167\n",
            "Iteration 194, loss = 1291730734.42390537\n",
            "Iteration 195, loss = 1289281881.04707575\n",
            "Iteration 196, loss = 1286827651.24142289\n",
            "Iteration 197, loss = 1284364048.72755933\n",
            "Iteration 198, loss = 1281904635.24630070\n",
            "Iteration 199, loss = 1279427384.96594524\n",
            "Iteration 200, loss = 1276933207.20609808\n",
            "Iteration 201, loss = 1274476334.51742268\n",
            "Iteration 202, loss = 1271988724.76187754\n",
            "Iteration 203, loss = 1269478537.17969155\n",
            "Iteration 204, loss = 1266984077.75356627\n",
            "Iteration 205, loss = 1264475366.31961560\n",
            "Iteration 206, loss = 1261968980.31714749\n",
            "Iteration 207, loss = 1259429482.73675561\n",
            "Iteration 208, loss = 1256887356.66430593\n",
            "Iteration 209, loss = 1254348282.48838139\n",
            "Iteration 210, loss = 1251793230.13788986\n",
            "Iteration 211, loss = 1249251198.61454010\n",
            "Iteration 212, loss = 1246662199.80192065\n",
            "Iteration 213, loss = 1244087922.96739554\n",
            "Iteration 214, loss = 1241519569.92295742\n",
            "Iteration 215, loss = 1238920613.31643653\n",
            "Iteration 216, loss = 1236333888.36380696\n",
            "Iteration 217, loss = 1233739930.41235590\n",
            "Iteration 218, loss = 1231129453.17916822\n",
            "Iteration 219, loss = 1228545303.57293272\n",
            "Iteration 220, loss = 1225930134.98576617\n",
            "Iteration 221, loss = 1223312452.84693408\n",
            "Iteration 222, loss = 1220709134.49059391\n",
            "Iteration 223, loss = 1218109631.12235880\n",
            "Iteration 224, loss = 1215481353.54868221\n",
            "Iteration 225, loss = 1212841173.30192995\n",
            "Iteration 226, loss = 1210220677.59588408\n",
            "Iteration 227, loss = 1207601981.44866276\n",
            "Iteration 228, loss = 1204957024.67506528\n",
            "Iteration 229, loss = 1202300221.53434539\n",
            "Iteration 230, loss = 1199641609.98831081\n",
            "Iteration 231, loss = 1196997215.04921007\n",
            "Iteration 232, loss = 1194334565.49692321\n",
            "Iteration 233, loss = 1191662793.54520583\n",
            "Iteration 234, loss = 1188976903.59315658\n",
            "Iteration 235, loss = 1186297408.57176948\n",
            "Iteration 236, loss = 1183609232.55765271\n",
            "Iteration 237, loss = 1180912646.94798970\n",
            "Iteration 238, loss = 1178216055.77432990\n",
            "Iteration 239, loss = 1175485167.43231177\n",
            "Iteration 240, loss = 1172791861.69448566\n",
            "Iteration 241, loss = 1170071350.46294951\n",
            "Iteration 242, loss = 1167363177.09457278\n",
            "Iteration 243, loss = 1164632888.75576496\n",
            "Iteration 244, loss = 1161911215.02019954\n",
            "Iteration 245, loss = 1159200836.01492500\n",
            "Iteration 246, loss = 1156469322.18120527\n",
            "Iteration 247, loss = 1153748022.01523805\n",
            "Iteration 248, loss = 1151017892.33072424\n",
            "Iteration 249, loss = 1148308133.23381615\n",
            "Iteration 250, loss = 1145563507.83714843\n",
            "Iteration 251, loss = 1142821752.34200644\n",
            "Iteration 252, loss = 1140087057.28370833\n",
            "Iteration 253, loss = 1137336010.77321482\n",
            "Iteration 254, loss = 1134599069.43986011\n",
            "Iteration 255, loss = 1131850252.56617999\n",
            "Iteration 256, loss = 1129079798.15980864\n",
            "Iteration 257, loss = 1126319594.67170835\n",
            "Iteration 258, loss = 1123537279.26979756\n",
            "Iteration 259, loss = 1120777178.18071175\n",
            "Iteration 260, loss = 1117997926.00249720\n",
            "Iteration 261, loss = 1115209735.85574794\n",
            "Iteration 262, loss = 1112427778.91993403\n",
            "Iteration 263, loss = 1109652930.08498335\n",
            "Iteration 264, loss = 1106848902.87567663\n",
            "Iteration 265, loss = 1104100159.06419230\n",
            "Iteration 266, loss = 1101310451.91127515\n",
            "Iteration 267, loss = 1098515252.56399179\n",
            "Iteration 268, loss = 1095738126.17840219\n",
            "Iteration 269, loss = 1092960999.14377832\n",
            "Iteration 270, loss = 1090121565.27660966\n",
            "Iteration 271, loss = 1087373022.58033419\n",
            "Iteration 272, loss = 1084540919.16696858\n",
            "Iteration 273, loss = 1081712175.07446074\n",
            "Iteration 274, loss = 1078909378.34738588\n",
            "Iteration 275, loss = 1076075368.69295764\n",
            "Iteration 276, loss = 1073276093.28118265\n",
            "Iteration 277, loss = 1070456321.64595306\n",
            "Iteration 278, loss = 1067637055.86903167\n",
            "Iteration 279, loss = 1064812386.53095293\n",
            "Iteration 280, loss = 1062020323.89272499\n",
            "Iteration 281, loss = 1059218366.38201475\n",
            "Iteration 282, loss = 1056385443.89641023\n",
            "Iteration 283, loss = 1053587363.03893864\n",
            "Iteration 284, loss = 1050770104.63425374\n",
            "Iteration 285, loss = 1047933708.04176795\n",
            "Iteration 286, loss = 1045129724.42178047\n",
            "Iteration 287, loss = 1042311429.96329725\n",
            "Iteration 288, loss = 1039477075.46480846\n",
            "Iteration 289, loss = 1036642711.64969885\n",
            "Iteration 290, loss = 1033849203.01816380\n",
            "Iteration 291, loss = 1031006567.22018218\n",
            "Iteration 292, loss = 1028188769.14531100\n",
            "Iteration 293, loss = 1025383245.16172743\n",
            "Iteration 294, loss = 1022574902.31630874\n",
            "Iteration 295, loss = 1019754309.75393748\n",
            "Iteration 296, loss = 1016941620.03731084\n",
            "Iteration 297, loss = 1014102697.88819098\n",
            "Iteration 298, loss = 1011280330.39042127\n",
            "Iteration 299, loss = 1008435622.60846281\n",
            "Iteration 300, loss = 1005628412.64090526\n",
            "Iteration 301, loss = 1002747218.17488265\n",
            "Iteration 302, loss = 999909208.62955940\n",
            "Iteration 303, loss = 997053641.23218703\n",
            "Iteration 304, loss = 994216245.59715414\n",
            "Iteration 305, loss = 991365334.19519627\n",
            "Iteration 306, loss = 988480981.67728615\n",
            "Iteration 307, loss = 985679945.70035231\n",
            "Iteration 308, loss = 982789853.66524792\n",
            "Iteration 309, loss = 979955255.64885414\n",
            "Iteration 310, loss = 977147068.02163136\n",
            "Iteration 311, loss = 974298395.36912405\n",
            "Iteration 312, loss = 971458945.37562859\n",
            "Iteration 313, loss = 968642281.09333742\n",
            "Iteration 314, loss = 965801395.19363654\n",
            "Iteration 315, loss = 962952015.58132553\n",
            "Iteration 316, loss = 960166277.09729660\n",
            "Iteration 317, loss = 957265769.81582630\n",
            "Iteration 318, loss = 954461759.31345022\n",
            "Iteration 319, loss = 951612472.39675462\n",
            "Iteration 320, loss = 948761135.99573708\n",
            "Iteration 321, loss = 945953920.26371586\n",
            "Iteration 322, loss = 943084134.90023482\n",
            "Iteration 323, loss = 940255611.49765444\n",
            "Iteration 324, loss = 937474387.07245243\n",
            "Iteration 325, loss = 934609885.73797059\n",
            "Iteration 326, loss = 931802300.90996826\n",
            "Iteration 327, loss = 928999796.54433906\n",
            "Iteration 328, loss = 926184246.15286708\n",
            "Iteration 329, loss = 923382164.82215953\n",
            "Iteration 330, loss = 920615701.11800706\n",
            "Iteration 331, loss = 917807822.97328877\n",
            "Iteration 332, loss = 915027614.50994003\n",
            "Iteration 333, loss = 912246755.88560092\n",
            "Iteration 334, loss = 909462984.50513732\n",
            "Iteration 335, loss = 906686896.99924839\n",
            "Iteration 336, loss = 903878255.24683940\n",
            "Iteration 337, loss = 901136704.40411091\n",
            "Iteration 338, loss = 898343990.90734363\n",
            "Iteration 339, loss = 895549385.22736990\n",
            "Iteration 340, loss = 892765300.02412629\n",
            "Iteration 341, loss = 890034466.81395459\n",
            "Iteration 342, loss = 887288149.29928696\n",
            "Iteration 343, loss = 884483803.23486912\n",
            "Iteration 344, loss = 881766731.06205380\n",
            "Iteration 345, loss = 879010799.56468868\n",
            "Iteration 346, loss = 876306642.26583040\n",
            "Iteration 347, loss = 873512725.85502088\n",
            "Iteration 348, loss = 870797615.39402521\n",
            "Iteration 349, loss = 868046968.78454733\n",
            "Iteration 350, loss = 865360949.00321615\n",
            "Iteration 351, loss = 862600826.85013783\n",
            "Iteration 352, loss = 859843910.43217850\n",
            "Iteration 353, loss = 857111782.04941773\n",
            "Iteration 354, loss = 854373367.99268353\n",
            "Iteration 355, loss = 851619386.05693460\n",
            "Iteration 356, loss = 848874459.47174525\n",
            "Iteration 357, loss = 846125183.08774686\n",
            "Iteration 358, loss = 843353112.74302769\n",
            "Iteration 359, loss = 840607671.91751432\n",
            "Iteration 360, loss = 837874766.87695992\n",
            "Iteration 361, loss = 835119649.59014726\n",
            "Iteration 362, loss = 832417115.92524850\n",
            "Iteration 363, loss = 829684149.50788677\n",
            "Iteration 364, loss = 826970018.56332815\n",
            "Iteration 365, loss = 824228812.95241976\n",
            "Iteration 366, loss = 821542604.06690395\n",
            "Iteration 367, loss = 818838991.64441156\n",
            "Iteration 368, loss = 816094662.93734884\n",
            "Iteration 369, loss = 813399186.40382218\n",
            "Iteration 370, loss = 810700343.90880060\n",
            "Iteration 371, loss = 808017439.02264178\n",
            "Iteration 372, loss = 805251527.03810847\n",
            "Iteration 373, loss = 802624373.56651962\n",
            "Iteration 374, loss = 799943447.35326779\n",
            "Iteration 375, loss = 797231413.52442622\n",
            "Iteration 376, loss = 794560220.72777557\n",
            "Iteration 377, loss = 791918635.32662511\n",
            "Iteration 378, loss = 789238751.23346996\n",
            "Iteration 379, loss = 786562544.10758018\n",
            "Iteration 380, loss = 783931184.84986484\n",
            "Iteration 381, loss = 781233871.26182866\n",
            "Iteration 382, loss = 778621762.28957546\n",
            "Iteration 383, loss = 775955676.40684330\n",
            "Iteration 384, loss = 773334688.19498730\n",
            "Iteration 385, loss = 770669075.43668747\n",
            "Iteration 386, loss = 768081805.12452626\n",
            "Iteration 387, loss = 765429597.88626206\n",
            "Iteration 388, loss = 762820305.55853438\n",
            "Iteration 389, loss = 760217215.06902075\n",
            "Iteration 390, loss = 757568987.51395035\n",
            "Iteration 391, loss = 754976525.91496134\n",
            "Iteration 392, loss = 752377502.43864059\n",
            "Iteration 393, loss = 749759833.38916159\n",
            "Iteration 394, loss = 747157211.63719666\n",
            "Iteration 395, loss = 744560068.58774829\n",
            "Iteration 396, loss = 742035191.25171268\n",
            "Iteration 397, loss = 739403292.26102734\n",
            "Iteration 398, loss = 736840636.12325644\n",
            "Iteration 399, loss = 734283599.32058823\n",
            "Iteration 400, loss = 731698774.64977801\n",
            "Iteration 401, loss = 729154518.50066411\n",
            "Iteration 402, loss = 726549082.74147260\n",
            "Iteration 403, loss = 724036429.73606467\n",
            "Iteration 404, loss = 721447346.92542565\n",
            "Iteration 405, loss = 718889081.65346932\n",
            "Iteration 406, loss = 716361161.81300139\n",
            "Iteration 407, loss = 713815653.17722905\n",
            "Iteration 408, loss = 711285102.34757590\n",
            "Iteration 409, loss = 708774571.26751292\n",
            "Iteration 410, loss = 706190835.71463680\n",
            "Iteration 411, loss = 703741138.79951024\n",
            "Iteration 412, loss = 701225515.30058217\n",
            "Iteration 413, loss = 698686997.76953888\n",
            "Iteration 414, loss = 696184465.06536865\n",
            "Iteration 415, loss = 693687374.06574535\n",
            "Iteration 416, loss = 691231505.04051530\n",
            "Iteration 417, loss = 688716949.88225520\n",
            "Iteration 418, loss = 686259671.98990858\n",
            "Iteration 419, loss = 683785038.90620935\n",
            "Iteration 420, loss = 681332180.88913429\n",
            "Iteration 421, loss = 678901243.55037808\n",
            "Iteration 422, loss = 676432592.58261240\n",
            "Iteration 423, loss = 674020537.87886214\n",
            "Iteration 424, loss = 671526519.13719130\n",
            "Iteration 425, loss = 669113196.93688273\n",
            "Iteration 426, loss = 666675397.19968998\n",
            "Iteration 427, loss = 664225907.73021114\n",
            "Iteration 428, loss = 661765118.78736639\n",
            "Iteration 429, loss = 659303634.40475011\n",
            "Iteration 430, loss = 656873275.84533036\n",
            "Iteration 431, loss = 654426538.59576607\n",
            "Iteration 432, loss = 651948730.43037498\n",
            "Iteration 433, loss = 649560271.61200762\n",
            "Iteration 434, loss = 647110307.36997306\n",
            "Iteration 435, loss = 644715778.38562441\n",
            "Iteration 436, loss = 642289812.39847910\n",
            "Iteration 437, loss = 639919377.45277178\n",
            "Iteration 438, loss = 637481157.49709952\n",
            "Iteration 439, loss = 635124364.53426003\n",
            "Iteration 440, loss = 632736735.58268809\n",
            "Iteration 441, loss = 630354796.98048818\n",
            "Iteration 442, loss = 627996749.37773609\n",
            "Iteration 443, loss = 625617201.39103317\n",
            "Iteration 444, loss = 623296612.75708663\n",
            "Iteration 445, loss = 620919620.29551804\n",
            "Iteration 446, loss = 618642341.84675479\n",
            "Iteration 447, loss = 616261733.29576886\n",
            "Iteration 448, loss = 614000168.15521228\n",
            "Iteration 449, loss = 611664360.62084484\n",
            "Iteration 450, loss = 609350386.72593558\n",
            "Iteration 451, loss = 607067840.47342825\n",
            "Iteration 452, loss = 604765876.13935614\n",
            "Iteration 453, loss = 602498213.98629153\n",
            "Iteration 454, loss = 600163406.87643993\n",
            "Iteration 455, loss = 597868378.57916927\n",
            "Iteration 456, loss = 595594270.73517120\n",
            "Iteration 457, loss = 593297810.31402826\n",
            "Iteration 458, loss = 591038671.70233285\n",
            "Iteration 459, loss = 588742590.88912868\n",
            "Iteration 460, loss = 586469963.41156077\n",
            "Iteration 461, loss = 584244404.21420729\n",
            "Iteration 462, loss = 581989870.01267910\n",
            "Iteration 463, loss = 579724178.46945059\n",
            "Iteration 464, loss = 577508807.17063475\n",
            "Iteration 465, loss = 575294920.68148947\n",
            "Iteration 466, loss = 573050019.94726205\n",
            "Iteration 467, loss = 570836081.57659483\n",
            "Iteration 468, loss = 568630973.98070586\n",
            "Iteration 469, loss = 566432723.87487149\n",
            "Iteration 470, loss = 564257891.91618586\n",
            "Iteration 471, loss = 562086448.63330162\n",
            "Iteration 472, loss = 559947224.35069871\n",
            "Iteration 473, loss = 557766729.46909237\n",
            "Iteration 474, loss = 555639693.57729983\n",
            "Iteration 475, loss = 553482637.69435203\n",
            "Iteration 476, loss = 551399388.23321927\n",
            "Iteration 477, loss = 549180715.81109989\n",
            "Iteration 478, loss = 547062539.95685840\n",
            "Iteration 479, loss = 544901524.88715172\n",
            "Iteration 480, loss = 542723891.56567883\n",
            "Iteration 481, loss = 540539376.67213345\n",
            "Iteration 482, loss = 538385211.85594583\n",
            "Iteration 483, loss = 536228632.69273901\n",
            "Iteration 484, loss = 534083958.61243600\n",
            "Iteration 485, loss = 531909486.82683676\n",
            "Iteration 486, loss = 529789703.89892900\n",
            "Iteration 487, loss = 527688091.73334914\n",
            "Iteration 488, loss = 525536521.63675463\n",
            "Iteration 489, loss = 523447846.85145056\n",
            "Iteration 490, loss = 521345955.85564023\n",
            "Iteration 491, loss = 519220686.78537405\n",
            "Iteration 492, loss = 517156181.40392601\n",
            "Iteration 493, loss = 515096881.24100083\n",
            "Iteration 494, loss = 513001762.85746247\n",
            "Iteration 495, loss = 510955441.44416183\n",
            "Iteration 496, loss = 508917891.93041807\n",
            "Iteration 497, loss = 506905797.94993728\n",
            "Iteration 498, loss = 504860692.83237416\n",
            "Iteration 499, loss = 502870511.64529222\n",
            "Iteration 500, loss = 500872154.46400559\n",
            "Iteration 501, loss = 498873144.86534309\n",
            "Iteration 502, loss = 496879168.06119168\n",
            "Iteration 503, loss = 494866648.44858360\n",
            "Iteration 504, loss = 492876744.98222321\n",
            "Iteration 505, loss = 490881796.82798368\n",
            "Iteration 506, loss = 488829111.88695097\n",
            "Iteration 507, loss = 486868000.55531365\n",
            "Iteration 508, loss = 484788297.12875962\n",
            "Iteration 509, loss = 482799468.40164137\n",
            "Iteration 510, loss = 480813159.77928358\n",
            "Iteration 511, loss = 478843728.34852314\n",
            "Iteration 512, loss = 476796794.94253409\n",
            "Iteration 513, loss = 474870968.76423085\n",
            "Iteration 514, loss = 472883341.95933396\n",
            "Iteration 515, loss = 470931814.84494531\n",
            "Iteration 516, loss = 468971636.29584402\n",
            "Iteration 517, loss = 467019635.95420676\n",
            "Iteration 518, loss = 465069890.49712831\n",
            "Iteration 519, loss = 463186106.77831709\n",
            "Iteration 520, loss = 461236865.46143681\n",
            "Iteration 521, loss = 459332315.62381709\n",
            "Iteration 522, loss = 457432278.58207613\n",
            "Iteration 523, loss = 455553983.63109136\n",
            "Iteration 524, loss = 453717295.22215545\n",
            "Iteration 525, loss = 451805811.23781019\n",
            "Iteration 526, loss = 449956855.24929011\n",
            "Iteration 527, loss = 448093473.06343085\n",
            "Iteration 528, loss = 446241486.40060830\n",
            "Iteration 529, loss = 444370243.73675972\n",
            "Iteration 530, loss = 442524280.47484112\n",
            "Iteration 531, loss = 440643381.97405833\n",
            "Iteration 532, loss = 438818477.32313675\n",
            "Iteration 533, loss = 436931291.96912462\n",
            "Iteration 534, loss = 435096878.16588879\n",
            "Iteration 535, loss = 433221975.81162345\n",
            "Iteration 536, loss = 431418486.57602555\n",
            "Iteration 537, loss = 429589189.83063442\n",
            "Iteration 538, loss = 427750402.56822479\n",
            "Iteration 539, loss = 425945290.50564718\n",
            "Iteration 540, loss = 424145143.28036898\n",
            "Iteration 541, loss = 422328338.92156595\n",
            "Iteration 542, loss = 420573868.38563162\n",
            "Iteration 543, loss = 418791827.43362480\n",
            "Iteration 544, loss = 417023102.70432287\n",
            "Iteration 545, loss = 415256847.56437635\n",
            "Iteration 546, loss = 413531261.59062701\n",
            "Iteration 547, loss = 411747558.12967199\n",
            "Iteration 548, loss = 409999348.40987021\n",
            "Iteration 549, loss = 408253717.76023048\n",
            "Iteration 550, loss = 406514722.19099879\n",
            "Iteration 551, loss = 404794779.27293253\n",
            "Iteration 552, loss = 403021409.16907126\n",
            "Iteration 553, loss = 401308857.10080308\n",
            "Iteration 554, loss = 399616488.93712580\n",
            "Iteration 555, loss = 397900840.94376725\n",
            "Iteration 556, loss = 396209475.16341877\n",
            "Iteration 557, loss = 394529144.56822199\n",
            "Iteration 558, loss = 392850952.61311090\n",
            "Iteration 559, loss = 391193216.29235393\n",
            "Iteration 560, loss = 389539166.29216582\n",
            "Iteration 561, loss = 387920220.66262072\n",
            "Iteration 562, loss = 386254701.48182684\n",
            "Iteration 563, loss = 384640056.03623569\n",
            "Iteration 564, loss = 382982862.32780290\n",
            "Iteration 565, loss = 381356622.63043052\n",
            "Iteration 566, loss = 379714110.05032665\n",
            "Iteration 567, loss = 378080243.57369304\n",
            "Iteration 568, loss = 376467495.36069798\n",
            "Iteration 569, loss = 374824551.19964659\n",
            "Iteration 570, loss = 373234903.90103328\n",
            "Iteration 571, loss = 371610886.80297351\n",
            "Iteration 572, loss = 370030592.16272974\n",
            "Iteration 573, loss = 368399842.79707521\n",
            "Iteration 574, loss = 366818451.98525202\n",
            "Iteration 575, loss = 365221261.28786355\n",
            "Iteration 576, loss = 363623389.82675087\n",
            "Iteration 577, loss = 362039427.13797426\n",
            "Iteration 578, loss = 360434767.25010562\n",
            "Iteration 579, loss = 358856880.06683660\n",
            "Iteration 580, loss = 357285748.34380257\n",
            "Iteration 581, loss = 355734575.47618872\n",
            "Iteration 582, loss = 354167962.90209460\n",
            "Iteration 583, loss = 352609359.08165616\n",
            "Iteration 584, loss = 351069072.43509901\n",
            "Iteration 585, loss = 349546125.30457687\n",
            "Iteration 586, loss = 348031742.09072810\n",
            "Iteration 587, loss = 346488209.54076755\n",
            "Iteration 588, loss = 344980965.51833862\n",
            "Iteration 589, loss = 343458046.96024102\n",
            "Iteration 590, loss = 341940281.87414503\n",
            "Iteration 591, loss = 340441222.22232229\n",
            "Iteration 592, loss = 338934156.85812396\n",
            "Iteration 593, loss = 337427231.17321926\n",
            "Iteration 594, loss = 335928483.12121344\n",
            "Iteration 595, loss = 334422422.86583173\n",
            "Iteration 596, loss = 332956067.36957651\n",
            "Iteration 597, loss = 331468782.33268332\n",
            "Iteration 598, loss = 329980336.14212877\n",
            "Iteration 599, loss = 328507960.58249635\n",
            "Iteration 600, loss = 327077526.19196522\n",
            "Iteration 601, loss = 325625689.03621387\n",
            "Iteration 602, loss = 324176714.64170557\n",
            "Iteration 603, loss = 322746216.17083830\n",
            "Iteration 604, loss = 321324140.89558899\n",
            "Iteration 605, loss = 319875509.49182421\n",
            "Iteration 606, loss = 318455391.33005500\n",
            "Iteration 607, loss = 317028306.42104602\n",
            "Iteration 608, loss = 315606420.41424596\n",
            "Iteration 609, loss = 314152105.01402712\n",
            "Iteration 610, loss = 312731295.31059021\n",
            "Iteration 611, loss = 311331913.26257718\n",
            "Iteration 612, loss = 309891120.18132305\n",
            "Iteration 613, loss = 308477674.90769339\n",
            "Iteration 614, loss = 307105217.84601349\n",
            "Iteration 615, loss = 305699393.99716407\n",
            "Iteration 616, loss = 304326607.89818114\n",
            "Iteration 617, loss = 302932833.14890462\n",
            "Iteration 618, loss = 301566703.68916100\n",
            "Iteration 619, loss = 300184823.17078388\n",
            "Iteration 620, loss = 298821419.88948292\n",
            "Iteration 621, loss = 297470235.95102710\n",
            "Iteration 622, loss = 296079252.66267073\n",
            "Iteration 623, loss = 294737033.60790849\n",
            "Iteration 624, loss = 293371665.73266762\n",
            "Iteration 625, loss = 292032797.95774388\n",
            "Iteration 626, loss = 290708458.19027191\n",
            "Iteration 627, loss = 289348838.79907066\n",
            "Iteration 628, loss = 288065543.93243957\n",
            "Iteration 629, loss = 286727804.46408230\n",
            "Iteration 630, loss = 285425565.94482428\n",
            "Iteration 631, loss = 284160360.23934108\n",
            "Iteration 632, loss = 282848807.02526414\n",
            "Iteration 633, loss = 281560739.44465369\n",
            "Iteration 634, loss = 280298476.25162655\n",
            "Iteration 635, loss = 279018266.53506237\n",
            "Iteration 636, loss = 277756776.87066245\n",
            "Iteration 637, loss = 276513247.96886623\n",
            "Iteration 638, loss = 275234757.15563709\n",
            "Iteration 639, loss = 274024374.06028628\n",
            "Iteration 640, loss = 272772430.96717364\n",
            "Iteration 641, loss = 271566596.21738064\n",
            "Iteration 642, loss = 270331117.22869420\n",
            "Iteration 643, loss = 269135552.70019406\n",
            "Iteration 644, loss = 267909228.45663509\n",
            "Iteration 645, loss = 266713779.93685490\n",
            "Iteration 646, loss = 265503160.55566123\n",
            "Iteration 647, loss = 264270069.37491027\n",
            "Iteration 648, loss = 263079446.62238622\n",
            "Iteration 649, loss = 261869722.57562575\n",
            "Iteration 650, loss = 260660815.63745603\n",
            "Iteration 651, loss = 259471583.11288095\n",
            "Iteration 652, loss = 258292107.16136181\n",
            "Iteration 653, loss = 257091092.79967156\n",
            "Iteration 654, loss = 255921006.59642008\n",
            "Iteration 655, loss = 254738732.00518355\n",
            "Iteration 656, loss = 253580334.35087037\n",
            "Iteration 657, loss = 252405697.83211997\n",
            "Iteration 658, loss = 251223302.06347859\n",
            "Iteration 659, loss = 250059278.49412090\n",
            "Iteration 660, loss = 248914794.92923164\n",
            "Iteration 661, loss = 247740987.91823325\n",
            "Iteration 662, loss = 246587585.53257397\n",
            "Iteration 663, loss = 245442185.29102460\n",
            "Iteration 664, loss = 244344731.00230572\n",
            "Iteration 665, loss = 243198548.24487585\n",
            "Iteration 666, loss = 242084748.62327150\n",
            "Iteration 667, loss = 240987431.56547385\n",
            "Iteration 668, loss = 239879106.22681180\n",
            "Iteration 669, loss = 238776400.86876509\n",
            "Iteration 670, loss = 237708210.67002124\n",
            "Iteration 671, loss = 236615729.70702916\n",
            "Iteration 672, loss = 235527003.89365128\n",
            "Iteration 673, loss = 234466210.03819451\n",
            "Iteration 674, loss = 233399021.79732347\n",
            "Iteration 675, loss = 232329344.83417082\n",
            "Iteration 676, loss = 231256527.94883010\n",
            "Iteration 677, loss = 230204674.09714350\n",
            "Iteration 678, loss = 229141544.26354101\n",
            "Iteration 679, loss = 228073930.31780791\n",
            "Iteration 680, loss = 227036502.72897065\n",
            "Iteration 681, loss = 225946341.39763606\n",
            "Iteration 682, loss = 224916742.54880917\n",
            "Iteration 683, loss = 223894494.86844802\n",
            "Iteration 684, loss = 222842888.09826338\n",
            "Iteration 685, loss = 221825545.60497287\n",
            "Iteration 686, loss = 220792575.07883504\n",
            "Iteration 687, loss = 219764006.78565162\n",
            "Iteration 688, loss = 218781439.92030129\n",
            "Iteration 689, loss = 217766143.43632105\n",
            "Iteration 690, loss = 216778068.71395236\n",
            "Iteration 691, loss = 215768325.40969506\n",
            "Iteration 692, loss = 214809308.23675945\n",
            "Iteration 693, loss = 213834918.01576161\n",
            "Iteration 694, loss = 212856311.78686881\n",
            "Iteration 695, loss = 211880821.89316535\n",
            "Iteration 696, loss = 210912706.09504741\n",
            "Iteration 697, loss = 209950434.33651009\n",
            "Iteration 698, loss = 208993097.61190397\n",
            "Iteration 699, loss = 208020141.24495038\n",
            "Iteration 700, loss = 207067758.78508234\n",
            "Iteration 701, loss = 206109270.82445687\n",
            "Iteration 702, loss = 205164110.69349772\n",
            "Iteration 703, loss = 204215729.06151497\n",
            "Iteration 704, loss = 203248312.68634197\n",
            "Iteration 705, loss = 202326328.91133216\n",
            "Iteration 706, loss = 201386837.84987575\n",
            "Iteration 707, loss = 200442629.64831746\n",
            "Iteration 708, loss = 199503829.25922599\n",
            "Iteration 709, loss = 198600371.32866064\n",
            "Iteration 710, loss = 197672160.15684971\n",
            "Iteration 711, loss = 196773842.01135820\n",
            "Iteration 712, loss = 195864496.08160669\n",
            "Iteration 713, loss = 194975074.22890288\n",
            "Iteration 714, loss = 194092401.47357714\n",
            "Iteration 715, loss = 193202749.02022484\n",
            "Iteration 716, loss = 192336097.14494330\n",
            "Iteration 717, loss = 191443776.36798769\n",
            "Iteration 718, loss = 190604234.33331567\n",
            "Iteration 719, loss = 189737320.85050252\n",
            "Iteration 720, loss = 188873113.85262248\n",
            "Iteration 721, loss = 188034187.09524080\n",
            "Iteration 722, loss = 187172169.42604628\n",
            "Iteration 723, loss = 186340627.47224632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 724, loss = 185513261.18950668\n",
            "Iteration 725, loss = 184662969.27208260\n",
            "Iteration 726, loss = 183840943.95784611\n",
            "Iteration 727, loss = 183010072.69281563\n",
            "Iteration 728, loss = 182191415.51182404\n",
            "Iteration 729, loss = 181361783.39053667\n",
            "Iteration 730, loss = 180522681.48923162\n",
            "Iteration 731, loss = 179710852.63668194\n",
            "Iteration 732, loss = 178906343.47020686\n",
            "Iteration 733, loss = 178101157.39296639\n",
            "Iteration 734, loss = 177288687.07310411\n",
            "Iteration 735, loss = 176504601.99757281\n",
            "Iteration 736, loss = 175727921.32852209\n",
            "Iteration 737, loss = 174950191.02637285\n",
            "Iteration 738, loss = 174166137.68269813\n",
            "Iteration 739, loss = 173412593.59353864\n",
            "Iteration 740, loss = 172645102.20699650\n",
            "Iteration 741, loss = 171905744.59783033\n",
            "Iteration 742, loss = 171145032.02950713\n",
            "Iteration 743, loss = 170419232.11957288\n",
            "Iteration 744, loss = 169679429.09089059\n",
            "Iteration 745, loss = 168947570.93241957\n",
            "Iteration 746, loss = 168224204.10464928\n",
            "Iteration 747, loss = 167494819.22833902\n",
            "Iteration 748, loss = 166776569.30128756\n",
            "Iteration 749, loss = 166040449.98889166\n",
            "Iteration 750, loss = 165321692.07894969\n",
            "Iteration 751, loss = 164598424.67572653\n",
            "Iteration 752, loss = 163859541.32458916\n",
            "Iteration 753, loss = 163151723.12019068\n",
            "Iteration 754, loss = 162424026.69019452\n",
            "Iteration 755, loss = 161704344.42251000\n",
            "Iteration 756, loss = 160997753.87014163\n",
            "Iteration 757, loss = 160282946.86767820\n",
            "Iteration 758, loss = 159582533.81130999\n",
            "Iteration 759, loss = 158891639.62180519\n",
            "Iteration 760, loss = 158185115.89645600\n",
            "Iteration 761, loss = 157504778.34078279\n",
            "Iteration 762, loss = 156824382.77672455\n",
            "Iteration 763, loss = 156132586.08141065\n",
            "Iteration 764, loss = 155476238.61291513\n",
            "Iteration 765, loss = 154792458.85720801\n",
            "Iteration 766, loss = 154118119.37310761\n",
            "Iteration 767, loss = 153450119.26857454\n",
            "Iteration 768, loss = 152782760.79387438\n",
            "Iteration 769, loss = 152112811.86553276\n",
            "Iteration 770, loss = 151445601.14327255\n",
            "Iteration 771, loss = 150774318.38290182\n",
            "Iteration 772, loss = 150126428.39102417\n",
            "Iteration 773, loss = 149451494.38906145\n",
            "Iteration 774, loss = 148802687.70667312\n",
            "Iteration 775, loss = 148142664.70733368\n",
            "Iteration 776, loss = 147486789.26710778\n",
            "Iteration 777, loss = 146837735.50885829\n",
            "Iteration 778, loss = 146198730.76499519\n",
            "Iteration 779, loss = 145563754.79162586\n",
            "Iteration 780, loss = 144908975.38978747\n",
            "Iteration 781, loss = 144293629.57709953\n",
            "Iteration 782, loss = 143674391.53917089\n",
            "Iteration 783, loss = 143044903.60634556\n",
            "Iteration 784, loss = 142434323.57871610\n",
            "Iteration 785, loss = 141805107.76824680\n",
            "Iteration 786, loss = 141219916.78643829\n",
            "Iteration 787, loss = 140603076.03370100\n",
            "Iteration 788, loss = 140007357.94252774\n",
            "Iteration 789, loss = 139402441.74929062\n",
            "Iteration 790, loss = 138807847.11679438\n",
            "Iteration 791, loss = 138210924.78125495\n",
            "Iteration 792, loss = 137625421.66091645\n",
            "Iteration 793, loss = 137027873.62837732\n",
            "Iteration 794, loss = 136429874.04743642\n",
            "Iteration 795, loss = 135837955.05439895\n",
            "Iteration 796, loss = 135243203.59721753\n",
            "Iteration 797, loss = 134667410.58561003\n",
            "Iteration 798, loss = 134087759.41357969\n",
            "Iteration 799, loss = 133501063.95135197\n",
            "Iteration 800, loss = 132909740.00266655\n",
            "Iteration 801, loss = 132343820.63152924\n",
            "Iteration 802, loss = 131768928.04372770\n",
            "Iteration 803, loss = 131180823.63417393\n",
            "Iteration 804, loss = 130595374.91162460\n",
            "Iteration 805, loss = 130027293.08282477\n",
            "Iteration 806, loss = 129441451.14871839\n",
            "Iteration 807, loss = 128868990.65712970\n",
            "Iteration 808, loss = 128294643.54573175\n",
            "Iteration 809, loss = 127722947.50699496\n",
            "Iteration 810, loss = 127175869.30101839\n",
            "Iteration 811, loss = 126615258.58552036\n",
            "Iteration 812, loss = 126074214.57381518\n",
            "Iteration 813, loss = 125523816.21206230\n",
            "Iteration 814, loss = 124989601.38927335\n",
            "Iteration 815, loss = 124461465.91960491\n",
            "Iteration 816, loss = 123931795.85986863\n",
            "Iteration 817, loss = 123403424.47607347\n",
            "Iteration 818, loss = 122876529.25792114\n",
            "Iteration 819, loss = 122368421.98642841\n",
            "Iteration 820, loss = 121841022.65746386\n",
            "Iteration 821, loss = 121342835.36812036\n",
            "Iteration 822, loss = 120841733.89053042\n",
            "Iteration 823, loss = 120333467.34574649\n",
            "Iteration 824, loss = 119841052.37313065\n",
            "Iteration 825, loss = 119360067.32028829\n",
            "Iteration 826, loss = 118866994.31018744\n",
            "Iteration 827, loss = 118375536.34046462\n",
            "Iteration 828, loss = 117896721.15162832\n",
            "Iteration 829, loss = 117420419.51459651\n",
            "Iteration 830, loss = 116931647.38167514\n",
            "Iteration 831, loss = 116462054.26233509\n",
            "Iteration 832, loss = 115984448.79306017\n",
            "Iteration 833, loss = 115507134.83793256\n",
            "Iteration 834, loss = 115031608.75043997\n",
            "Iteration 835, loss = 114565200.66250032\n",
            "Iteration 836, loss = 114099974.70770983\n",
            "Iteration 837, loss = 113622941.71610655\n",
            "Iteration 838, loss = 113165068.25292990\n",
            "Iteration 839, loss = 112683009.35160159\n",
            "Iteration 840, loss = 112222604.17761050\n",
            "Iteration 841, loss = 111765386.10389055\n",
            "Iteration 842, loss = 111293423.51532561\n",
            "Iteration 843, loss = 110828082.93022069\n",
            "Iteration 844, loss = 110374988.17556536\n",
            "Iteration 845, loss = 109921208.18867572\n",
            "Iteration 846, loss = 109461598.53346735\n",
            "Iteration 847, loss = 109007456.52665895\n",
            "Iteration 848, loss = 108573780.08185296\n",
            "Iteration 849, loss = 108117349.57246451\n",
            "Iteration 850, loss = 107677228.93475831\n",
            "Iteration 851, loss = 107250702.69487639\n",
            "Iteration 852, loss = 106802090.16878165\n",
            "Iteration 853, loss = 106377007.87125488\n",
            "Iteration 854, loss = 105947440.31797808\n",
            "Iteration 855, loss = 105509961.38026820\n",
            "Iteration 856, loss = 105095773.48139805\n",
            "Iteration 857, loss = 104655986.47751099\n",
            "Iteration 858, loss = 104251931.09601150\n",
            "Iteration 859, loss = 103830449.36106271\n",
            "Iteration 860, loss = 103409160.13371092\n",
            "Iteration 861, loss = 103016323.72029690\n",
            "Iteration 862, loss = 102604261.05071822\n",
            "Iteration 863, loss = 102202373.42655501\n",
            "Iteration 864, loss = 101817818.80958229\n",
            "Iteration 865, loss = 101419806.16114920\n",
            "Iteration 866, loss = 101026148.77088360\n",
            "Iteration 867, loss = 100626997.65192379\n",
            "Iteration 868, loss = 100256985.02492642\n",
            "Iteration 869, loss = 99857264.85312158\n",
            "Iteration 870, loss = 99470310.55967908\n",
            "Iteration 871, loss = 99091538.57309127\n",
            "Iteration 872, loss = 98705124.49716040\n",
            "Iteration 873, loss = 98328945.01707587\n",
            "Iteration 874, loss = 97957955.80188031\n",
            "Iteration 875, loss = 97573704.23880771\n",
            "Iteration 876, loss = 97202263.48251750\n",
            "Iteration 877, loss = 96824911.84045921\n",
            "Iteration 878, loss = 96452794.49013610\n",
            "Iteration 879, loss = 96074646.22211502\n",
            "Iteration 880, loss = 95702433.25619581\n",
            "Iteration 881, loss = 95325453.02778277\n",
            "Iteration 882, loss = 94959590.33711182\n",
            "Iteration 883, loss = 94597933.19373026\n",
            "Iteration 884, loss = 94226323.00148264\n",
            "Iteration 885, loss = 93862582.48464589\n",
            "Iteration 886, loss = 93493737.42307921\n",
            "Iteration 887, loss = 93143113.24310762\n",
            "Iteration 888, loss = 92781088.33684748\n",
            "Iteration 889, loss = 92421388.45834036\n",
            "Iteration 890, loss = 92056555.20060095\n",
            "Iteration 891, loss = 91695705.11834882\n",
            "Iteration 892, loss = 91352254.46272215\n",
            "Iteration 893, loss = 90991878.10123058\n",
            "Iteration 894, loss = 90637803.80347662\n",
            "Iteration 895, loss = 90296642.42690793\n",
            "Iteration 896, loss = 89950920.22113396\n",
            "Iteration 897, loss = 89605731.33181615\n",
            "Iteration 898, loss = 89274015.23683727\n",
            "Iteration 899, loss = 88934291.47978623\n",
            "Iteration 900, loss = 88598052.44929190\n",
            "Iteration 901, loss = 88262572.34660085\n",
            "Iteration 902, loss = 87923228.92352924\n",
            "Iteration 903, loss = 87592343.18544416\n",
            "Iteration 904, loss = 87253928.50903937\n",
            "Iteration 905, loss = 86925684.07999645\n",
            "Iteration 906, loss = 86590584.82092325\n",
            "Iteration 907, loss = 86266268.12037720\n",
            "Iteration 908, loss = 85941550.26353972\n",
            "Iteration 909, loss = 85608625.14387920\n",
            "Iteration 910, loss = 85295378.26309867\n",
            "Iteration 911, loss = 84967165.99647884\n",
            "Iteration 912, loss = 84653889.45007366\n",
            "Iteration 913, loss = 84329210.79595916\n",
            "Iteration 914, loss = 84002591.50529274\n",
            "Iteration 915, loss = 83698824.40463716\n",
            "Iteration 916, loss = 83383718.95115876\n",
            "Iteration 917, loss = 83065757.72829565\n",
            "Iteration 918, loss = 82757352.64501904\n",
            "Iteration 919, loss = 82448041.15171064\n",
            "Iteration 920, loss = 82146198.13848357\n",
            "Iteration 921, loss = 81845569.30544510\n",
            "Iteration 922, loss = 81542951.92630304\n",
            "Iteration 923, loss = 81249890.43132415\n",
            "Iteration 924, loss = 80947221.17240916\n",
            "Iteration 925, loss = 80652451.42799495\n",
            "Iteration 926, loss = 80367028.99122943\n",
            "Iteration 927, loss = 80064892.47486949\n",
            "Iteration 928, loss = 79774435.62622716\n",
            "Iteration 929, loss = 79482305.86151229\n",
            "Iteration 930, loss = 79191643.81693529\n",
            "Iteration 931, loss = 78908259.48811078\n",
            "Iteration 932, loss = 78626285.98007175\n",
            "Iteration 933, loss = 78345003.52426119\n",
            "Iteration 934, loss = 78067677.34429777\n",
            "Iteration 935, loss = 77795488.61124499\n",
            "Iteration 936, loss = 77514656.24790531\n",
            "Iteration 937, loss = 77242214.98887523\n",
            "Iteration 938, loss = 76972975.06207670\n",
            "Iteration 939, loss = 76691753.77821745\n",
            "Iteration 940, loss = 76433962.40722705\n",
            "Iteration 941, loss = 76149841.75215375\n",
            "Iteration 942, loss = 75883166.51884066\n",
            "Iteration 943, loss = 75617917.57208548\n",
            "Iteration 944, loss = 75349404.77262650\n",
            "Iteration 945, loss = 75092625.97018735\n",
            "Iteration 946, loss = 74820611.74924053\n",
            "Iteration 947, loss = 74561189.32586235\n",
            "Iteration 948, loss = 74315939.08981200\n",
            "Iteration 949, loss = 74053893.57236171\n",
            "Iteration 950, loss = 73803927.50518672\n",
            "Iteration 951, loss = 73564288.87188931\n",
            "Iteration 952, loss = 73310851.88851325\n",
            "Iteration 953, loss = 73070053.87096050\n",
            "Iteration 954, loss = 72827350.90540621\n",
            "Iteration 955, loss = 72588081.20523071\n",
            "Iteration 956, loss = 72354306.37907241\n",
            "Iteration 957, loss = 72111330.90980472\n",
            "Iteration 958, loss = 71879749.27030350\n",
            "Iteration 959, loss = 71648385.91955721\n",
            "Iteration 960, loss = 71419810.38859040\n",
            "Iteration 961, loss = 71190740.25726703\n",
            "Iteration 962, loss = 70966404.76151246\n",
            "Iteration 963, loss = 70748253.95991232\n",
            "Iteration 964, loss = 70526455.98472224\n",
            "Iteration 965, loss = 70308982.27660225\n",
            "Iteration 966, loss = 70094890.65487814\n",
            "Iteration 967, loss = 69888968.31179124\n",
            "Iteration 968, loss = 69679130.20766224\n",
            "Iteration 969, loss = 69476533.15396811\n",
            "Iteration 970, loss = 69274182.16476730\n",
            "Iteration 971, loss = 69075068.29257673\n",
            "Iteration 972, loss = 68878412.88928142\n",
            "Iteration 973, loss = 68683384.74408168\n",
            "Iteration 974, loss = 68487269.82592462\n",
            "Iteration 975, loss = 68295823.04725534\n",
            "Iteration 976, loss = 68101555.63499163\n",
            "Iteration 977, loss = 67915030.52648519\n",
            "Iteration 978, loss = 67724125.78498417\n",
            "Iteration 979, loss = 67543417.19432844\n",
            "Iteration 980, loss = 67358319.66273642\n",
            "Iteration 981, loss = 67173015.51650664\n",
            "Iteration 982, loss = 66998388.09006820\n",
            "Iteration 983, loss = 66810705.49047872\n",
            "Iteration 984, loss = 66639498.31032856\n",
            "Iteration 985, loss = 66460550.84873983\n",
            "Iteration 986, loss = 66286876.69040222\n",
            "Iteration 987, loss = 66107388.59775176\n",
            "Iteration 988, loss = 65945268.41375460\n",
            "Iteration 989, loss = 65773854.80936611\n",
            "Iteration 990, loss = 65608201.06777949\n",
            "Iteration 991, loss = 65440230.38118063\n",
            "Iteration 992, loss = 65283075.12178467\n",
            "Iteration 993, loss = 65127149.92870183\n",
            "Iteration 994, loss = 64958761.31423351\n",
            "Iteration 995, loss = 64805099.80581725\n",
            "Iteration 996, loss = 64646764.88951599\n",
            "Iteration 997, loss = 64504049.77006631\n",
            "Iteration 998, loss = 64346138.10510001\n",
            "Iteration 999, loss = 64206260.48021970\n",
            "Iteration 1000, loss = 64061979.69083523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1529950825.77668715\n",
            "Iteration 2, loss = 308507992.57169801\n",
            "Iteration 3, loss = 212446757.89033756\n",
            "Iteration 4, loss = 103115453.39684363\n",
            "Iteration 5, loss = 76552448.60503165\n",
            "Iteration 6, loss = 62699651.02630945\n",
            "Iteration 7, loss = 72529845.41809209\n",
            "Iteration 8, loss = 71479779.27486679\n",
            "Iteration 9, loss = 62904927.50847667\n",
            "Iteration 10, loss = 53242223.75266352\n",
            "Iteration 11, loss = 45414903.94572051\n",
            "Iteration 12, loss = 39080954.26575273\n",
            "Iteration 13, loss = 31373011.02935915\n",
            "Iteration 14, loss = 28197086.87828122\n",
            "Iteration 15, loss = 23555548.64241927\n",
            "Iteration 16, loss = 21670245.29099130\n",
            "Iteration 17, loss = 19113864.24320780\n",
            "Iteration 18, loss = 16147071.20843838\n",
            "Iteration 19, loss = 14252598.81325591\n",
            "Iteration 20, loss = 13071383.67050703\n",
            "Iteration 21, loss = 11327704.13025325\n",
            "Iteration 22, loss = 10447060.04551679\n",
            "Iteration 23, loss = 9387510.90880489\n",
            "Iteration 24, loss = 8635889.50267688\n",
            "Iteration 25, loss = 7965875.35469306\n",
            "Iteration 26, loss = 7585988.43777651\n",
            "Iteration 27, loss = 7640757.62067330\n",
            "Iteration 28, loss = 10699191.81703726\n",
            "Iteration 29, loss = 7700991.05098960\n",
            "Iteration 30, loss = 6432691.91186876\n",
            "Iteration 31, loss = 6167954.27565528\n",
            "Iteration 32, loss = 6046814.07558993\n",
            "Iteration 33, loss = 6202146.83790343\n",
            "Iteration 34, loss = 5779280.71222423\n",
            "Iteration 35, loss = 5652506.38696074\n",
            "Iteration 36, loss = 5608241.82826673\n",
            "Iteration 37, loss = 5449997.51678564\n",
            "Iteration 38, loss = 5440492.37280660\n",
            "Iteration 39, loss = 5374733.03667411\n",
            "Iteration 40, loss = 5263582.51418339\n",
            "Iteration 41, loss = 5247585.00698708\n",
            "Iteration 42, loss = 5111868.43216457\n",
            "Iteration 43, loss = 5014852.02292934\n",
            "Iteration 44, loss = 5188501.41305949\n",
            "Iteration 45, loss = 4879502.05972020\n",
            "Iteration 46, loss = 4839431.48951357\n",
            "Iteration 47, loss = 4779152.41882252\n",
            "Iteration 48, loss = 4722531.62104716\n",
            "Iteration 49, loss = 4686006.73510546\n",
            "Iteration 50, loss = 4744254.91688728\n",
            "Iteration 51, loss = 4931923.59523360\n",
            "Iteration 52, loss = 4939259.53138192\n",
            "Iteration 53, loss = 4866639.46309127\n",
            "Iteration 54, loss = 4748927.78968781\n",
            "Iteration 55, loss = 4736386.60877203\n",
            "Iteration 56, loss = 5210771.84406158\n",
            "Iteration 57, loss = 5256698.78096228\n",
            "Iteration 58, loss = 4522127.43029656\n",
            "Iteration 59, loss = 8517725.50201564\n",
            "Iteration 60, loss = 10830181.06206308\n",
            "Iteration 61, loss = 10994134.37109048\n",
            "Iteration 62, loss = 10028521.96468552\n",
            "Iteration 63, loss = 8857082.68815387\n",
            "Iteration 64, loss = 8247600.78878556\n",
            "Iteration 65, loss = 7178396.56214940\n",
            "Iteration 66, loss = 6979406.59810085\n",
            "Iteration 67, loss = 6647943.24969950\n",
            "Iteration 68, loss = 7919478.39389566\n",
            "Iteration 69, loss = 7714123.03731789\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538806961.00378799\n",
            "Iteration 2, loss = 1538773727.67524576\n",
            "Iteration 3, loss = 1538738424.49121666\n",
            "Iteration 4, loss = 1538699835.77157927\n",
            "Iteration 5, loss = 1538658536.47918034\n",
            "Iteration 6, loss = 1538615466.89843559\n",
            "Iteration 7, loss = 1538568639.31938028\n",
            "Iteration 8, loss = 1538517848.33870625\n",
            "Iteration 9, loss = 1538464986.59122372\n",
            "Iteration 10, loss = 1538406559.69676018\n",
            "Iteration 11, loss = 1538346211.26480913\n",
            "Iteration 12, loss = 1538286035.82257438\n",
            "Iteration 13, loss = 1538216916.21439242\n",
            "Iteration 14, loss = 1538145837.88024092\n",
            "Iteration 15, loss = 1538073884.61784458\n",
            "Iteration 16, loss = 1538000527.37691617\n",
            "Iteration 17, loss = 1537921091.66855383\n",
            "Iteration 18, loss = 1537838884.18801713\n",
            "Iteration 19, loss = 1537754191.72487164\n",
            "Iteration 20, loss = 1537663242.79965162\n",
            "Iteration 21, loss = 1537569493.77058315\n",
            "Iteration 22, loss = 1537471663.95681429\n",
            "Iteration 23, loss = 1537367519.48840332\n",
            "Iteration 24, loss = 1537258779.96510720\n",
            "Iteration 25, loss = 1537144713.28984761\n",
            "Iteration 26, loss = 1537025322.38113570\n",
            "Iteration 27, loss = 1536900238.90566230\n",
            "Iteration 28, loss = 1536769385.42367482\n",
            "Iteration 29, loss = 1536633944.30973125\n",
            "Iteration 30, loss = 1536493006.93365097\n",
            "Iteration 31, loss = 1536347700.69424844\n",
            "Iteration 32, loss = 1536198309.88845992\n",
            "Iteration 33, loss = 1536044962.59129667\n",
            "Iteration 34, loss = 1535886695.65156698\n",
            "Iteration 35, loss = 1535725411.52366424\n",
            "Iteration 36, loss = 1535562286.43780828\n",
            "Iteration 37, loss = 1535395544.50183773\n",
            "Iteration 38, loss = 1535227547.49344635\n",
            "Iteration 39, loss = 1535054655.04595900\n",
            "Iteration 40, loss = 1534879372.05143738\n",
            "Iteration 41, loss = 1534701513.27150083\n",
            "Iteration 42, loss = 1534522606.42428970\n",
            "Iteration 43, loss = 1534343825.40946221\n",
            "Iteration 44, loss = 1534163744.30751944\n",
            "Iteration 45, loss = 1533984288.06878400\n",
            "Iteration 46, loss = 1533805746.08157802\n",
            "Iteration 47, loss = 1533626337.43649220\n",
            "Iteration 48, loss = 1533447240.57842731\n",
            "Iteration 49, loss = 1533269292.35807395\n",
            "Iteration 50, loss = 1533091316.60510254\n",
            "Iteration 51, loss = 1532914678.61732960\n",
            "Iteration 52, loss = 1532738855.51004243\n",
            "Iteration 53, loss = 1532563240.65971708\n",
            "Iteration 54, loss = 1532388181.35754061\n",
            "Iteration 55, loss = 1532216189.48225594\n",
            "Iteration 56, loss = 1532042794.96966386\n",
            "Iteration 57, loss = 1531872127.61884737\n",
            "Iteration 58, loss = 1531701826.65500975\n",
            "Iteration 59, loss = 1531533412.00377250\n",
            "Iteration 60, loss = 1531365758.60377145\n",
            "Iteration 61, loss = 1531198128.79466391\n",
            "Iteration 62, loss = 1531032597.09175658\n",
            "Iteration 63, loss = 1530866890.15509534\n",
            "Iteration 64, loss = 1530702437.26055741\n",
            "Iteration 65, loss = 1530540286.13432217\n",
            "Iteration 66, loss = 1530377970.81883025\n",
            "Iteration 67, loss = 1530216775.41888332\n",
            "Iteration 68, loss = 1530056575.47856212\n",
            "Iteration 69, loss = 1529897350.27882218\n",
            "Iteration 70, loss = 1529738290.83967781\n",
            "Iteration 71, loss = 1529581017.84393644\n",
            "Iteration 72, loss = 1529424656.43606186\n",
            "Iteration 73, loss = 1529267467.76247501\n",
            "Iteration 74, loss = 1529112847.22297502\n",
            "Iteration 75, loss = 1528958503.94350004\n",
            "Iteration 76, loss = 1528805015.11677265\n",
            "Iteration 77, loss = 1528651173.19498301\n",
            "Iteration 78, loss = 1528499483.15677333\n",
            "Iteration 79, loss = 1528348886.73664498\n",
            "Iteration 80, loss = 1528197724.48176575\n",
            "Iteration 81, loss = 1528048660.29330897\n",
            "Iteration 82, loss = 1527899852.51708150\n",
            "Iteration 83, loss = 1527753060.33434319\n",
            "Iteration 84, loss = 1527606241.98230624\n",
            "Iteration 85, loss = 1527460232.12475514\n",
            "Iteration 86, loss = 1527313909.88920975\n",
            "Iteration 87, loss = 1527168969.35156274\n",
            "Iteration 88, loss = 1527023584.48665357\n",
            "Iteration 89, loss = 1526878354.30640531\n",
            "Iteration 90, loss = 1526734502.49121785\n",
            "Iteration 91, loss = 1526591942.69754648\n",
            "Iteration 92, loss = 1526448942.69044042\n",
            "Iteration 93, loss = 1526307146.54096603\n",
            "Iteration 94, loss = 1526165603.17770720\n",
            "Iteration 95, loss = 1526023973.09898973\n",
            "Iteration 96, loss = 1525884241.87261128\n",
            "Iteration 97, loss = 1525744002.66328669\n",
            "Iteration 98, loss = 1525605255.18693328\n",
            "Iteration 99, loss = 1525465413.50629163\n",
            "Iteration 100, loss = 1525327190.29499245\n",
            "Iteration 101, loss = 1525190303.06297159\n",
            "Iteration 102, loss = 1525052339.12191677\n",
            "Iteration 103, loss = 1524914959.68775082\n",
            "Iteration 104, loss = 1524778339.75698805\n",
            "Iteration 105, loss = 1524642551.36772466\n",
            "Iteration 106, loss = 1524505951.86120319\n",
            "Iteration 107, loss = 1524369271.34781909\n",
            "Iteration 108, loss = 1524233432.29601908\n",
            "Iteration 109, loss = 1524098198.98733282\n",
            "Iteration 110, loss = 1523962262.30847859\n",
            "Iteration 111, loss = 1523827983.36688066\n",
            "Iteration 112, loss = 1523693277.86950421\n",
            "Iteration 113, loss = 1523558552.69628382\n",
            "Iteration 114, loss = 1523425445.84327507\n",
            "Iteration 115, loss = 1523291456.88407850\n",
            "Iteration 116, loss = 1523158750.11449218\n",
            "Iteration 117, loss = 1523025641.76227140\n",
            "Iteration 118, loss = 1522893549.66033864\n",
            "Iteration 119, loss = 1522760547.65916014\n",
            "Iteration 120, loss = 1522628974.31032991\n",
            "Iteration 121, loss = 1522497342.62562132\n",
            "Iteration 122, loss = 1522366020.28543401\n",
            "Iteration 123, loss = 1522234339.20719457\n",
            "Iteration 124, loss = 1522103834.45046639\n",
            "Iteration 125, loss = 1521972994.63888001\n",
            "Iteration 126, loss = 1521843475.09890819\n",
            "Iteration 127, loss = 1521713114.47080326\n",
            "Iteration 128, loss = 1521584273.96980762\n",
            "Iteration 129, loss = 1521454061.95018506\n",
            "Iteration 130, loss = 1521325398.71251202\n",
            "Iteration 131, loss = 1521196896.91126561\n",
            "Iteration 132, loss = 1521068523.46247840\n",
            "Iteration 133, loss = 1520940000.80544662\n",
            "Iteration 134, loss = 1520812592.60575509\n",
            "Iteration 135, loss = 1520684129.09684086\n",
            "Iteration 136, loss = 1520556326.80995655\n",
            "Iteration 137, loss = 1520428977.77453375\n",
            "Iteration 138, loss = 1520301885.45405245\n",
            "Iteration 139, loss = 1520173930.06381941\n",
            "Iteration 140, loss = 1520047088.36609936\n",
            "Iteration 141, loss = 1519919859.89113355\n",
            "Iteration 142, loss = 1519792942.91358733\n",
            "Iteration 143, loss = 1519666314.58249784\n",
            "Iteration 144, loss = 1519539981.99713373\n",
            "Iteration 145, loss = 1519413294.16486001\n",
            "Iteration 146, loss = 1519287629.76372647\n",
            "Iteration 147, loss = 1519161370.36958218\n",
            "Iteration 148, loss = 1519036622.09930611\n",
            "Iteration 149, loss = 1518910012.27275491\n",
            "Iteration 150, loss = 1518784908.02465081\n",
            "Iteration 151, loss = 1518659780.71431255\n",
            "Iteration 152, loss = 1518534498.21069241\n",
            "Iteration 153, loss = 1518409061.84823632\n",
            "Iteration 154, loss = 1518284509.58263087\n",
            "Iteration 155, loss = 1518159679.26545906\n",
            "Iteration 156, loss = 1518035041.29775429\n",
            "Iteration 157, loss = 1517911282.33227253\n",
            "Iteration 158, loss = 1517786714.31990123\n",
            "Iteration 159, loss = 1517663187.31087661\n",
            "Iteration 160, loss = 1517539959.44257188\n",
            "Iteration 161, loss = 1517416063.85416889\n",
            "Iteration 162, loss = 1517292521.75814247\n",
            "Iteration 163, loss = 1517170298.29197931\n",
            "Iteration 164, loss = 1517046723.85850787\n",
            "Iteration 165, loss = 1516924156.42646360\n",
            "Iteration 166, loss = 1516800528.03229117\n",
            "Iteration 167, loss = 1516678493.73058009\n",
            "Iteration 168, loss = 1516555970.89873815\n",
            "Iteration 169, loss = 1516433515.22010326\n",
            "Iteration 170, loss = 1516311059.49931622\n",
            "Iteration 171, loss = 1516188195.67198205\n",
            "Iteration 172, loss = 1516065661.35035324\n",
            "Iteration 173, loss = 1515943911.83164263\n",
            "Iteration 174, loss = 1515821065.49379468\n",
            "Iteration 175, loss = 1515698465.94657063\n",
            "Iteration 176, loss = 1515577053.64199185\n",
            "Iteration 177, loss = 1515454596.62141967\n",
            "Iteration 178, loss = 1515332256.12216425\n",
            "Iteration 179, loss = 1515210531.44467068\n",
            "Iteration 180, loss = 1515088777.28762317\n",
            "Iteration 181, loss = 1514966398.97367120\n",
            "Iteration 182, loss = 1514845384.50092244\n",
            "Iteration 183, loss = 1514723616.26606655\n",
            "Iteration 184, loss = 1514601942.54862809\n",
            "Iteration 185, loss = 1514480483.01481533\n",
            "Iteration 186, loss = 1514359643.95414877\n",
            "Iteration 187, loss = 1514238462.24158907\n",
            "Iteration 188, loss = 1514117293.50211501\n",
            "Iteration 189, loss = 1513997126.15004325\n",
            "Iteration 190, loss = 1513876050.45630121\n",
            "Iteration 191, loss = 1513756168.79556179\n",
            "Iteration 192, loss = 1513635775.91599488\n",
            "Iteration 193, loss = 1513515702.88519979\n",
            "Iteration 194, loss = 1513395875.70410204\n",
            "Iteration 195, loss = 1513276009.13379478\n",
            "Iteration 196, loss = 1513155890.22219539\n",
            "Iteration 197, loss = 1513037046.16880417\n",
            "Iteration 198, loss = 1512917264.59376454\n",
            "Iteration 199, loss = 1512798136.23396349\n",
            "Iteration 200, loss = 1512678411.66869521\n",
            "Iteration 201, loss = 1512559985.16469359\n",
            "Iteration 202, loss = 1512441367.14478588\n",
            "Iteration 203, loss = 1512322174.99868131\n",
            "Iteration 204, loss = 1512203805.90754533\n",
            "Iteration 205, loss = 1512084664.54040432\n",
            "Iteration 206, loss = 1511966797.79307532\n",
            "Iteration 207, loss = 1511848203.62012506\n",
            "Iteration 208, loss = 1511729861.13525963\n",
            "Iteration 209, loss = 1511611933.58297062\n",
            "Iteration 210, loss = 1511493725.29069877\n",
            "Iteration 211, loss = 1511375852.60857892\n",
            "Iteration 212, loss = 1511257728.68578887\n",
            "Iteration 213, loss = 1511139569.99536729\n",
            "Iteration 214, loss = 1511020988.04274178\n",
            "Iteration 215, loss = 1510902422.93633175\n",
            "Iteration 216, loss = 1510784416.76016355\n",
            "Iteration 217, loss = 1510666490.41704869\n",
            "Iteration 218, loss = 1510547443.73256731\n",
            "Iteration 219, loss = 1510429816.45643544\n",
            "Iteration 220, loss = 1510311259.64037061\n",
            "Iteration 221, loss = 1510193863.59546137\n",
            "Iteration 222, loss = 1510075544.72921515\n",
            "Iteration 223, loss = 1509958535.38157582\n",
            "Iteration 224, loss = 1509839822.02757072\n",
            "Iteration 225, loss = 1509722659.66627741\n",
            "Iteration 226, loss = 1509605939.25162768\n",
            "Iteration 227, loss = 1509487902.91600823\n",
            "Iteration 228, loss = 1509370672.54288840\n",
            "Iteration 229, loss = 1509253761.32488155\n",
            "Iteration 230, loss = 1509136883.65033937\n",
            "Iteration 231, loss = 1509020336.47311592\n",
            "Iteration 232, loss = 1508902992.57546902\n",
            "Iteration 233, loss = 1508786075.08963537\n",
            "Iteration 234, loss = 1508670535.36098480\n",
            "Iteration 235, loss = 1508553842.45334506\n",
            "Iteration 236, loss = 1508436899.75069857\n",
            "Iteration 237, loss = 1508321190.28879833\n",
            "Iteration 238, loss = 1508205287.58633637\n",
            "Iteration 239, loss = 1508088083.54268289\n",
            "Iteration 240, loss = 1507971726.13834333\n",
            "Iteration 241, loss = 1507855479.81576467\n",
            "Iteration 242, loss = 1507738741.44897580\n",
            "Iteration 243, loss = 1507622340.47901607\n",
            "Iteration 244, loss = 1507505774.91135836\n",
            "Iteration 245, loss = 1507389334.56781316\n",
            "Iteration 246, loss = 1507273183.11086464\n",
            "Iteration 247, loss = 1507158503.71844149\n",
            "Iteration 248, loss = 1507041661.78990579\n",
            "Iteration 249, loss = 1506926635.38841724\n",
            "Iteration 250, loss = 1506811963.30939007\n",
            "Iteration 251, loss = 1506696863.24619913\n",
            "Iteration 252, loss = 1506581912.15384793\n",
            "Iteration 253, loss = 1506466944.27274942\n",
            "Iteration 254, loss = 1506352276.62524557\n",
            "Iteration 255, loss = 1506237107.02157879\n",
            "Iteration 256, loss = 1506122319.44487572\n",
            "Iteration 257, loss = 1506007882.69661117\n",
            "Iteration 258, loss = 1505891939.72248173\n",
            "Iteration 259, loss = 1505776795.10124397\n",
            "Iteration 260, loss = 1505661741.80014753\n",
            "Iteration 261, loss = 1505546321.50251341\n",
            "Iteration 262, loss = 1505431246.23079515\n",
            "Iteration 263, loss = 1505316189.24637294\n",
            "Iteration 264, loss = 1505200453.50150657\n",
            "Iteration 265, loss = 1505085556.63901186\n",
            "Iteration 266, loss = 1504970115.33910155\n",
            "Iteration 267, loss = 1504855479.77779198\n",
            "Iteration 268, loss = 1504741017.24297690\n",
            "Iteration 269, loss = 1504625060.14894223\n",
            "Iteration 270, loss = 1504511355.52674150\n",
            "Iteration 271, loss = 1504396035.43991971\n",
            "Iteration 272, loss = 1504280846.21446776\n",
            "Iteration 273, loss = 1504166862.20032072\n",
            "Iteration 274, loss = 1504051960.75170398\n",
            "Iteration 275, loss = 1503936094.53395820\n",
            "Iteration 276, loss = 1503822536.22404265\n",
            "Iteration 277, loss = 1503707604.79748344\n",
            "Iteration 278, loss = 1503593240.81978512\n",
            "Iteration 279, loss = 1503478839.86463666\n",
            "Iteration 280, loss = 1503365521.68713355\n",
            "Iteration 281, loss = 1503250644.70533919\n",
            "Iteration 282, loss = 1503137254.89972210\n",
            "Iteration 283, loss = 1503023659.32885027\n",
            "Iteration 284, loss = 1502909617.26913118\n",
            "Iteration 285, loss = 1502796094.04146028\n",
            "Iteration 286, loss = 1502682713.72585559\n",
            "Iteration 287, loss = 1502568616.39409256\n",
            "Iteration 288, loss = 1502455554.09658408\n",
            "Iteration 289, loss = 1502341360.58796716\n",
            "Iteration 290, loss = 1502228329.29156041\n",
            "Iteration 291, loss = 1502114705.45286155\n",
            "Iteration 292, loss = 1502001107.47551537\n",
            "Iteration 293, loss = 1501887296.12598181\n",
            "Iteration 294, loss = 1501774140.01062894\n",
            "Iteration 295, loss = 1501660221.48330760\n",
            "Iteration 296, loss = 1501546412.64748645\n",
            "Iteration 297, loss = 1501433396.89547181\n",
            "Iteration 298, loss = 1501319363.61211586\n",
            "Iteration 299, loss = 1501205914.95573640\n",
            "Iteration 300, loss = 1501093019.21795225\n",
            "Iteration 301, loss = 1500979573.22324634\n",
            "Iteration 302, loss = 1500865981.47566509\n",
            "Iteration 303, loss = 1500752738.94971180\n",
            "Iteration 304, loss = 1500639254.58124995\n",
            "Iteration 305, loss = 1500526224.06194210\n",
            "Iteration 306, loss = 1500412808.08744287\n",
            "Iteration 307, loss = 1500299285.63552046\n",
            "Iteration 308, loss = 1500185391.07638860\n",
            "Iteration 309, loss = 1500072758.23655462\n",
            "Iteration 310, loss = 1499959946.32844734\n",
            "Iteration 311, loss = 1499845604.64739728\n",
            "Iteration 312, loss = 1499733644.95039821\n",
            "Iteration 313, loss = 1499620402.00842571\n",
            "Iteration 314, loss = 1499507259.46415734\n",
            "Iteration 315, loss = 1499393973.25014830\n",
            "Iteration 316, loss = 1499281232.85973239\n",
            "Iteration 317, loss = 1499167685.96387601\n",
            "Iteration 318, loss = 1499054442.42721701\n",
            "Iteration 319, loss = 1498941217.72296643\n",
            "Iteration 320, loss = 1498828322.85293150\n",
            "Iteration 321, loss = 1498715169.62800360\n",
            "Iteration 322, loss = 1498602045.80920506\n",
            "Iteration 323, loss = 1498489921.62013459\n",
            "Iteration 324, loss = 1498377153.50700903\n",
            "Iteration 325, loss = 1498264429.78045273\n",
            "Iteration 326, loss = 1498152138.99414206\n",
            "Iteration 327, loss = 1498039640.33471918\n",
            "Iteration 328, loss = 1497927813.71552992\n",
            "Iteration 329, loss = 1497814892.03302240\n",
            "Iteration 330, loss = 1497702871.20862269\n",
            "Iteration 331, loss = 1497591466.55862260\n",
            "Iteration 332, loss = 1497479406.40058374\n",
            "Iteration 333, loss = 1497366317.07294679\n",
            "Iteration 334, loss = 1497255387.83969045\n",
            "Iteration 335, loss = 1497142753.40647316\n",
            "Iteration 336, loss = 1497031477.70436668\n",
            "Iteration 337, loss = 1496919292.04459167\n",
            "Iteration 338, loss = 1496807232.76734900\n",
            "Iteration 339, loss = 1496695097.00189042\n",
            "Iteration 340, loss = 1496583747.95544744\n",
            "Iteration 341, loss = 1496471716.36369371\n",
            "Iteration 342, loss = 1496359386.92851400\n",
            "Iteration 343, loss = 1496247491.97596073\n",
            "Iteration 344, loss = 1496135847.25806808\n",
            "Iteration 345, loss = 1496024011.93255281\n",
            "Iteration 346, loss = 1495912195.62402439\n",
            "Iteration 347, loss = 1495800348.39365768\n",
            "Iteration 348, loss = 1495689233.73704767\n",
            "Iteration 349, loss = 1495576752.55277872\n",
            "Iteration 350, loss = 1495466279.09666491\n",
            "Iteration 351, loss = 1495353924.70802140\n",
            "Iteration 352, loss = 1495242532.80565763\n",
            "Iteration 353, loss = 1495131401.60828042\n",
            "Iteration 354, loss = 1495019999.71260548\n",
            "Iteration 355, loss = 1494908126.51195145\n",
            "Iteration 356, loss = 1494796869.32529736\n",
            "Iteration 357, loss = 1494686163.12271380\n",
            "Iteration 358, loss = 1494573816.14452004\n",
            "Iteration 359, loss = 1494463112.59383988\n",
            "Iteration 360, loss = 1494351352.17912698\n",
            "Iteration 361, loss = 1494240185.03686380\n",
            "Iteration 362, loss = 1494128709.87425160\n",
            "Iteration 363, loss = 1494017441.53994727\n",
            "Iteration 364, loss = 1493906240.40327215\n",
            "Iteration 365, loss = 1493795631.95503044\n",
            "Iteration 366, loss = 1493684308.37718272\n",
            "Iteration 367, loss = 1493573748.36047459\n",
            "Iteration 368, loss = 1493462872.37643194\n",
            "Iteration 369, loss = 1493352493.28071642\n",
            "Iteration 370, loss = 1493241540.91165137\n",
            "Iteration 371, loss = 1493130768.76037526\n",
            "Iteration 372, loss = 1493019444.79436660\n",
            "Iteration 373, loss = 1492908130.97600174\n",
            "Iteration 374, loss = 1492797440.75835085\n",
            "Iteration 375, loss = 1492685621.60447812\n",
            "Iteration 376, loss = 1492574313.63695574\n",
            "Iteration 377, loss = 1492463245.26568460\n",
            "Iteration 378, loss = 1492351415.47044420\n",
            "Iteration 379, loss = 1492241248.15952492\n",
            "Iteration 380, loss = 1492129185.77046657\n",
            "Iteration 381, loss = 1492018639.70171356\n",
            "Iteration 382, loss = 1491907421.02837443\n",
            "Iteration 383, loss = 1491796350.09165382\n",
            "Iteration 384, loss = 1491686092.32404113\n",
            "Iteration 385, loss = 1491575828.46621799\n",
            "Iteration 386, loss = 1491464695.80534124\n",
            "Iteration 387, loss = 1491354289.99128199\n",
            "Iteration 388, loss = 1491244157.84328079\n",
            "Iteration 389, loss = 1491134056.01591110\n",
            "Iteration 390, loss = 1491022885.50383615\n",
            "Iteration 391, loss = 1490913063.64815402\n",
            "Iteration 392, loss = 1490801984.36751962\n",
            "Iteration 393, loss = 1490691518.09215879\n",
            "Iteration 394, loss = 1490580750.89439368\n",
            "Iteration 395, loss = 1490470456.88224101\n",
            "Iteration 396, loss = 1490359480.03512454\n",
            "Iteration 397, loss = 1490248488.70036936\n",
            "Iteration 398, loss = 1490138540.28223705\n",
            "Iteration 399, loss = 1490027227.92757869\n",
            "Iteration 400, loss = 1489917137.45136833\n",
            "Iteration 401, loss = 1489806109.89235735\n",
            "Iteration 402, loss = 1489695585.41696501\n",
            "Iteration 403, loss = 1489586011.08157992\n",
            "Iteration 404, loss = 1489475038.00328612\n",
            "Iteration 405, loss = 1489365591.67553282\n",
            "Iteration 406, loss = 1489255333.04303265\n",
            "Iteration 407, loss = 1489145424.15825415\n",
            "Iteration 408, loss = 1489035983.84550667\n",
            "Iteration 409, loss = 1488925933.74653006\n",
            "Iteration 410, loss = 1488815854.21352291\n",
            "Iteration 411, loss = 1488706327.08431172\n",
            "Iteration 412, loss = 1488596799.68753719\n",
            "Iteration 413, loss = 1488486207.55581355\n",
            "Iteration 414, loss = 1488375731.78224063\n",
            "Iteration 415, loss = 1488266158.24916744\n",
            "Iteration 416, loss = 1488155473.78408694\n",
            "Iteration 417, loss = 1488045261.50721025\n",
            "Iteration 418, loss = 1487934806.95499468\n",
            "Iteration 419, loss = 1487824703.39526534\n",
            "Iteration 420, loss = 1487714125.26381922\n",
            "Iteration 421, loss = 1487603981.94017100\n",
            "Iteration 422, loss = 1487494098.15958405\n",
            "Iteration 423, loss = 1487384191.60116673\n",
            "Iteration 424, loss = 1487273671.71392918\n",
            "Iteration 425, loss = 1487165156.76283789\n",
            "Iteration 426, loss = 1487054697.66784525\n",
            "Iteration 427, loss = 1486944462.09755445\n",
            "Iteration 428, loss = 1486835686.24101782\n",
            "Iteration 429, loss = 1486725377.62242675\n",
            "Iteration 430, loss = 1486616105.60067153\n",
            "Iteration 431, loss = 1486505752.54828882\n",
            "Iteration 432, loss = 1486396510.52372646\n",
            "Iteration 433, loss = 1486286156.25566339\n",
            "Iteration 434, loss = 1486176420.33157301\n",
            "Iteration 435, loss = 1486066281.52917576\n",
            "Iteration 436, loss = 1485956647.01655722\n",
            "Iteration 437, loss = 1485846279.10942364\n",
            "Iteration 438, loss = 1485737095.30914855\n",
            "Iteration 439, loss = 1485627604.33780575\n",
            "Iteration 440, loss = 1485517260.50033164\n",
            "Iteration 441, loss = 1485408026.76175475\n",
            "Iteration 442, loss = 1485298658.84491658\n",
            "Iteration 443, loss = 1485189146.01360202\n",
            "Iteration 444, loss = 1485080009.05481982\n",
            "Iteration 445, loss = 1484970358.49297237\n",
            "Iteration 446, loss = 1484860525.41981554\n",
            "Iteration 447, loss = 1484751219.22582626\n",
            "Iteration 448, loss = 1484642141.21724796\n",
            "Iteration 449, loss = 1484532245.52089930\n",
            "Iteration 450, loss = 1484422829.37454724\n",
            "Iteration 451, loss = 1484312992.52290869\n",
            "Iteration 452, loss = 1484203516.51477647\n",
            "Iteration 453, loss = 1484094680.35828114\n",
            "Iteration 454, loss = 1483984757.15862465\n",
            "Iteration 455, loss = 1483875582.63170886\n",
            "Iteration 456, loss = 1483766644.82406020\n",
            "Iteration 457, loss = 1483657468.74278712\n",
            "Iteration 458, loss = 1483548067.09952593\n",
            "Iteration 459, loss = 1483438906.41994500\n",
            "Iteration 460, loss = 1483329772.51218271\n",
            "Iteration 461, loss = 1483220771.94026160\n",
            "Iteration 462, loss = 1483110959.44787359\n",
            "Iteration 463, loss = 1483002972.81850696\n",
            "Iteration 464, loss = 1482893508.48122907\n",
            "Iteration 465, loss = 1482784741.00955510\n",
            "Iteration 466, loss = 1482675633.96597695\n",
            "Iteration 467, loss = 1482566308.30217957\n",
            "Iteration 468, loss = 1482458125.04060793\n",
            "Iteration 469, loss = 1482347729.13100839\n",
            "Iteration 470, loss = 1482239234.13066149\n",
            "Iteration 471, loss = 1482130073.99513483\n",
            "Iteration 472, loss = 1482020482.44961882\n",
            "Iteration 473, loss = 1481910996.13225508\n",
            "Iteration 474, loss = 1481802745.98857641\n",
            "Iteration 475, loss = 1481692921.29720783\n",
            "Iteration 476, loss = 1481584579.60919261\n",
            "Iteration 477, loss = 1481474898.96219468\n",
            "Iteration 478, loss = 1481366292.25579023\n",
            "Iteration 479, loss = 1481257154.93011928\n",
            "Iteration 480, loss = 1481148751.46845627\n",
            "Iteration 481, loss = 1481038893.77618122\n",
            "Iteration 482, loss = 1480929848.24866199\n",
            "Iteration 483, loss = 1480821014.48906446\n",
            "Iteration 484, loss = 1480711849.25719452\n",
            "Iteration 485, loss = 1480602717.46070313\n",
            "Iteration 486, loss = 1480493864.90053678\n",
            "Iteration 487, loss = 1480384507.04217863\n",
            "Iteration 488, loss = 1480275582.48095298\n",
            "Iteration 489, loss = 1480167414.41500640\n",
            "Iteration 490, loss = 1480057702.37795639\n",
            "Iteration 491, loss = 1479948729.97121310\n",
            "Iteration 492, loss = 1479840162.06566596\n",
            "Iteration 493, loss = 1479731380.70453453\n",
            "Iteration 494, loss = 1479621657.93075275\n",
            "Iteration 495, loss = 1479513355.89647317\n",
            "Iteration 496, loss = 1479403899.14917135\n",
            "Iteration 497, loss = 1479295731.85373807\n",
            "Iteration 498, loss = 1479186724.42468953\n",
            "Iteration 499, loss = 1479078353.28080606\n",
            "Iteration 500, loss = 1478969706.59816980\n",
            "Iteration 501, loss = 1478861640.40111279\n",
            "Iteration 502, loss = 1478753048.00387645\n",
            "Iteration 503, loss = 1478644336.42826056\n",
            "Iteration 504, loss = 1478536381.94135118\n",
            "Iteration 505, loss = 1478427864.85648131\n",
            "Iteration 506, loss = 1478318539.60738873\n",
            "Iteration 507, loss = 1478210366.70193434\n",
            "Iteration 508, loss = 1478101186.89470100\n",
            "Iteration 509, loss = 1477992291.45445037\n",
            "Iteration 510, loss = 1477883994.72306657\n",
            "Iteration 511, loss = 1477774781.77970219\n",
            "Iteration 512, loss = 1477666632.97863388\n",
            "Iteration 513, loss = 1477557693.55392408\n",
            "Iteration 514, loss = 1477450076.41782475\n",
            "Iteration 515, loss = 1477341973.32026577\n",
            "Iteration 516, loss = 1477233775.97919726\n",
            "Iteration 517, loss = 1477125810.81282425\n",
            "Iteration 518, loss = 1477017928.51838851\n",
            "Iteration 519, loss = 1476910464.86706686\n",
            "Iteration 520, loss = 1476801423.14368129\n",
            "Iteration 521, loss = 1476693265.91688132\n",
            "Iteration 522, loss = 1476585252.02362514\n",
            "Iteration 523, loss = 1476476938.87714887\n",
            "Iteration 524, loss = 1476368504.74443197\n",
            "Iteration 525, loss = 1476260043.67527747\n",
            "Iteration 526, loss = 1476152149.10500669\n",
            "Iteration 527, loss = 1476043624.41089463\n",
            "Iteration 528, loss = 1475936141.85249543\n",
            "Iteration 529, loss = 1475828067.34957623\n",
            "Iteration 530, loss = 1475720564.02902770\n",
            "Iteration 531, loss = 1475613261.07448339\n",
            "Iteration 532, loss = 1475505192.80020881\n",
            "Iteration 533, loss = 1475398050.12841296\n",
            "Iteration 534, loss = 1475289980.79018927\n",
            "Iteration 535, loss = 1475182854.85768914\n",
            "Iteration 536, loss = 1475075503.09030962\n",
            "Iteration 537, loss = 1474967548.37378764\n",
            "Iteration 538, loss = 1474859550.72578931\n",
            "Iteration 539, loss = 1474752413.40161872\n",
            "Iteration 540, loss = 1474644959.59277058\n",
            "Iteration 541, loss = 1474537597.62630367\n",
            "Iteration 542, loss = 1474430004.48464441\n",
            "Iteration 543, loss = 1474322370.08824396\n",
            "Iteration 544, loss = 1474215311.62779641\n",
            "Iteration 545, loss = 1474107371.11139584\n",
            "Iteration 546, loss = 1474000188.00843096\n",
            "Iteration 547, loss = 1473892599.53739548\n",
            "Iteration 548, loss = 1473785506.93917608\n",
            "Iteration 549, loss = 1473677494.21705770\n",
            "Iteration 550, loss = 1473569919.64905739\n",
            "Iteration 551, loss = 1473462197.45844460\n",
            "Iteration 552, loss = 1473354688.29813552\n",
            "Iteration 553, loss = 1473247163.40126443\n",
            "Iteration 554, loss = 1473139294.18225121\n",
            "Iteration 555, loss = 1473031882.11988759\n",
            "Iteration 556, loss = 1472924092.97343111\n",
            "Iteration 557, loss = 1472816544.02631021\n",
            "Iteration 558, loss = 1472709089.19362950\n",
            "Iteration 559, loss = 1472601765.45640039\n",
            "Iteration 560, loss = 1472494048.60457397\n",
            "Iteration 561, loss = 1472386935.51702809\n",
            "Iteration 562, loss = 1472279373.96100092\n",
            "Iteration 563, loss = 1472172645.72355604\n",
            "Iteration 564, loss = 1472065523.77941370\n",
            "Iteration 565, loss = 1471958319.92903066\n",
            "Iteration 566, loss = 1471851701.09271741\n",
            "Iteration 567, loss = 1471744324.63244724\n",
            "Iteration 568, loss = 1471636872.31461477\n",
            "Iteration 569, loss = 1471530312.47350383\n",
            "Iteration 570, loss = 1471423421.08389688\n",
            "Iteration 571, loss = 1471316021.07780695\n",
            "Iteration 572, loss = 1471209046.89777112\n",
            "Iteration 573, loss = 1471102531.94835687\n",
            "Iteration 574, loss = 1470995382.61419964\n",
            "Iteration 575, loss = 1470887814.26698399\n",
            "Iteration 576, loss = 1470781663.73989201\n",
            "Iteration 577, loss = 1470674046.02430081\n",
            "Iteration 578, loss = 1470566505.20233679\n",
            "Iteration 579, loss = 1470459422.45439076\n",
            "Iteration 580, loss = 1470353210.66972923\n",
            "Iteration 581, loss = 1470244786.15938401\n",
            "Iteration 582, loss = 1470138176.20575905\n",
            "Iteration 583, loss = 1470031106.18968391\n",
            "Iteration 584, loss = 1469923870.86957169\n",
            "Iteration 585, loss = 1469817437.27588534\n",
            "Iteration 586, loss = 1469709516.07366109\n",
            "Iteration 587, loss = 1469603208.92209387\n",
            "Iteration 588, loss = 1469495863.83930182\n",
            "Iteration 589, loss = 1469388090.45530677\n",
            "Iteration 590, loss = 1469280574.75795245\n",
            "Iteration 591, loss = 1469173017.55416703\n",
            "Iteration 592, loss = 1469065017.01030207\n",
            "Iteration 593, loss = 1468956933.41505075\n",
            "Iteration 594, loss = 1468848982.42512798\n",
            "Iteration 595, loss = 1468741420.88634181\n",
            "Iteration 596, loss = 1468633213.71975422\n",
            "Iteration 597, loss = 1468525055.17465234\n",
            "Iteration 598, loss = 1468417969.98348975\n",
            "Iteration 599, loss = 1468310642.03817129\n",
            "Iteration 600, loss = 1468202810.72890949\n",
            "Iteration 601, loss = 1468095151.28242207\n",
            "Iteration 602, loss = 1467988085.10812449\n",
            "Iteration 603, loss = 1467880758.33208394\n",
            "Iteration 604, loss = 1467773203.66597652\n",
            "Iteration 605, loss = 1467665282.84540725\n",
            "Iteration 606, loss = 1467557593.07462335\n",
            "Iteration 607, loss = 1467451331.83025074\n",
            "Iteration 608, loss = 1467343189.35027814\n",
            "Iteration 609, loss = 1467235837.05789757\n",
            "Iteration 610, loss = 1467129539.25618863\n",
            "Iteration 611, loss = 1467021736.65405345\n",
            "Iteration 612, loss = 1466914842.87354755\n",
            "Iteration 613, loss = 1466808308.68130660\n",
            "Iteration 614, loss = 1466701596.19996643\n",
            "Iteration 615, loss = 1466594572.31531262\n",
            "Iteration 616, loss = 1466488306.69526243\n",
            "Iteration 617, loss = 1466381563.55773234\n",
            "Iteration 618, loss = 1466275110.20314884\n",
            "Iteration 619, loss = 1466168911.55730295\n",
            "Iteration 620, loss = 1466062484.57617426\n",
            "Iteration 621, loss = 1465956275.88368130\n",
            "Iteration 622, loss = 1465850380.80965853\n",
            "Iteration 623, loss = 1465743891.93422461\n",
            "Iteration 624, loss = 1465637972.88759804\n",
            "Iteration 625, loss = 1465531639.47937536\n",
            "Iteration 626, loss = 1465425612.49318862\n",
            "Iteration 627, loss = 1465319493.47058415\n",
            "Iteration 628, loss = 1465212952.27635145\n",
            "Iteration 629, loss = 1465106526.45035148\n",
            "Iteration 630, loss = 1464999892.48488116\n",
            "Iteration 631, loss = 1464892928.92799044\n",
            "Iteration 632, loss = 1464787015.13654280\n",
            "Iteration 633, loss = 1464679646.50680852\n",
            "Iteration 634, loss = 1464573108.59114075\n",
            "Iteration 635, loss = 1464466380.66691518\n",
            "Iteration 636, loss = 1464359425.73232198\n",
            "Iteration 637, loss = 1464252926.51423502\n",
            "Iteration 638, loss = 1464146768.45951509\n",
            "Iteration 639, loss = 1464039565.65788078\n",
            "Iteration 640, loss = 1463933487.41328430\n",
            "Iteration 641, loss = 1463826985.24256301\n",
            "Iteration 642, loss = 1463720905.59150028\n",
            "Iteration 643, loss = 1463614553.89822173\n",
            "Iteration 644, loss = 1463508503.24203229\n",
            "Iteration 645, loss = 1463401595.47394109\n",
            "Iteration 646, loss = 1463296361.73394942\n",
            "Iteration 647, loss = 1463189562.03235650\n",
            "Iteration 648, loss = 1463083686.29037428\n",
            "Iteration 649, loss = 1462977433.88282657\n",
            "Iteration 650, loss = 1462871531.29065084\n",
            "Iteration 651, loss = 1462764116.92930579\n",
            "Iteration 652, loss = 1462658739.52004480\n",
            "Iteration 653, loss = 1462551706.79190278\n",
            "Iteration 654, loss = 1462444813.99095082\n",
            "Iteration 655, loss = 1462337986.14411688\n",
            "Iteration 656, loss = 1462231618.55577087\n",
            "Iteration 657, loss = 1462124594.49583626\n",
            "Iteration 658, loss = 1462018114.05561972\n",
            "Iteration 659, loss = 1461911166.40052962\n",
            "Iteration 660, loss = 1461804687.36669421\n",
            "Iteration 661, loss = 1461698119.53886747\n",
            "Iteration 662, loss = 1461591747.31411433\n",
            "Iteration 663, loss = 1461485681.29010606\n",
            "Iteration 664, loss = 1461377966.70769024\n",
            "Iteration 665, loss = 1461272121.21581078\n",
            "Iteration 666, loss = 1461166179.00208354\n",
            "Iteration 667, loss = 1461058633.10707116\n",
            "Iteration 668, loss = 1460952339.72458172\n",
            "Iteration 669, loss = 1460846176.14645600\n",
            "Iteration 670, loss = 1460739121.37972474\n",
            "Iteration 671, loss = 1460633559.29351044\n",
            "Iteration 672, loss = 1460526984.39596057\n",
            "Iteration 673, loss = 1460420307.58015800\n",
            "Iteration 674, loss = 1460313992.03126264\n",
            "Iteration 675, loss = 1460207717.30259132\n",
            "Iteration 676, loss = 1460102257.28950572\n",
            "Iteration 677, loss = 1459995687.09415007\n",
            "Iteration 678, loss = 1459889709.77647901\n",
            "Iteration 679, loss = 1459783721.76325011\n",
            "Iteration 680, loss = 1459677924.27097750\n",
            "Iteration 681, loss = 1459571618.94903541\n",
            "Iteration 682, loss = 1459465816.64725304\n",
            "Iteration 683, loss = 1459359349.77435398\n",
            "Iteration 684, loss = 1459252320.12980652\n",
            "Iteration 685, loss = 1459146199.04410267\n",
            "Iteration 686, loss = 1459038830.73225856\n",
            "Iteration 687, loss = 1458932280.05711627\n",
            "Iteration 688, loss = 1458825436.83893704\n",
            "Iteration 689, loss = 1458717915.55684114\n",
            "Iteration 690, loss = 1458611089.26700711\n",
            "Iteration 691, loss = 1458504004.39173460\n",
            "Iteration 692, loss = 1458396599.11307311\n",
            "Iteration 693, loss = 1458290849.47209859\n",
            "Iteration 694, loss = 1458183737.55704498\n",
            "Iteration 695, loss = 1458076730.45421004\n",
            "Iteration 696, loss = 1457970200.98414445\n",
            "Iteration 697, loss = 1457863494.34719992\n",
            "Iteration 698, loss = 1457757753.48823071\n",
            "Iteration 699, loss = 1457650690.20262957\n",
            "Iteration 700, loss = 1457543950.40435314\n",
            "Iteration 701, loss = 1457437561.87370491\n",
            "Iteration 702, loss = 1457330897.68802762\n",
            "Iteration 703, loss = 1457224194.32492161\n",
            "Iteration 704, loss = 1457118077.71626520\n",
            "Iteration 705, loss = 1457011479.08247185\n",
            "Iteration 706, loss = 1456905456.97223663\n",
            "Iteration 707, loss = 1456799589.41956663\n",
            "Iteration 708, loss = 1456693701.08213472\n",
            "Iteration 709, loss = 1456587027.48485327\n",
            "Iteration 710, loss = 1456481295.85283566\n",
            "Iteration 711, loss = 1456375657.58953762\n",
            "Iteration 712, loss = 1456269600.39805555\n",
            "Iteration 713, loss = 1456163407.73118711\n",
            "Iteration 714, loss = 1456057661.56414223\n",
            "Iteration 715, loss = 1455951833.77762175\n",
            "Iteration 716, loss = 1455845795.81642675\n",
            "Iteration 717, loss = 1455740500.27698326\n",
            "Iteration 718, loss = 1455634329.36898351\n",
            "Iteration 719, loss = 1455528411.67586327\n",
            "Iteration 720, loss = 1455423470.34390473\n",
            "Iteration 721, loss = 1455316917.35102034\n",
            "Iteration 722, loss = 1455212073.58452773\n",
            "Iteration 723, loss = 1455105939.16518974\n",
            "Iteration 724, loss = 1455001127.18835735\n",
            "Iteration 725, loss = 1454895210.47938800\n",
            "Iteration 726, loss = 1454788952.00442910\n",
            "Iteration 727, loss = 1454683581.41546082\n",
            "Iteration 728, loss = 1454577911.15896773\n",
            "Iteration 729, loss = 1454471212.64582825\n",
            "Iteration 730, loss = 1454365659.82581830\n",
            "Iteration 731, loss = 1454259539.69105411\n",
            "Iteration 732, loss = 1454153641.75227857\n",
            "Iteration 733, loss = 1454047361.31704617\n",
            "Iteration 734, loss = 1453941863.49396992\n",
            "Iteration 735, loss = 1453835973.35996890\n",
            "Iteration 736, loss = 1453730437.45410419\n",
            "Iteration 737, loss = 1453624173.58928680\n",
            "Iteration 738, loss = 1453518696.02564168\n",
            "Iteration 739, loss = 1453413231.14033031\n",
            "Iteration 740, loss = 1453307191.01050186\n",
            "Iteration 741, loss = 1453202039.18314314\n",
            "Iteration 742, loss = 1453096010.35781884\n",
            "Iteration 743, loss = 1452990239.68917799\n",
            "Iteration 744, loss = 1452885297.25926375\n",
            "Iteration 745, loss = 1452779688.61356020\n",
            "Iteration 746, loss = 1452674468.44790363\n",
            "Iteration 747, loss = 1452569261.56975603\n",
            "Iteration 748, loss = 1452463959.50901175\n",
            "Iteration 749, loss = 1452359228.05250454\n",
            "Iteration 750, loss = 1452253069.18620968\n",
            "Iteration 751, loss = 1452148559.73680711\n",
            "Iteration 752, loss = 1452042381.72629452\n",
            "Iteration 753, loss = 1451937241.52683139\n",
            "Iteration 754, loss = 1451831066.54908514\n",
            "Iteration 755, loss = 1451725633.51185107\n",
            "Iteration 756, loss = 1451619830.23503590\n",
            "Iteration 757, loss = 1451514455.52721310\n",
            "Iteration 758, loss = 1451408450.83801866\n",
            "Iteration 759, loss = 1451302228.11285996\n",
            "Iteration 760, loss = 1451197611.20952940\n",
            "Iteration 761, loss = 1451091397.60355210\n",
            "Iteration 762, loss = 1450985234.93145013\n",
            "Iteration 763, loss = 1450879442.27495265\n",
            "Iteration 764, loss = 1450773861.39212823\n",
            "Iteration 765, loss = 1450667742.78777218\n",
            "Iteration 766, loss = 1450561922.49343991\n",
            "Iteration 767, loss = 1450455620.68861604\n",
            "Iteration 768, loss = 1450351360.15764213\n",
            "Iteration 769, loss = 1450245149.70838666\n",
            "Iteration 770, loss = 1450140344.11994267\n",
            "Iteration 771, loss = 1450034656.61777163\n",
            "Iteration 772, loss = 1449929858.63403511\n",
            "Iteration 773, loss = 1449824758.72030091\n",
            "Iteration 774, loss = 1449718968.66448617\n",
            "Iteration 775, loss = 1449613511.59367681\n",
            "Iteration 776, loss = 1449508002.93569422\n",
            "Iteration 777, loss = 1449403293.00073457\n",
            "Iteration 778, loss = 1449297798.92128968\n",
            "Iteration 779, loss = 1449192852.61330938\n",
            "Iteration 780, loss = 1449087943.44717193\n",
            "Iteration 781, loss = 1448983234.18074203\n",
            "Iteration 782, loss = 1448878648.63148689\n",
            "Iteration 783, loss = 1448773341.05993080\n",
            "Iteration 784, loss = 1448668670.50453067\n",
            "Iteration 785, loss = 1448563519.36793399\n",
            "Iteration 786, loss = 1448458674.20141101\n",
            "Iteration 787, loss = 1448353741.12380028\n",
            "Iteration 788, loss = 1448247662.26839542\n",
            "Iteration 789, loss = 1448142185.63846540\n",
            "Iteration 790, loss = 1448036191.71142817\n",
            "Iteration 791, loss = 1447931088.59811783\n",
            "Iteration 792, loss = 1447825541.04766250\n",
            "Iteration 793, loss = 1447719117.06822324\n",
            "Iteration 794, loss = 1447614295.20482230\n",
            "Iteration 795, loss = 1447508771.98642898\n",
            "Iteration 796, loss = 1447403882.30631566\n",
            "Iteration 797, loss = 1447298800.78412867\n",
            "Iteration 798, loss = 1447194230.99560690\n",
            "Iteration 799, loss = 1447089169.01543546\n",
            "Iteration 800, loss = 1446984677.66114569\n",
            "Iteration 801, loss = 1446879174.57430768\n",
            "Iteration 802, loss = 1446775036.51111054\n",
            "Iteration 803, loss = 1446669559.93309212\n",
            "Iteration 804, loss = 1446564986.43121862\n",
            "Iteration 805, loss = 1446459547.06054711\n",
            "Iteration 806, loss = 1446355043.30410600\n",
            "Iteration 807, loss = 1446249623.07687616\n",
            "Iteration 808, loss = 1446144230.91986775\n",
            "Iteration 809, loss = 1446039638.43639946\n",
            "Iteration 810, loss = 1445933837.43054128\n",
            "Iteration 811, loss = 1445828564.62614059\n",
            "Iteration 812, loss = 1445723570.60406208\n",
            "Iteration 813, loss = 1445618081.39666033\n",
            "Iteration 814, loss = 1445512735.12714815\n",
            "Iteration 815, loss = 1445407793.29088521\n",
            "Iteration 816, loss = 1445303024.08921123\n",
            "Iteration 817, loss = 1445198282.93674183\n",
            "Iteration 818, loss = 1445092642.21294761\n",
            "Iteration 819, loss = 1444988085.94029355\n",
            "Iteration 820, loss = 1444883380.87657619\n",
            "Iteration 821, loss = 1444778235.77879167\n",
            "Iteration 822, loss = 1444673646.18419862\n",
            "Iteration 823, loss = 1444567961.72839189\n",
            "Iteration 824, loss = 1444463542.97197509\n",
            "Iteration 825, loss = 1444358609.25460291\n",
            "Iteration 826, loss = 1444253426.39871550\n",
            "Iteration 827, loss = 1444149363.44622254\n",
            "Iteration 828, loss = 1444044310.69475079\n",
            "Iteration 829, loss = 1443939178.89658523\n",
            "Iteration 830, loss = 1443835486.42459941\n",
            "Iteration 831, loss = 1443729859.91690469\n",
            "Iteration 832, loss = 1443625820.64064360\n",
            "Iteration 833, loss = 1443520452.94803667\n",
            "Iteration 834, loss = 1443415580.20519161\n",
            "Iteration 835, loss = 1443310973.59103084\n",
            "Iteration 836, loss = 1443206068.72513151\n",
            "Iteration 837, loss = 1443100421.49294758\n",
            "Iteration 838, loss = 1442995219.11564183\n",
            "Iteration 839, loss = 1442890452.23172832\n",
            "Iteration 840, loss = 1442785218.93608475\n",
            "Iteration 841, loss = 1442679303.58870029\n",
            "Iteration 842, loss = 1442573948.03638411\n",
            "Iteration 843, loss = 1442468629.84112430\n",
            "Iteration 844, loss = 1442363404.28497863\n",
            "Iteration 845, loss = 1442258147.95902228\n",
            "Iteration 846, loss = 1442152221.54094219\n",
            "Iteration 847, loss = 1442047304.26198292\n",
            "Iteration 848, loss = 1441942608.64376187\n",
            "Iteration 849, loss = 1441837954.97148108\n",
            "Iteration 850, loss = 1441732736.10313845\n",
            "Iteration 851, loss = 1441628243.03497529\n",
            "Iteration 852, loss = 1441523198.57379222\n",
            "Iteration 853, loss = 1441419509.24193549\n",
            "Iteration 854, loss = 1441314351.45547056\n",
            "Iteration 855, loss = 1441210034.59491181\n",
            "Iteration 856, loss = 1441105486.82721090\n",
            "Iteration 857, loss = 1441000641.68719506\n",
            "Iteration 858, loss = 1440896532.01325345\n",
            "Iteration 859, loss = 1440791633.96085072\n",
            "Iteration 860, loss = 1440687246.11634135\n",
            "Iteration 861, loss = 1440581841.74852443\n",
            "Iteration 862, loss = 1440477584.91738749\n",
            "Iteration 863, loss = 1440372486.56700349\n",
            "Iteration 864, loss = 1440267454.76433635\n",
            "Iteration 865, loss = 1440163157.03224516\n",
            "Iteration 866, loss = 1440058259.07669950\n",
            "Iteration 867, loss = 1439953449.46494150\n",
            "Iteration 868, loss = 1439849469.27016449\n",
            "Iteration 869, loss = 1439744841.59612775\n",
            "Iteration 870, loss = 1439640639.97122264\n",
            "Iteration 871, loss = 1439536391.44014859\n",
            "Iteration 872, loss = 1439432009.68922782\n",
            "Iteration 873, loss = 1439328196.16640854\n",
            "Iteration 874, loss = 1439223156.32294011\n",
            "Iteration 875, loss = 1439120052.71684027\n",
            "Iteration 876, loss = 1439014455.85531664\n",
            "Iteration 877, loss = 1438910463.12297344\n",
            "Iteration 878, loss = 1438805908.69891953\n",
            "Iteration 879, loss = 1438701134.03623056\n",
            "Iteration 880, loss = 1438597679.06444263\n",
            "Iteration 881, loss = 1438491784.54379630\n",
            "Iteration 882, loss = 1438388379.28097320\n",
            "Iteration 883, loss = 1438284152.05546451\n",
            "Iteration 884, loss = 1438179788.75085163\n",
            "Iteration 885, loss = 1438075886.93457794\n",
            "Iteration 886, loss = 1437971915.36571431\n",
            "Iteration 887, loss = 1437867541.36369228\n",
            "Iteration 888, loss = 1437763507.19137311\n",
            "Iteration 889, loss = 1437659309.96549392\n",
            "Iteration 890, loss = 1437554541.76057243\n",
            "Iteration 891, loss = 1437450438.04300618\n",
            "Iteration 892, loss = 1437345989.73228121\n",
            "Iteration 893, loss = 1437241579.51202226\n",
            "Iteration 894, loss = 1437137029.10425544\n",
            "Iteration 895, loss = 1437032851.37528110\n",
            "Iteration 896, loss = 1436928454.07566905\n",
            "Iteration 897, loss = 1436824119.60137463\n",
            "Iteration 898, loss = 1436719623.33917499\n",
            "Iteration 899, loss = 1436616006.07298279\n",
            "Iteration 900, loss = 1436511002.04391861\n",
            "Iteration 901, loss = 1436407154.45700002\n",
            "Iteration 902, loss = 1436302582.28118086\n",
            "Iteration 903, loss = 1436198751.56740665\n",
            "Iteration 904, loss = 1436094561.86454916\n",
            "Iteration 905, loss = 1435990228.63777947\n",
            "Iteration 906, loss = 1435886010.75580978\n",
            "Iteration 907, loss = 1435781649.42608428\n",
            "Iteration 908, loss = 1435677395.71403384\n",
            "Iteration 909, loss = 1435572578.86797595\n",
            "Iteration 910, loss = 1435467583.11367202\n",
            "Iteration 911, loss = 1435363258.58621931\n",
            "Iteration 912, loss = 1435258167.05095220\n",
            "Iteration 913, loss = 1435153562.89576221\n",
            "Iteration 914, loss = 1435048999.56069922\n",
            "Iteration 915, loss = 1434944000.51632929\n",
            "Iteration 916, loss = 1434838831.85242748\n",
            "Iteration 917, loss = 1434735070.05996037\n",
            "Iteration 918, loss = 1434630416.70526624\n",
            "Iteration 919, loss = 1434525479.14723206\n",
            "Iteration 920, loss = 1434421473.96787357\n",
            "Iteration 921, loss = 1434316689.41013432\n",
            "Iteration 922, loss = 1434212519.80607247\n",
            "Iteration 923, loss = 1434107481.91072488\n",
            "Iteration 924, loss = 1434003311.62368345\n",
            "Iteration 925, loss = 1433898837.46632409\n",
            "Iteration 926, loss = 1433793686.30512738\n",
            "Iteration 927, loss = 1433690124.98752594\n",
            "Iteration 928, loss = 1433585178.15508485\n",
            "Iteration 929, loss = 1433481135.58245206\n",
            "Iteration 930, loss = 1433377204.33186531\n",
            "Iteration 931, loss = 1433272177.02328014\n",
            "Iteration 932, loss = 1433168187.12810612\n",
            "Iteration 933, loss = 1433063995.07297587\n",
            "Iteration 934, loss = 1432958889.99858236\n",
            "Iteration 935, loss = 1432854742.64452934\n",
            "Iteration 936, loss = 1432750116.39895868\n",
            "Iteration 937, loss = 1432646058.39707541\n",
            "Iteration 938, loss = 1432541147.37510157\n",
            "Iteration 939, loss = 1432437246.19775438\n",
            "Iteration 940, loss = 1432333403.37212372\n",
            "Iteration 941, loss = 1432229978.72377205\n",
            "Iteration 942, loss = 1432125884.86538720\n",
            "Iteration 943, loss = 1432022307.95440125\n",
            "Iteration 944, loss = 1431918273.72243452\n",
            "Iteration 945, loss = 1431814610.17751718\n",
            "Iteration 946, loss = 1431710630.59529948\n",
            "Iteration 947, loss = 1431606604.58132744\n",
            "Iteration 948, loss = 1431503153.49947596\n",
            "Iteration 949, loss = 1431398723.38542128\n",
            "Iteration 950, loss = 1431295035.02706313\n",
            "Iteration 951, loss = 1431191802.25858951\n",
            "Iteration 952, loss = 1431087374.17689371\n",
            "Iteration 953, loss = 1430983893.26276708\n",
            "Iteration 954, loss = 1430880740.03499269\n",
            "Iteration 955, loss = 1430776201.03188586\n",
            "Iteration 956, loss = 1430672785.30497384\n",
            "Iteration 957, loss = 1430569216.95809603\n",
            "Iteration 958, loss = 1430465284.09082460\n",
            "Iteration 959, loss = 1430360915.78936696\n",
            "Iteration 960, loss = 1430257167.05347085\n",
            "Iteration 961, loss = 1430153479.63658214\n",
            "Iteration 962, loss = 1430049332.38676906\n",
            "Iteration 963, loss = 1429945088.54424071\n",
            "Iteration 964, loss = 1429841590.37424207\n",
            "Iteration 965, loss = 1429737459.28820014\n",
            "Iteration 966, loss = 1429633667.91111803\n",
            "Iteration 967, loss = 1429529692.27315688\n",
            "Iteration 968, loss = 1429426123.47822237\n",
            "Iteration 969, loss = 1429321928.49515224\n",
            "Iteration 970, loss = 1429218378.47371912\n",
            "Iteration 971, loss = 1429115037.89330626\n",
            "Iteration 972, loss = 1429011476.05804968\n",
            "Iteration 973, loss = 1428908022.33318567\n",
            "Iteration 974, loss = 1428804174.15956235\n",
            "Iteration 975, loss = 1428701090.65052366\n",
            "Iteration 976, loss = 1428597111.46544456\n",
            "Iteration 977, loss = 1428494904.23767948\n",
            "Iteration 978, loss = 1428390663.51920724\n",
            "Iteration 979, loss = 1428287044.48454237\n",
            "Iteration 980, loss = 1428183413.13717103\n",
            "Iteration 981, loss = 1428079983.36359024\n",
            "Iteration 982, loss = 1427976761.92325020\n",
            "Iteration 983, loss = 1427872751.49162626\n",
            "Iteration 984, loss = 1427769169.93993044\n",
            "Iteration 985, loss = 1427664788.03105354\n",
            "Iteration 986, loss = 1427560944.02612066\n",
            "Iteration 987, loss = 1427456705.05345082\n",
            "Iteration 988, loss = 1427352508.82888198\n",
            "Iteration 989, loss = 1427247974.41918015\n",
            "Iteration 990, loss = 1427143973.57148743\n",
            "Iteration 991, loss = 1427039915.99698925\n",
            "Iteration 992, loss = 1426936114.36887455\n",
            "Iteration 993, loss = 1426832165.75930214\n",
            "Iteration 994, loss = 1426727985.92752457\n",
            "Iteration 995, loss = 1426624511.73218799\n",
            "Iteration 996, loss = 1426520458.86957073\n",
            "Iteration 997, loss = 1426416659.95285320\n",
            "Iteration 998, loss = 1426313020.39283419\n",
            "Iteration 999, loss = 1426209100.86325216\n",
            "Iteration 1000, loss = 1426105845.11954165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1525345062.97201371\n",
            "Iteration 2, loss = 202733963.13385284\n",
            "Iteration 3, loss = 122259574.69563830\n",
            "Iteration 4, loss = 81708903.08653226\n",
            "Iteration 5, loss = 51954609.46766718\n",
            "Iteration 6, loss = 39226697.04335799\n",
            "Iteration 7, loss = 42465394.22164501\n",
            "Iteration 8, loss = 44921918.78720666\n",
            "Iteration 9, loss = 43220906.52210902\n",
            "Iteration 10, loss = 29271853.84360127\n",
            "Iteration 11, loss = 20885124.77083410\n",
            "Iteration 12, loss = 20645305.23446583\n",
            "Iteration 13, loss = 21761451.45810925\n",
            "Iteration 14, loss = 17545280.36127574\n",
            "Iteration 15, loss = 19559994.37904556\n",
            "Iteration 16, loss = 20850973.83585307\n",
            "Iteration 17, loss = 19974980.05071966\n",
            "Iteration 18, loss = 17416758.65549929\n",
            "Iteration 19, loss = 16308680.72752439\n",
            "Iteration 20, loss = 14183549.88358572\n",
            "Iteration 21, loss = 13347742.71702382\n",
            "Iteration 22, loss = 10893270.61957888\n",
            "Iteration 23, loss = 10551822.82939121\n",
            "Iteration 24, loss = 10355272.69049190\n",
            "Iteration 25, loss = 9974503.88017395\n",
            "Iteration 26, loss = 9598452.71357846\n",
            "Iteration 27, loss = 9465969.27270986\n",
            "Iteration 28, loss = 9134927.49211396\n",
            "Iteration 29, loss = 9227100.26008443\n",
            "Iteration 30, loss = 8659847.70961588\n",
            "Iteration 31, loss = 8530994.44289518\n",
            "Iteration 32, loss = 8545427.74745495\n",
            "Iteration 33, loss = 7889318.67725726\n",
            "Iteration 34, loss = 7994519.90114139\n",
            "Iteration 35, loss = 7727403.03430360\n",
            "Iteration 36, loss = 7455872.84074330\n",
            "Iteration 37, loss = 7276108.08831826\n",
            "Iteration 38, loss = 7045332.94546509\n",
            "Iteration 39, loss = 7166381.46755767\n",
            "Iteration 40, loss = 6928530.96068288\n",
            "Iteration 41, loss = 6645530.20486933\n",
            "Iteration 42, loss = 6516157.28881384\n",
            "Iteration 43, loss = 6412719.54652329\n",
            "Iteration 44, loss = 6326813.60042111\n",
            "Iteration 45, loss = 6240277.55626349\n",
            "Iteration 46, loss = 6182572.76419275\n",
            "Iteration 47, loss = 6097881.20502449\n",
            "Iteration 48, loss = 5981427.62876967\n",
            "Iteration 49, loss = 5910383.36347259\n",
            "Iteration 50, loss = 5889763.44911661\n",
            "Iteration 51, loss = 5730717.66913439\n",
            "Iteration 52, loss = 5710344.46500277\n",
            "Iteration 53, loss = 5575467.23336527\n",
            "Iteration 54, loss = 5564708.75630653\n",
            "Iteration 55, loss = 5480536.92309954\n",
            "Iteration 56, loss = 5524144.27428660\n",
            "Iteration 57, loss = 5405110.01382673\n",
            "Iteration 58, loss = 5569507.47442274\n",
            "Iteration 59, loss = 5383022.40252812\n",
            "Iteration 60, loss = 5611152.74174780\n",
            "Iteration 61, loss = 5399978.05626029\n",
            "Iteration 62, loss = 5289730.40408325\n",
            "Iteration 63, loss = 5189657.92456568\n",
            "Iteration 64, loss = 5065951.62835320\n",
            "Iteration 65, loss = 5138561.40855864\n",
            "Iteration 66, loss = 5139564.39929263\n",
            "Iteration 67, loss = 4989469.05377338\n",
            "Iteration 68, loss = 4855843.01810341\n",
            "Iteration 69, loss = 4890873.91388628\n",
            "Iteration 70, loss = 4814404.62647397\n",
            "Iteration 71, loss = 4793515.34872210\n",
            "Iteration 72, loss = 4745259.44715118\n",
            "Iteration 73, loss = 4718146.41091366\n",
            "Iteration 74, loss = 4931414.58896941\n",
            "Iteration 75, loss = 4626721.30461793\n",
            "Iteration 76, loss = 4599600.37872439\n",
            "Iteration 77, loss = 4545995.96712501\n",
            "Iteration 78, loss = 4541682.59404182\n",
            "Iteration 79, loss = 4473596.18504878\n",
            "Iteration 80, loss = 4484245.89798669\n",
            "Iteration 81, loss = 4472312.91677899\n",
            "Iteration 82, loss = 4472390.74458299\n",
            "Iteration 83, loss = 4393730.17118482\n",
            "Iteration 84, loss = 4432491.85975054\n",
            "Iteration 85, loss = 4305012.37486373\n",
            "Iteration 86, loss = 4334851.71003572\n",
            "Iteration 87, loss = 4441931.28905571\n",
            "Iteration 88, loss = 4280020.37071816\n",
            "Iteration 89, loss = 4246427.20103576\n",
            "Iteration 90, loss = 4222739.94725255\n",
            "Iteration 91, loss = 4262628.71136985\n",
            "Iteration 92, loss = 4210760.03833613\n",
            "Iteration 93, loss = 4178838.63781704\n",
            "Iteration 94, loss = 4136474.77018199\n",
            "Iteration 95, loss = 4209481.40748595\n",
            "Iteration 96, loss = 4147686.99285090\n",
            "Iteration 97, loss = 4094642.39039803\n",
            "Iteration 98, loss = 4086130.11262805\n",
            "Iteration 99, loss = 4056710.28136353\n",
            "Iteration 100, loss = 4063585.20771641\n",
            "Iteration 101, loss = 4152229.38274491\n",
            "Iteration 102, loss = 4030210.86725118\n",
            "Iteration 103, loss = 4017242.62004996\n",
            "Iteration 104, loss = 4024564.97960278\n",
            "Iteration 105, loss = 3983164.67175358\n",
            "Iteration 106, loss = 4043989.19429183\n",
            "Iteration 107, loss = 4049567.78714069\n",
            "Iteration 108, loss = 4086618.84732151\n",
            "Iteration 109, loss = 4069503.09338584\n",
            "Iteration 110, loss = 4004372.76848467\n",
            "Iteration 111, loss = 4323574.20304605\n",
            "Iteration 112, loss = 3998897.79545067\n",
            "Iteration 113, loss = 3880416.05263931\n",
            "Iteration 114, loss = 3855038.02185943\n",
            "Iteration 115, loss = 3906523.31870326\n",
            "Iteration 116, loss = 3831068.49134856\n",
            "Iteration 117, loss = 3886223.51266640\n",
            "Iteration 118, loss = 3826221.24598484\n",
            "Iteration 119, loss = 3851264.31428092\n",
            "Iteration 120, loss = 3796785.43309630\n",
            "Iteration 121, loss = 3879667.28523328\n",
            "Iteration 122, loss = 3868548.10051412\n",
            "Iteration 123, loss = 3790219.47218545\n",
            "Iteration 124, loss = 3743668.62522735\n",
            "Iteration 125, loss = 3763607.87874981\n",
            "Iteration 126, loss = 3760783.00698230\n",
            "Iteration 127, loss = 3768622.17584084\n",
            "Iteration 128, loss = 3831685.65622237\n",
            "Iteration 129, loss = 3712854.66259933\n",
            "Iteration 130, loss = 3714400.01242298\n",
            "Iteration 131, loss = 3748186.88662134\n",
            "Iteration 132, loss = 3712449.22883666\n",
            "Iteration 133, loss = 3911571.50782738\n",
            "Iteration 134, loss = 3714803.40797173\n",
            "Iteration 135, loss = 3650756.16565703\n",
            "Iteration 136, loss = 3653522.92822309\n",
            "Iteration 137, loss = 3725218.82869141\n",
            "Iteration 138, loss = 3736366.20532020\n",
            "Iteration 139, loss = 3680126.11877018\n",
            "Iteration 140, loss = 3625588.23000195\n",
            "Iteration 141, loss = 3600522.10263988\n",
            "Iteration 142, loss = 3608389.66135118\n",
            "Iteration 143, loss = 3606886.67479751\n",
            "Iteration 144, loss = 3594039.13068218\n",
            "Iteration 145, loss = 3594405.25172120\n",
            "Iteration 146, loss = 3604471.75763557\n",
            "Iteration 147, loss = 3571390.76004801\n",
            "Iteration 148, loss = 3584415.73251204\n",
            "Iteration 149, loss = 3565092.55780966\n",
            "Iteration 150, loss = 3562808.08198880\n",
            "Iteration 151, loss = 3579509.54899043\n",
            "Iteration 152, loss = 3565880.80788444\n",
            "Iteration 153, loss = 3548728.68909618\n",
            "Iteration 154, loss = 3557743.28684862\n",
            "Iteration 155, loss = 3621541.12143213\n",
            "Iteration 156, loss = 3834138.46372418\n",
            "Iteration 157, loss = 3636784.91877410\n",
            "Iteration 158, loss = 3644340.05489583\n",
            "Iteration 159, loss = 3531161.12232340\n",
            "Iteration 160, loss = 3700761.86592104\n",
            "Iteration 161, loss = 3540529.95920765\n",
            "Iteration 162, loss = 3780027.94882162\n",
            "Iteration 163, loss = 3839501.45010878\n",
            "Iteration 164, loss = 3498145.64799563\n",
            "Iteration 165, loss = 3513628.64275604\n",
            "Iteration 166, loss = 3530746.32479889\n",
            "Iteration 167, loss = 3491594.79961357\n",
            "Iteration 168, loss = 3487180.88790099\n",
            "Iteration 169, loss = 3481315.45264433\n",
            "Iteration 170, loss = 3532035.83337599\n",
            "Iteration 171, loss = 3703634.25266916\n",
            "Iteration 172, loss = 3637274.47050666\n",
            "Iteration 173, loss = 3477491.26909572\n",
            "Iteration 174, loss = 3529310.48969467\n",
            "Iteration 175, loss = 3485720.20794607\n",
            "Iteration 176, loss = 3441763.00118346\n",
            "Iteration 177, loss = 3457709.73126331\n",
            "Iteration 178, loss = 3464537.59596962\n",
            "Iteration 179, loss = 3506547.33001181\n",
            "Iteration 180, loss = 3441486.04877740\n",
            "Iteration 181, loss = 3441447.74915913\n",
            "Iteration 182, loss = 3425218.87552250\n",
            "Iteration 183, loss = 3425031.50074769\n",
            "Iteration 184, loss = 3438934.68227136\n",
            "Iteration 185, loss = 3457353.64332249\n",
            "Iteration 186, loss = 3415337.36622394\n",
            "Iteration 187, loss = 3453157.73959394\n",
            "Iteration 188, loss = 3415646.16554792\n",
            "Iteration 189, loss = 3447054.67263064\n",
            "Iteration 190, loss = 3465318.56394405\n",
            "Iteration 191, loss = 3420448.51415997\n",
            "Iteration 192, loss = 3399058.91459942\n",
            "Iteration 193, loss = 3402586.14363104\n",
            "Iteration 194, loss = 3399844.00172197\n",
            "Iteration 195, loss = 3483555.98542116\n",
            "Iteration 196, loss = 3607082.95102120\n",
            "Iteration 197, loss = 3392893.41079044\n",
            "Iteration 198, loss = 3419985.43524096\n",
            "Iteration 199, loss = 3626329.48102582\n",
            "Iteration 200, loss = 3412847.89807142\n",
            "Iteration 201, loss = 3412905.53690686\n",
            "Iteration 202, loss = 3386800.33867262\n",
            "Iteration 203, loss = 3398687.50693056\n",
            "Iteration 204, loss = 3568979.32208960\n",
            "Iteration 205, loss = 3414738.62153805\n",
            "Iteration 206, loss = 3483238.05257634\n",
            "Iteration 207, loss = 3396372.87059321\n",
            "Iteration 208, loss = 3584234.73499642\n",
            "Iteration 209, loss = 3354594.98231785\n",
            "Iteration 210, loss = 3392190.32481602\n",
            "Iteration 211, loss = 3370078.99181872\n",
            "Iteration 212, loss = 3457535.62420695\n",
            "Iteration 213, loss = 3632650.78853750\n",
            "Iteration 214, loss = 3365247.73288342\n",
            "Iteration 215, loss = 3431836.91086752\n",
            "Iteration 216, loss = 3332416.07095234\n",
            "Iteration 217, loss = 3335432.47048381\n",
            "Iteration 218, loss = 3383734.24627112\n",
            "Iteration 219, loss = 3366818.42090122\n",
            "Iteration 220, loss = 3405804.36132214\n",
            "Iteration 221, loss = 3372719.55648522\n",
            "Iteration 222, loss = 3365043.95364966\n",
            "Iteration 223, loss = 3376073.78865386\n",
            "Iteration 224, loss = 3410956.12669945\n",
            "Iteration 225, loss = 3328285.95649052\n",
            "Iteration 226, loss = 3379274.44542969\n",
            "Iteration 227, loss = 3368128.95070171\n",
            "Iteration 228, loss = 3321719.75070862\n",
            "Iteration 229, loss = 3370453.06618352\n",
            "Iteration 230, loss = 3308532.48431438\n",
            "Iteration 231, loss = 3299905.24924138\n",
            "Iteration 232, loss = 3315495.34876150\n",
            "Iteration 233, loss = 3332773.82897549\n",
            "Iteration 234, loss = 3425808.03506199\n",
            "Iteration 235, loss = 3325239.52622649\n",
            "Iteration 236, loss = 3306763.86617766\n",
            "Iteration 237, loss = 3308264.47727587\n",
            "Iteration 238, loss = 3324419.90007025\n",
            "Iteration 239, loss = 3436410.86644297\n",
            "Iteration 240, loss = 3354903.70926946\n",
            "Iteration 241, loss = 3308796.73929186\n",
            "Iteration 242, loss = 3285252.39912722\n",
            "Iteration 243, loss = 3312898.27638464\n",
            "Iteration 244, loss = 3344872.90073350\n",
            "Iteration 245, loss = 3323345.31180788\n",
            "Iteration 246, loss = 3300390.62111150\n",
            "Iteration 247, loss = 3277506.90568637\n",
            "Iteration 248, loss = 3301227.56381647\n",
            "Iteration 249, loss = 3484925.83946966\n",
            "Iteration 250, loss = 3268770.40690213\n",
            "Iteration 251, loss = 3479486.22256948\n",
            "Iteration 252, loss = 3270719.87023746\n",
            "Iteration 253, loss = 3260630.44361718\n",
            "Iteration 254, loss = 3265132.51526694\n",
            "Iteration 255, loss = 3321065.72288852\n",
            "Iteration 256, loss = 3374357.80187218\n",
            "Iteration 257, loss = 3264316.14707359\n",
            "Iteration 258, loss = 3272749.03866993\n",
            "Iteration 259, loss = 3267812.21530771\n",
            "Iteration 260, loss = 3379548.24343910\n",
            "Iteration 261, loss = 3276449.68624345\n",
            "Iteration 262, loss = 3344573.02051866\n",
            "Iteration 263, loss = 3337281.96472350\n",
            "Iteration 264, loss = 3315513.67413774\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538813555.28831506\n",
            "Iteration 2, loss = 1538775068.93124104\n",
            "Iteration 3, loss = 1538737238.20588040\n",
            "Iteration 4, loss = 1538699870.33775115\n",
            "Iteration 5, loss = 1538658642.62044287\n",
            "Iteration 6, loss = 1538618257.28013229\n",
            "Iteration 7, loss = 1538575093.39290833\n",
            "Iteration 8, loss = 1538526688.15866637\n",
            "Iteration 9, loss = 1538478550.52020073\n",
            "Iteration 10, loss = 1538426766.32693243\n",
            "Iteration 11, loss = 1538371360.89630866\n",
            "Iteration 12, loss = 1538314859.69307899\n",
            "Iteration 13, loss = 1538252450.94609833\n",
            "Iteration 14, loss = 1538189361.60199714\n",
            "Iteration 15, loss = 1538121718.88194394\n",
            "Iteration 16, loss = 1538051581.27460814\n",
            "Iteration 17, loss = 1537977227.58734298\n",
            "Iteration 18, loss = 1537900021.07016945\n",
            "Iteration 19, loss = 1537817719.02420092\n",
            "Iteration 20, loss = 1537730026.08076954\n",
            "Iteration 21, loss = 1537641050.27382994\n",
            "Iteration 22, loss = 1537546417.60802054\n",
            "Iteration 23, loss = 1537448760.11489391\n",
            "Iteration 24, loss = 1537343901.07814646\n",
            "Iteration 25, loss = 1537235275.75687051\n",
            "Iteration 26, loss = 1537120732.84704518\n",
            "Iteration 27, loss = 1537002741.01836443\n",
            "Iteration 28, loss = 1536878697.33448815\n",
            "Iteration 29, loss = 1536750463.15938640\n",
            "Iteration 30, loss = 1536615840.87070704\n",
            "Iteration 31, loss = 1536476921.25067997\n",
            "Iteration 32, loss = 1536332310.67368031\n",
            "Iteration 33, loss = 1536183708.29625940\n",
            "Iteration 34, loss = 1536030203.44935226\n",
            "Iteration 35, loss = 1535872723.85158873\n",
            "Iteration 36, loss = 1535711547.15946913\n",
            "Iteration 37, loss = 1535546035.44125342\n",
            "Iteration 38, loss = 1535377362.16152692\n",
            "Iteration 39, loss = 1535205333.62128901\n",
            "Iteration 40, loss = 1535030005.46406293\n",
            "Iteration 41, loss = 1534851895.66683340\n",
            "Iteration 42, loss = 1534670996.63843870\n",
            "Iteration 43, loss = 1534488828.30828691\n",
            "Iteration 44, loss = 1534305962.13933563\n",
            "Iteration 45, loss = 1534122090.01345468\n",
            "Iteration 46, loss = 1533937521.27402878\n",
            "Iteration 47, loss = 1533753263.65570068\n",
            "Iteration 48, loss = 1533567921.85153627\n",
            "Iteration 49, loss = 1533382576.92042732\n",
            "Iteration 50, loss = 1533195805.63867593\n",
            "Iteration 51, loss = 1533010649.53377962\n",
            "Iteration 52, loss = 1532826288.05683422\n",
            "Iteration 53, loss = 1532643924.09865355\n",
            "Iteration 54, loss = 1532462300.87067986\n",
            "Iteration 55, loss = 1532283556.99730802\n",
            "Iteration 56, loss = 1532105197.46367121\n",
            "Iteration 57, loss = 1531927744.00319743\n",
            "Iteration 58, loss = 1531751678.40931201\n",
            "Iteration 59, loss = 1531577491.34829760\n",
            "Iteration 60, loss = 1531403155.83069420\n",
            "Iteration 61, loss = 1531229705.37166452\n",
            "Iteration 62, loss = 1531058837.57356882\n",
            "Iteration 63, loss = 1530888739.72442985\n",
            "Iteration 64, loss = 1530718397.89279270\n",
            "Iteration 65, loss = 1530551261.82519412\n",
            "Iteration 66, loss = 1530382841.43973494\n",
            "Iteration 67, loss = 1530217542.43973660\n",
            "Iteration 68, loss = 1530053411.66155696\n",
            "Iteration 69, loss = 1529890253.47962546\n",
            "Iteration 70, loss = 1529728135.03242993\n",
            "Iteration 71, loss = 1529568303.81988931\n",
            "Iteration 72, loss = 1529408423.85312271\n",
            "Iteration 73, loss = 1529249069.80579972\n",
            "Iteration 74, loss = 1529091700.50459933\n",
            "Iteration 75, loss = 1528935656.23544788\n",
            "Iteration 76, loss = 1528779164.60662389\n",
            "Iteration 77, loss = 1528624291.55786610\n",
            "Iteration 78, loss = 1528469886.39374328\n",
            "Iteration 79, loss = 1528316117.26777172\n",
            "Iteration 80, loss = 1528163978.71989703\n",
            "Iteration 81, loss = 1528010894.81591463\n",
            "Iteration 82, loss = 1527860151.13236713\n",
            "Iteration 83, loss = 1527708986.35684609\n",
            "Iteration 84, loss = 1527559598.43355441\n",
            "Iteration 85, loss = 1527409354.85926652\n",
            "Iteration 86, loss = 1527260979.12607336\n",
            "Iteration 87, loss = 1527112597.94922781\n",
            "Iteration 88, loss = 1526963914.58277822\n",
            "Iteration 89, loss = 1526817055.16157150\n",
            "Iteration 90, loss = 1526670376.44047403\n",
            "Iteration 91, loss = 1526524401.66805434\n",
            "Iteration 92, loss = 1526378461.56319904\n",
            "Iteration 93, loss = 1526232968.84134841\n",
            "Iteration 94, loss = 1526088827.73624134\n",
            "Iteration 95, loss = 1525944735.37926936\n",
            "Iteration 96, loss = 1525801817.42196846\n",
            "Iteration 97, loss = 1525658667.52322841\n",
            "Iteration 98, loss = 1525516803.03871393\n",
            "Iteration 99, loss = 1525375104.06413579\n",
            "Iteration 100, loss = 1525234993.32932234\n",
            "Iteration 101, loss = 1525093632.54366589\n",
            "Iteration 102, loss = 1524954427.23923159\n",
            "Iteration 103, loss = 1524814700.72348094\n",
            "Iteration 104, loss = 1524675317.69120383\n",
            "Iteration 105, loss = 1524536138.02498221\n",
            "Iteration 106, loss = 1524398342.78602576\n",
            "Iteration 107, loss = 1524260761.07135272\n",
            "Iteration 108, loss = 1524122804.79830194\n",
            "Iteration 109, loss = 1523985746.09960485\n",
            "Iteration 110, loss = 1523848566.18992138\n",
            "Iteration 111, loss = 1523712880.90430093\n",
            "Iteration 112, loss = 1523576285.68863940\n",
            "Iteration 113, loss = 1523441223.23757410\n",
            "Iteration 114, loss = 1523304990.11840367\n",
            "Iteration 115, loss = 1523170100.15511394\n",
            "Iteration 116, loss = 1523035959.73214889\n",
            "Iteration 117, loss = 1522901535.95940113\n",
            "Iteration 118, loss = 1522766845.14572001\n",
            "Iteration 119, loss = 1522634060.96008587\n",
            "Iteration 120, loss = 1522500652.82606530\n",
            "Iteration 121, loss = 1522367984.78718042\n",
            "Iteration 122, loss = 1522234952.77682328\n",
            "Iteration 123, loss = 1522103699.52126598\n",
            "Iteration 124, loss = 1521971440.66390610\n",
            "Iteration 125, loss = 1521839918.54985976\n",
            "Iteration 126, loss = 1521708869.71726274\n",
            "Iteration 127, loss = 1521577968.66891241\n",
            "Iteration 128, loss = 1521446993.78033471\n",
            "Iteration 129, loss = 1521316173.31153679\n",
            "Iteration 130, loss = 1521185579.77056074\n",
            "Iteration 131, loss = 1521054711.41784000\n",
            "Iteration 132, loss = 1520925106.51942611\n",
            "Iteration 133, loss = 1520794677.78302598\n",
            "Iteration 134, loss = 1520665053.31678605\n",
            "Iteration 135, loss = 1520535900.41322398\n",
            "Iteration 136, loss = 1520406064.18838334\n",
            "Iteration 137, loss = 1520277913.84525871\n",
            "Iteration 138, loss = 1520149539.46609712\n",
            "Iteration 139, loss = 1520021533.03278708\n",
            "Iteration 140, loss = 1519893218.76141214\n",
            "Iteration 141, loss = 1519766461.96034026\n",
            "Iteration 142, loss = 1519637895.33917928\n",
            "Iteration 143, loss = 1519512099.63683343\n",
            "Iteration 144, loss = 1519384707.29479837\n",
            "Iteration 145, loss = 1519258176.59173751\n",
            "Iteration 146, loss = 1519131913.37670851\n",
            "Iteration 147, loss = 1519006539.15160346\n",
            "Iteration 148, loss = 1518880119.91244197\n",
            "Iteration 149, loss = 1518754285.95850182\n",
            "Iteration 150, loss = 1518629115.72792196\n",
            "Iteration 151, loss = 1518502760.11594081\n",
            "Iteration 152, loss = 1518377593.96098948\n",
            "Iteration 153, loss = 1518252366.76190758\n",
            "Iteration 154, loss = 1518127179.31552243\n",
            "Iteration 155, loss = 1518002017.12736225\n",
            "Iteration 156, loss = 1517877684.38260269\n",
            "Iteration 157, loss = 1517753642.04415917\n",
            "Iteration 158, loss = 1517629568.56114411\n",
            "Iteration 159, loss = 1517506041.99435258\n",
            "Iteration 160, loss = 1517382421.65377378\n",
            "Iteration 161, loss = 1517259928.00598407\n",
            "Iteration 162, loss = 1517137053.62240529\n",
            "Iteration 163, loss = 1517013313.29127479\n",
            "Iteration 164, loss = 1516890119.61042809\n",
            "Iteration 165, loss = 1516767075.18259907\n",
            "Iteration 166, loss = 1516644598.51107168\n",
            "Iteration 167, loss = 1516520298.65897727\n",
            "Iteration 168, loss = 1516397257.53917456\n",
            "Iteration 169, loss = 1516274874.07429075\n",
            "Iteration 170, loss = 1516151878.09477139\n",
            "Iteration 171, loss = 1516029313.45563984\n",
            "Iteration 172, loss = 1515906655.98826838\n",
            "Iteration 173, loss = 1515783748.97930503\n",
            "Iteration 174, loss = 1515661624.45775223\n",
            "Iteration 175, loss = 1515538739.87690043\n",
            "Iteration 176, loss = 1515416715.86934042\n",
            "Iteration 177, loss = 1515293636.73473382\n",
            "Iteration 178, loss = 1515171723.64273047\n",
            "Iteration 179, loss = 1515050208.80068731\n",
            "Iteration 180, loss = 1514928550.62612200\n",
            "Iteration 181, loss = 1514807154.27637887\n",
            "Iteration 182, loss = 1514685869.14063668\n",
            "Iteration 183, loss = 1514566065.73942232\n",
            "Iteration 184, loss = 1514444872.56820631\n",
            "Iteration 185, loss = 1514324713.95284247\n",
            "Iteration 186, loss = 1514204376.73076916\n",
            "Iteration 187, loss = 1514084091.23918462\n",
            "Iteration 188, loss = 1513963728.72494745\n",
            "Iteration 189, loss = 1513843418.74191475\n",
            "Iteration 190, loss = 1513722827.70792794\n",
            "Iteration 191, loss = 1513602936.92380381\n",
            "Iteration 192, loss = 1513482704.67238617\n",
            "Iteration 193, loss = 1513362694.35715485\n",
            "Iteration 194, loss = 1513242422.28426266\n",
            "Iteration 195, loss = 1513122762.44343090\n",
            "Iteration 196, loss = 1513002902.81659245\n",
            "Iteration 197, loss = 1512882841.32405567\n",
            "Iteration 198, loss = 1512763301.75280452\n",
            "Iteration 199, loss = 1512643706.73583031\n",
            "Iteration 200, loss = 1512524479.39007211\n",
            "Iteration 201, loss = 1512404242.01123238\n",
            "Iteration 202, loss = 1512285103.63462257\n",
            "Iteration 203, loss = 1512165109.16329932\n",
            "Iteration 204, loss = 1512046221.92551517\n",
            "Iteration 205, loss = 1511926420.96223259\n",
            "Iteration 206, loss = 1511807051.56227875\n",
            "Iteration 207, loss = 1511687896.51750636\n",
            "Iteration 208, loss = 1511568774.69734693\n",
            "Iteration 209, loss = 1511449681.64879942\n",
            "Iteration 210, loss = 1511331235.29684973\n",
            "Iteration 211, loss = 1511212254.16181922\n",
            "Iteration 212, loss = 1511093424.94110465\n",
            "Iteration 213, loss = 1510975741.46758318\n",
            "Iteration 214, loss = 1510856248.24089670\n",
            "Iteration 215, loss = 1510737683.51499724\n",
            "Iteration 216, loss = 1510619477.81448483\n",
            "Iteration 217, loss = 1510501002.12865520\n",
            "Iteration 218, loss = 1510382291.49087167\n",
            "Iteration 219, loss = 1510264519.89185476\n",
            "Iteration 220, loss = 1510146471.44721937\n",
            "Iteration 221, loss = 1510028403.97782540\n",
            "Iteration 222, loss = 1509911315.47754908\n",
            "Iteration 223, loss = 1509793719.21247959\n",
            "Iteration 224, loss = 1509676485.24143696\n",
            "Iteration 225, loss = 1509558897.41056085\n",
            "Iteration 226, loss = 1509441375.01311684\n",
            "Iteration 227, loss = 1509323825.24271035\n",
            "Iteration 228, loss = 1509205651.43161607\n",
            "Iteration 229, loss = 1509088695.01954079\n",
            "Iteration 230, loss = 1508970199.03865337\n",
            "Iteration 231, loss = 1508852760.17991948\n",
            "Iteration 232, loss = 1508734866.97389245\n",
            "Iteration 233, loss = 1508617533.97321558\n",
            "Iteration 234, loss = 1508499614.41310358\n",
            "Iteration 235, loss = 1508382364.18429923\n",
            "Iteration 236, loss = 1508264997.84117723\n",
            "Iteration 237, loss = 1508147972.03877020\n",
            "Iteration 238, loss = 1508030445.09219646\n",
            "Iteration 239, loss = 1507913682.82060027\n",
            "Iteration 240, loss = 1507797149.93266201\n",
            "Iteration 241, loss = 1507680754.70101213\n",
            "Iteration 242, loss = 1507563282.51397181\n",
            "Iteration 243, loss = 1507447702.19784069\n",
            "Iteration 244, loss = 1507331191.89451408\n",
            "Iteration 245, loss = 1507215439.32380629\n",
            "Iteration 246, loss = 1507098570.13905025\n",
            "Iteration 247, loss = 1506982822.48424172\n",
            "Iteration 248, loss = 1506867424.02661467\n",
            "Iteration 249, loss = 1506752041.81540585\n",
            "Iteration 250, loss = 1506635925.06720042\n",
            "Iteration 251, loss = 1506521021.01872420\n",
            "Iteration 252, loss = 1506406500.55917835\n",
            "Iteration 253, loss = 1506290867.82230902\n",
            "Iteration 254, loss = 1506175854.03120089\n",
            "Iteration 255, loss = 1506060864.08378887\n",
            "Iteration 256, loss = 1505946245.90669656\n",
            "Iteration 257, loss = 1505830987.79769969\n",
            "Iteration 258, loss = 1505715573.29790044\n",
            "Iteration 259, loss = 1505600640.48471236\n",
            "Iteration 260, loss = 1505485270.76993680\n",
            "Iteration 261, loss = 1505370211.15192437\n",
            "Iteration 262, loss = 1505253797.30170536\n",
            "Iteration 263, loss = 1505139636.12983441\n",
            "Iteration 264, loss = 1505023296.59846425\n",
            "Iteration 265, loss = 1504909088.82671666\n",
            "Iteration 266, loss = 1504794548.16554451\n",
            "Iteration 267, loss = 1504679677.73395276\n",
            "Iteration 268, loss = 1504565395.95831203\n",
            "Iteration 269, loss = 1504450780.62982917\n",
            "Iteration 270, loss = 1504336746.30304956\n",
            "Iteration 271, loss = 1504222124.26317787\n",
            "Iteration 272, loss = 1504107460.27498603\n",
            "Iteration 273, loss = 1503993316.50257087\n",
            "Iteration 274, loss = 1503878581.73369241\n",
            "Iteration 275, loss = 1503764488.32690263\n",
            "Iteration 276, loss = 1503650291.21496487\n",
            "Iteration 277, loss = 1503536233.70476079\n",
            "Iteration 278, loss = 1503421658.26020837\n",
            "Iteration 279, loss = 1503307831.49030304\n",
            "Iteration 280, loss = 1503194289.34389639\n",
            "Iteration 281, loss = 1503078853.91096258\n",
            "Iteration 282, loss = 1502965028.68107367\n",
            "Iteration 283, loss = 1502850635.21430731\n",
            "Iteration 284, loss = 1502735830.04008722\n",
            "Iteration 285, loss = 1502621825.00164247\n",
            "Iteration 286, loss = 1502507204.04133892\n",
            "Iteration 287, loss = 1502392763.38577580\n",
            "Iteration 288, loss = 1502278577.03795123\n",
            "Iteration 289, loss = 1502164751.52366304\n",
            "Iteration 290, loss = 1502049757.04754472\n",
            "Iteration 291, loss = 1501936379.81582427\n",
            "Iteration 292, loss = 1501822704.35334969\n",
            "Iteration 293, loss = 1501707722.41892004\n",
            "Iteration 294, loss = 1501594460.95533729\n",
            "Iteration 295, loss = 1501480661.73918319\n",
            "Iteration 296, loss = 1501365458.80955553\n",
            "Iteration 297, loss = 1501251776.83114195\n",
            "Iteration 298, loss = 1501137489.93327284\n",
            "Iteration 299, loss = 1501022773.96711445\n",
            "Iteration 300, loss = 1500908039.90776038\n",
            "Iteration 301, loss = 1500794497.51889777\n",
            "Iteration 302, loss = 1500678768.43273664\n",
            "Iteration 303, loss = 1500565202.33933258\n",
            "Iteration 304, loss = 1500450357.76094604\n",
            "Iteration 305, loss = 1500336863.17649674\n",
            "Iteration 306, loss = 1500222496.46264720\n",
            "Iteration 307, loss = 1500108603.33155155\n",
            "Iteration 308, loss = 1499994632.90628386\n",
            "Iteration 309, loss = 1499881100.44050241\n",
            "Iteration 310, loss = 1499767707.88194060\n",
            "Iteration 311, loss = 1499653376.91894889\n",
            "Iteration 312, loss = 1499539832.93390441\n",
            "Iteration 313, loss = 1499426638.67511249\n",
            "Iteration 314, loss = 1499313377.00775003\n",
            "Iteration 315, loss = 1499199263.85777116\n",
            "Iteration 316, loss = 1499085936.41015291\n",
            "Iteration 317, loss = 1498972632.85581255\n",
            "Iteration 318, loss = 1498859457.69015479\n",
            "Iteration 319, loss = 1498745436.84423685\n",
            "Iteration 320, loss = 1498632500.11388063\n",
            "Iteration 321, loss = 1498518613.07569242\n",
            "Iteration 322, loss = 1498405194.42415786\n",
            "Iteration 323, loss = 1498291410.78644085\n",
            "Iteration 324, loss = 1498178576.33738232\n",
            "Iteration 325, loss = 1498064876.15019751\n",
            "Iteration 326, loss = 1497952454.91866398\n",
            "Iteration 327, loss = 1497839298.60336137\n",
            "Iteration 328, loss = 1497726868.30181384\n",
            "Iteration 329, loss = 1497614549.12815189\n",
            "Iteration 330, loss = 1497501737.49783278\n",
            "Iteration 331, loss = 1497390121.54932904\n",
            "Iteration 332, loss = 1497277868.34850335\n",
            "Iteration 333, loss = 1497165021.96975470\n",
            "Iteration 334, loss = 1497053038.42897487\n",
            "Iteration 335, loss = 1496940897.07930636\n",
            "Iteration 336, loss = 1496828480.92820406\n",
            "Iteration 337, loss = 1496716078.25411129\n",
            "Iteration 338, loss = 1496604326.44526196\n",
            "Iteration 339, loss = 1496491783.82948184\n",
            "Iteration 340, loss = 1496380939.66567492\n",
            "Iteration 341, loss = 1496268883.48181629\n",
            "Iteration 342, loss = 1496156943.72497821\n",
            "Iteration 343, loss = 1496045509.74656820\n",
            "Iteration 344, loss = 1495934523.87659669\n",
            "Iteration 345, loss = 1495822710.26332092\n",
            "Iteration 346, loss = 1495710887.25846291\n",
            "Iteration 347, loss = 1495598143.08421731\n",
            "Iteration 348, loss = 1495486682.24577093\n",
            "Iteration 349, loss = 1495373998.22063541\n",
            "Iteration 350, loss = 1495262264.94607210\n",
            "Iteration 351, loss = 1495149442.35926056\n",
            "Iteration 352, loss = 1495038005.76167798\n",
            "Iteration 353, loss = 1494925735.05865908\n",
            "Iteration 354, loss = 1494814347.66373944\n",
            "Iteration 355, loss = 1494702489.92573643\n",
            "Iteration 356, loss = 1494590626.01808429\n",
            "Iteration 357, loss = 1494479632.87480068\n",
            "Iteration 358, loss = 1494368523.32093477\n",
            "Iteration 359, loss = 1494256700.28252220\n",
            "Iteration 360, loss = 1494145505.59171557\n",
            "Iteration 361, loss = 1494035459.49331927\n",
            "Iteration 362, loss = 1493923709.34696770\n",
            "Iteration 363, loss = 1493812832.80050302\n",
            "Iteration 364, loss = 1493702119.14431286\n",
            "Iteration 365, loss = 1493591323.22235250\n",
            "Iteration 366, loss = 1493480404.10018563\n",
            "Iteration 367, loss = 1493369233.83216071\n",
            "Iteration 368, loss = 1493258445.54587841\n",
            "Iteration 369, loss = 1493147659.63380909\n",
            "Iteration 370, loss = 1493036218.27675629\n",
            "Iteration 371, loss = 1492925560.24228907\n",
            "Iteration 372, loss = 1492814637.12704778\n",
            "Iteration 373, loss = 1492703348.92392635\n",
            "Iteration 374, loss = 1492592256.02975750\n",
            "Iteration 375, loss = 1492480619.39887023\n",
            "Iteration 376, loss = 1492370055.50673771\n",
            "Iteration 377, loss = 1492257953.33438516\n",
            "Iteration 378, loss = 1492147630.55446768\n",
            "Iteration 379, loss = 1492036128.63980031\n",
            "Iteration 380, loss = 1491924467.02258015\n",
            "Iteration 381, loss = 1491813719.99400163\n",
            "Iteration 382, loss = 1491703121.79236078\n",
            "Iteration 383, loss = 1491591461.98698425\n",
            "Iteration 384, loss = 1491480743.29833293\n",
            "Iteration 385, loss = 1491370080.96320009\n",
            "Iteration 386, loss = 1491258699.15846276\n",
            "Iteration 387, loss = 1491148091.38200712\n",
            "Iteration 388, loss = 1491036342.38924670\n",
            "Iteration 389, loss = 1490925743.63591337\n",
            "Iteration 390, loss = 1490814612.67656541\n",
            "Iteration 391, loss = 1490703711.83295679\n",
            "Iteration 392, loss = 1490592121.40342045\n",
            "Iteration 393, loss = 1490480991.36237454\n",
            "Iteration 394, loss = 1490370606.87412763\n",
            "Iteration 395, loss = 1490259294.32281971\n",
            "Iteration 396, loss = 1490148293.97153664\n",
            "Iteration 397, loss = 1490037218.96349072\n",
            "Iteration 398, loss = 1489925984.82598424\n",
            "Iteration 399, loss = 1489815055.52348590\n",
            "Iteration 400, loss = 1489703918.49757290\n",
            "Iteration 401, loss = 1489592691.62291837\n",
            "Iteration 402, loss = 1489481771.72806668\n",
            "Iteration 403, loss = 1489370523.88128591\n",
            "Iteration 404, loss = 1489259715.92774892\n",
            "Iteration 405, loss = 1489148693.54057693\n",
            "Iteration 406, loss = 1489038466.71571994\n",
            "Iteration 407, loss = 1488927630.19948888\n",
            "Iteration 408, loss = 1488817224.62409949\n",
            "Iteration 409, loss = 1488707222.90840101\n",
            "Iteration 410, loss = 1488596597.78564906\n",
            "Iteration 411, loss = 1488487244.82685852\n",
            "Iteration 412, loss = 1488376554.41333556\n",
            "Iteration 413, loss = 1488267043.00526023\n",
            "Iteration 414, loss = 1488156946.64872074\n",
            "Iteration 415, loss = 1488046892.20406318\n",
            "Iteration 416, loss = 1487936299.21228623\n",
            "Iteration 417, loss = 1487826476.86325121\n",
            "Iteration 418, loss = 1487716677.38051105\n",
            "Iteration 419, loss = 1487605839.01480794\n",
            "Iteration 420, loss = 1487496148.26084471\n",
            "Iteration 421, loss = 1487385598.27345991\n",
            "Iteration 422, loss = 1487275553.00107241\n",
            "Iteration 423, loss = 1487164977.51447248\n",
            "Iteration 424, loss = 1487055488.48824906\n",
            "Iteration 425, loss = 1486945278.90969563\n",
            "Iteration 426, loss = 1486834465.60981631\n",
            "Iteration 427, loss = 1486724759.50364137\n",
            "Iteration 428, loss = 1486614351.97764635\n",
            "Iteration 429, loss = 1486503674.70547438\n",
            "Iteration 430, loss = 1486393544.70432305\n",
            "Iteration 431, loss = 1486282796.20454550\n",
            "Iteration 432, loss = 1486172737.67831111\n",
            "Iteration 433, loss = 1486062825.38313937\n",
            "Iteration 434, loss = 1485951971.74059534\n",
            "Iteration 435, loss = 1485842316.78073597\n",
            "Iteration 436, loss = 1485732414.84173155\n",
            "Iteration 437, loss = 1485622052.59946108\n",
            "Iteration 438, loss = 1485512437.36482286\n",
            "Iteration 439, loss = 1485402347.87076092\n",
            "Iteration 440, loss = 1485292649.94008136\n",
            "Iteration 441, loss = 1485182302.95312834\n",
            "Iteration 442, loss = 1485072634.72283816\n",
            "Iteration 443, loss = 1484962737.29691815\n",
            "Iteration 444, loss = 1484853141.71120143\n",
            "Iteration 445, loss = 1484742919.37063718\n",
            "Iteration 446, loss = 1484632836.38681388\n",
            "Iteration 447, loss = 1484523148.32886648\n",
            "Iteration 448, loss = 1484413670.94305873\n",
            "Iteration 449, loss = 1484303715.06315899\n",
            "Iteration 450, loss = 1484193334.30249906\n",
            "Iteration 451, loss = 1484084344.04374647\n",
            "Iteration 452, loss = 1483973893.24589825\n",
            "Iteration 453, loss = 1483864688.00516176\n",
            "Iteration 454, loss = 1483753942.88349962\n",
            "Iteration 455, loss = 1483644579.08950639\n",
            "Iteration 456, loss = 1483534930.81612253\n",
            "Iteration 457, loss = 1483425399.35145950\n",
            "Iteration 458, loss = 1483315567.02503514\n",
            "Iteration 459, loss = 1483206236.33152318\n",
            "Iteration 460, loss = 1483097490.04847360\n",
            "Iteration 461, loss = 1482988561.58637190\n",
            "Iteration 462, loss = 1482879947.77637458\n",
            "Iteration 463, loss = 1482770788.98705578\n",
            "Iteration 464, loss = 1482662496.10566521\n",
            "Iteration 465, loss = 1482553454.13443637\n",
            "Iteration 466, loss = 1482444942.95621109\n",
            "Iteration 467, loss = 1482337052.52088332\n",
            "Iteration 468, loss = 1482227860.07929707\n",
            "Iteration 469, loss = 1482118383.83084917\n",
            "Iteration 470, loss = 1482009727.31661081\n",
            "Iteration 471, loss = 1481900907.20084023\n",
            "Iteration 472, loss = 1481791801.66279173\n",
            "Iteration 473, loss = 1481682397.76758838\n",
            "Iteration 474, loss = 1481573650.84011126\n",
            "Iteration 475, loss = 1481464877.39590716\n",
            "Iteration 476, loss = 1481355781.45982456\n",
            "Iteration 477, loss = 1481247700.88049126\n",
            "Iteration 478, loss = 1481138671.75698042\n",
            "Iteration 479, loss = 1481030118.13482714\n",
            "Iteration 480, loss = 1480921530.69752049\n",
            "Iteration 481, loss = 1480813037.76733780\n",
            "Iteration 482, loss = 1480704638.15045428\n",
            "Iteration 483, loss = 1480595653.38654017\n",
            "Iteration 484, loss = 1480486992.04888749\n",
            "Iteration 485, loss = 1480378382.36210227\n",
            "Iteration 486, loss = 1480269735.57926250\n",
            "Iteration 487, loss = 1480161420.63951969\n",
            "Iteration 488, loss = 1480052543.47497725\n",
            "Iteration 489, loss = 1479944090.02986646\n",
            "Iteration 490, loss = 1479836255.02821136\n",
            "Iteration 491, loss = 1479728020.79186606\n",
            "Iteration 492, loss = 1479619901.96571398\n",
            "Iteration 493, loss = 1479511510.23466516\n",
            "Iteration 494, loss = 1479403327.04119825\n",
            "Iteration 495, loss = 1479295078.15301824\n",
            "Iteration 496, loss = 1479186996.10009575\n",
            "Iteration 497, loss = 1479078172.77617359\n",
            "Iteration 498, loss = 1478970169.77545977\n",
            "Iteration 499, loss = 1478860963.06568789\n",
            "Iteration 500, loss = 1478752180.58707714\n",
            "Iteration 501, loss = 1478644128.97147608\n",
            "Iteration 502, loss = 1478535409.00742960\n",
            "Iteration 503, loss = 1478426397.82958651\n",
            "Iteration 504, loss = 1478317214.19051671\n",
            "Iteration 505, loss = 1478209189.94731236\n",
            "Iteration 506, loss = 1478100171.38944888\n",
            "Iteration 507, loss = 1477991009.81381369\n",
            "Iteration 508, loss = 1477883098.70121288\n",
            "Iteration 509, loss = 1477773449.06587934\n",
            "Iteration 510, loss = 1477664563.19034123\n",
            "Iteration 511, loss = 1477556284.18200111\n",
            "Iteration 512, loss = 1477446916.92681932\n",
            "Iteration 513, loss = 1477338163.59451461\n",
            "Iteration 514, loss = 1477230080.77986789\n",
            "Iteration 515, loss = 1477121446.60637593\n",
            "Iteration 516, loss = 1477011783.91019917\n",
            "Iteration 517, loss = 1476904517.02309346\n",
            "Iteration 518, loss = 1476795448.09897399\n",
            "Iteration 519, loss = 1476687565.58294320\n",
            "Iteration 520, loss = 1476578479.53742647\n",
            "Iteration 521, loss = 1476470297.31632566\n",
            "Iteration 522, loss = 1476362794.91637683\n",
            "Iteration 523, loss = 1476253408.34814668\n",
            "Iteration 524, loss = 1476146265.85892344\n",
            "Iteration 525, loss = 1476038351.60637355\n",
            "Iteration 526, loss = 1475929850.03101373\n",
            "Iteration 527, loss = 1475822903.35447836\n",
            "Iteration 528, loss = 1475714927.44670296\n",
            "Iteration 529, loss = 1475607280.76443052\n",
            "Iteration 530, loss = 1475499009.68689895\n",
            "Iteration 531, loss = 1475391630.39632750\n",
            "Iteration 532, loss = 1475283100.97881866\n",
            "Iteration 533, loss = 1475174713.94154048\n",
            "Iteration 534, loss = 1475066618.92800570\n",
            "Iteration 535, loss = 1474957628.42362475\n",
            "Iteration 536, loss = 1474849105.68568969\n",
            "Iteration 537, loss = 1474740845.21937132\n",
            "Iteration 538, loss = 1474631882.03043747\n",
            "Iteration 539, loss = 1474522882.56799412\n",
            "Iteration 540, loss = 1474414291.43178225\n",
            "Iteration 541, loss = 1474305917.17895412\n",
            "Iteration 542, loss = 1474197299.04974484\n",
            "Iteration 543, loss = 1474088767.75827980\n",
            "Iteration 544, loss = 1473980126.33241153\n",
            "Iteration 545, loss = 1473871951.08520436\n",
            "Iteration 546, loss = 1473764177.17137623\n",
            "Iteration 547, loss = 1473655281.38939738\n",
            "Iteration 548, loss = 1473548114.96098161\n",
            "Iteration 549, loss = 1473439814.83818603\n",
            "Iteration 550, loss = 1473331912.24463701\n",
            "Iteration 551, loss = 1473224312.98347545\n",
            "Iteration 552, loss = 1473116427.92622495\n",
            "Iteration 553, loss = 1473008714.86591864\n",
            "Iteration 554, loss = 1472901234.86863470\n",
            "Iteration 555, loss = 1472793725.47621989\n",
            "Iteration 556, loss = 1472685452.12716818\n",
            "Iteration 557, loss = 1472578049.25815511\n",
            "Iteration 558, loss = 1472469942.45084095\n",
            "Iteration 559, loss = 1472362178.70591688\n",
            "Iteration 560, loss = 1472254442.35410380\n",
            "Iteration 561, loss = 1472146313.73091125\n",
            "Iteration 562, loss = 1472038338.42286086\n",
            "Iteration 563, loss = 1471931301.30304623\n",
            "Iteration 564, loss = 1471823176.56840873\n",
            "Iteration 565, loss = 1471716021.85838127\n",
            "Iteration 566, loss = 1471608404.72858429\n",
            "Iteration 567, loss = 1471501796.64016175\n",
            "Iteration 568, loss = 1471395271.68637013\n",
            "Iteration 569, loss = 1471287263.41432810\n",
            "Iteration 570, loss = 1471180564.18031216\n",
            "Iteration 571, loss = 1471073306.20957422\n",
            "Iteration 572, loss = 1470966668.03384566\n",
            "Iteration 573, loss = 1470858728.34641290\n",
            "Iteration 574, loss = 1470751890.96390009\n",
            "Iteration 575, loss = 1470643804.44903779\n",
            "Iteration 576, loss = 1470537237.13355923\n",
            "Iteration 577, loss = 1470429004.19653368\n",
            "Iteration 578, loss = 1470322132.16886449\n",
            "Iteration 579, loss = 1470214321.08670306\n",
            "Iteration 580, loss = 1470107125.42391586\n",
            "Iteration 581, loss = 1470000029.21883178\n",
            "Iteration 582, loss = 1469891894.22169185\n",
            "Iteration 583, loss = 1469784888.74685502\n",
            "Iteration 584, loss = 1469676877.91894102\n",
            "Iteration 585, loss = 1469570028.83339858\n",
            "Iteration 586, loss = 1469461784.27423263\n",
            "Iteration 587, loss = 1469354601.67312527\n",
            "Iteration 588, loss = 1469246924.85467863\n",
            "Iteration 589, loss = 1469139287.38573480\n",
            "Iteration 590, loss = 1469031840.16978168\n",
            "Iteration 591, loss = 1468924911.83648872\n",
            "Iteration 592, loss = 1468817263.74666810\n",
            "Iteration 593, loss = 1468710502.98907733\n",
            "Iteration 594, loss = 1468603595.63007164\n",
            "Iteration 595, loss = 1468497053.17088175\n",
            "Iteration 596, loss = 1468390558.35360694\n",
            "Iteration 597, loss = 1468283598.89338684\n",
            "Iteration 598, loss = 1468177307.38144970\n",
            "Iteration 599, loss = 1468070440.58271980\n",
            "Iteration 600, loss = 1467963951.34435606\n",
            "Iteration 601, loss = 1467856756.42795873\n",
            "Iteration 602, loss = 1467749803.23384261\n",
            "Iteration 603, loss = 1467643233.04038501\n",
            "Iteration 604, loss = 1467535254.48095059\n",
            "Iteration 605, loss = 1467428513.79232717\n",
            "Iteration 606, loss = 1467322098.14825678\n",
            "Iteration 607, loss = 1467214545.67077470\n",
            "Iteration 608, loss = 1467107777.05271196\n",
            "Iteration 609, loss = 1467001390.82748270\n",
            "Iteration 610, loss = 1466894714.29284930\n",
            "Iteration 611, loss = 1466787779.11630416\n",
            "Iteration 612, loss = 1466681391.93217993\n",
            "Iteration 613, loss = 1466575678.88049579\n",
            "Iteration 614, loss = 1466468918.66836143\n",
            "Iteration 615, loss = 1466362638.57566357\n",
            "Iteration 616, loss = 1466256636.07777596\n",
            "Iteration 617, loss = 1466149582.15473008\n",
            "Iteration 618, loss = 1466043261.52738810\n",
            "Iteration 619, loss = 1465936910.14926624\n",
            "Iteration 620, loss = 1465829815.11734653\n",
            "Iteration 621, loss = 1465723066.79714632\n",
            "Iteration 622, loss = 1465616240.38861990\n",
            "Iteration 623, loss = 1465509033.48638272\n",
            "Iteration 624, loss = 1465402454.11246514\n",
            "Iteration 625, loss = 1465295866.97824836\n",
            "Iteration 626, loss = 1465188323.94496131\n",
            "Iteration 627, loss = 1465081552.61913919\n",
            "Iteration 628, loss = 1464974763.51603270\n",
            "Iteration 629, loss = 1464867193.36759186\n",
            "Iteration 630, loss = 1464760444.52393222\n",
            "Iteration 631, loss = 1464652517.98004055\n",
            "Iteration 632, loss = 1464545973.43965411\n",
            "Iteration 633, loss = 1464438825.97386193\n",
            "Iteration 634, loss = 1464331249.77219987\n",
            "Iteration 635, loss = 1464224953.98844051\n",
            "Iteration 636, loss = 1464117817.95723772\n",
            "Iteration 637, loss = 1464011197.77562046\n",
            "Iteration 638, loss = 1463903706.28603363\n",
            "Iteration 639, loss = 1463797393.38988423\n",
            "Iteration 640, loss = 1463690635.32271743\n",
            "Iteration 641, loss = 1463583010.83294368\n",
            "Iteration 642, loss = 1463476867.33052182\n",
            "Iteration 643, loss = 1463369995.01077533\n",
            "Iteration 644, loss = 1463263434.34344530\n",
            "Iteration 645, loss = 1463156815.46860814\n",
            "Iteration 646, loss = 1463049990.41732955\n",
            "Iteration 647, loss = 1462943279.15526128\n",
            "Iteration 648, loss = 1462836537.39894581\n",
            "Iteration 649, loss = 1462728941.62671232\n",
            "Iteration 650, loss = 1462622020.41354489\n",
            "Iteration 651, loss = 1462514698.78555059\n",
            "Iteration 652, loss = 1462407856.08442950\n",
            "Iteration 653, loss = 1462299890.64191914\n",
            "Iteration 654, loss = 1462193241.08201027\n",
            "Iteration 655, loss = 1462085443.67417526\n",
            "Iteration 656, loss = 1461978879.06487274\n",
            "Iteration 657, loss = 1461871330.62239361\n",
            "Iteration 658, loss = 1461763944.06648755\n",
            "Iteration 659, loss = 1461656612.04400039\n",
            "Iteration 660, loss = 1461549190.82015157\n",
            "Iteration 661, loss = 1461442177.59473300\n",
            "Iteration 662, loss = 1461334926.73031664\n",
            "Iteration 663, loss = 1461227491.34703350\n",
            "Iteration 664, loss = 1461120170.27457190\n",
            "Iteration 665, loss = 1461013032.77513885\n",
            "Iteration 666, loss = 1460905570.79069829\n",
            "Iteration 667, loss = 1460798483.89494801\n",
            "Iteration 668, loss = 1460690715.00045824\n",
            "Iteration 669, loss = 1460584007.18018770\n",
            "Iteration 670, loss = 1460476248.39595413\n",
            "Iteration 671, loss = 1460369241.44419599\n",
            "Iteration 672, loss = 1460262909.91938591\n",
            "Iteration 673, loss = 1460155511.68264389\n",
            "Iteration 674, loss = 1460048602.26396012\n",
            "Iteration 675, loss = 1459941941.83769703\n",
            "Iteration 676, loss = 1459835348.45334983\n",
            "Iteration 677, loss = 1459728972.68133545\n",
            "Iteration 678, loss = 1459621707.49188924\n",
            "Iteration 679, loss = 1459515500.29163003\n",
            "Iteration 680, loss = 1459409286.81063819\n",
            "Iteration 681, loss = 1459302884.47479701\n",
            "Iteration 682, loss = 1459196388.96988130\n",
            "Iteration 683, loss = 1459090678.62803912\n",
            "Iteration 684, loss = 1458985869.59532905\n",
            "Iteration 685, loss = 1458878772.64535332\n",
            "Iteration 686, loss = 1458774543.91863322\n",
            "Iteration 687, loss = 1458668472.39036417\n",
            "Iteration 688, loss = 1458563758.96602273\n",
            "Iteration 689, loss = 1458458217.15784550\n",
            "Iteration 690, loss = 1458352460.31119227\n",
            "Iteration 691, loss = 1458247699.77209878\n",
            "Iteration 692, loss = 1458142187.14421487\n",
            "Iteration 693, loss = 1458036823.06395245\n",
            "Iteration 694, loss = 1457930905.23723149\n",
            "Iteration 695, loss = 1457825496.37738299\n",
            "Iteration 696, loss = 1457719659.14514232\n",
            "Iteration 697, loss = 1457613781.65961933\n",
            "Iteration 698, loss = 1457507550.76349473\n",
            "Iteration 699, loss = 1457401642.14996314\n",
            "Iteration 700, loss = 1457295599.44460750\n",
            "Iteration 701, loss = 1457188869.21740365\n",
            "Iteration 702, loss = 1457083207.30320621\n",
            "Iteration 703, loss = 1456976459.18195176\n",
            "Iteration 704, loss = 1456869471.01553965\n",
            "Iteration 705, loss = 1456763953.78486896\n",
            "Iteration 706, loss = 1456656894.11866069\n",
            "Iteration 707, loss = 1456551494.43967867\n",
            "Iteration 708, loss = 1456444379.75381374\n",
            "Iteration 709, loss = 1456338458.34835005\n",
            "Iteration 710, loss = 1456232280.01494098\n",
            "Iteration 711, loss = 1456126075.40366435\n",
            "Iteration 712, loss = 1456020119.71076584\n",
            "Iteration 713, loss = 1455914706.13638592\n",
            "Iteration 714, loss = 1455808205.53147221\n",
            "Iteration 715, loss = 1455702989.36111403\n",
            "Iteration 716, loss = 1455596153.84140778\n",
            "Iteration 717, loss = 1455491204.80001926\n",
            "Iteration 718, loss = 1455385598.65039802\n",
            "Iteration 719, loss = 1455279507.75507450\n",
            "Iteration 720, loss = 1455174034.18925238\n",
            "Iteration 721, loss = 1455067755.93629503\n",
            "Iteration 722, loss = 1454962524.75676417\n",
            "Iteration 723, loss = 1454856454.73090816\n",
            "Iteration 724, loss = 1454749543.98264647\n",
            "Iteration 725, loss = 1454644459.74414539\n",
            "Iteration 726, loss = 1454537525.51752853\n",
            "Iteration 727, loss = 1454432011.98767328\n",
            "Iteration 728, loss = 1454326260.62691092\n",
            "Iteration 729, loss = 1454219837.37826276\n",
            "Iteration 730, loss = 1454113994.72559738\n",
            "Iteration 731, loss = 1454009088.79136419\n",
            "Iteration 732, loss = 1453902814.13187099\n",
            "Iteration 733, loss = 1453797242.07000065\n",
            "Iteration 734, loss = 1453690846.33904815\n",
            "Iteration 735, loss = 1453585475.33807182\n",
            "Iteration 736, loss = 1453479378.33804607\n",
            "Iteration 737, loss = 1453372692.21666455\n",
            "Iteration 738, loss = 1453266828.77132511\n",
            "Iteration 739, loss = 1453161075.24245596\n",
            "Iteration 740, loss = 1453054350.35471749\n",
            "Iteration 741, loss = 1452948075.47918677\n",
            "Iteration 742, loss = 1452842736.52606583\n",
            "Iteration 743, loss = 1452736317.42201900\n",
            "Iteration 744, loss = 1452630052.95691061\n",
            "Iteration 745, loss = 1452524301.07939005\n",
            "Iteration 746, loss = 1452418815.80949569\n",
            "Iteration 747, loss = 1452312790.75001025\n",
            "Iteration 748, loss = 1452206391.78394723\n",
            "Iteration 749, loss = 1452101585.96936917\n",
            "Iteration 750, loss = 1451994825.43163228\n",
            "Iteration 751, loss = 1451889270.09064984\n",
            "Iteration 752, loss = 1451783591.59927392\n",
            "Iteration 753, loss = 1451678010.91778302\n",
            "Iteration 754, loss = 1451572033.73848939\n",
            "Iteration 755, loss = 1451466576.77969432\n",
            "Iteration 756, loss = 1451360989.82634258\n",
            "Iteration 757, loss = 1451255351.79074192\n",
            "Iteration 758, loss = 1451150269.75374341\n",
            "Iteration 759, loss = 1451044712.39263511\n",
            "Iteration 760, loss = 1450939106.36874294\n",
            "Iteration 761, loss = 1450834162.34261799\n",
            "Iteration 762, loss = 1450728485.58221483\n",
            "Iteration 763, loss = 1450622164.32335711\n",
            "Iteration 764, loss = 1450517811.32425594\n",
            "Iteration 765, loss = 1450411905.60028362\n",
            "Iteration 766, loss = 1450306610.16835403\n",
            "Iteration 767, loss = 1450200862.08832550\n",
            "Iteration 768, loss = 1450096034.93097353\n",
            "Iteration 769, loss = 1449989827.95141935\n",
            "Iteration 770, loss = 1449884761.03286171\n",
            "Iteration 771, loss = 1449779228.48418188\n",
            "Iteration 772, loss = 1449673425.37043095\n",
            "Iteration 773, loss = 1449568511.35506034\n",
            "Iteration 774, loss = 1449462828.42275906\n",
            "Iteration 775, loss = 1449357998.14426255\n",
            "Iteration 776, loss = 1449253291.59250498\n",
            "Iteration 777, loss = 1449148073.14066935\n",
            "Iteration 778, loss = 1449042593.98486423\n",
            "Iteration 779, loss = 1448938595.65160394\n",
            "Iteration 780, loss = 1448832902.87996769\n",
            "Iteration 781, loss = 1448727804.99701238\n",
            "Iteration 782, loss = 1448622640.82584929\n",
            "Iteration 783, loss = 1448517806.50080800\n",
            "Iteration 784, loss = 1448412487.48851657\n",
            "Iteration 785, loss = 1448307494.45026970\n",
            "Iteration 786, loss = 1448202191.96597147\n",
            "Iteration 787, loss = 1448097716.26854420\n",
            "Iteration 788, loss = 1447993781.26098657\n",
            "Iteration 789, loss = 1447888691.18064690\n",
            "Iteration 790, loss = 1447784078.84509063\n",
            "Iteration 791, loss = 1447679135.23004889\n",
            "Iteration 792, loss = 1447574508.09202147\n",
            "Iteration 793, loss = 1447469400.60394359\n",
            "Iteration 794, loss = 1447365222.03287911\n",
            "Iteration 795, loss = 1447259274.34103966\n",
            "Iteration 796, loss = 1447153984.61901736\n",
            "Iteration 797, loss = 1447048710.02336884\n",
            "Iteration 798, loss = 1446944400.50089073\n",
            "Iteration 799, loss = 1446838875.48904634\n",
            "Iteration 800, loss = 1446733093.11218452\n",
            "Iteration 801, loss = 1446628368.50375795\n",
            "Iteration 802, loss = 1446523910.03012323\n",
            "Iteration 803, loss = 1446417775.70563293\n",
            "Iteration 804, loss = 1446313617.54145694\n",
            "Iteration 805, loss = 1446207559.48515296\n",
            "Iteration 806, loss = 1446102711.37537837\n",
            "Iteration 807, loss = 1445998023.04303360\n",
            "Iteration 808, loss = 1445892837.43237495\n",
            "Iteration 809, loss = 1445788014.74641252\n",
            "Iteration 810, loss = 1445683507.66891432\n",
            "Iteration 811, loss = 1445578104.44002175\n",
            "Iteration 812, loss = 1445473675.24351478\n",
            "Iteration 813, loss = 1445368428.62674594\n",
            "Iteration 814, loss = 1445263251.96667910\n",
            "Iteration 815, loss = 1445158096.43054533\n",
            "Iteration 816, loss = 1445053066.23716688\n",
            "Iteration 817, loss = 1444947321.60242844\n",
            "Iteration 818, loss = 1444842753.97325706\n",
            "Iteration 819, loss = 1444736988.33144855\n",
            "Iteration 820, loss = 1444632479.01169109\n",
            "Iteration 821, loss = 1444527517.56197834\n",
            "Iteration 822, loss = 1444422171.10613680\n",
            "Iteration 823, loss = 1444318137.63518810\n",
            "Iteration 824, loss = 1444213377.75745845\n",
            "Iteration 825, loss = 1444108413.43919635\n",
            "Iteration 826, loss = 1444004403.66847610\n",
            "Iteration 827, loss = 1443899799.62419271\n",
            "Iteration 828, loss = 1443794843.02526283\n",
            "Iteration 829, loss = 1443691094.05962825\n",
            "Iteration 830, loss = 1443586191.05723596\n",
            "Iteration 831, loss = 1443481974.98619246\n",
            "Iteration 832, loss = 1443377545.83145332\n",
            "Iteration 833, loss = 1443272494.45388103\n",
            "Iteration 834, loss = 1443168081.69707513\n",
            "Iteration 835, loss = 1443063390.71832871\n",
            "Iteration 836, loss = 1442958592.19274139\n",
            "Iteration 837, loss = 1442853400.05653334\n",
            "Iteration 838, loss = 1442748883.61024857\n",
            "Iteration 839, loss = 1442643658.71036220\n",
            "Iteration 840, loss = 1442539299.89904022\n",
            "Iteration 841, loss = 1442434230.66706085\n",
            "Iteration 842, loss = 1442329328.75270104\n",
            "Iteration 843, loss = 1442225317.80892229\n",
            "Iteration 844, loss = 1442120639.70602489\n",
            "Iteration 845, loss = 1442016443.33584571\n",
            "Iteration 846, loss = 1441911455.25385880\n",
            "Iteration 847, loss = 1441807674.01114631\n",
            "Iteration 848, loss = 1441702621.25528741\n",
            "Iteration 849, loss = 1441598141.13314176\n",
            "Iteration 850, loss = 1441493804.30166316\n",
            "Iteration 851, loss = 1441387964.49248505\n",
            "Iteration 852, loss = 1441283368.90352845\n",
            "Iteration 853, loss = 1441179341.68685150\n",
            "Iteration 854, loss = 1441073776.67363071\n",
            "Iteration 855, loss = 1440968644.72039819\n",
            "Iteration 856, loss = 1440864226.39674759\n",
            "Iteration 857, loss = 1440759402.10495925\n",
            "Iteration 858, loss = 1440653989.05716658\n",
            "Iteration 859, loss = 1440549429.97665191\n",
            "Iteration 860, loss = 1440443892.58584404\n",
            "Iteration 861, loss = 1440338911.98568249\n",
            "Iteration 862, loss = 1440233289.83789039\n",
            "Iteration 863, loss = 1440129670.65072894\n",
            "Iteration 864, loss = 1440023552.79373121\n",
            "Iteration 865, loss = 1439920255.50125432\n",
            "Iteration 866, loss = 1439816071.06174803\n",
            "Iteration 867, loss = 1439711005.76752877\n",
            "Iteration 868, loss = 1439608126.23951459\n",
            "Iteration 869, loss = 1439503765.37259626\n",
            "Iteration 870, loss = 1439399673.23581886\n",
            "Iteration 871, loss = 1439295298.59004760\n",
            "Iteration 872, loss = 1439191364.88029265\n",
            "Iteration 873, loss = 1439086859.97394824\n",
            "Iteration 874, loss = 1438982066.18631291\n",
            "Iteration 875, loss = 1438877897.55499744\n",
            "Iteration 876, loss = 1438773249.81713629\n",
            "Iteration 877, loss = 1438667905.86205316\n",
            "Iteration 878, loss = 1438563761.63235307\n",
            "Iteration 879, loss = 1438459038.30333257\n",
            "Iteration 880, loss = 1438353205.63653970\n",
            "Iteration 881, loss = 1438248841.37933660\n",
            "Iteration 882, loss = 1438143751.36378384\n",
            "Iteration 883, loss = 1438038925.49532199\n",
            "Iteration 884, loss = 1437934163.75171423\n",
            "Iteration 885, loss = 1437829621.11199951\n",
            "Iteration 886, loss = 1437725006.28015280\n",
            "Iteration 887, loss = 1437620888.54864669\n",
            "Iteration 888, loss = 1437516454.88433886\n",
            "Iteration 889, loss = 1437412685.11198473\n",
            "Iteration 890, loss = 1437308806.09996438\n",
            "Iteration 891, loss = 1437203799.50643325\n",
            "Iteration 892, loss = 1437099970.56559205\n",
            "Iteration 893, loss = 1436996004.70435214\n",
            "Iteration 894, loss = 1436891418.36878753\n",
            "Iteration 895, loss = 1436786302.88801360\n",
            "Iteration 896, loss = 1436681810.89902401\n",
            "Iteration 897, loss = 1436576985.34112167\n",
            "Iteration 898, loss = 1436472016.53831410\n",
            "Iteration 899, loss = 1436366538.55893159\n",
            "Iteration 900, loss = 1436262176.00335574\n",
            "Iteration 901, loss = 1436156765.72248101\n",
            "Iteration 902, loss = 1436052631.17963982\n",
            "Iteration 903, loss = 1435947813.18093801\n",
            "Iteration 904, loss = 1435842700.65918612\n",
            "Iteration 905, loss = 1435738462.21520996\n",
            "Iteration 906, loss = 1435634311.55051851\n",
            "Iteration 907, loss = 1435530003.43906569\n",
            "Iteration 908, loss = 1435424821.59584808\n",
            "Iteration 909, loss = 1435320811.97275734\n",
            "Iteration 910, loss = 1435216952.65678382\n",
            "Iteration 911, loss = 1435112116.69661403\n",
            "Iteration 912, loss = 1435008036.51322079\n",
            "Iteration 913, loss = 1434903532.15293765\n",
            "Iteration 914, loss = 1434798449.02239728\n",
            "Iteration 915, loss = 1434694636.82561302\n",
            "Iteration 916, loss = 1434589789.49752665\n",
            "Iteration 917, loss = 1434485554.59201980\n",
            "Iteration 918, loss = 1434380696.77045345\n",
            "Iteration 919, loss = 1434276597.64749765\n",
            "Iteration 920, loss = 1434172942.73860955\n",
            "Iteration 921, loss = 1434067799.21807861\n",
            "Iteration 922, loss = 1433964847.77331758\n",
            "Iteration 923, loss = 1433860824.43091416\n",
            "Iteration 924, loss = 1433756462.87247086\n",
            "Iteration 925, loss = 1433652076.17154574\n",
            "Iteration 926, loss = 1433549034.95112514\n",
            "Iteration 927, loss = 1433445097.15512657\n",
            "Iteration 928, loss = 1433340682.55348420\n",
            "Iteration 929, loss = 1433236735.11129260\n",
            "Iteration 930, loss = 1433133419.98082471\n",
            "Iteration 931, loss = 1433029903.67464042\n",
            "Iteration 932, loss = 1432925539.56937790\n",
            "Iteration 933, loss = 1432822708.73813772\n",
            "Iteration 934, loss = 1432718855.04461551\n",
            "Iteration 935, loss = 1432615256.24020767\n",
            "Iteration 936, loss = 1432512631.15166068\n",
            "Iteration 937, loss = 1432408520.94735909\n",
            "Iteration 938, loss = 1432305318.30980802\n",
            "Iteration 939, loss = 1432202305.04341793\n",
            "Iteration 940, loss = 1432098838.00110626\n",
            "Iteration 941, loss = 1431995138.01860809\n",
            "Iteration 942, loss = 1431892264.75918007\n",
            "Iteration 943, loss = 1431789328.95697880\n",
            "Iteration 944, loss = 1431685902.73678398\n",
            "Iteration 945, loss = 1431582916.25826263\n",
            "Iteration 946, loss = 1431479736.40262389\n",
            "Iteration 947, loss = 1431376792.23758841\n",
            "Iteration 948, loss = 1431274694.52522230\n",
            "Iteration 949, loss = 1431171159.23356366\n",
            "Iteration 950, loss = 1431068906.63546181\n",
            "Iteration 951, loss = 1430965636.75817347\n",
            "Iteration 952, loss = 1430862432.43728542\n",
            "Iteration 953, loss = 1430759436.89384031\n",
            "Iteration 954, loss = 1430656385.21830654\n",
            "Iteration 955, loss = 1430552221.60661983\n",
            "Iteration 956, loss = 1430449493.03596187\n",
            "Iteration 957, loss = 1430345380.52010345\n",
            "Iteration 958, loss = 1430241952.03186917\n",
            "Iteration 959, loss = 1430138621.62961292\n",
            "Iteration 960, loss = 1430035283.83429527\n",
            "Iteration 961, loss = 1429931049.26750898\n",
            "Iteration 962, loss = 1429828132.76134467\n",
            "Iteration 963, loss = 1429724672.48853850\n",
            "Iteration 964, loss = 1429621019.21903110\n",
            "Iteration 965, loss = 1429517527.39633274\n",
            "Iteration 966, loss = 1429414203.64567184\n",
            "Iteration 967, loss = 1429311158.16316557\n",
            "Iteration 968, loss = 1429207397.76623011\n",
            "Iteration 969, loss = 1429104250.89861941\n",
            "Iteration 970, loss = 1429000827.58587432\n",
            "Iteration 971, loss = 1428897324.37433124\n",
            "Iteration 972, loss = 1428793719.63625288\n",
            "Iteration 973, loss = 1428690194.32873821\n",
            "Iteration 974, loss = 1428586285.10879636\n",
            "Iteration 975, loss = 1428482815.97239804\n",
            "Iteration 976, loss = 1428378722.36386919\n",
            "Iteration 977, loss = 1428275051.41978025\n",
            "Iteration 978, loss = 1428171078.82765460\n",
            "Iteration 979, loss = 1428066844.81168556\n",
            "Iteration 980, loss = 1427962448.48968458\n",
            "Iteration 981, loss = 1427858825.52370977\n",
            "Iteration 982, loss = 1427754375.48928857\n",
            "Iteration 983, loss = 1427650239.84857535\n",
            "Iteration 984, loss = 1427545790.67748737\n",
            "Iteration 985, loss = 1427442548.31598234\n",
            "Iteration 986, loss = 1427338252.76474071\n",
            "Iteration 987, loss = 1427233834.35706663\n",
            "Iteration 988, loss = 1427131166.08575821\n",
            "Iteration 989, loss = 1427026819.71561670\n",
            "Iteration 990, loss = 1426923070.75145364\n",
            "Iteration 991, loss = 1426819268.11990571\n",
            "Iteration 992, loss = 1426715670.19697690\n",
            "Iteration 993, loss = 1426611363.93462443\n",
            "Iteration 994, loss = 1426508556.37248945\n",
            "Iteration 995, loss = 1426403571.85120964\n",
            "Iteration 996, loss = 1426300276.27507877\n",
            "Iteration 997, loss = 1426196586.34305954\n",
            "Iteration 998, loss = 1426092610.81571150\n",
            "Iteration 999, loss = 1425989314.60049152\n",
            "Iteration 1000, loss = 1425885312.88021779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1533278096.08431578\n",
            "Iteration 2, loss = 397666305.31079608\n",
            "Iteration 3, loss = 106807325.94592610\n",
            "Iteration 4, loss = 95951346.44649583\n",
            "Iteration 5, loss = 93939600.73162337\n",
            "Iteration 6, loss = 116390355.86622652\n",
            "Iteration 7, loss = 74291640.19154705\n",
            "Iteration 8, loss = 62117331.07341737\n",
            "Iteration 9, loss = 52973075.89175178\n",
            "Iteration 10, loss = 48880686.76279265\n",
            "Iteration 11, loss = 47773505.15108335\n",
            "Iteration 12, loss = 49383235.95124262\n",
            "Iteration 13, loss = 46912564.15075205\n",
            "Iteration 14, loss = 47008912.55145948\n",
            "Iteration 15, loss = 46739552.83683814\n",
            "Iteration 16, loss = 43803326.90151279\n",
            "Iteration 17, loss = 41759853.66757601\n",
            "Iteration 18, loss = 40339895.98454991\n",
            "Iteration 19, loss = 36125026.02236998\n",
            "Iteration 20, loss = 35081363.22110324\n",
            "Iteration 21, loss = 33114831.91678340\n",
            "Iteration 22, loss = 32776544.83706896\n",
            "Iteration 23, loss = 31128614.84769332\n",
            "Iteration 24, loss = 29463096.40125781\n",
            "Iteration 25, loss = 29363536.70272428\n",
            "Iteration 26, loss = 28740337.50051142\n",
            "Iteration 27, loss = 28780180.06860090\n",
            "Iteration 28, loss = 28484603.87957832\n",
            "Iteration 29, loss = 28215731.46267784\n",
            "Iteration 30, loss = 28784150.43972939\n",
            "Iteration 31, loss = 28534373.12488090\n",
            "Iteration 32, loss = 28983529.96968671\n",
            "Iteration 33, loss = 28772520.00781062\n",
            "Iteration 34, loss = 28694073.60376430\n",
            "Iteration 35, loss = 28428725.40165927\n",
            "Iteration 36, loss = 28257812.54480468\n",
            "Iteration 37, loss = 28085750.67010025\n",
            "Iteration 38, loss = 27417545.53535230\n",
            "Iteration 39, loss = 27199453.69089209\n",
            "Iteration 40, loss = 26699554.12089919\n",
            "Iteration 41, loss = 26500687.35310395\n",
            "Iteration 42, loss = 26083749.52695284\n",
            "Iteration 43, loss = 25695812.54850466\n",
            "Iteration 44, loss = 25722545.46157435\n",
            "Iteration 45, loss = 25291041.77572811\n",
            "Iteration 46, loss = 25213168.52184155\n",
            "Iteration 47, loss = 25547234.05978407\n",
            "Iteration 48, loss = 24724518.08117506\n",
            "Iteration 49, loss = 24512183.53093493\n",
            "Iteration 50, loss = 24461326.33970408\n",
            "Iteration 51, loss = 24267037.25915647\n",
            "Iteration 52, loss = 24166156.78894424\n",
            "Iteration 53, loss = 24108224.26830126\n",
            "Iteration 54, loss = 23990147.37403751\n",
            "Iteration 55, loss = 24187841.94976920\n",
            "Iteration 56, loss = 24091965.89147545\n",
            "Iteration 57, loss = 23757173.64624633\n",
            "Iteration 58, loss = 23560059.72159100\n",
            "Iteration 59, loss = 23773729.41885971\n",
            "Iteration 60, loss = 23405906.38402400\n",
            "Iteration 61, loss = 23383742.18275378\n",
            "Iteration 62, loss = 23338714.09908350\n",
            "Iteration 63, loss = 23449330.75490597\n",
            "Iteration 64, loss = 23335590.06559438\n",
            "Iteration 65, loss = 23362491.15457787\n",
            "Iteration 66, loss = 23141745.45588238\n",
            "Iteration 67, loss = 23139015.62543441\n",
            "Iteration 68, loss = 23160188.55009370\n",
            "Iteration 69, loss = 23073278.25123291\n",
            "Iteration 70, loss = 23081861.71954993\n",
            "Iteration 71, loss = 23039539.20560546\n",
            "Iteration 72, loss = 22929790.56578498\n",
            "Iteration 73, loss = 22871146.61797446\n",
            "Iteration 74, loss = 22927732.05121148\n",
            "Iteration 75, loss = 22952821.90719259\n",
            "Iteration 76, loss = 23182632.80004427\n",
            "Iteration 77, loss = 23545640.86188411\n",
            "Iteration 78, loss = 23720042.57326011\n",
            "Iteration 79, loss = 23763691.39913948\n",
            "Iteration 80, loss = 23736847.33032718\n",
            "Iteration 81, loss = 23951935.13895808\n",
            "Iteration 82, loss = 24436662.40878023\n",
            "Iteration 83, loss = 23840633.75581011\n",
            "Iteration 84, loss = 23637836.85679097\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538823985.01507735\n",
            "Iteration 2, loss = 1538787244.24009848\n",
            "Iteration 3, loss = 1538751300.32836032\n",
            "Iteration 4, loss = 1538713488.94940710\n",
            "Iteration 5, loss = 1538675347.47566366\n",
            "Iteration 6, loss = 1538634471.90724277\n",
            "Iteration 7, loss = 1538592713.89565349\n",
            "Iteration 8, loss = 1538549189.16739202\n",
            "Iteration 9, loss = 1538501038.27547503\n",
            "Iteration 10, loss = 1538448033.18316984\n",
            "Iteration 11, loss = 1538395616.16529369\n",
            "Iteration 12, loss = 1538338361.51492381\n",
            "Iteration 13, loss = 1538275169.90135646\n",
            "Iteration 14, loss = 1538212127.43602324\n",
            "Iteration 15, loss = 1538142749.98795581\n",
            "Iteration 16, loss = 1538070373.23958468\n",
            "Iteration 17, loss = 1537993366.14700270\n",
            "Iteration 18, loss = 1537914556.32128310\n",
            "Iteration 19, loss = 1537836161.15160656\n",
            "Iteration 20, loss = 1537749063.01353717\n",
            "Iteration 21, loss = 1537659423.18054724\n",
            "Iteration 22, loss = 1537567082.37005305\n",
            "Iteration 23, loss = 1537467520.74912906\n",
            "Iteration 24, loss = 1537366078.45510936\n",
            "Iteration 25, loss = 1537258574.72079229\n",
            "Iteration 26, loss = 1537146958.86421752\n",
            "Iteration 27, loss = 1537031261.18264103\n",
            "Iteration 28, loss = 1536910216.90410876\n",
            "Iteration 29, loss = 1536784559.46263742\n",
            "Iteration 30, loss = 1536654218.29465723\n",
            "Iteration 31, loss = 1536517598.84468722\n",
            "Iteration 32, loss = 1536375786.01934433\n",
            "Iteration 33, loss = 1536227957.27518773\n",
            "Iteration 34, loss = 1536075082.23498845\n",
            "Iteration 35, loss = 1535917810.89988327\n",
            "Iteration 36, loss = 1535755314.26932406\n",
            "Iteration 37, loss = 1535588469.60311770\n",
            "Iteration 38, loss = 1535417167.51942706\n",
            "Iteration 39, loss = 1535242701.01995254\n",
            "Iteration 40, loss = 1535064127.23453927\n",
            "Iteration 41, loss = 1534882696.67476535\n",
            "Iteration 42, loss = 1534700594.52888060\n",
            "Iteration 43, loss = 1534515087.88854098\n",
            "Iteration 44, loss = 1534327443.89953637\n",
            "Iteration 45, loss = 1534138960.85977483\n",
            "Iteration 46, loss = 1533949288.33246541\n",
            "Iteration 47, loss = 1533758708.38652897\n",
            "Iteration 48, loss = 1533568299.66219926\n",
            "Iteration 49, loss = 1533379208.36395168\n",
            "Iteration 50, loss = 1533191596.32058525\n",
            "Iteration 51, loss = 1533006717.47951674\n",
            "Iteration 52, loss = 1532821095.24696541\n",
            "Iteration 53, loss = 1532637466.96048379\n",
            "Iteration 54, loss = 1532454240.85102224\n",
            "Iteration 55, loss = 1532272974.69687200\n",
            "Iteration 56, loss = 1532093523.20417738\n",
            "Iteration 57, loss = 1531914739.55015540\n",
            "Iteration 58, loss = 1531738009.38683915\n",
            "Iteration 59, loss = 1531562949.57382178\n",
            "Iteration 60, loss = 1531388955.60407043\n",
            "Iteration 61, loss = 1531216403.50081468\n",
            "Iteration 62, loss = 1531045573.10394931\n",
            "Iteration 63, loss = 1530875976.41812944\n",
            "Iteration 64, loss = 1530706774.01363969\n",
            "Iteration 65, loss = 1530539908.22052598\n",
            "Iteration 66, loss = 1530374355.10411572\n",
            "Iteration 67, loss = 1530208706.86307192\n",
            "Iteration 68, loss = 1530045728.44507575\n",
            "Iteration 69, loss = 1529882804.35598040\n",
            "Iteration 70, loss = 1529721486.08636594\n",
            "Iteration 71, loss = 1529560953.47615886\n",
            "Iteration 72, loss = 1529401092.17715406\n",
            "Iteration 73, loss = 1529242794.99956274\n",
            "Iteration 74, loss = 1529084345.92957425\n",
            "Iteration 75, loss = 1528927240.70390224\n",
            "Iteration 76, loss = 1528771519.50679636\n",
            "Iteration 77, loss = 1528615611.20275044\n",
            "Iteration 78, loss = 1528461718.79804897\n",
            "Iteration 79, loss = 1528307616.69663095\n",
            "Iteration 80, loss = 1528153697.99644136\n",
            "Iteration 81, loss = 1528002313.24396825\n",
            "Iteration 82, loss = 1527849867.38781643\n",
            "Iteration 83, loss = 1527699134.03564930\n",
            "Iteration 84, loss = 1527548620.80435395\n",
            "Iteration 85, loss = 1527399218.33869314\n",
            "Iteration 86, loss = 1527249366.56211519\n",
            "Iteration 87, loss = 1527101644.56567955\n",
            "Iteration 88, loss = 1526953194.02305770\n",
            "Iteration 89, loss = 1526806552.49469256\n",
            "Iteration 90, loss = 1526659392.25758600\n",
            "Iteration 91, loss = 1526514161.59548187\n",
            "Iteration 92, loss = 1526368414.10599518\n",
            "Iteration 93, loss = 1526223578.11275053\n",
            "Iteration 94, loss = 1526079594.07328582\n",
            "Iteration 95, loss = 1525936072.66672993\n",
            "Iteration 96, loss = 1525793057.04706883\n",
            "Iteration 97, loss = 1525650588.54331064\n",
            "Iteration 98, loss = 1525509254.95165372\n",
            "Iteration 99, loss = 1525368333.60384989\n",
            "Iteration 100, loss = 1525227138.74541140\n",
            "Iteration 101, loss = 1525087480.60727763\n",
            "Iteration 102, loss = 1524948504.58256698\n",
            "Iteration 103, loss = 1524809931.31247759\n",
            "Iteration 104, loss = 1524670662.14328170\n",
            "Iteration 105, loss = 1524533149.96598649\n",
            "Iteration 106, loss = 1524395791.14524817\n",
            "Iteration 107, loss = 1524257836.91260433\n",
            "Iteration 108, loss = 1524121636.66393757\n",
            "Iteration 109, loss = 1523984994.82023811\n",
            "Iteration 110, loss = 1523848960.97138596\n",
            "Iteration 111, loss = 1523713108.33606553\n",
            "Iteration 112, loss = 1523578520.48880649\n",
            "Iteration 113, loss = 1523443713.12615156\n",
            "Iteration 114, loss = 1523308972.54589796\n",
            "Iteration 115, loss = 1523174868.30021191\n",
            "Iteration 116, loss = 1523041439.52568293\n",
            "Iteration 117, loss = 1522907257.98737669\n",
            "Iteration 118, loss = 1522774390.33929324\n",
            "Iteration 119, loss = 1522640736.85061216\n",
            "Iteration 120, loss = 1522508417.58666897\n",
            "Iteration 121, loss = 1522375633.21588206\n",
            "Iteration 122, loss = 1522243161.04665804\n",
            "Iteration 123, loss = 1522110498.08091760\n",
            "Iteration 124, loss = 1521978918.21998549\n",
            "Iteration 125, loss = 1521846766.12678790\n",
            "Iteration 126, loss = 1521714853.31099677\n",
            "Iteration 127, loss = 1521583375.86085558\n",
            "Iteration 128, loss = 1521452481.82921100\n",
            "Iteration 129, loss = 1521321076.71151161\n",
            "Iteration 130, loss = 1521190317.79814816\n",
            "Iteration 131, loss = 1521059540.12204099\n",
            "Iteration 132, loss = 1520929536.53651977\n",
            "Iteration 133, loss = 1520799400.26278782\n",
            "Iteration 134, loss = 1520670222.85906124\n",
            "Iteration 135, loss = 1520539789.33661103\n",
            "Iteration 136, loss = 1520410288.34597087\n",
            "Iteration 137, loss = 1520282130.97011542\n",
            "Iteration 138, loss = 1520152945.45994353\n",
            "Iteration 139, loss = 1520023758.08715272\n",
            "Iteration 140, loss = 1519895701.99881673\n",
            "Iteration 141, loss = 1519766887.74372768\n",
            "Iteration 142, loss = 1519639432.68324161\n",
            "Iteration 143, loss = 1519511231.08572936\n",
            "Iteration 144, loss = 1519383866.12367868\n",
            "Iteration 145, loss = 1519257324.09887981\n",
            "Iteration 146, loss = 1519129700.11621833\n",
            "Iteration 147, loss = 1519004082.00331402\n",
            "Iteration 148, loss = 1518877376.82265139\n",
            "Iteration 149, loss = 1518751776.66531682\n",
            "Iteration 150, loss = 1518626101.86616755\n",
            "Iteration 151, loss = 1518499830.63232684\n",
            "Iteration 152, loss = 1518374733.63875675\n",
            "Iteration 153, loss = 1518248750.60763025\n",
            "Iteration 154, loss = 1518123037.26658058\n",
            "Iteration 155, loss = 1517998316.82710767\n",
            "Iteration 156, loss = 1517872315.62213874\n",
            "Iteration 157, loss = 1517746957.60411811\n",
            "Iteration 158, loss = 1517622600.46481037\n",
            "Iteration 159, loss = 1517497705.26130199\n",
            "Iteration 160, loss = 1517373070.33523583\n",
            "Iteration 161, loss = 1517248594.51315236\n",
            "Iteration 162, loss = 1517124449.55113053\n",
            "Iteration 163, loss = 1517000814.48055148\n",
            "Iteration 164, loss = 1516876580.43407845\n",
            "Iteration 165, loss = 1516752933.26802254\n",
            "Iteration 166, loss = 1516628711.48712730\n",
            "Iteration 167, loss = 1516506139.93355131\n",
            "Iteration 168, loss = 1516381471.28998160\n",
            "Iteration 169, loss = 1516258677.12321901\n",
            "Iteration 170, loss = 1516134709.77407765\n",
            "Iteration 171, loss = 1516012510.47963572\n",
            "Iteration 172, loss = 1515888696.42326546\n",
            "Iteration 173, loss = 1515766127.70484209\n",
            "Iteration 174, loss = 1515643190.42193389\n",
            "Iteration 175, loss = 1515520146.16451478\n",
            "Iteration 176, loss = 1515398005.93800545\n",
            "Iteration 177, loss = 1515275696.33355260\n",
            "Iteration 178, loss = 1515152983.83228016\n",
            "Iteration 179, loss = 1515031409.09016037\n",
            "Iteration 180, loss = 1514909489.77700901\n",
            "Iteration 181, loss = 1514787586.07356191\n",
            "Iteration 182, loss = 1514666189.26639295\n",
            "Iteration 183, loss = 1514544773.51898026\n",
            "Iteration 184, loss = 1514422862.54908919\n",
            "Iteration 185, loss = 1514302202.86123133\n",
            "Iteration 186, loss = 1514181594.65686774\n",
            "Iteration 187, loss = 1514059918.39147162\n",
            "Iteration 188, loss = 1513939433.90483093\n",
            "Iteration 189, loss = 1513819094.45057559\n",
            "Iteration 190, loss = 1513698833.61460710\n",
            "Iteration 191, loss = 1513578051.03624034\n",
            "Iteration 192, loss = 1513457553.90310431\n",
            "Iteration 193, loss = 1513337261.02136636\n",
            "Iteration 194, loss = 1513217693.79552317\n",
            "Iteration 195, loss = 1513096574.05205441\n",
            "Iteration 196, loss = 1512976615.66459990\n",
            "Iteration 197, loss = 1512857381.61614466\n",
            "Iteration 198, loss = 1512737074.06928301\n",
            "Iteration 199, loss = 1512617057.34493899\n",
            "Iteration 200, loss = 1512497616.56653237\n",
            "Iteration 201, loss = 1512378172.06488895\n",
            "Iteration 202, loss = 1512258186.49352241\n",
            "Iteration 203, loss = 1512139072.95920944\n",
            "Iteration 204, loss = 1512020310.73608351\n",
            "Iteration 205, loss = 1511900579.10491180\n",
            "Iteration 206, loss = 1511781746.43405437\n",
            "Iteration 207, loss = 1511663095.44169259\n",
            "Iteration 208, loss = 1511544914.77633905\n",
            "Iteration 209, loss = 1511426439.34355450\n",
            "Iteration 210, loss = 1511307714.76923704\n",
            "Iteration 211, loss = 1511190066.64708328\n",
            "Iteration 212, loss = 1511071415.86842227\n",
            "Iteration 213, loss = 1510953098.42144322\n",
            "Iteration 214, loss = 1510834886.13828897\n",
            "Iteration 215, loss = 1510716036.50062060\n",
            "Iteration 216, loss = 1510597788.15558052\n",
            "Iteration 217, loss = 1510479994.74167109\n",
            "Iteration 218, loss = 1510361207.41552925\n",
            "Iteration 219, loss = 1510242718.36448789\n",
            "Iteration 220, loss = 1510124057.08354568\n",
            "Iteration 221, loss = 1510006914.45688820\n",
            "Iteration 222, loss = 1509888485.35352993\n",
            "Iteration 223, loss = 1509770493.92354417\n",
            "Iteration 224, loss = 1509651956.78882766\n",
            "Iteration 225, loss = 1509534218.06346154\n",
            "Iteration 226, loss = 1509417289.60543609\n",
            "Iteration 227, loss = 1509298929.88544655\n",
            "Iteration 228, loss = 1509182090.57577491\n",
            "Iteration 229, loss = 1509064070.94458461\n",
            "Iteration 230, loss = 1508947589.03769588\n",
            "Iteration 231, loss = 1508829895.04767513\n",
            "Iteration 232, loss = 1508713981.00882030\n",
            "Iteration 233, loss = 1508596792.42395568\n",
            "Iteration 234, loss = 1508480203.84118891\n",
            "Iteration 235, loss = 1508364086.03304052\n",
            "Iteration 236, loss = 1508246932.02621365\n",
            "Iteration 237, loss = 1508131446.44326687\n",
            "Iteration 238, loss = 1508015221.75906181\n",
            "Iteration 239, loss = 1507898835.11402869\n",
            "Iteration 240, loss = 1507782605.15304923\n",
            "Iteration 241, loss = 1507667514.29713154\n",
            "Iteration 242, loss = 1507550509.26000690\n",
            "Iteration 243, loss = 1507434811.91182446\n",
            "Iteration 244, loss = 1507318140.59400320\n",
            "Iteration 245, loss = 1507202141.51980209\n",
            "Iteration 246, loss = 1507085495.93517089\n",
            "Iteration 247, loss = 1506969318.92813492\n",
            "Iteration 248, loss = 1506852031.50909734\n",
            "Iteration 249, loss = 1506736437.43436289\n",
            "Iteration 250, loss = 1506620127.32612181\n",
            "Iteration 251, loss = 1506503108.97739911\n",
            "Iteration 252, loss = 1506387196.78356600\n",
            "Iteration 253, loss = 1506272185.03115058\n",
            "Iteration 254, loss = 1506155874.17239332\n",
            "Iteration 255, loss = 1506039914.22155094\n",
            "Iteration 256, loss = 1505924177.60399318\n",
            "Iteration 257, loss = 1505808472.41402793\n",
            "Iteration 258, loss = 1505693089.10991383\n",
            "Iteration 259, loss = 1505578570.11901212\n",
            "Iteration 260, loss = 1505462280.24566460\n",
            "Iteration 261, loss = 1505346840.77247548\n",
            "Iteration 262, loss = 1505232615.37929130\n",
            "Iteration 263, loss = 1505117127.52529097\n",
            "Iteration 264, loss = 1505003030.50704837\n",
            "Iteration 265, loss = 1504887835.21014643\n",
            "Iteration 266, loss = 1504773186.86527681\n",
            "Iteration 267, loss = 1504658099.54512572\n",
            "Iteration 268, loss = 1504543584.90232730\n",
            "Iteration 269, loss = 1504428569.23009562\n",
            "Iteration 270, loss = 1504313452.45147276\n",
            "Iteration 271, loss = 1504199295.99611235\n",
            "Iteration 272, loss = 1504084513.61332107\n",
            "Iteration 273, loss = 1503969518.22020531\n",
            "Iteration 274, loss = 1503855274.20932174\n",
            "Iteration 275, loss = 1503740982.64875603\n",
            "Iteration 276, loss = 1503626645.42443609\n",
            "Iteration 277, loss = 1503511668.74038124\n",
            "Iteration 278, loss = 1503397738.02538037\n",
            "Iteration 279, loss = 1503283272.08889222\n",
            "Iteration 280, loss = 1503169225.67746735\n",
            "Iteration 281, loss = 1503054682.60775852\n",
            "Iteration 282, loss = 1502940860.37435889\n",
            "Iteration 283, loss = 1502827404.53726649\n",
            "Iteration 284, loss = 1502713422.40395355\n",
            "Iteration 285, loss = 1502599579.66353106\n",
            "Iteration 286, loss = 1502485357.13002872\n",
            "Iteration 287, loss = 1502371957.11240554\n",
            "Iteration 288, loss = 1502258013.25582051\n",
            "Iteration 289, loss = 1502144175.29469514\n",
            "Iteration 290, loss = 1502029703.76378202\n",
            "Iteration 291, loss = 1501915326.74304128\n",
            "Iteration 292, loss = 1501801561.27070045\n",
            "Iteration 293, loss = 1501687501.52429843\n",
            "Iteration 294, loss = 1501574222.80516195\n",
            "Iteration 295, loss = 1501458948.57610202\n",
            "Iteration 296, loss = 1501345302.10022187\n",
            "Iteration 297, loss = 1501231722.74250984\n",
            "Iteration 298, loss = 1501117503.13309765\n",
            "Iteration 299, loss = 1501003733.47846484\n",
            "Iteration 300, loss = 1500890229.98417950\n",
            "Iteration 301, loss = 1500776135.77744532\n",
            "Iteration 302, loss = 1500662120.70360851\n",
            "Iteration 303, loss = 1500549091.42105603\n",
            "Iteration 304, loss = 1500435023.36729932\n",
            "Iteration 305, loss = 1500321015.76982927\n",
            "Iteration 306, loss = 1500208189.48335314\n",
            "Iteration 307, loss = 1500094139.12904143\n",
            "Iteration 308, loss = 1499980958.39246798\n",
            "Iteration 309, loss = 1499866966.97738600\n",
            "Iteration 310, loss = 1499754044.69575572\n",
            "Iteration 311, loss = 1499640203.75637579\n",
            "Iteration 312, loss = 1499527016.44503355\n",
            "Iteration 313, loss = 1499413819.44104052\n",
            "Iteration 314, loss = 1499300370.02924371\n",
            "Iteration 315, loss = 1499187631.07429504\n",
            "Iteration 316, loss = 1499073908.14031124\n",
            "Iteration 317, loss = 1498961140.51894116\n",
            "Iteration 318, loss = 1498848525.28411889\n",
            "Iteration 319, loss = 1498735625.44969606\n",
            "Iteration 320, loss = 1498622980.79379678\n",
            "Iteration 321, loss = 1498509984.42473793\n",
            "Iteration 322, loss = 1498397530.71372032\n",
            "Iteration 323, loss = 1498285169.77873373\n",
            "Iteration 324, loss = 1498172417.01589131\n",
            "Iteration 325, loss = 1498060705.39685488\n",
            "Iteration 326, loss = 1497947368.36595654\n",
            "Iteration 327, loss = 1497835528.25294733\n",
            "Iteration 328, loss = 1497722228.20479417\n",
            "Iteration 329, loss = 1497610003.26049781\n",
            "Iteration 330, loss = 1497496348.15339947\n",
            "Iteration 331, loss = 1497383276.23459935\n",
            "Iteration 332, loss = 1497270434.66198993\n",
            "Iteration 333, loss = 1497158040.96705222\n",
            "Iteration 334, loss = 1497044280.24361396\n",
            "Iteration 335, loss = 1496931528.82216311\n",
            "Iteration 336, loss = 1496818796.32156324\n",
            "Iteration 337, loss = 1496706118.50901341\n",
            "Iteration 338, loss = 1496593053.60724044\n",
            "Iteration 339, loss = 1496480582.29768729\n",
            "Iteration 340, loss = 1496367959.65554833\n",
            "Iteration 341, loss = 1496255618.31999922\n",
            "Iteration 342, loss = 1496143026.15810966\n",
            "Iteration 343, loss = 1496030618.83743477\n",
            "Iteration 344, loss = 1495918515.47751212\n",
            "Iteration 345, loss = 1495806023.19908023\n",
            "Iteration 346, loss = 1495694392.41922951\n",
            "Iteration 347, loss = 1495581821.06550455\n",
            "Iteration 348, loss = 1495469306.05074143\n",
            "Iteration 349, loss = 1495357342.84257865\n",
            "Iteration 350, loss = 1495245742.53549004\n",
            "Iteration 351, loss = 1495133608.20924258\n",
            "Iteration 352, loss = 1495021894.39560437\n",
            "Iteration 353, loss = 1494909686.54297304\n",
            "Iteration 354, loss = 1494798199.42734218\n",
            "Iteration 355, loss = 1494686339.16664314\n",
            "Iteration 356, loss = 1494575259.45612168\n",
            "Iteration 357, loss = 1494463943.93779922\n",
            "Iteration 358, loss = 1494352373.01369619\n",
            "Iteration 359, loss = 1494241671.46022129\n",
            "Iteration 360, loss = 1494130193.11176324\n",
            "Iteration 361, loss = 1494019344.78505015\n",
            "Iteration 362, loss = 1493908381.63517785\n",
            "Iteration 363, loss = 1493797942.92605352\n",
            "Iteration 364, loss = 1493686771.68536830\n",
            "Iteration 365, loss = 1493575781.41589999\n",
            "Iteration 366, loss = 1493465198.89807463\n",
            "Iteration 367, loss = 1493353770.08678412\n",
            "Iteration 368, loss = 1493243408.72517896\n",
            "Iteration 369, loss = 1493131769.05126977\n",
            "Iteration 370, loss = 1493022089.67025495\n",
            "Iteration 371, loss = 1492909493.95670152\n",
            "Iteration 372, loss = 1492798084.59700775\n",
            "Iteration 373, loss = 1492686877.73222399\n",
            "Iteration 374, loss = 1492574435.14948726\n",
            "Iteration 375, loss = 1492463479.64317536\n",
            "Iteration 376, loss = 1492351001.10363579\n",
            "Iteration 377, loss = 1492239650.47826719\n",
            "Iteration 378, loss = 1492127698.84326911\n",
            "Iteration 379, loss = 1492016573.51874924\n",
            "Iteration 380, loss = 1491905096.53115439\n",
            "Iteration 381, loss = 1491793455.26569366\n",
            "Iteration 382, loss = 1491682188.72300506\n",
            "Iteration 383, loss = 1491570968.60579896\n",
            "Iteration 384, loss = 1491460455.79921174\n",
            "Iteration 385, loss = 1491348838.84538174\n",
            "Iteration 386, loss = 1491238129.46436238\n",
            "Iteration 387, loss = 1491127790.17695951\n",
            "Iteration 388, loss = 1491017079.17595196\n",
            "Iteration 389, loss = 1490906722.06770968\n",
            "Iteration 390, loss = 1490795920.26154160\n",
            "Iteration 391, loss = 1490686234.80737710\n",
            "Iteration 392, loss = 1490574851.79801846\n",
            "Iteration 393, loss = 1490464116.28485775\n",
            "Iteration 394, loss = 1490354495.57383180\n",
            "Iteration 395, loss = 1490242999.13242412\n",
            "Iteration 396, loss = 1490133009.50111461\n",
            "Iteration 397, loss = 1490023015.08328009\n",
            "Iteration 398, loss = 1489912800.01894379\n",
            "Iteration 399, loss = 1489802405.58159471\n",
            "Iteration 400, loss = 1489692472.23940229\n",
            "Iteration 401, loss = 1489582459.73113227\n",
            "Iteration 402, loss = 1489471293.34975743\n",
            "Iteration 403, loss = 1489361635.73693848\n",
            "Iteration 404, loss = 1489250858.95303488\n",
            "Iteration 405, loss = 1489140348.74102378\n",
            "Iteration 406, loss = 1489029759.99833345\n",
            "Iteration 407, loss = 1488919172.84504032\n",
            "Iteration 408, loss = 1488808761.02013659\n",
            "Iteration 409, loss = 1488698558.21681094\n",
            "Iteration 410, loss = 1488587888.85588717\n",
            "Iteration 411, loss = 1488477256.30077600\n",
            "Iteration 412, loss = 1488366746.23389339\n",
            "Iteration 413, loss = 1488256828.35422277\n",
            "Iteration 414, loss = 1488146120.32391596\n",
            "Iteration 415, loss = 1488035153.37606668\n",
            "Iteration 416, loss = 1487925641.61950469\n",
            "Iteration 417, loss = 1487814802.25039554\n",
            "Iteration 418, loss = 1487704247.85969353\n",
            "Iteration 419, loss = 1487593752.37845564\n",
            "Iteration 420, loss = 1487483255.32616782\n",
            "Iteration 421, loss = 1487372328.48563385\n",
            "Iteration 422, loss = 1487262064.75216365\n",
            "Iteration 423, loss = 1487151999.91078806\n",
            "Iteration 424, loss = 1487041246.91310596\n",
            "Iteration 425, loss = 1486931346.46780753\n",
            "Iteration 426, loss = 1486820960.68451118\n",
            "Iteration 427, loss = 1486710445.02269411\n",
            "Iteration 428, loss = 1486600445.20265412\n",
            "Iteration 429, loss = 1486490140.79705143\n",
            "Iteration 430, loss = 1486379882.53994179\n",
            "Iteration 431, loss = 1486269965.31694770\n",
            "Iteration 432, loss = 1486159800.82615995\n",
            "Iteration 433, loss = 1486049934.72288156\n",
            "Iteration 434, loss = 1485940087.91921568\n",
            "Iteration 435, loss = 1485830538.81219649\n",
            "Iteration 436, loss = 1485720955.92078376\n",
            "Iteration 437, loss = 1485611436.35638976\n",
            "Iteration 438, loss = 1485501719.16477537\n",
            "Iteration 439, loss = 1485391918.85422301\n",
            "Iteration 440, loss = 1485282732.05393314\n",
            "Iteration 441, loss = 1485172834.93059206\n",
            "Iteration 442, loss = 1485062919.73277354\n",
            "Iteration 443, loss = 1484953022.09034634\n",
            "Iteration 444, loss = 1484844280.87768817\n",
            "Iteration 445, loss = 1484734411.81263447\n",
            "Iteration 446, loss = 1484624466.84420538\n",
            "Iteration 447, loss = 1484515640.04216242\n",
            "Iteration 448, loss = 1484406838.07547045\n",
            "Iteration 449, loss = 1484297590.17092872\n",
            "Iteration 450, loss = 1484188833.60210204\n",
            "Iteration 451, loss = 1484080179.69636011\n",
            "Iteration 452, loss = 1483971231.55582285\n",
            "Iteration 453, loss = 1483862903.14033771\n",
            "Iteration 454, loss = 1483753382.83597589\n",
            "Iteration 455, loss = 1483644349.12599397\n",
            "Iteration 456, loss = 1483535788.48771477\n",
            "Iteration 457, loss = 1483426240.09295940\n",
            "Iteration 458, loss = 1483317138.58992505\n",
            "Iteration 459, loss = 1483208085.73819637\n",
            "Iteration 460, loss = 1483098241.81636119\n",
            "Iteration 461, loss = 1482989402.29638505\n",
            "Iteration 462, loss = 1482879965.73138261\n",
            "Iteration 463, loss = 1482770527.67379808\n",
            "Iteration 464, loss = 1482660698.57513809\n",
            "Iteration 465, loss = 1482551274.89219117\n",
            "Iteration 466, loss = 1482441931.85299921\n",
            "Iteration 467, loss = 1482332662.64091849\n",
            "Iteration 468, loss = 1482223089.35428119\n",
            "Iteration 469, loss = 1482113634.39476705\n",
            "Iteration 470, loss = 1482004237.58333921\n",
            "Iteration 471, loss = 1481895323.26310825\n",
            "Iteration 472, loss = 1481785272.92104769\n",
            "Iteration 473, loss = 1481675976.15516067\n",
            "Iteration 474, loss = 1481566891.06279349\n",
            "Iteration 475, loss = 1481457428.70457101\n",
            "Iteration 476, loss = 1481348405.01094627\n",
            "Iteration 477, loss = 1481239545.60753703\n",
            "Iteration 478, loss = 1481130287.67465544\n",
            "Iteration 479, loss = 1481021891.84753847\n",
            "Iteration 480, loss = 1480912883.92428637\n",
            "Iteration 481, loss = 1480803821.87082982\n",
            "Iteration 482, loss = 1480695310.06640553\n",
            "Iteration 483, loss = 1480586722.96045589\n",
            "Iteration 484, loss = 1480477141.77540588\n",
            "Iteration 485, loss = 1480368956.80117559\n",
            "Iteration 486, loss = 1480260253.73147488\n",
            "Iteration 487, loss = 1480151003.84068465\n",
            "Iteration 488, loss = 1480042721.63592339\n",
            "Iteration 489, loss = 1479933985.31599879\n",
            "Iteration 490, loss = 1479825152.09600067\n",
            "Iteration 491, loss = 1479716550.93944716\n",
            "Iteration 492, loss = 1479607803.15112543\n",
            "Iteration 493, loss = 1479498738.47404957\n",
            "Iteration 494, loss = 1479389620.98804069\n",
            "Iteration 495, loss = 1479281214.13240409\n",
            "Iteration 496, loss = 1479172466.00659871\n",
            "Iteration 497, loss = 1479063995.88930607\n",
            "Iteration 498, loss = 1478954676.01262617\n",
            "Iteration 499, loss = 1478847134.51422310\n",
            "Iteration 500, loss = 1478738382.14381671\n",
            "Iteration 501, loss = 1478630911.00807548\n",
            "Iteration 502, loss = 1478521597.87038541\n",
            "Iteration 503, loss = 1478413484.11611438\n",
            "Iteration 504, loss = 1478305539.91583085\n",
            "Iteration 505, loss = 1478197060.57961893\n",
            "Iteration 506, loss = 1478089176.12111354\n",
            "Iteration 507, loss = 1477980632.29966307\n",
            "Iteration 508, loss = 1477873070.52625108\n",
            "Iteration 509, loss = 1477764357.08157992\n",
            "Iteration 510, loss = 1477657080.13662314\n",
            "Iteration 511, loss = 1477548127.37962723\n",
            "Iteration 512, loss = 1477440638.22093797\n",
            "Iteration 513, loss = 1477333087.68274283\n",
            "Iteration 514, loss = 1477224926.64199758\n",
            "Iteration 515, loss = 1477117228.08743978\n",
            "Iteration 516, loss = 1477009894.18110943\n",
            "Iteration 517, loss = 1476902531.32927203\n",
            "Iteration 518, loss = 1476794794.92843223\n",
            "Iteration 519, loss = 1476687319.87788892\n",
            "Iteration 520, loss = 1476579853.19419765\n",
            "Iteration 521, loss = 1476472355.80432153\n",
            "Iteration 522, loss = 1476363931.62658119\n",
            "Iteration 523, loss = 1476256004.29040980\n",
            "Iteration 524, loss = 1476147846.63666081\n",
            "Iteration 525, loss = 1476039487.20087934\n",
            "Iteration 526, loss = 1475930845.32556677\n",
            "Iteration 527, loss = 1475822575.63858771\n",
            "Iteration 528, loss = 1475713324.85224438\n",
            "Iteration 529, loss = 1475604038.65375185\n",
            "Iteration 530, loss = 1475495745.96292520\n",
            "Iteration 531, loss = 1475386222.78509927\n",
            "Iteration 532, loss = 1475277367.49064398\n",
            "Iteration 533, loss = 1475167514.81799603\n",
            "Iteration 534, loss = 1475058722.65541458\n",
            "Iteration 535, loss = 1474950055.46942115\n",
            "Iteration 536, loss = 1474841170.66481185\n",
            "Iteration 537, loss = 1474733239.13778877\n",
            "Iteration 538, loss = 1474624173.62759995\n",
            "Iteration 539, loss = 1474515927.60221124\n",
            "Iteration 540, loss = 1474407447.84217572\n",
            "Iteration 541, loss = 1474300072.98727751\n",
            "Iteration 542, loss = 1474191766.19267273\n",
            "Iteration 543, loss = 1474082884.93569040\n",
            "Iteration 544, loss = 1473975471.05122328\n",
            "Iteration 545, loss = 1473867420.94155550\n",
            "Iteration 546, loss = 1473758919.23829603\n",
            "Iteration 547, loss = 1473650566.71608901\n",
            "Iteration 548, loss = 1473542600.20709562\n",
            "Iteration 549, loss = 1473433933.32782340\n",
            "Iteration 550, loss = 1473325534.21211481\n",
            "Iteration 551, loss = 1473217893.30775666\n",
            "Iteration 552, loss = 1473108776.50020051\n",
            "Iteration 553, loss = 1473001264.09988689\n",
            "Iteration 554, loss = 1472892434.30316710\n",
            "Iteration 555, loss = 1472784895.41879892\n",
            "Iteration 556, loss = 1472677402.74675274\n",
            "Iteration 557, loss = 1472569344.52426863\n",
            "Iteration 558, loss = 1472461857.32408643\n",
            "Iteration 559, loss = 1472354535.82785225\n",
            "Iteration 560, loss = 1472246023.99625421\n",
            "Iteration 561, loss = 1472138915.96338582\n",
            "Iteration 562, loss = 1472030948.43515325\n",
            "Iteration 563, loss = 1471923322.88226056\n",
            "Iteration 564, loss = 1471816766.63869429\n",
            "Iteration 565, loss = 1471708971.20623398\n",
            "Iteration 566, loss = 1471601714.51261830\n",
            "Iteration 567, loss = 1471494515.70188832\n",
            "Iteration 568, loss = 1471387888.98493624\n",
            "Iteration 569, loss = 1471281276.17800140\n",
            "Iteration 570, loss = 1471173814.70362926\n",
            "Iteration 571, loss = 1471066439.20154381\n",
            "Iteration 572, loss = 1470959702.02807021\n",
            "Iteration 573, loss = 1470852233.31627154\n",
            "Iteration 574, loss = 1470744630.68215466\n",
            "Iteration 575, loss = 1470637089.68843699\n",
            "Iteration 576, loss = 1470529989.93962622\n",
            "Iteration 577, loss = 1470422359.71414733\n",
            "Iteration 578, loss = 1470314665.28459978\n",
            "Iteration 579, loss = 1470207928.20225477\n",
            "Iteration 580, loss = 1470100870.88679743\n",
            "Iteration 581, loss = 1469993044.10782027\n",
            "Iteration 582, loss = 1469886066.77626657\n",
            "Iteration 583, loss = 1469778860.02205539\n",
            "Iteration 584, loss = 1469670986.87988186\n",
            "Iteration 585, loss = 1469563895.04429388\n",
            "Iteration 586, loss = 1469456290.56221008\n",
            "Iteration 587, loss = 1469348576.78338194\n",
            "Iteration 588, loss = 1469240420.77108288\n",
            "Iteration 589, loss = 1469132732.79436660\n",
            "Iteration 590, loss = 1469024868.34372044\n",
            "Iteration 591, loss = 1468916805.45777512\n",
            "Iteration 592, loss = 1468809394.98990369\n",
            "Iteration 593, loss = 1468701440.75771904\n",
            "Iteration 594, loss = 1468593746.33266234\n",
            "Iteration 595, loss = 1468486080.83731437\n",
            "Iteration 596, loss = 1468378421.62521839\n",
            "Iteration 597, loss = 1468271273.11301351\n",
            "Iteration 598, loss = 1468162947.63588738\n",
            "Iteration 599, loss = 1468055902.30694366\n",
            "Iteration 600, loss = 1467948298.20471168\n",
            "Iteration 601, loss = 1467841107.87891364\n",
            "Iteration 602, loss = 1467733561.17626810\n",
            "Iteration 603, loss = 1467626118.19374871\n",
            "Iteration 604, loss = 1467518809.08128738\n",
            "Iteration 605, loss = 1467410920.98521662\n",
            "Iteration 606, loss = 1467303606.88608909\n",
            "Iteration 607, loss = 1467196587.78683925\n",
            "Iteration 608, loss = 1467089290.94510865\n",
            "Iteration 609, loss = 1466981758.95834732\n",
            "Iteration 610, loss = 1466875093.06487131\n",
            "Iteration 611, loss = 1466768541.19428468\n",
            "Iteration 612, loss = 1466661605.62550712\n",
            "Iteration 613, loss = 1466554565.44147849\n",
            "Iteration 614, loss = 1466448294.58280849\n",
            "Iteration 615, loss = 1466341384.75989985\n",
            "Iteration 616, loss = 1466234553.99609399\n",
            "Iteration 617, loss = 1466127553.95088911\n",
            "Iteration 618, loss = 1466020134.98962355\n",
            "Iteration 619, loss = 1465914530.92848206\n",
            "Iteration 620, loss = 1465806369.09560752\n",
            "Iteration 621, loss = 1465699953.25653839\n",
            "Iteration 622, loss = 1465592718.87737203\n",
            "Iteration 623, loss = 1465486563.12356949\n",
            "Iteration 624, loss = 1465379777.15091753\n",
            "Iteration 625, loss = 1465272830.05665660\n",
            "Iteration 626, loss = 1465166544.18840384\n",
            "Iteration 627, loss = 1465060268.29210019\n",
            "Iteration 628, loss = 1464952988.94838595\n",
            "Iteration 629, loss = 1464846617.76914620\n",
            "Iteration 630, loss = 1464739930.68638086\n",
            "Iteration 631, loss = 1464632857.74524999\n",
            "Iteration 632, loss = 1464525526.08240032\n",
            "Iteration 633, loss = 1464419123.31537247\n",
            "Iteration 634, loss = 1464311645.58972645\n",
            "Iteration 635, loss = 1464205395.96631551\n",
            "Iteration 636, loss = 1464098790.15088773\n",
            "Iteration 637, loss = 1463992001.62625957\n",
            "Iteration 638, loss = 1463885497.38448739\n",
            "Iteration 639, loss = 1463779768.96128631\n",
            "Iteration 640, loss = 1463672101.54922438\n",
            "Iteration 641, loss = 1463565936.37261701\n",
            "Iteration 642, loss = 1463459469.64470696\n",
            "Iteration 643, loss = 1463352203.99294186\n",
            "Iteration 644, loss = 1463245568.34513307\n",
            "Iteration 645, loss = 1463138367.54011273\n",
            "Iteration 646, loss = 1463032289.17794490\n",
            "Iteration 647, loss = 1462925004.63042545\n",
            "Iteration 648, loss = 1462818546.41001940\n",
            "Iteration 649, loss = 1462712219.14724302\n",
            "Iteration 650, loss = 1462605808.88470984\n",
            "Iteration 651, loss = 1462499480.71614146\n",
            "Iteration 652, loss = 1462393855.08713913\n",
            "Iteration 653, loss = 1462287203.30477500\n",
            "Iteration 654, loss = 1462181353.08847189\n",
            "Iteration 655, loss = 1462075713.91943359\n",
            "Iteration 656, loss = 1461969812.01179600\n",
            "Iteration 657, loss = 1461864200.29295444\n",
            "Iteration 658, loss = 1461758449.83589816\n",
            "Iteration 659, loss = 1461652149.59612012\n",
            "Iteration 660, loss = 1461546903.17579746\n",
            "Iteration 661, loss = 1461440661.20562744\n",
            "Iteration 662, loss = 1461335150.41933513\n",
            "Iteration 663, loss = 1461228642.11735702\n",
            "Iteration 664, loss = 1461122663.43666410\n",
            "Iteration 665, loss = 1461016713.17435884\n",
            "Iteration 666, loss = 1460910578.36898398\n",
            "Iteration 667, loss = 1460804320.32481360\n",
            "Iteration 668, loss = 1460698129.58602881\n",
            "Iteration 669, loss = 1460592552.23222256\n",
            "Iteration 670, loss = 1460486347.19939017\n",
            "Iteration 671, loss = 1460380792.39622307\n",
            "Iteration 672, loss = 1460274639.38158059\n",
            "Iteration 673, loss = 1460168557.55240273\n",
            "Iteration 674, loss = 1460062740.92376590\n",
            "Iteration 675, loss = 1459956559.98120499\n",
            "Iteration 676, loss = 1459850822.91978955\n",
            "Iteration 677, loss = 1459744882.04671788\n",
            "Iteration 678, loss = 1459639061.68318820\n",
            "Iteration 679, loss = 1459533043.41821837\n",
            "Iteration 680, loss = 1459426611.57311726\n",
            "Iteration 681, loss = 1459321409.14754272\n",
            "Iteration 682, loss = 1459215386.29272079\n",
            "Iteration 683, loss = 1459108922.22164559\n",
            "Iteration 684, loss = 1459003056.70968413\n",
            "Iteration 685, loss = 1458897303.48720717\n",
            "Iteration 686, loss = 1458790938.10767198\n",
            "Iteration 687, loss = 1458685095.77187848\n",
            "Iteration 688, loss = 1458578644.98572826\n",
            "Iteration 689, loss = 1458473084.16367006\n",
            "Iteration 690, loss = 1458366167.31606197\n",
            "Iteration 691, loss = 1458260088.55637074\n",
            "Iteration 692, loss = 1458153538.47366929\n",
            "Iteration 693, loss = 1458047230.54663062\n",
            "Iteration 694, loss = 1457941802.23463321\n",
            "Iteration 695, loss = 1457834649.67357373\n",
            "Iteration 696, loss = 1457728569.24690199\n",
            "Iteration 697, loss = 1457623011.19055653\n",
            "Iteration 698, loss = 1457516841.08281898\n",
            "Iteration 699, loss = 1457410483.00389552\n",
            "Iteration 700, loss = 1457304351.80176783\n",
            "Iteration 701, loss = 1457198150.45302057\n",
            "Iteration 702, loss = 1457092030.31315947\n",
            "Iteration 703, loss = 1456985798.41917682\n",
            "Iteration 704, loss = 1456879840.42177725\n",
            "Iteration 705, loss = 1456773614.04551411\n",
            "Iteration 706, loss = 1456667426.49653339\n",
            "Iteration 707, loss = 1456561386.25355506\n",
            "Iteration 708, loss = 1456455015.37860775\n",
            "Iteration 709, loss = 1456349390.83051825\n",
            "Iteration 710, loss = 1456242595.13180923\n",
            "Iteration 711, loss = 1456135947.51210618\n",
            "Iteration 712, loss = 1456030058.76093245\n",
            "Iteration 713, loss = 1455923581.11471152\n",
            "Iteration 714, loss = 1455816712.83688593\n",
            "Iteration 715, loss = 1455710546.54411721\n",
            "Iteration 716, loss = 1455604036.77056766\n",
            "Iteration 717, loss = 1455498148.00596046\n",
            "Iteration 718, loss = 1455391023.01689649\n",
            "Iteration 719, loss = 1455285438.18984890\n",
            "Iteration 720, loss = 1455179505.58722901\n",
            "Iteration 721, loss = 1455073375.04688692\n",
            "Iteration 722, loss = 1454968317.52987146\n",
            "Iteration 723, loss = 1454861649.01947331\n",
            "Iteration 724, loss = 1454756700.53678870\n",
            "Iteration 725, loss = 1454651372.94497299\n",
            "Iteration 726, loss = 1454545411.52409768\n",
            "Iteration 727, loss = 1454440241.05180740\n",
            "Iteration 728, loss = 1454334126.55519891\n",
            "Iteration 729, loss = 1454229083.19906569\n",
            "Iteration 730, loss = 1454123869.94361806\n",
            "Iteration 731, loss = 1454017507.76398873\n",
            "Iteration 732, loss = 1453911784.41823411\n",
            "Iteration 733, loss = 1453807407.60591817\n",
            "Iteration 734, loss = 1453701378.17999220\n",
            "Iteration 735, loss = 1453595819.45288038\n",
            "Iteration 736, loss = 1453490917.39620185\n",
            "Iteration 737, loss = 1453384677.09112501\n",
            "Iteration 738, loss = 1453278905.62911820\n",
            "Iteration 739, loss = 1453172930.75237632\n",
            "Iteration 740, loss = 1453067138.44208097\n",
            "Iteration 741, loss = 1452960830.41780972\n",
            "Iteration 742, loss = 1452854568.74445748\n",
            "Iteration 743, loss = 1452749047.69692826\n",
            "Iteration 744, loss = 1452642382.12325811\n",
            "Iteration 745, loss = 1452536523.25580645\n",
            "Iteration 746, loss = 1452430664.98894095\n",
            "Iteration 747, loss = 1452324708.31505775\n",
            "Iteration 748, loss = 1452219370.82464480\n",
            "Iteration 749, loss = 1452113217.48099566\n",
            "Iteration 750, loss = 1452007783.99057078\n",
            "Iteration 751, loss = 1451902123.57269788\n",
            "Iteration 752, loss = 1451796181.55766296\n",
            "Iteration 753, loss = 1451690953.13567519\n",
            "Iteration 754, loss = 1451584954.12060833\n",
            "Iteration 755, loss = 1451479497.36837149\n",
            "Iteration 756, loss = 1451373601.46740174\n",
            "Iteration 757, loss = 1451268527.58708978\n",
            "Iteration 758, loss = 1451162154.34655023\n",
            "Iteration 759, loss = 1451056980.28228998\n",
            "Iteration 760, loss = 1450951838.01855421\n",
            "Iteration 761, loss = 1450846012.89100909\n",
            "Iteration 762, loss = 1450740473.34592628\n",
            "Iteration 763, loss = 1450635728.12512898\n",
            "Iteration 764, loss = 1450530334.25260806\n",
            "Iteration 765, loss = 1450425432.90554333\n",
            "Iteration 766, loss = 1450320540.07902765\n",
            "Iteration 767, loss = 1450215928.38805795\n",
            "Iteration 768, loss = 1450110815.40662622\n",
            "Iteration 769, loss = 1450005381.50309014\n",
            "Iteration 770, loss = 1449900504.79195523\n",
            "Iteration 771, loss = 1449795140.00979590\n",
            "Iteration 772, loss = 1449689326.04823685\n",
            "Iteration 773, loss = 1449583373.30466557\n",
            "Iteration 774, loss = 1449477460.78562999\n",
            "Iteration 775, loss = 1449371149.89016652\n",
            "Iteration 776, loss = 1449265498.43439126\n",
            "Iteration 777, loss = 1449159056.76283550\n",
            "Iteration 778, loss = 1449053972.62829280\n",
            "Iteration 779, loss = 1448948276.20747232\n",
            "Iteration 780, loss = 1448842185.53347254\n",
            "Iteration 781, loss = 1448737407.96349812\n",
            "Iteration 782, loss = 1448632123.83955669\n",
            "Iteration 783, loss = 1448526534.90464687\n",
            "Iteration 784, loss = 1448421085.49380636\n",
            "Iteration 785, loss = 1448315805.51550341\n",
            "Iteration 786, loss = 1448210432.38183427\n",
            "Iteration 787, loss = 1448104316.20957303\n",
            "Iteration 788, loss = 1447999409.28362536\n",
            "Iteration 789, loss = 1447893509.86105871\n",
            "Iteration 790, loss = 1447788588.08148170\n",
            "Iteration 791, loss = 1447682746.43825388\n",
            "Iteration 792, loss = 1447578340.57139206\n",
            "Iteration 793, loss = 1447472477.30431962\n",
            "Iteration 794, loss = 1447367225.78714228\n",
            "Iteration 795, loss = 1447261921.80743122\n",
            "Iteration 796, loss = 1447156225.62549376\n",
            "Iteration 797, loss = 1447050453.36886406\n",
            "Iteration 798, loss = 1446944416.65025878\n",
            "Iteration 799, loss = 1446838754.93868470\n",
            "Iteration 800, loss = 1446733035.90063906\n",
            "Iteration 801, loss = 1446626590.82935143\n",
            "Iteration 802, loss = 1446522043.79705048\n",
            "Iteration 803, loss = 1446416122.37574649\n",
            "Iteration 804, loss = 1446310884.43558908\n",
            "Iteration 805, loss = 1446206120.88085890\n",
            "Iteration 806, loss = 1446100883.61916423\n",
            "Iteration 807, loss = 1445996072.54356289\n",
            "Iteration 808, loss = 1445890438.79614449\n",
            "Iteration 809, loss = 1445786410.19387841\n",
            "Iteration 810, loss = 1445680952.36867571\n",
            "Iteration 811, loss = 1445576087.02742529\n",
            "Iteration 812, loss = 1445471116.05373526\n",
            "Iteration 813, loss = 1445367203.94782472\n",
            "Iteration 814, loss = 1445261698.07094932\n",
            "Iteration 815, loss = 1445157136.08227134\n",
            "Iteration 816, loss = 1445052461.39140654\n",
            "Iteration 817, loss = 1444947843.20587206\n",
            "Iteration 818, loss = 1444842302.83112788\n",
            "Iteration 819, loss = 1444737491.63223743\n",
            "Iteration 820, loss = 1444632100.96674252\n",
            "Iteration 821, loss = 1444526139.63940930\n",
            "Iteration 822, loss = 1444420830.30194306\n",
            "Iteration 823, loss = 1444315830.07918763\n",
            "Iteration 824, loss = 1444209990.16371202\n",
            "Iteration 825, loss = 1444104079.29720140\n",
            "Iteration 826, loss = 1443998775.35099125\n",
            "Iteration 827, loss = 1443893733.43678617\n",
            "Iteration 828, loss = 1443788521.98966885\n",
            "Iteration 829, loss = 1443683339.22633076\n",
            "Iteration 830, loss = 1443577925.30540133\n",
            "Iteration 831, loss = 1443472760.76682973\n",
            "Iteration 832, loss = 1443367916.72911477\n",
            "Iteration 833, loss = 1443262798.57024789\n",
            "Iteration 834, loss = 1443157575.19485044\n",
            "Iteration 835, loss = 1443053224.96661878\n",
            "Iteration 836, loss = 1442948331.90903759\n",
            "Iteration 837, loss = 1442844208.76118970\n",
            "Iteration 838, loss = 1442739390.35514140\n",
            "Iteration 839, loss = 1442635087.22070169\n",
            "Iteration 840, loss = 1442531103.29493260\n",
            "Iteration 841, loss = 1442426448.96098566\n",
            "Iteration 842, loss = 1442322860.53902602\n",
            "Iteration 843, loss = 1442218107.26728129\n",
            "Iteration 844, loss = 1442114097.82674766\n",
            "Iteration 845, loss = 1442010028.85025501\n",
            "Iteration 846, loss = 1441906505.38981414\n",
            "Iteration 847, loss = 1441801547.45125747\n",
            "Iteration 848, loss = 1441697976.45821428\n",
            "Iteration 849, loss = 1441593558.24927640\n",
            "Iteration 850, loss = 1441488925.64232373\n",
            "Iteration 851, loss = 1441384090.30493402\n",
            "Iteration 852, loss = 1441278895.93773961\n",
            "Iteration 853, loss = 1441174506.81412816\n",
            "Iteration 854, loss = 1441068463.65332055\n",
            "Iteration 855, loss = 1440964141.65148616\n",
            "Iteration 856, loss = 1440859033.70969415\n",
            "Iteration 857, loss = 1440753923.44043469\n",
            "Iteration 858, loss = 1440649771.63766623\n",
            "Iteration 859, loss = 1440544522.69858503\n",
            "Iteration 860, loss = 1440440546.73164034\n",
            "Iteration 861, loss = 1440336073.35893726\n",
            "Iteration 862, loss = 1440232310.58605075\n",
            "Iteration 863, loss = 1440127893.99218035\n",
            "Iteration 864, loss = 1440023582.76473212\n",
            "Iteration 865, loss = 1439919758.96349955\n",
            "Iteration 866, loss = 1439815779.22669411\n",
            "Iteration 867, loss = 1439710939.49528217\n",
            "Iteration 868, loss = 1439607049.13607645\n",
            "Iteration 869, loss = 1439501631.39419246\n",
            "Iteration 870, loss = 1439397037.78503466\n",
            "Iteration 871, loss = 1439292092.29229927\n",
            "Iteration 872, loss = 1439186946.81465125\n",
            "Iteration 873, loss = 1439082620.87572312\n",
            "Iteration 874, loss = 1438976797.71132064\n",
            "Iteration 875, loss = 1438872322.52681398\n",
            "Iteration 876, loss = 1438767675.04745913\n",
            "Iteration 877, loss = 1438663274.27051640\n",
            "Iteration 878, loss = 1438559006.35556722\n",
            "Iteration 879, loss = 1438455049.16430950\n",
            "Iteration 880, loss = 1438351024.89258265\n",
            "Iteration 881, loss = 1438246712.24216080\n",
            "Iteration 882, loss = 1438143272.71510696\n",
            "Iteration 883, loss = 1438038736.08047438\n",
            "Iteration 884, loss = 1437935553.19437099\n",
            "Iteration 885, loss = 1437831760.36648631\n",
            "Iteration 886, loss = 1437727643.50524378\n",
            "Iteration 887, loss = 1437624192.27025580\n",
            "Iteration 888, loss = 1437519928.93227029\n",
            "Iteration 889, loss = 1437416238.14930487\n",
            "Iteration 890, loss = 1437312108.63587952\n",
            "Iteration 891, loss = 1437207057.66942024\n",
            "Iteration 892, loss = 1437103481.71807170\n",
            "Iteration 893, loss = 1436999671.68524647\n",
            "Iteration 894, loss = 1436894401.71218443\n",
            "Iteration 895, loss = 1436791300.42968035\n",
            "Iteration 896, loss = 1436686514.67821503\n",
            "Iteration 897, loss = 1436583430.18233252\n",
            "Iteration 898, loss = 1436479080.16933632\n",
            "Iteration 899, loss = 1436374341.00275993\n",
            "Iteration 900, loss = 1436270773.17936540\n",
            "Iteration 901, loss = 1436165452.44297504\n",
            "Iteration 902, loss = 1436061429.17855000\n",
            "Iteration 903, loss = 1435956380.74139714\n",
            "Iteration 904, loss = 1435852148.35234523\n",
            "Iteration 905, loss = 1435747192.20912552\n",
            "Iteration 906, loss = 1435642887.34192824\n",
            "Iteration 907, loss = 1435537871.67705035\n",
            "Iteration 908, loss = 1435433342.03501177\n",
            "Iteration 909, loss = 1435328514.50198674\n",
            "Iteration 910, loss = 1435224295.03410101\n",
            "Iteration 911, loss = 1435119772.81427693\n",
            "Iteration 912, loss = 1435014999.30524373\n",
            "Iteration 913, loss = 1434910845.71426010\n",
            "Iteration 914, loss = 1434805392.94752645\n",
            "Iteration 915, loss = 1434701490.25589013\n",
            "Iteration 916, loss = 1434597071.89165306\n",
            "Iteration 917, loss = 1434492100.60699797\n",
            "Iteration 918, loss = 1434387895.38100767\n",
            "Iteration 919, loss = 1434282885.81806755\n",
            "Iteration 920, loss = 1434178656.95721197\n",
            "Iteration 921, loss = 1434074489.20656419\n",
            "Iteration 922, loss = 1433969939.94316435\n",
            "Iteration 923, loss = 1433865752.27327561\n",
            "Iteration 924, loss = 1433761506.54424238\n",
            "Iteration 925, loss = 1433657036.64331317\n",
            "Iteration 926, loss = 1433553606.33710432\n",
            "Iteration 927, loss = 1433448769.95319462\n",
            "Iteration 928, loss = 1433344426.22180963\n",
            "Iteration 929, loss = 1433241010.88498807\n",
            "Iteration 930, loss = 1433136753.44787550\n",
            "Iteration 931, loss = 1433033070.09446549\n",
            "Iteration 932, loss = 1432928753.18942785\n",
            "Iteration 933, loss = 1432825326.83713102\n",
            "Iteration 934, loss = 1432721944.15078783\n",
            "Iteration 935, loss = 1432617307.62440276\n",
            "Iteration 936, loss = 1432513753.84165025\n",
            "Iteration 937, loss = 1432409873.81154299\n",
            "Iteration 938, loss = 1432305472.88086915\n",
            "Iteration 939, loss = 1432201654.70721865\n",
            "Iteration 940, loss = 1432096857.69888616\n",
            "Iteration 941, loss = 1431993486.89381170\n",
            "Iteration 942, loss = 1431889246.30525637\n",
            "Iteration 943, loss = 1431785125.04655457\n",
            "Iteration 944, loss = 1431681423.48762941\n",
            "Iteration 945, loss = 1431577497.99606824\n",
            "Iteration 946, loss = 1431474189.28242731\n",
            "Iteration 947, loss = 1431369661.92341089\n",
            "Iteration 948, loss = 1431266252.17321301\n",
            "Iteration 949, loss = 1431162058.30281901\n",
            "Iteration 950, loss = 1431058309.37241125\n",
            "Iteration 951, loss = 1430954216.05862594\n",
            "Iteration 952, loss = 1430850453.56218123\n",
            "Iteration 953, loss = 1430745979.65587950\n",
            "Iteration 954, loss = 1430642075.20539284\n",
            "Iteration 955, loss = 1430538463.99914503\n",
            "Iteration 956, loss = 1430433667.12463379\n",
            "Iteration 957, loss = 1430330259.61828899\n",
            "Iteration 958, loss = 1430225604.51574135\n",
            "Iteration 959, loss = 1430121995.95529032\n",
            "Iteration 960, loss = 1430017064.57309079\n",
            "Iteration 961, loss = 1429913681.16674638\n",
            "Iteration 962, loss = 1429809762.58654308\n",
            "Iteration 963, loss = 1429705208.97550297\n",
            "Iteration 964, loss = 1429601319.82718897\n",
            "Iteration 965, loss = 1429496963.62325931\n",
            "Iteration 966, loss = 1429393136.51537848\n",
            "Iteration 967, loss = 1429288894.31930137\n",
            "Iteration 968, loss = 1429185112.70768332\n",
            "Iteration 969, loss = 1429080271.24776340\n",
            "Iteration 970, loss = 1428976424.17053938\n",
            "Iteration 971, loss = 1428872845.96685100\n",
            "Iteration 972, loss = 1428768255.43930197\n",
            "Iteration 973, loss = 1428664809.70783567\n",
            "Iteration 974, loss = 1428560879.01035166\n",
            "Iteration 975, loss = 1428456447.36531973\n",
            "Iteration 976, loss = 1428352931.02992964\n",
            "Iteration 977, loss = 1428248201.16994143\n",
            "Iteration 978, loss = 1428144698.48455906\n",
            "Iteration 979, loss = 1428040659.73001504\n",
            "Iteration 980, loss = 1427936428.42694449\n",
            "Iteration 981, loss = 1427831658.06001854\n",
            "Iteration 982, loss = 1427728153.48470855\n",
            "Iteration 983, loss = 1427624032.61462379\n",
            "Iteration 984, loss = 1427520701.79023361\n",
            "Iteration 985, loss = 1427416798.75932169\n",
            "Iteration 986, loss = 1427313182.75684524\n",
            "Iteration 987, loss = 1427209870.38561082\n",
            "Iteration 988, loss = 1427106054.26572919\n",
            "Iteration 989, loss = 1427003043.26762891\n",
            "Iteration 990, loss = 1426899543.13799596\n",
            "Iteration 991, loss = 1426796386.02134705\n",
            "Iteration 992, loss = 1426692757.75952816\n",
            "Iteration 993, loss = 1426589167.60230565\n",
            "Iteration 994, loss = 1426485661.48713970\n",
            "Iteration 995, loss = 1426382300.87452769\n",
            "Iteration 996, loss = 1426278681.82738090\n",
            "Iteration 997, loss = 1426175333.59110355\n",
            "Iteration 998, loss = 1426071590.48409867\n",
            "Iteration 999, loss = 1425967586.98156047\n",
            "Iteration 1000, loss = 1425864426.88217020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1325118676.37007546\n",
            "Iteration 2, loss = 1457011037.67733502\n",
            "Iteration 3, loss = 527533854.29769617\n",
            "Iteration 4, loss = 184067572.64470580\n",
            "Iteration 5, loss = 25405840.60971592\n",
            "Iteration 6, loss = 56046189.58821362\n",
            "Iteration 7, loss = 111458180.99785189\n",
            "Iteration 8, loss = 117251559.73232827\n",
            "Iteration 9, loss = 79908525.25227693\n",
            "Iteration 10, loss = 37117073.01294056\n",
            "Iteration 11, loss = 15243353.04067148\n",
            "Iteration 12, loss = 14950526.72489605\n",
            "Iteration 13, loss = 21606990.36058750\n",
            "Iteration 14, loss = 24390925.93445103\n",
            "Iteration 15, loss = 20336442.44747480\n",
            "Iteration 16, loss = 14695024.04243640\n",
            "Iteration 17, loss = 10470324.19561206\n",
            "Iteration 18, loss = 9566183.32404116\n",
            "Iteration 19, loss = 9942021.66543094\n",
            "Iteration 20, loss = 9834844.82986437\n",
            "Iteration 21, loss = 9353197.32574715\n",
            "Iteration 22, loss = 8593482.05039677\n",
            "Iteration 23, loss = 7933303.27031447\n",
            "Iteration 24, loss = 7876170.81760902\n",
            "Iteration 25, loss = 7395853.38162360\n",
            "Iteration 26, loss = 7302689.30843226\n",
            "Iteration 27, loss = 7195453.51883204\n",
            "Iteration 28, loss = 6900553.44937880\n",
            "Iteration 29, loss = 6708842.47391668\n",
            "Iteration 30, loss = 6483154.91374640\n",
            "Iteration 31, loss = 6341318.45179033\n",
            "Iteration 32, loss = 6258405.21278910\n",
            "Iteration 33, loss = 6228038.07896934\n",
            "Iteration 34, loss = 6102321.63483584\n",
            "Iteration 35, loss = 5991979.79379420\n",
            "Iteration 36, loss = 5923988.64819967\n",
            "Iteration 37, loss = 5889942.46047359\n",
            "Iteration 38, loss = 5806904.92335785\n",
            "Iteration 39, loss = 5828392.29943637\n",
            "Iteration 40, loss = 5777445.11181777\n",
            "Iteration 41, loss = 5713333.81511099\n",
            "Iteration 42, loss = 5627615.75937881\n",
            "Iteration 43, loss = 5480922.03698339\n",
            "Iteration 44, loss = 5430756.24653208\n",
            "Iteration 45, loss = 5388296.00793277\n",
            "Iteration 46, loss = 5369524.78935272\n",
            "Iteration 47, loss = 5368545.93855865\n",
            "Iteration 48, loss = 5369770.17026372\n",
            "Iteration 49, loss = 5353910.49518774\n",
            "Iteration 50, loss = 5216902.82438261\n",
            "Iteration 51, loss = 5193243.89912365\n",
            "Iteration 52, loss = 5153186.48345091\n",
            "Iteration 53, loss = 5130722.96648483\n",
            "Iteration 54, loss = 5122933.20369987\n",
            "Iteration 55, loss = 5099610.66479108\n",
            "Iteration 56, loss = 5036214.99138620\n",
            "Iteration 57, loss = 5019497.78516572\n",
            "Iteration 58, loss = 4997245.81826579\n",
            "Iteration 59, loss = 4999814.26557250\n",
            "Iteration 60, loss = 5070019.07160158\n",
            "Iteration 61, loss = 4932202.06073322\n",
            "Iteration 62, loss = 4995020.66566571\n",
            "Iteration 63, loss = 5175564.16118735\n",
            "Iteration 64, loss = 4874952.88201832\n",
            "Iteration 65, loss = 5104595.99641684\n",
            "Iteration 66, loss = 4829041.12050465\n",
            "Iteration 67, loss = 4825202.52082577\n",
            "Iteration 68, loss = 4837860.16839501\n",
            "Iteration 69, loss = 4876610.64873158\n",
            "Iteration 70, loss = 4766186.89536369\n",
            "Iteration 71, loss = 4738869.03249684\n",
            "Iteration 72, loss = 4735605.46200044\n",
            "Iteration 73, loss = 4731952.94766346\n",
            "Iteration 74, loss = 4758439.43977695\n",
            "Iteration 75, loss = 4702171.37802109\n",
            "Iteration 76, loss = 4682676.62642465\n",
            "Iteration 77, loss = 4672310.23019848\n",
            "Iteration 78, loss = 4673425.56088388\n",
            "Iteration 79, loss = 4712952.74791330\n",
            "Iteration 80, loss = 4625577.96977300\n",
            "Iteration 81, loss = 4601863.90124689\n",
            "Iteration 82, loss = 4614944.12854205\n",
            "Iteration 83, loss = 4781136.94449961\n",
            "Iteration 84, loss = 4802346.56558874\n",
            "Iteration 85, loss = 4552934.09807723\n",
            "Iteration 86, loss = 4563258.24813786\n",
            "Iteration 87, loss = 4543914.62757864\n",
            "Iteration 88, loss = 4528012.20352919\n",
            "Iteration 89, loss = 4525724.98868796\n",
            "Iteration 90, loss = 4563780.40255437\n",
            "Iteration 91, loss = 4546392.85659738\n",
            "Iteration 92, loss = 4480249.13291801\n",
            "Iteration 93, loss = 4542500.21849604\n",
            "Iteration 94, loss = 4477569.50699922\n",
            "Iteration 95, loss = 4454450.71765899\n",
            "Iteration 96, loss = 4448708.55130098\n",
            "Iteration 97, loss = 4468497.40868776\n",
            "Iteration 98, loss = 4453364.80908152\n",
            "Iteration 99, loss = 4437891.14923135\n",
            "Iteration 100, loss = 4434157.96841389\n",
            "Iteration 101, loss = 4418780.07756203\n",
            "Iteration 102, loss = 4434921.52864172\n",
            "Iteration 103, loss = 4442162.05042162\n",
            "Iteration 104, loss = 4423889.71535758\n",
            "Iteration 105, loss = 4389965.33111904\n",
            "Iteration 106, loss = 4372907.98453088\n",
            "Iteration 107, loss = 4376950.22638342\n",
            "Iteration 108, loss = 4360761.76383238\n",
            "Iteration 109, loss = 4350718.37176650\n",
            "Iteration 110, loss = 4339360.99276839\n",
            "Iteration 111, loss = 4338754.15337825\n",
            "Iteration 112, loss = 4351609.17520487\n",
            "Iteration 113, loss = 4325754.93757311\n",
            "Iteration 114, loss = 4313310.98204155\n",
            "Iteration 115, loss = 4306095.54681293\n",
            "Iteration 116, loss = 4322603.38633146\n",
            "Iteration 117, loss = 4316676.91149289\n",
            "Iteration 118, loss = 4317410.81018070\n",
            "Iteration 119, loss = 4295078.96240534\n",
            "Iteration 120, loss = 4295237.99912200\n",
            "Iteration 121, loss = 4341271.84138597\n",
            "Iteration 122, loss = 4441714.99912041\n",
            "Iteration 123, loss = 4283247.19866236\n",
            "Iteration 124, loss = 4251370.16905328\n",
            "Iteration 125, loss = 4294015.51586768\n",
            "Iteration 126, loss = 4427776.67057962\n",
            "Iteration 127, loss = 4269479.13325868\n",
            "Iteration 128, loss = 4259796.57758328\n",
            "Iteration 129, loss = 4274819.46615681\n",
            "Iteration 130, loss = 4231519.35916483\n",
            "Iteration 131, loss = 4443421.81319838\n",
            "Iteration 132, loss = 4261933.24698153\n",
            "Iteration 133, loss = 4236877.59011686\n",
            "Iteration 134, loss = 4279698.69958173\n",
            "Iteration 135, loss = 4198586.77229940\n",
            "Iteration 136, loss = 4187790.28083360\n",
            "Iteration 137, loss = 4183763.22786613\n",
            "Iteration 138, loss = 4170383.77537781\n",
            "Iteration 139, loss = 4167179.50460582\n",
            "Iteration 140, loss = 4170106.14200709\n",
            "Iteration 141, loss = 4202264.54926564\n",
            "Iteration 142, loss = 4302645.96940367\n",
            "Iteration 143, loss = 4156761.17202954\n",
            "Iteration 144, loss = 4145568.90858899\n",
            "Iteration 145, loss = 4136836.04595929\n",
            "Iteration 146, loss = 4188131.12586484\n",
            "Iteration 147, loss = 4296562.87306557\n",
            "Iteration 148, loss = 4128659.40693168\n",
            "Iteration 149, loss = 4182781.56512750\n",
            "Iteration 150, loss = 4241680.75499639\n",
            "Iteration 151, loss = 4173800.84111515\n",
            "Iteration 152, loss = 4323359.54091408\n",
            "Iteration 153, loss = 4319011.01235368\n",
            "Iteration 154, loss = 4153318.45002954\n",
            "Iteration 155, loss = 4113098.01568016\n",
            "Iteration 156, loss = 4103149.63177068\n",
            "Iteration 157, loss = 4113492.07987898\n",
            "Iteration 158, loss = 4132656.06942761\n",
            "Iteration 159, loss = 4119770.79376813\n",
            "Iteration 160, loss = 4083993.95846891\n",
            "Iteration 161, loss = 4079601.00276003\n",
            "Iteration 162, loss = 4081996.65090802\n",
            "Iteration 163, loss = 4153450.94273068\n",
            "Iteration 164, loss = 4321916.61796590\n",
            "Iteration 165, loss = 4299649.14000089\n",
            "Iteration 166, loss = 4090758.55190757\n",
            "Iteration 167, loss = 4082073.22075095\n",
            "Iteration 168, loss = 4152093.27629598\n",
            "Iteration 169, loss = 4107877.84281818\n",
            "Iteration 170, loss = 4135971.74465452\n",
            "Iteration 171, loss = 4063187.57250012\n",
            "Iteration 172, loss = 4047559.33552138\n",
            "Iteration 173, loss = 4080514.97247945\n",
            "Iteration 174, loss = 4313666.44841871\n",
            "Iteration 175, loss = 4238912.73739062\n",
            "Iteration 176, loss = 4034593.08457007\n",
            "Iteration 177, loss = 4063059.36784519\n",
            "Iteration 178, loss = 4017683.96489169\n",
            "Iteration 179, loss = 4095410.95189077\n",
            "Iteration 180, loss = 4141213.37285423\n",
            "Iteration 181, loss = 4191138.65429104\n",
            "Iteration 182, loss = 4017644.85351419\n",
            "Iteration 183, loss = 4030722.68295807\n",
            "Iteration 184, loss = 4014049.50718469\n",
            "Iteration 185, loss = 4017966.68129748\n",
            "Iteration 186, loss = 3996608.61447100\n",
            "Iteration 187, loss = 4010015.23216909\n",
            "Iteration 188, loss = 4002929.34956934\n",
            "Iteration 189, loss = 3988032.49444525\n",
            "Iteration 190, loss = 4015142.47849480\n",
            "Iteration 191, loss = 3998295.83092817\n",
            "Iteration 192, loss = 3984503.24265845\n",
            "Iteration 193, loss = 4033824.46995145\n",
            "Iteration 194, loss = 4070935.98194076\n",
            "Iteration 195, loss = 4005225.64539309\n",
            "Iteration 196, loss = 4000012.74738543\n",
            "Iteration 197, loss = 3983846.35766981\n",
            "Iteration 198, loss = 3969979.85710682\n",
            "Iteration 199, loss = 3975078.79439479\n",
            "Iteration 200, loss = 3969825.44116051\n",
            "Iteration 201, loss = 4043589.12337928\n",
            "Iteration 202, loss = 4080438.95122448\n",
            "Iteration 203, loss = 3992825.70336734\n",
            "Iteration 204, loss = 3980344.09079475\n",
            "Iteration 205, loss = 4011719.70392374\n",
            "Iteration 206, loss = 3979261.44692356\n",
            "Iteration 207, loss = 3950154.76432812\n",
            "Iteration 208, loss = 3946232.94978713\n",
            "Iteration 209, loss = 3946781.48578785\n",
            "Iteration 210, loss = 3947465.97093153\n",
            "Iteration 211, loss = 3954229.60146651\n",
            "Iteration 212, loss = 4046124.72484046\n",
            "Iteration 213, loss = 3929619.83386192\n",
            "Iteration 214, loss = 4026892.87933091\n",
            "Iteration 215, loss = 3958608.49008211\n",
            "Iteration 216, loss = 3948241.36214550\n",
            "Iteration 217, loss = 4065644.90654145\n",
            "Iteration 218, loss = 3928226.93253255\n",
            "Iteration 219, loss = 4039753.16928416\n",
            "Iteration 220, loss = 3987333.95526188\n",
            "Iteration 221, loss = 3952275.00606253\n",
            "Iteration 222, loss = 3926727.29434579\n",
            "Iteration 223, loss = 3932850.15441778\n",
            "Iteration 224, loss = 3941457.27509022\n",
            "Iteration 225, loss = 3909241.57895072\n",
            "Iteration 226, loss = 3923146.21224109\n",
            "Iteration 227, loss = 3936479.87406832\n",
            "Iteration 228, loss = 3955124.16556406\n",
            "Iteration 229, loss = 3934142.81884077\n",
            "Iteration 230, loss = 3998233.27573152\n",
            "Iteration 231, loss = 4060101.36065041\n",
            "Iteration 232, loss = 3892045.14199312\n",
            "Iteration 233, loss = 4028619.67016705\n",
            "Iteration 234, loss = 3939229.17408806\n",
            "Iteration 235, loss = 3933542.96526754\n",
            "Iteration 236, loss = 3937430.81333312\n",
            "Iteration 237, loss = 3890164.64635028\n",
            "Iteration 238, loss = 3907829.59849212\n",
            "Iteration 239, loss = 3906786.71477623\n",
            "Iteration 240, loss = 3886039.76850949\n",
            "Iteration 241, loss = 3910164.83770321\n",
            "Iteration 242, loss = 3893974.93701138\n",
            "Iteration 243, loss = 3904615.47629676\n",
            "Iteration 244, loss = 3921222.47936810\n",
            "Iteration 245, loss = 3888602.54979589\n",
            "Iteration 246, loss = 3900561.84514798\n",
            "Iteration 247, loss = 3914473.20272831\n",
            "Iteration 248, loss = 3932285.33691559\n",
            "Iteration 249, loss = 3980790.55416667\n",
            "Iteration 250, loss = 3899712.80489689\n",
            "Iteration 251, loss = 3920626.45722086\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538821750.45750785\n",
            "Iteration 2, loss = 1538763209.00123239\n",
            "Iteration 3, loss = 1538705599.90727806\n",
            "Iteration 4, loss = 1538646851.50569057\n",
            "Iteration 5, loss = 1538587978.37380171\n",
            "Iteration 6, loss = 1538528164.23405552\n",
            "Iteration 7, loss = 1538468252.29760623\n",
            "Iteration 8, loss = 1538406428.32347989\n",
            "Iteration 9, loss = 1538343789.49751472\n",
            "Iteration 10, loss = 1538279725.81144953\n",
            "Iteration 11, loss = 1538212635.66111422\n",
            "Iteration 12, loss = 1538145722.58821654\n",
            "Iteration 13, loss = 1538074443.08955979\n",
            "Iteration 14, loss = 1538003640.48923326\n",
            "Iteration 15, loss = 1537928583.67024827\n",
            "Iteration 16, loss = 1537852058.61766171\n",
            "Iteration 17, loss = 1537773081.16324115\n",
            "Iteration 18, loss = 1537690173.64682150\n",
            "Iteration 19, loss = 1537608942.23520279\n",
            "Iteration 20, loss = 1537524555.78541660\n",
            "Iteration 21, loss = 1537436477.01465130\n",
            "Iteration 22, loss = 1537347894.18056798\n",
            "Iteration 23, loss = 1537259906.04366636\n",
            "Iteration 24, loss = 1537167490.84624743\n",
            "Iteration 25, loss = 1537075239.05885482\n",
            "Iteration 26, loss = 1536982458.54608226\n",
            "Iteration 27, loss = 1536886721.44708920\n",
            "Iteration 28, loss = 1536790950.07979703\n",
            "Iteration 29, loss = 1536695108.42697334\n",
            "Iteration 30, loss = 1536597106.90546989\n",
            "Iteration 31, loss = 1536497837.40812540\n",
            "Iteration 32, loss = 1536400220.17073154\n",
            "Iteration 33, loss = 1536299389.13250422\n",
            "Iteration 34, loss = 1536199749.23242831\n",
            "Iteration 35, loss = 1536099969.32120275\n",
            "Iteration 36, loss = 1535997758.61198759\n",
            "Iteration 37, loss = 1535896033.93156362\n",
            "Iteration 38, loss = 1535795214.13602567\n",
            "Iteration 39, loss = 1535690169.53264332\n",
            "Iteration 40, loss = 1535586657.72093749\n",
            "Iteration 41, loss = 1535481994.61754203\n",
            "Iteration 42, loss = 1535377246.21231818\n",
            "Iteration 43, loss = 1535268793.89210463\n",
            "Iteration 44, loss = 1535161152.28198075\n",
            "Iteration 45, loss = 1535052140.40648460\n",
            "Iteration 46, loss = 1534941178.83022404\n",
            "Iteration 47, loss = 1534828724.93810201\n",
            "Iteration 48, loss = 1534715269.15698338\n",
            "Iteration 49, loss = 1534599002.45786619\n",
            "Iteration 50, loss = 1534481443.87779880\n",
            "Iteration 51, loss = 1534361756.52913928\n",
            "Iteration 52, loss = 1534240371.21150160\n",
            "Iteration 53, loss = 1534116249.47512245\n",
            "Iteration 54, loss = 1533990314.40371561\n",
            "Iteration 55, loss = 1533862742.42165542\n",
            "Iteration 56, loss = 1533732313.81837440\n",
            "Iteration 57, loss = 1533600797.70927191\n",
            "Iteration 58, loss = 1533467344.86529279\n",
            "Iteration 59, loss = 1533332095.97373295\n",
            "Iteration 60, loss = 1533195251.46559072\n",
            "Iteration 61, loss = 1533057145.39451671\n",
            "Iteration 62, loss = 1532919298.19216752\n",
            "Iteration 63, loss = 1532779335.43007040\n",
            "Iteration 64, loss = 1532639878.19671893\n",
            "Iteration 65, loss = 1532500182.55580807\n",
            "Iteration 66, loss = 1532359862.89585209\n",
            "Iteration 67, loss = 1532218764.64312100\n",
            "Iteration 68, loss = 1532077155.56611538\n",
            "Iteration 69, loss = 1531935467.64886069\n",
            "Iteration 70, loss = 1531792528.23927999\n",
            "Iteration 71, loss = 1531649982.33603692\n",
            "Iteration 72, loss = 1531506499.69895267\n",
            "Iteration 73, loss = 1531363658.19523549\n",
            "Iteration 74, loss = 1531221086.68376756\n",
            "Iteration 75, loss = 1531078042.02205133\n",
            "Iteration 76, loss = 1530934717.08440804\n",
            "Iteration 77, loss = 1530792285.56291223\n",
            "Iteration 78, loss = 1530650192.34730601\n",
            "Iteration 79, loss = 1530507437.58494663\n",
            "Iteration 80, loss = 1530366215.16707897\n",
            "Iteration 81, loss = 1530223257.26306915\n",
            "Iteration 82, loss = 1530081404.26102710\n",
            "Iteration 83, loss = 1529939849.11689425\n",
            "Iteration 84, loss = 1529797323.51374292\n",
            "Iteration 85, loss = 1529654829.24062991\n",
            "Iteration 86, loss = 1529513884.10268116\n",
            "Iteration 87, loss = 1529371904.49148202\n",
            "Iteration 88, loss = 1529230142.46196294\n",
            "Iteration 89, loss = 1529089804.89721537\n",
            "Iteration 90, loss = 1528947939.04560137\n",
            "Iteration 91, loss = 1528807982.15190077\n",
            "Iteration 92, loss = 1528667139.27167201\n",
            "Iteration 93, loss = 1528526875.29914713\n",
            "Iteration 94, loss = 1528387878.35282230\n",
            "Iteration 95, loss = 1528247304.01668239\n",
            "Iteration 96, loss = 1528107378.33375549\n",
            "Iteration 97, loss = 1527968008.90978241\n",
            "Iteration 98, loss = 1527827634.88465977\n",
            "Iteration 99, loss = 1527688027.37933588\n",
            "Iteration 100, loss = 1527549633.91375494\n",
            "Iteration 101, loss = 1527409100.10245252\n",
            "Iteration 102, loss = 1527270292.97065353\n",
            "Iteration 103, loss = 1527131367.06822968\n",
            "Iteration 104, loss = 1526993558.75238729\n",
            "Iteration 105, loss = 1526854331.15150642\n",
            "Iteration 106, loss = 1526715896.21955967\n",
            "Iteration 107, loss = 1526577885.72743487\n",
            "Iteration 108, loss = 1526439662.13521504\n",
            "Iteration 109, loss = 1526301800.67742157\n",
            "Iteration 110, loss = 1526164712.41633439\n",
            "Iteration 111, loss = 1526027194.54089165\n",
            "Iteration 112, loss = 1525890859.90068841\n",
            "Iteration 113, loss = 1525754900.19870567\n",
            "Iteration 114, loss = 1525618759.84939098\n",
            "Iteration 115, loss = 1525483805.43675494\n",
            "Iteration 116, loss = 1525348293.42553234\n",
            "Iteration 117, loss = 1525213422.49211168\n",
            "Iteration 118, loss = 1525079010.70504546\n",
            "Iteration 119, loss = 1524944891.00515008\n",
            "Iteration 120, loss = 1524809783.69458365\n",
            "Iteration 121, loss = 1524675876.13013434\n",
            "Iteration 122, loss = 1524541927.56217837\n",
            "Iteration 123, loss = 1524408399.70646977\n",
            "Iteration 124, loss = 1524274521.21661210\n",
            "Iteration 125, loss = 1524141798.87716007\n",
            "Iteration 126, loss = 1524009293.44489002\n",
            "Iteration 127, loss = 1523876728.80400062\n",
            "Iteration 128, loss = 1523744787.91053772\n",
            "Iteration 129, loss = 1523612849.82411218\n",
            "Iteration 130, loss = 1523481279.02080107\n",
            "Iteration 131, loss = 1523350452.90018702\n",
            "Iteration 132, loss = 1523218673.03755593\n",
            "Iteration 133, loss = 1523088346.40423846\n",
            "Iteration 134, loss = 1522956833.87142682\n",
            "Iteration 135, loss = 1522825653.72873569\n",
            "Iteration 136, loss = 1522694953.74843264\n",
            "Iteration 137, loss = 1522563799.63879633\n",
            "Iteration 138, loss = 1522434020.14727402\n",
            "Iteration 139, loss = 1522303226.40576363\n",
            "Iteration 140, loss = 1522173248.12341428\n",
            "Iteration 141, loss = 1522043368.29809332\n",
            "Iteration 142, loss = 1521913826.95572352\n",
            "Iteration 143, loss = 1521784695.45898771\n",
            "Iteration 144, loss = 1521656024.60678029\n",
            "Iteration 145, loss = 1521526201.63540816\n",
            "Iteration 146, loss = 1521396986.78381729\n",
            "Iteration 147, loss = 1521268478.55680728\n",
            "Iteration 148, loss = 1521139217.80561376\n",
            "Iteration 149, loss = 1521010972.31494164\n",
            "Iteration 150, loss = 1520881124.64370298\n",
            "Iteration 151, loss = 1520754255.15836549\n",
            "Iteration 152, loss = 1520625743.97825027\n",
            "Iteration 153, loss = 1520498458.68773723\n",
            "Iteration 154, loss = 1520370791.69476748\n",
            "Iteration 155, loss = 1520243740.18615174\n",
            "Iteration 156, loss = 1520117128.61709619\n",
            "Iteration 157, loss = 1519990535.61035109\n",
            "Iteration 158, loss = 1519863752.01352143\n",
            "Iteration 159, loss = 1519737211.50928521\n",
            "Iteration 160, loss = 1519611084.61762547\n",
            "Iteration 161, loss = 1519484709.29149556\n",
            "Iteration 162, loss = 1519358409.47107172\n",
            "Iteration 163, loss = 1519232996.46889067\n",
            "Iteration 164, loss = 1519106433.23287368\n",
            "Iteration 165, loss = 1518981116.87400317\n",
            "Iteration 166, loss = 1518855492.96463180\n",
            "Iteration 167, loss = 1518728741.35776329\n",
            "Iteration 168, loss = 1518604541.57582355\n",
            "Iteration 169, loss = 1518477993.48139954\n",
            "Iteration 170, loss = 1518352800.31966543\n",
            "Iteration 171, loss = 1518227479.85514593\n",
            "Iteration 172, loss = 1518102295.78205872\n",
            "Iteration 173, loss = 1517977964.53154445\n",
            "Iteration 174, loss = 1517852231.18854856\n",
            "Iteration 175, loss = 1517728352.00525951\n",
            "Iteration 176, loss = 1517604016.99185991\n",
            "Iteration 177, loss = 1517479073.12023878\n",
            "Iteration 178, loss = 1517355271.22751164\n",
            "Iteration 179, loss = 1517230667.54687858\n",
            "Iteration 180, loss = 1517106674.43844295\n",
            "Iteration 181, loss = 1516982291.48688054\n",
            "Iteration 182, loss = 1516858955.49932957\n",
            "Iteration 183, loss = 1516734801.29780149\n",
            "Iteration 184, loss = 1516611063.41209626\n",
            "Iteration 185, loss = 1516488127.96991038\n",
            "Iteration 186, loss = 1516364967.36002183\n",
            "Iteration 187, loss = 1516242127.68208885\n",
            "Iteration 188, loss = 1516120035.92902708\n",
            "Iteration 189, loss = 1515996485.28007507\n",
            "Iteration 190, loss = 1515873985.21028590\n",
            "Iteration 191, loss = 1515751570.41895938\n",
            "Iteration 192, loss = 1515628161.84080791\n",
            "Iteration 193, loss = 1515505515.05160666\n",
            "Iteration 194, loss = 1515382443.73676014\n",
            "Iteration 195, loss = 1515259032.23781323\n",
            "Iteration 196, loss = 1515136503.82871819\n",
            "Iteration 197, loss = 1515014185.46262646\n",
            "Iteration 198, loss = 1514891901.31934667\n",
            "Iteration 199, loss = 1514769032.64167309\n",
            "Iteration 200, loss = 1514646417.07871437\n",
            "Iteration 201, loss = 1514524766.40614533\n",
            "Iteration 202, loss = 1514402553.05803347\n",
            "Iteration 203, loss = 1514279838.53964114\n",
            "Iteration 204, loss = 1514158710.80291891\n",
            "Iteration 205, loss = 1514036510.33706093\n",
            "Iteration 206, loss = 1513914141.83873844\n",
            "Iteration 207, loss = 1513793342.65767527\n",
            "Iteration 208, loss = 1513671778.28221154\n",
            "Iteration 209, loss = 1513550155.49639297\n",
            "Iteration 210, loss = 1513429555.31369519\n",
            "Iteration 211, loss = 1513307351.82331419\n",
            "Iteration 212, loss = 1513187300.63503981\n",
            "Iteration 213, loss = 1513066079.63887119\n",
            "Iteration 214, loss = 1512945859.53133440\n",
            "Iteration 215, loss = 1512824993.10936522\n",
            "Iteration 216, loss = 1512705020.52580452\n",
            "Iteration 217, loss = 1512583995.78851986\n",
            "Iteration 218, loss = 1512463767.24881053\n",
            "Iteration 219, loss = 1512344079.03476024\n",
            "Iteration 220, loss = 1512222838.50458956\n",
            "Iteration 221, loss = 1512102625.25111675\n",
            "Iteration 222, loss = 1511982568.50578523\n",
            "Iteration 223, loss = 1511862229.58967876\n",
            "Iteration 224, loss = 1511741512.18744826\n",
            "Iteration 225, loss = 1511622283.00144601\n",
            "Iteration 226, loss = 1511502046.18416309\n",
            "Iteration 227, loss = 1511382063.25419641\n",
            "Iteration 228, loss = 1511263045.92510271\n",
            "Iteration 229, loss = 1511142679.67576051\n",
            "Iteration 230, loss = 1511023756.96361828\n",
            "Iteration 231, loss = 1510904426.87928414\n",
            "Iteration 232, loss = 1510785086.84407330\n",
            "Iteration 233, loss = 1510666024.51366258\n",
            "Iteration 234, loss = 1510546515.78094697\n",
            "Iteration 235, loss = 1510428374.21255636\n",
            "Iteration 236, loss = 1510309298.85422254\n",
            "Iteration 237, loss = 1510191174.89990830\n",
            "Iteration 238, loss = 1510073160.28709483\n",
            "Iteration 239, loss = 1509954576.17472076\n",
            "Iteration 240, loss = 1509837440.79818964\n",
            "Iteration 241, loss = 1509720055.11358953\n",
            "Iteration 242, loss = 1509601734.86869669\n",
            "Iteration 243, loss = 1509484438.32942486\n",
            "Iteration 244, loss = 1509366578.28714657\n",
            "Iteration 245, loss = 1509248855.07373452\n",
            "Iteration 246, loss = 1509131504.20764208\n",
            "Iteration 247, loss = 1509013855.12343645\n",
            "Iteration 248, loss = 1508896566.92713881\n",
            "Iteration 249, loss = 1508779291.38158083\n",
            "Iteration 250, loss = 1508662586.70552015\n",
            "Iteration 251, loss = 1508545485.24196553\n",
            "Iteration 252, loss = 1508427987.84478998\n",
            "Iteration 253, loss = 1508311549.00380754\n",
            "Iteration 254, loss = 1508194757.21821117\n",
            "Iteration 255, loss = 1508077339.03006148\n",
            "Iteration 256, loss = 1507960245.29700875\n",
            "Iteration 257, loss = 1507843636.00716877\n",
            "Iteration 258, loss = 1507726046.96719146\n",
            "Iteration 259, loss = 1507609776.13818359\n",
            "Iteration 260, loss = 1507492630.42656183\n",
            "Iteration 261, loss = 1507376045.25565577\n",
            "Iteration 262, loss = 1507259111.05447197\n",
            "Iteration 263, loss = 1507143016.54983497\n",
            "Iteration 264, loss = 1507026492.67637420\n",
            "Iteration 265, loss = 1506909553.91135645\n",
            "Iteration 266, loss = 1506793215.40470600\n",
            "Iteration 267, loss = 1506676728.37750602\n",
            "Iteration 268, loss = 1506560489.02478576\n",
            "Iteration 269, loss = 1506443268.26698542\n",
            "Iteration 270, loss = 1506327448.79549289\n",
            "Iteration 271, loss = 1506210404.17507958\n",
            "Iteration 272, loss = 1506093822.74981499\n",
            "Iteration 273, loss = 1505976969.54222989\n",
            "Iteration 274, loss = 1505861118.64015293\n",
            "Iteration 275, loss = 1505744074.57549167\n",
            "Iteration 276, loss = 1505627474.45526481\n",
            "Iteration 277, loss = 1505511571.32822180\n",
            "Iteration 278, loss = 1505394277.96887779\n",
            "Iteration 279, loss = 1505279013.05351019\n",
            "Iteration 280, loss = 1505162147.72255325\n",
            "Iteration 281, loss = 1505045795.39332652\n",
            "Iteration 282, loss = 1504928639.08618665\n",
            "Iteration 283, loss = 1504813368.94145441\n",
            "Iteration 284, loss = 1504696231.94892025\n",
            "Iteration 285, loss = 1504580435.81730628\n",
            "Iteration 286, loss = 1504464092.88780856\n",
            "Iteration 287, loss = 1504347915.47988391\n",
            "Iteration 288, loss = 1504231736.34356356\n",
            "Iteration 289, loss = 1504116262.16317177\n",
            "Iteration 290, loss = 1503999792.01162791\n",
            "Iteration 291, loss = 1503883446.75336814\n",
            "Iteration 292, loss = 1503767429.09778523\n",
            "Iteration 293, loss = 1503652224.75801325\n",
            "Iteration 294, loss = 1503534690.39187384\n",
            "Iteration 295, loss = 1503419111.77859688\n",
            "Iteration 296, loss = 1503303310.95196319\n",
            "Iteration 297, loss = 1503187032.36929512\n",
            "Iteration 298, loss = 1503071117.51637530\n",
            "Iteration 299, loss = 1502955024.44720531\n",
            "Iteration 300, loss = 1502839832.29099512\n",
            "Iteration 301, loss = 1502723894.93637419\n",
            "Iteration 302, loss = 1502608442.86683130\n",
            "Iteration 303, loss = 1502493053.34988165\n",
            "Iteration 304, loss = 1502377849.50534487\n",
            "Iteration 305, loss = 1502262415.38302255\n",
            "Iteration 306, loss = 1502147724.75842261\n",
            "Iteration 307, loss = 1502032393.81588054\n",
            "Iteration 308, loss = 1501918265.81109452\n",
            "Iteration 309, loss = 1501803308.69181275\n",
            "Iteration 310, loss = 1501688572.23804593\n",
            "Iteration 311, loss = 1501575346.42548251\n",
            "Iteration 312, loss = 1501460884.15668511\n",
            "Iteration 313, loss = 1501345794.64721918\n",
            "Iteration 314, loss = 1501232083.45562601\n",
            "Iteration 315, loss = 1501117236.66117573\n",
            "Iteration 316, loss = 1501003423.11023784\n",
            "Iteration 317, loss = 1500888601.04914308\n",
            "Iteration 318, loss = 1500773573.34150076\n",
            "Iteration 319, loss = 1500658856.39797807\n",
            "Iteration 320, loss = 1500545602.65777540\n",
            "Iteration 321, loss = 1500430112.12904692\n",
            "Iteration 322, loss = 1500316699.84560704\n",
            "Iteration 323, loss = 1500202426.79800224\n",
            "Iteration 324, loss = 1500087549.33551693\n",
            "Iteration 325, loss = 1499974033.03564835\n",
            "Iteration 326, loss = 1499859427.66143990\n",
            "Iteration 327, loss = 1499744486.78986335\n",
            "Iteration 328, loss = 1499630150.31072116\n",
            "Iteration 329, loss = 1499515016.55644989\n",
            "Iteration 330, loss = 1499400940.19009304\n",
            "Iteration 331, loss = 1499286101.97022080\n",
            "Iteration 332, loss = 1499171419.50570202\n",
            "Iteration 333, loss = 1499057371.40031838\n",
            "Iteration 334, loss = 1498942777.19511127\n",
            "Iteration 335, loss = 1498828458.04767251\n",
            "Iteration 336, loss = 1498715342.45580053\n",
            "Iteration 337, loss = 1498600901.71071267\n",
            "Iteration 338, loss = 1498487720.70026278\n",
            "Iteration 339, loss = 1498374366.50820971\n",
            "Iteration 340, loss = 1498261159.02462745\n",
            "Iteration 341, loss = 1498148956.14103937\n",
            "Iteration 342, loss = 1498035700.21023297\n",
            "Iteration 343, loss = 1497922816.32375383\n",
            "Iteration 344, loss = 1497809876.80417967\n",
            "Iteration 345, loss = 1497696872.27705407\n",
            "Iteration 346, loss = 1497583116.91544962\n",
            "Iteration 347, loss = 1497470120.40555882\n",
            "Iteration 348, loss = 1497356409.46029162\n",
            "Iteration 349, loss = 1497243400.85084295\n",
            "Iteration 350, loss = 1497129802.03800297\n",
            "Iteration 351, loss = 1497016144.35699058\n",
            "Iteration 352, loss = 1496903120.49564981\n",
            "Iteration 353, loss = 1496790183.70021892\n",
            "Iteration 354, loss = 1496676475.73509097\n",
            "Iteration 355, loss = 1496563700.40913320\n",
            "Iteration 356, loss = 1496450576.11697769\n",
            "Iteration 357, loss = 1496337757.23970318\n",
            "Iteration 358, loss = 1496224873.65503860\n",
            "Iteration 359, loss = 1496111782.99153662\n",
            "Iteration 360, loss = 1495998210.49379492\n",
            "Iteration 361, loss = 1495884787.42058229\n",
            "Iteration 362, loss = 1495771323.54660749\n",
            "Iteration 363, loss = 1495658339.15584731\n",
            "Iteration 364, loss = 1495545792.68304372\n",
            "Iteration 365, loss = 1495432295.14806437\n",
            "Iteration 366, loss = 1495319856.98688626\n",
            "Iteration 367, loss = 1495207448.94298482\n",
            "Iteration 368, loss = 1495095271.36007714\n",
            "Iteration 369, loss = 1494983248.99139166\n",
            "Iteration 370, loss = 1494871258.72327375\n",
            "Iteration 371, loss = 1494759172.08263040\n",
            "Iteration 372, loss = 1494647095.40214682\n",
            "Iteration 373, loss = 1494534767.58462548\n",
            "Iteration 374, loss = 1494423546.58305073\n",
            "Iteration 375, loss = 1494311195.24499464\n",
            "Iteration 376, loss = 1494198955.23109651\n",
            "Iteration 377, loss = 1494086623.45786929\n",
            "Iteration 378, loss = 1493974723.68424535\n",
            "Iteration 379, loss = 1493862237.43467546\n",
            "Iteration 380, loss = 1493749901.20515299\n",
            "Iteration 381, loss = 1493637354.81153035\n",
            "Iteration 382, loss = 1493525156.25776625\n",
            "Iteration 383, loss = 1493412459.50587678\n",
            "Iteration 384, loss = 1493300409.54454803\n",
            "Iteration 385, loss = 1493187552.75695634\n",
            "Iteration 386, loss = 1493075378.85379887\n",
            "Iteration 387, loss = 1492962676.55924749\n",
            "Iteration 388, loss = 1492850173.94898248\n",
            "Iteration 389, loss = 1492737343.89986372\n",
            "Iteration 390, loss = 1492624723.43547726\n",
            "Iteration 391, loss = 1492512708.47113633\n",
            "Iteration 392, loss = 1492399411.13818026\n",
            "Iteration 393, loss = 1492287218.74755144\n",
            "Iteration 394, loss = 1492174656.09868741\n",
            "Iteration 395, loss = 1492062202.02351952\n",
            "Iteration 396, loss = 1491949754.53176212\n",
            "Iteration 397, loss = 1491837365.34874916\n",
            "Iteration 398, loss = 1491725256.63159585\n",
            "Iteration 399, loss = 1491612637.14155936\n",
            "Iteration 400, loss = 1491500553.71301341\n",
            "Iteration 401, loss = 1491388363.45522594\n",
            "Iteration 402, loss = 1491276516.26751041\n",
            "Iteration 403, loss = 1491164136.23492742\n",
            "Iteration 404, loss = 1491052061.70096374\n",
            "Iteration 405, loss = 1490940094.01769328\n",
            "Iteration 406, loss = 1490828206.38472247\n",
            "Iteration 407, loss = 1490716775.87185431\n",
            "Iteration 408, loss = 1490605091.93459320\n",
            "Iteration 409, loss = 1490493363.85260606\n",
            "Iteration 410, loss = 1490382173.09746790\n",
            "Iteration 411, loss = 1490270813.97543120\n",
            "Iteration 412, loss = 1490159661.86522913\n",
            "Iteration 413, loss = 1490048204.55558395\n",
            "Iteration 414, loss = 1489937696.65366054\n",
            "Iteration 415, loss = 1489826206.51141953\n",
            "Iteration 416, loss = 1489715262.27808833\n",
            "Iteration 417, loss = 1489604685.87763739\n",
            "Iteration 418, loss = 1489493299.67310214\n",
            "Iteration 419, loss = 1489383019.73977542\n",
            "Iteration 420, loss = 1489271552.00718212\n",
            "Iteration 421, loss = 1489160242.81649470\n",
            "Iteration 422, loss = 1489049299.64208579\n",
            "Iteration 423, loss = 1488937749.66394734\n",
            "Iteration 424, loss = 1488826065.62342548\n",
            "Iteration 425, loss = 1488714588.68583441\n",
            "Iteration 426, loss = 1488603442.75221086\n",
            "Iteration 427, loss = 1488491849.05490685\n",
            "Iteration 428, loss = 1488380383.98946214\n",
            "Iteration 429, loss = 1488269016.21062756\n",
            "Iteration 430, loss = 1488157469.06143737\n",
            "Iteration 431, loss = 1488047056.66208935\n",
            "Iteration 432, loss = 1487935966.11737418\n",
            "Iteration 433, loss = 1487824947.30183172\n",
            "Iteration 434, loss = 1487713771.29844546\n",
            "Iteration 435, loss = 1487602917.77720213\n",
            "Iteration 436, loss = 1487492524.33547235\n",
            "Iteration 437, loss = 1487380863.78991795\n",
            "Iteration 438, loss = 1487270206.57792521\n",
            "Iteration 439, loss = 1487159485.42875934\n",
            "Iteration 440, loss = 1487048957.85801029\n",
            "Iteration 441, loss = 1486937767.48982096\n",
            "Iteration 442, loss = 1486827304.48812222\n",
            "Iteration 443, loss = 1486717215.17078328\n",
            "Iteration 444, loss = 1486606673.95872164\n",
            "Iteration 445, loss = 1486496293.86672258\n",
            "Iteration 446, loss = 1486386166.54370642\n",
            "Iteration 447, loss = 1486276276.61984348\n",
            "Iteration 448, loss = 1486165200.01572275\n",
            "Iteration 449, loss = 1486054884.96128726\n",
            "Iteration 450, loss = 1485944302.90714860\n",
            "Iteration 451, loss = 1485834062.67748952\n",
            "Iteration 452, loss = 1485722552.79859877\n",
            "Iteration 453, loss = 1485612313.28844833\n",
            "Iteration 454, loss = 1485501727.59807467\n",
            "Iteration 455, loss = 1485390268.34768558\n",
            "Iteration 456, loss = 1485279792.97037363\n",
            "Iteration 457, loss = 1485169286.81369400\n",
            "Iteration 458, loss = 1485058667.35313034\n",
            "Iteration 459, loss = 1484948641.40915203\n",
            "Iteration 460, loss = 1484837890.56028318\n",
            "Iteration 461, loss = 1484728185.95193028\n",
            "Iteration 462, loss = 1484617117.96462822\n",
            "Iteration 463, loss = 1484507036.47986794\n",
            "Iteration 464, loss = 1484396726.68207741\n",
            "Iteration 465, loss = 1484285609.29846525\n",
            "Iteration 466, loss = 1484175112.82149887\n",
            "Iteration 467, loss = 1484064383.88578653\n",
            "Iteration 468, loss = 1483953562.65730524\n",
            "Iteration 469, loss = 1483842799.02373695\n",
            "Iteration 470, loss = 1483731784.02290726\n",
            "Iteration 471, loss = 1483620829.48319125\n",
            "Iteration 472, loss = 1483509703.36442947\n",
            "Iteration 473, loss = 1483398739.81250048\n",
            "Iteration 474, loss = 1483287433.11949039\n",
            "Iteration 475, loss = 1483176331.11206961\n",
            "Iteration 476, loss = 1483065283.51015711\n",
            "Iteration 477, loss = 1482954149.76643014\n",
            "Iteration 478, loss = 1482843551.06756735\n",
            "Iteration 479, loss = 1482732423.59744763\n",
            "Iteration 480, loss = 1482622383.24876881\n",
            "Iteration 481, loss = 1482510989.03878927\n",
            "Iteration 482, loss = 1482401202.33170891\n",
            "Iteration 483, loss = 1482290760.26959085\n",
            "Iteration 484, loss = 1482180691.40146089\n",
            "Iteration 485, loss = 1482071092.11417484\n",
            "Iteration 486, loss = 1481961237.43554020\n",
            "Iteration 487, loss = 1481851773.29089880\n",
            "Iteration 488, loss = 1481742301.37914920\n",
            "Iteration 489, loss = 1481633393.52051902\n",
            "Iteration 490, loss = 1481524539.77257729\n",
            "Iteration 491, loss = 1481415244.85531688\n",
            "Iteration 492, loss = 1481306571.51781058\n",
            "Iteration 493, loss = 1481198345.50149846\n",
            "Iteration 494, loss = 1481089374.95057225\n",
            "Iteration 495, loss = 1480980561.04947066\n",
            "Iteration 496, loss = 1480872040.99163985\n",
            "Iteration 497, loss = 1480762291.71647239\n",
            "Iteration 498, loss = 1480653218.64196491\n",
            "Iteration 499, loss = 1480544283.74642825\n",
            "Iteration 500, loss = 1480434324.19998574\n",
            "Iteration 501, loss = 1480325037.31555867\n",
            "Iteration 502, loss = 1480215816.87161279\n",
            "Iteration 503, loss = 1480105632.06872916\n",
            "Iteration 504, loss = 1479997618.96194196\n",
            "Iteration 505, loss = 1479887600.48472857\n",
            "Iteration 506, loss = 1479778796.75088453\n",
            "Iteration 507, loss = 1479669605.45714164\n",
            "Iteration 508, loss = 1479560909.73156548\n",
            "Iteration 509, loss = 1479451303.68476200\n",
            "Iteration 510, loss = 1479343104.11547399\n",
            "Iteration 511, loss = 1479232597.62242627\n",
            "Iteration 512, loss = 1479124079.78402138\n",
            "Iteration 513, loss = 1479015141.86019516\n",
            "Iteration 514, loss = 1478905607.20013785\n",
            "Iteration 515, loss = 1478796450.38927698\n",
            "Iteration 516, loss = 1478687177.04673600\n",
            "Iteration 517, loss = 1478578512.55297375\n",
            "Iteration 518, loss = 1478467960.68188643\n",
            "Iteration 519, loss = 1478359727.75889206\n",
            "Iteration 520, loss = 1478249475.03040695\n",
            "Iteration 521, loss = 1478140420.08882403\n",
            "Iteration 522, loss = 1478030813.95311284\n",
            "Iteration 523, loss = 1477921270.03014493\n",
            "Iteration 524, loss = 1477812306.90678596\n",
            "Iteration 525, loss = 1477702799.04560733\n",
            "Iteration 526, loss = 1477593745.17696142\n",
            "Iteration 527, loss = 1477484397.15242648\n",
            "Iteration 528, loss = 1477375675.59276223\n",
            "Iteration 529, loss = 1477267169.16782475\n",
            "Iteration 530, loss = 1477157892.03826547\n",
            "Iteration 531, loss = 1477049356.79418540\n",
            "Iteration 532, loss = 1476940918.98494458\n",
            "Iteration 533, loss = 1476832670.92134285\n",
            "Iteration 534, loss = 1476723645.31851649\n",
            "Iteration 535, loss = 1476614853.34797955\n",
            "Iteration 536, loss = 1476506449.55275083\n",
            "Iteration 537, loss = 1476397112.89941359\n",
            "Iteration 538, loss = 1476288262.60378885\n",
            "Iteration 539, loss = 1476179498.12076879\n",
            "Iteration 540, loss = 1476070287.83428884\n",
            "Iteration 541, loss = 1475961780.95240545\n",
            "Iteration 542, loss = 1475853202.40098333\n",
            "Iteration 543, loss = 1475744932.22089767\n",
            "Iteration 544, loss = 1475636860.15963101\n",
            "Iteration 545, loss = 1475528276.78540635\n",
            "Iteration 546, loss = 1475419509.95462584\n",
            "Iteration 547, loss = 1475310971.69747138\n",
            "Iteration 548, loss = 1475202721.83752418\n",
            "Iteration 549, loss = 1475093250.72243500\n",
            "Iteration 550, loss = 1474984760.11549878\n",
            "Iteration 551, loss = 1474875582.53195643\n",
            "Iteration 552, loss = 1474767387.31959987\n",
            "Iteration 553, loss = 1474658185.11876321\n",
            "Iteration 554, loss = 1474549563.64083529\n",
            "Iteration 555, loss = 1474441197.84229302\n",
            "Iteration 556, loss = 1474331837.57715726\n",
            "Iteration 557, loss = 1474223386.30879211\n",
            "Iteration 558, loss = 1474114775.97239685\n",
            "Iteration 559, loss = 1474006152.12469697\n",
            "Iteration 560, loss = 1473897175.87308693\n",
            "Iteration 561, loss = 1473788194.56895614\n",
            "Iteration 562, loss = 1473679539.96586394\n",
            "Iteration 563, loss = 1473571295.52594447\n",
            "Iteration 564, loss = 1473462904.86205220\n",
            "Iteration 565, loss = 1473354085.94657946\n",
            "Iteration 566, loss = 1473246003.41856384\n",
            "Iteration 567, loss = 1473138354.53017473\n",
            "Iteration 568, loss = 1473030563.00299335\n",
            "Iteration 569, loss = 1472922212.92983985\n",
            "Iteration 570, loss = 1472815210.30096340\n",
            "Iteration 571, loss = 1472706924.46258378\n",
            "Iteration 572, loss = 1472599543.12527704\n",
            "Iteration 573, loss = 1472491539.39298415\n",
            "Iteration 574, loss = 1472383460.92633820\n",
            "Iteration 575, loss = 1472274874.92987895\n",
            "Iteration 576, loss = 1472166917.01454115\n",
            "Iteration 577, loss = 1472058335.75030041\n",
            "Iteration 578, loss = 1471950237.42735314\n",
            "Iteration 579, loss = 1471842250.12727880\n",
            "Iteration 580, loss = 1471734161.75071383\n",
            "Iteration 581, loss = 1471626723.82457280\n",
            "Iteration 582, loss = 1471518669.24592113\n",
            "Iteration 583, loss = 1471411404.36386085\n",
            "Iteration 584, loss = 1471303722.92072868\n",
            "Iteration 585, loss = 1471196204.57070231\n",
            "Iteration 586, loss = 1471088369.89152670\n",
            "Iteration 587, loss = 1470980434.88242221\n",
            "Iteration 588, loss = 1470872747.59716725\n",
            "Iteration 589, loss = 1470764692.86196756\n",
            "Iteration 590, loss = 1470657091.70906520\n",
            "Iteration 591, loss = 1470549366.02593732\n",
            "Iteration 592, loss = 1470441673.54704046\n",
            "Iteration 593, loss = 1470333757.13083172\n",
            "Iteration 594, loss = 1470226431.12313771\n",
            "Iteration 595, loss = 1470118496.27982092\n",
            "Iteration 596, loss = 1470010594.28869700\n",
            "Iteration 597, loss = 1469903258.49730086\n",
            "Iteration 598, loss = 1469795227.48982763\n",
            "Iteration 599, loss = 1469687168.05765939\n",
            "Iteration 600, loss = 1469579804.26679373\n",
            "Iteration 601, loss = 1469471520.93151903\n",
            "Iteration 602, loss = 1469363747.29374766\n",
            "Iteration 603, loss = 1469255704.02468801\n",
            "Iteration 604, loss = 1469147578.01924825\n",
            "Iteration 605, loss = 1469039724.93686914\n",
            "Iteration 606, loss = 1468931460.53126955\n",
            "Iteration 607, loss = 1468823288.45276332\n",
            "Iteration 608, loss = 1468714960.61762428\n",
            "Iteration 609, loss = 1468606580.57626772\n",
            "Iteration 610, loss = 1468498429.17986250\n",
            "Iteration 611, loss = 1468389422.28041744\n",
            "Iteration 612, loss = 1468282108.68139553\n",
            "Iteration 613, loss = 1468173378.30737162\n",
            "Iteration 614, loss = 1468065055.07940507\n",
            "Iteration 615, loss = 1467956846.56689882\n",
            "Iteration 616, loss = 1467849089.13991880\n",
            "Iteration 617, loss = 1467740976.96152782\n",
            "Iteration 618, loss = 1467632864.98200655\n",
            "Iteration 619, loss = 1467524912.45718646\n",
            "Iteration 620, loss = 1467417081.85792375\n",
            "Iteration 621, loss = 1467309202.84071040\n",
            "Iteration 622, loss = 1467202173.49095750\n",
            "Iteration 623, loss = 1467094124.91344738\n",
            "Iteration 624, loss = 1466986655.00005698\n",
            "Iteration 625, loss = 1466879637.67296290\n",
            "Iteration 626, loss = 1466771902.23558640\n",
            "Iteration 627, loss = 1466663568.33255577\n",
            "Iteration 628, loss = 1466556024.11039233\n",
            "Iteration 629, loss = 1466448896.57787776\n",
            "Iteration 630, loss = 1466340810.74488187\n",
            "Iteration 631, loss = 1466232887.97845864\n",
            "Iteration 632, loss = 1466125098.67555737\n",
            "Iteration 633, loss = 1466017694.00810337\n",
            "Iteration 634, loss = 1465909984.54047728\n",
            "Iteration 635, loss = 1465802731.58308458\n",
            "Iteration 636, loss = 1465694803.33793139\n",
            "Iteration 637, loss = 1465586934.17213416\n",
            "Iteration 638, loss = 1465479950.68758893\n",
            "Iteration 639, loss = 1465372533.24564600\n",
            "Iteration 640, loss = 1465264150.69263601\n",
            "Iteration 641, loss = 1465157724.75559044\n",
            "Iteration 642, loss = 1465049810.12808084\n",
            "Iteration 643, loss = 1464942299.40191436\n",
            "Iteration 644, loss = 1464835666.67382956\n",
            "Iteration 645, loss = 1464727931.95045924\n",
            "Iteration 646, loss = 1464620841.74706364\n",
            "Iteration 647, loss = 1464513784.75786376\n",
            "Iteration 648, loss = 1464406605.38606048\n",
            "Iteration 649, loss = 1464299638.08803797\n",
            "Iteration 650, loss = 1464192192.51023507\n",
            "Iteration 651, loss = 1464085409.54210925\n",
            "Iteration 652, loss = 1463978728.80852604\n",
            "Iteration 653, loss = 1463871505.92911649\n",
            "Iteration 654, loss = 1463764255.10521817\n",
            "Iteration 655, loss = 1463657463.25864530\n",
            "Iteration 656, loss = 1463550798.57183099\n",
            "Iteration 657, loss = 1463444001.35239196\n",
            "Iteration 658, loss = 1463337340.28198385\n",
            "Iteration 659, loss = 1463230237.91472363\n",
            "Iteration 660, loss = 1463123729.77947831\n",
            "Iteration 661, loss = 1463016556.94638681\n",
            "Iteration 662, loss = 1462909462.91823959\n",
            "Iteration 663, loss = 1462802639.05229807\n",
            "Iteration 664, loss = 1462695290.75268912\n",
            "Iteration 665, loss = 1462588579.67441607\n",
            "Iteration 666, loss = 1462481284.83408713\n",
            "Iteration 667, loss = 1462374613.92245245\n",
            "Iteration 668, loss = 1462267872.83972645\n",
            "Iteration 669, loss = 1462161135.46614003\n",
            "Iteration 670, loss = 1462054377.45632362\n",
            "Iteration 671, loss = 1461947889.75848293\n",
            "Iteration 672, loss = 1461840691.38737822\n",
            "Iteration 673, loss = 1461734940.03191829\n",
            "Iteration 674, loss = 1461627509.49302006\n",
            "Iteration 675, loss = 1461521011.11580920\n",
            "Iteration 676, loss = 1461414572.90681362\n",
            "Iteration 677, loss = 1461306853.49983072\n",
            "Iteration 678, loss = 1461201251.99654794\n",
            "Iteration 679, loss = 1461093404.63380909\n",
            "Iteration 680, loss = 1460986545.09293938\n",
            "Iteration 681, loss = 1460879371.35939360\n",
            "Iteration 682, loss = 1460772251.18230057\n",
            "Iteration 683, loss = 1460664776.32210445\n",
            "Iteration 684, loss = 1460557549.41882086\n",
            "Iteration 685, loss = 1460450230.51223397\n",
            "Iteration 686, loss = 1460342980.83247876\n",
            "Iteration 687, loss = 1460235868.59403253\n",
            "Iteration 688, loss = 1460129449.14100814\n",
            "Iteration 689, loss = 1460022009.06167078\n",
            "Iteration 690, loss = 1459915505.48331404\n",
            "Iteration 691, loss = 1459808801.46182013\n",
            "Iteration 692, loss = 1459701823.61085510\n",
            "Iteration 693, loss = 1459594947.83608389\n",
            "Iteration 694, loss = 1459487529.05507421\n",
            "Iteration 695, loss = 1459380975.85616279\n",
            "Iteration 696, loss = 1459272819.68910146\n",
            "Iteration 697, loss = 1459166914.00024986\n",
            "Iteration 698, loss = 1459059610.87709737\n",
            "Iteration 699, loss = 1458952619.82375216\n",
            "Iteration 700, loss = 1458845919.13114524\n",
            "Iteration 701, loss = 1458739453.28003788\n",
            "Iteration 702, loss = 1458632208.94287300\n",
            "Iteration 703, loss = 1458525638.54092431\n",
            "Iteration 704, loss = 1458418625.47186685\n",
            "Iteration 705, loss = 1458311447.32168221\n",
            "Iteration 706, loss = 1458204475.79875779\n",
            "Iteration 707, loss = 1458098325.03945827\n",
            "Iteration 708, loss = 1457990783.60456038\n",
            "Iteration 709, loss = 1457884344.17199969\n",
            "Iteration 710, loss = 1457777883.38863420\n",
            "Iteration 711, loss = 1457671646.75445008\n",
            "Iteration 712, loss = 1457565536.75264502\n",
            "Iteration 713, loss = 1457458814.85568428\n",
            "Iteration 714, loss = 1457353025.07606554\n",
            "Iteration 715, loss = 1457247437.94195342\n",
            "Iteration 716, loss = 1457140501.94568229\n",
            "Iteration 717, loss = 1457034884.31991172\n",
            "Iteration 718, loss = 1456928101.83854604\n",
            "Iteration 719, loss = 1456823337.56822658\n",
            "Iteration 720, loss = 1456716873.52861476\n",
            "Iteration 721, loss = 1456610745.03914285\n",
            "Iteration 722, loss = 1456504904.45901060\n",
            "Iteration 723, loss = 1456399554.69474626\n",
            "Iteration 724, loss = 1456293569.16165304\n",
            "Iteration 725, loss = 1456188392.25181770\n",
            "Iteration 726, loss = 1456082283.96736002\n",
            "Iteration 727, loss = 1455976092.69561625\n",
            "Iteration 728, loss = 1455871132.40584540\n",
            "Iteration 729, loss = 1455764995.03127193\n",
            "Iteration 730, loss = 1455659397.08865285\n",
            "Iteration 731, loss = 1455553673.61929083\n",
            "Iteration 732, loss = 1455447247.52552485\n",
            "Iteration 733, loss = 1455341741.95067811\n",
            "Iteration 734, loss = 1455235821.08903837\n",
            "Iteration 735, loss = 1455129643.73511386\n",
            "Iteration 736, loss = 1455023802.67055583\n",
            "Iteration 737, loss = 1454917264.83908153\n",
            "Iteration 738, loss = 1454811217.37202573\n",
            "Iteration 739, loss = 1454705107.04645824\n",
            "Iteration 740, loss = 1454599059.14237428\n",
            "Iteration 741, loss = 1454492781.59074330\n",
            "Iteration 742, loss = 1454387008.99605393\n",
            "Iteration 743, loss = 1454281087.27481914\n",
            "Iteration 744, loss = 1454174888.07508636\n",
            "Iteration 745, loss = 1454068412.26928306\n",
            "Iteration 746, loss = 1453962568.81603956\n",
            "Iteration 747, loss = 1453855801.48153448\n",
            "Iteration 748, loss = 1453749811.52761698\n",
            "Iteration 749, loss = 1453643318.23731518\n",
            "Iteration 750, loss = 1453537362.52731204\n",
            "Iteration 751, loss = 1453430901.82858348\n",
            "Iteration 752, loss = 1453325330.79510522\n",
            "Iteration 753, loss = 1453218956.23176050\n",
            "Iteration 754, loss = 1453113077.11802053\n",
            "Iteration 755, loss = 1453007685.31288958\n",
            "Iteration 756, loss = 1452900886.08768010\n",
            "Iteration 757, loss = 1452795765.21085620\n",
            "Iteration 758, loss = 1452689855.98005939\n",
            "Iteration 759, loss = 1452583407.70758820\n",
            "Iteration 760, loss = 1452478157.27437449\n",
            "Iteration 761, loss = 1452372756.73697233\n",
            "Iteration 762, loss = 1452265808.63327050\n",
            "Iteration 763, loss = 1452160360.59768248\n",
            "Iteration 764, loss = 1452053886.85600519\n",
            "Iteration 765, loss = 1451948399.32463932\n",
            "Iteration 766, loss = 1451842385.27420259\n",
            "Iteration 767, loss = 1451736210.97579527\n",
            "Iteration 768, loss = 1451630385.27152824\n",
            "Iteration 769, loss = 1451524802.24383712\n",
            "Iteration 770, loss = 1451418915.66947556\n",
            "Iteration 771, loss = 1451312982.03259826\n",
            "Iteration 772, loss = 1451207814.13101268\n",
            "Iteration 773, loss = 1451101765.11692572\n",
            "Iteration 774, loss = 1450996195.48570609\n",
            "Iteration 775, loss = 1450889797.59073949\n",
            "Iteration 776, loss = 1450784708.09852004\n",
            "Iteration 777, loss = 1450678297.39384580\n",
            "Iteration 778, loss = 1450572800.73161697\n",
            "Iteration 779, loss = 1450466652.99865866\n",
            "Iteration 780, loss = 1450360794.30655980\n",
            "Iteration 781, loss = 1450254099.41491580\n",
            "Iteration 782, loss = 1450148646.27809048\n",
            "Iteration 783, loss = 1450042322.15236259\n",
            "Iteration 784, loss = 1449936230.23010659\n",
            "Iteration 785, loss = 1449829758.58654237\n",
            "Iteration 786, loss = 1449724082.13711047\n",
            "Iteration 787, loss = 1449618082.99239945\n",
            "Iteration 788, loss = 1449512432.87254596\n",
            "Iteration 789, loss = 1449407323.43153143\n",
            "Iteration 790, loss = 1449301086.39587617\n",
            "Iteration 791, loss = 1449196390.22073030\n",
            "Iteration 792, loss = 1449090535.50594330\n",
            "Iteration 793, loss = 1448985391.88746142\n",
            "Iteration 794, loss = 1448879742.69228578\n",
            "Iteration 795, loss = 1448774146.90850806\n",
            "Iteration 796, loss = 1448669509.27868605\n",
            "Iteration 797, loss = 1448563654.64048386\n",
            "Iteration 798, loss = 1448458274.73192286\n",
            "Iteration 799, loss = 1448353430.23219228\n",
            "Iteration 800, loss = 1448247465.89642620\n",
            "Iteration 801, loss = 1448141534.48026252\n",
            "Iteration 802, loss = 1448036796.13900113\n",
            "Iteration 803, loss = 1447930914.95592332\n",
            "Iteration 804, loss = 1447824709.08293700\n",
            "Iteration 805, loss = 1447719935.76656556\n",
            "Iteration 806, loss = 1447613434.77939177\n",
            "Iteration 807, loss = 1447508455.64138269\n",
            "Iteration 808, loss = 1447401984.03624082\n",
            "Iteration 809, loss = 1447296991.29180527\n",
            "Iteration 810, loss = 1447191105.63277197\n",
            "Iteration 811, loss = 1447085347.51462698\n",
            "Iteration 812, loss = 1446979606.94635701\n",
            "Iteration 813, loss = 1446874626.08269119\n",
            "Iteration 814, loss = 1446768675.11745358\n",
            "Iteration 815, loss = 1446662995.36833000\n",
            "Iteration 816, loss = 1446557659.50975084\n",
            "Iteration 817, loss = 1446452004.49130821\n",
            "Iteration 818, loss = 1446346004.69178605\n",
            "Iteration 819, loss = 1446240695.44931197\n",
            "Iteration 820, loss = 1446135807.87305117\n",
            "Iteration 821, loss = 1446029694.96096230\n",
            "Iteration 822, loss = 1445924870.84789300\n",
            "Iteration 823, loss = 1445819168.93172908\n",
            "Iteration 824, loss = 1445714103.15170383\n",
            "Iteration 825, loss = 1445609292.66521692\n",
            "Iteration 826, loss = 1445503570.24664521\n",
            "Iteration 827, loss = 1445399539.57425523\n",
            "Iteration 828, loss = 1445293313.12328124\n",
            "Iteration 829, loss = 1445188999.86543870\n",
            "Iteration 830, loss = 1445084115.57585907\n",
            "Iteration 831, loss = 1444978574.29824138\n",
            "Iteration 832, loss = 1444873844.20430684\n",
            "Iteration 833, loss = 1444768679.13849425\n",
            "Iteration 834, loss = 1444663501.05772328\n",
            "Iteration 835, loss = 1444557606.67063713\n",
            "Iteration 836, loss = 1444453587.84211922\n",
            "Iteration 837, loss = 1444347363.05599642\n",
            "Iteration 838, loss = 1444242353.65115666\n",
            "Iteration 839, loss = 1444137399.21384764\n",
            "Iteration 840, loss = 1444032087.68887401\n",
            "Iteration 841, loss = 1443927004.64758682\n",
            "Iteration 842, loss = 1443822382.96320319\n",
            "Iteration 843, loss = 1443717256.76558375\n",
            "Iteration 844, loss = 1443612617.38944411\n",
            "Iteration 845, loss = 1443508135.75248528\n",
            "Iteration 846, loss = 1443402841.22971582\n",
            "Iteration 847, loss = 1443298006.57280540\n",
            "Iteration 848, loss = 1443193784.49998355\n",
            "Iteration 849, loss = 1443087996.91594529\n",
            "Iteration 850, loss = 1442983303.00502014\n",
            "Iteration 851, loss = 1442878296.56179142\n",
            "Iteration 852, loss = 1442772822.34243226\n",
            "Iteration 853, loss = 1442668139.45240498\n",
            "Iteration 854, loss = 1442562905.69543076\n",
            "Iteration 855, loss = 1442457694.12817693\n",
            "Iteration 856, loss = 1442352156.60692978\n",
            "Iteration 857, loss = 1442246723.69564176\n",
            "Iteration 858, loss = 1442141694.34248281\n",
            "Iteration 859, loss = 1442035518.62923980\n",
            "Iteration 860, loss = 1441930074.54710460\n",
            "Iteration 861, loss = 1441824296.87411141\n",
            "Iteration 862, loss = 1441718273.95194840\n",
            "Iteration 863, loss = 1441612964.03681421\n",
            "Iteration 864, loss = 1441507176.79675150\n",
            "Iteration 865, loss = 1441402045.81572342\n",
            "Iteration 866, loss = 1441296532.14212155\n",
            "Iteration 867, loss = 1441191486.32492113\n",
            "Iteration 868, loss = 1441087050.99420524\n",
            "Iteration 869, loss = 1440981865.07929850\n",
            "Iteration 870, loss = 1440877261.54761386\n",
            "Iteration 871, loss = 1440773212.74195457\n",
            "Iteration 872, loss = 1440668174.59782553\n",
            "Iteration 873, loss = 1440563833.75341225\n",
            "Iteration 874, loss = 1440459786.34569526\n",
            "Iteration 875, loss = 1440354966.64089417\n",
            "Iteration 876, loss = 1440249829.74997044\n",
            "Iteration 877, loss = 1440146023.06042290\n",
            "Iteration 878, loss = 1440040314.54280233\n",
            "Iteration 879, loss = 1439935519.13556051\n",
            "Iteration 880, loss = 1439830178.20852828\n",
            "Iteration 881, loss = 1439725124.90352392\n",
            "Iteration 882, loss = 1439620316.19731617\n",
            "Iteration 883, loss = 1439515139.53430700\n",
            "Iteration 884, loss = 1439410068.17891622\n",
            "Iteration 885, loss = 1439304823.36426449\n",
            "Iteration 886, loss = 1439200340.73926306\n",
            "Iteration 887, loss = 1439095118.22304153\n",
            "Iteration 888, loss = 1438990936.70244265\n",
            "Iteration 889, loss = 1438885621.78680587\n",
            "Iteration 890, loss = 1438781242.97326279\n",
            "Iteration 891, loss = 1438676381.75281835\n",
            "Iteration 892, loss = 1438572330.36868095\n",
            "Iteration 893, loss = 1438468090.18428183\n",
            "Iteration 894, loss = 1438363165.03319120\n",
            "Iteration 895, loss = 1438258376.46303892\n",
            "Iteration 896, loss = 1438154598.33403587\n",
            "Iteration 897, loss = 1438049347.63973951\n",
            "Iteration 898, loss = 1437944388.98487544\n",
            "Iteration 899, loss = 1437839190.87599301\n",
            "Iteration 900, loss = 1437734359.69752049\n",
            "Iteration 901, loss = 1437628811.43537712\n",
            "Iteration 902, loss = 1437523596.78531075\n",
            "Iteration 903, loss = 1437418253.14933801\n",
            "Iteration 904, loss = 1437312536.55560255\n",
            "Iteration 905, loss = 1437207476.18008089\n",
            "Iteration 906, loss = 1437102441.05688167\n",
            "Iteration 907, loss = 1436996781.62939501\n",
            "Iteration 908, loss = 1436892481.94228292\n",
            "Iteration 909, loss = 1436787846.23107767\n",
            "Iteration 910, loss = 1436683058.98959494\n",
            "Iteration 911, loss = 1436578051.85960364\n",
            "Iteration 912, loss = 1436474147.90325880\n",
            "Iteration 913, loss = 1436369940.46831417\n",
            "Iteration 914, loss = 1436266348.13932109\n",
            "Iteration 915, loss = 1436160889.28856134\n",
            "Iteration 916, loss = 1436057614.70242190\n",
            "Iteration 917, loss = 1435952905.27700210\n",
            "Iteration 918, loss = 1435848112.10261464\n",
            "Iteration 919, loss = 1435743817.84328842\n",
            "Iteration 920, loss = 1435638666.69546294\n",
            "Iteration 921, loss = 1435533758.30165696\n",
            "Iteration 922, loss = 1435428274.71706724\n",
            "Iteration 923, loss = 1435323155.56054235\n",
            "Iteration 924, loss = 1435217976.62090206\n",
            "Iteration 925, loss = 1435112813.75680137\n",
            "Iteration 926, loss = 1435007409.11787343\n",
            "Iteration 927, loss = 1434902531.18206668\n",
            "Iteration 928, loss = 1434797570.65556812\n",
            "Iteration 929, loss = 1434692545.42051959\n",
            "Iteration 930, loss = 1434587735.66673803\n",
            "Iteration 931, loss = 1434482501.05731964\n",
            "Iteration 932, loss = 1434377909.54201269\n",
            "Iteration 933, loss = 1434273328.17086720\n",
            "Iteration 934, loss = 1434168270.35286498\n",
            "Iteration 935, loss = 1434063410.26102161\n",
            "Iteration 936, loss = 1433958723.68505192\n",
            "Iteration 937, loss = 1433854157.42330885\n",
            "Iteration 938, loss = 1433748706.94026399\n",
            "Iteration 939, loss = 1433644453.26878285\n",
            "Iteration 940, loss = 1433539417.12178636\n",
            "Iteration 941, loss = 1433434578.68910789\n",
            "Iteration 942, loss = 1433329615.86956501\n",
            "Iteration 943, loss = 1433225716.89190674\n",
            "Iteration 944, loss = 1433120682.75443339\n",
            "Iteration 945, loss = 1433016772.11701727\n",
            "Iteration 946, loss = 1432912281.90491557\n",
            "Iteration 947, loss = 1432807435.23030591\n",
            "Iteration 948, loss = 1432703096.00119948\n",
            "Iteration 949, loss = 1432598080.22919106\n",
            "Iteration 950, loss = 1432493388.19706535\n",
            "Iteration 951, loss = 1432388455.91957045\n",
            "Iteration 952, loss = 1432283679.41394591\n",
            "Iteration 953, loss = 1432178955.25433898\n",
            "Iteration 954, loss = 1432073956.08196020\n",
            "Iteration 955, loss = 1431968971.50176263\n",
            "Iteration 956, loss = 1431864483.16816306\n",
            "Iteration 957, loss = 1431760127.36473012\n",
            "Iteration 958, loss = 1431655820.72403955\n",
            "Iteration 959, loss = 1431551248.38129640\n",
            "Iteration 960, loss = 1431447272.42317295\n",
            "Iteration 961, loss = 1431343472.93368578\n",
            "Iteration 962, loss = 1431240029.88263297\n",
            "Iteration 963, loss = 1431134996.08092713\n",
            "Iteration 964, loss = 1431032139.36874127\n",
            "Iteration 965, loss = 1430928061.78909016\n",
            "Iteration 966, loss = 1430824310.39091754\n",
            "Iteration 967, loss = 1430720316.95927405\n",
            "Iteration 968, loss = 1430616556.28776789\n",
            "Iteration 969, loss = 1430512740.00183463\n",
            "Iteration 970, loss = 1430408963.82730293\n",
            "Iteration 971, loss = 1430304909.84973574\n",
            "Iteration 972, loss = 1430201191.23968768\n",
            "Iteration 973, loss = 1430097365.89504337\n",
            "Iteration 974, loss = 1429993485.16638184\n",
            "Iteration 975, loss = 1429889218.18946815\n",
            "Iteration 976, loss = 1429785196.80779600\n",
            "Iteration 977, loss = 1429681694.67231703\n",
            "Iteration 978, loss = 1429577767.11955976\n",
            "Iteration 979, loss = 1429473348.39861465\n",
            "Iteration 980, loss = 1429370023.10977960\n",
            "Iteration 981, loss = 1429265359.96880078\n",
            "Iteration 982, loss = 1429161178.01927328\n",
            "Iteration 983, loss = 1429056892.61028266\n",
            "Iteration 984, loss = 1428952420.13768411\n",
            "Iteration 985, loss = 1428847293.39568830\n",
            "Iteration 986, loss = 1428743370.98958802\n",
            "Iteration 987, loss = 1428638790.37693095\n",
            "Iteration 988, loss = 1428533943.31165433\n",
            "Iteration 989, loss = 1428429171.61277771\n",
            "Iteration 990, loss = 1428325430.72673321\n",
            "Iteration 991, loss = 1428220738.40650272\n",
            "Iteration 992, loss = 1428116454.68699169\n",
            "Iteration 993, loss = 1428012281.67280865\n",
            "Iteration 994, loss = 1427907784.70712805\n",
            "Iteration 995, loss = 1427803422.19242573\n",
            "Iteration 996, loss = 1427698994.33917665\n",
            "Iteration 997, loss = 1427595088.12356377\n",
            "Iteration 998, loss = 1427490800.92725587\n",
            "Iteration 999, loss = 1427387317.28784609\n",
            "Iteration 1000, loss = 1427283443.92016411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1322787740.18250728\n",
            "Iteration 2, loss = 1339690743.15324330\n",
            "Iteration 3, loss = 444365197.74088109\n",
            "Iteration 4, loss = 76125122.76199979\n",
            "Iteration 5, loss = 51152233.40286764\n",
            "Iteration 6, loss = 119139985.31659298\n",
            "Iteration 7, loss = 138057829.58834702\n",
            "Iteration 8, loss = 91015444.68391168\n",
            "Iteration 9, loss = 38056357.88634425\n",
            "Iteration 10, loss = 17807490.56291115\n",
            "Iteration 11, loss = 23948706.34448008\n",
            "Iteration 12, loss = 31565255.13585291\n",
            "Iteration 13, loss = 29433265.39256385\n",
            "Iteration 14, loss = 21366632.68550531\n",
            "Iteration 15, loss = 15745435.30119321\n",
            "Iteration 16, loss = 14538257.77162164\n",
            "Iteration 17, loss = 15351479.83010420\n",
            "Iteration 18, loss = 15425088.65221799\n",
            "Iteration 19, loss = 14485925.08994873\n",
            "Iteration 20, loss = 12428282.22972256\n",
            "Iteration 21, loss = 11714125.81562195\n",
            "Iteration 22, loss = 11470456.09220766\n",
            "Iteration 23, loss = 11314439.95042860\n",
            "Iteration 24, loss = 10954067.04919328\n",
            "Iteration 25, loss = 10423151.56400092\n",
            "Iteration 26, loss = 9910220.48487860\n",
            "Iteration 27, loss = 9616070.67958619\n",
            "Iteration 28, loss = 9198225.84508803\n",
            "Iteration 29, loss = 9068535.93917290\n",
            "Iteration 30, loss = 8746008.42656584\n",
            "Iteration 31, loss = 8576291.83624914\n",
            "Iteration 32, loss = 8318611.94898172\n",
            "Iteration 33, loss = 8136881.80653382\n",
            "Iteration 34, loss = 7936877.49476104\n",
            "Iteration 35, loss = 7796653.58171637\n",
            "Iteration 36, loss = 7624501.04631636\n",
            "Iteration 37, loss = 7463189.83722191\n",
            "Iteration 38, loss = 7368739.57420175\n",
            "Iteration 39, loss = 7423079.82765365\n",
            "Iteration 40, loss = 7148800.61055820\n",
            "Iteration 41, loss = 6985485.26892131\n",
            "Iteration 42, loss = 6893029.56668808\n",
            "Iteration 43, loss = 6804594.45095834\n",
            "Iteration 44, loss = 6760093.43491424\n",
            "Iteration 45, loss = 6658683.43852714\n",
            "Iteration 46, loss = 6682083.01666846\n",
            "Iteration 47, loss = 6578453.71021500\n",
            "Iteration 48, loss = 6465594.62937217\n",
            "Iteration 49, loss = 6644844.70468650\n",
            "Iteration 50, loss = 6368642.92206646\n",
            "Iteration 51, loss = 6293418.63715675\n",
            "Iteration 52, loss = 6281668.16247174\n",
            "Iteration 53, loss = 6314384.80591716\n",
            "Iteration 54, loss = 6193355.53785253\n",
            "Iteration 55, loss = 6247331.28591746\n",
            "Iteration 56, loss = 6113687.13111378\n",
            "Iteration 57, loss = 6109775.97054871\n",
            "Iteration 58, loss = 6090860.79403921\n",
            "Iteration 59, loss = 6142111.31369771\n",
            "Iteration 60, loss = 6179338.25999289\n",
            "Iteration 61, loss = 5976768.66198333\n",
            "Iteration 62, loss = 5921793.55475292\n",
            "Iteration 63, loss = 5886621.93652106\n",
            "Iteration 64, loss = 6037445.13939752\n",
            "Iteration 65, loss = 5929329.58414673\n",
            "Iteration 66, loss = 5924342.18899732\n",
            "Iteration 67, loss = 5898318.67155034\n",
            "Iteration 68, loss = 5997090.57189358\n",
            "Iteration 69, loss = 5869886.41536748\n",
            "Iteration 70, loss = 6030463.15060813\n",
            "Iteration 71, loss = 5904228.44242548\n",
            "Iteration 72, loss = 5806556.17754361\n",
            "Iteration 73, loss = 5759961.19525968\n",
            "Iteration 74, loss = 5786417.55576949\n",
            "Iteration 75, loss = 5749682.99043723\n",
            "Iteration 76, loss = 5735820.07457565\n",
            "Iteration 77, loss = 5708761.76921637\n",
            "Iteration 78, loss = 5679565.25825205\n",
            "Iteration 79, loss = 5681363.68068780\n",
            "Iteration 80, loss = 5729556.52231184\n",
            "Iteration 81, loss = 5736957.35117515\n",
            "Iteration 82, loss = 5726024.97320214\n",
            "Iteration 83, loss = 5621397.67194913\n",
            "Iteration 84, loss = 5646062.11209918\n",
            "Iteration 85, loss = 5657133.57783564\n",
            "Iteration 86, loss = 5635369.23196038\n",
            "Iteration 87, loss = 5578947.44230129\n",
            "Iteration 88, loss = 5595049.39554193\n",
            "Iteration 89, loss = 5583870.92008575\n",
            "Iteration 90, loss = 5564502.68394536\n",
            "Iteration 91, loss = 5550811.94761039\n",
            "Iteration 92, loss = 5596133.88764976\n",
            "Iteration 93, loss = 5712410.62595657\n",
            "Iteration 94, loss = 5570163.40137273\n",
            "Iteration 95, loss = 5528849.99100808\n",
            "Iteration 96, loss = 5828591.46265413\n",
            "Iteration 97, loss = 5526514.93243200\n",
            "Iteration 98, loss = 5469535.62310728\n",
            "Iteration 99, loss = 5464078.33801017\n",
            "Iteration 100, loss = 5455612.21627933\n",
            "Iteration 101, loss = 5457903.16417477\n",
            "Iteration 102, loss = 5484258.31527723\n",
            "Iteration 103, loss = 5502855.44356049\n",
            "Iteration 104, loss = 5606751.27105528\n",
            "Iteration 105, loss = 5532240.05916648\n",
            "Iteration 106, loss = 5477711.55031829\n",
            "Iteration 107, loss = 5423401.50622905\n",
            "Iteration 108, loss = 5392610.20905427\n",
            "Iteration 109, loss = 5396875.65273258\n",
            "Iteration 110, loss = 5387403.59700415\n",
            "Iteration 111, loss = 5377046.84145988\n",
            "Iteration 112, loss = 5372346.75900985\n",
            "Iteration 113, loss = 5373045.88100715\n",
            "Iteration 114, loss = 5371993.07184934\n",
            "Iteration 115, loss = 5367971.34014354\n",
            "Iteration 116, loss = 5454875.04610259\n",
            "Iteration 117, loss = 5366098.03651659\n",
            "Iteration 118, loss = 5342805.70154751\n",
            "Iteration 119, loss = 5361115.74914422\n",
            "Iteration 120, loss = 5341429.67408884\n",
            "Iteration 121, loss = 5337326.11983718\n",
            "Iteration 122, loss = 5317918.69674531\n",
            "Iteration 123, loss = 5318970.12413472\n",
            "Iteration 124, loss = 5336163.55946420\n",
            "Iteration 125, loss = 5313008.08691740\n",
            "Iteration 126, loss = 5366318.71288883\n",
            "Iteration 127, loss = 5344575.58308786\n",
            "Iteration 128, loss = 5294138.72919387\n",
            "Iteration 129, loss = 5331542.93751748\n",
            "Iteration 130, loss = 5349050.92912849\n",
            "Iteration 131, loss = 5308941.90157518\n",
            "Iteration 132, loss = 5282096.26759288\n",
            "Iteration 133, loss = 5268246.48773140\n",
            "Iteration 134, loss = 5266824.44470488\n",
            "Iteration 135, loss = 5270960.41808663\n",
            "Iteration 136, loss = 5269690.84827012\n",
            "Iteration 137, loss = 5271317.27954246\n",
            "Iteration 138, loss = 5298978.11797327\n",
            "Iteration 139, loss = 5288811.92468329\n",
            "Iteration 140, loss = 5294776.55914001\n",
            "Iteration 141, loss = 5247653.89811879\n",
            "Iteration 142, loss = 5251979.39877898\n",
            "Iteration 143, loss = 5239721.06195194\n",
            "Iteration 144, loss = 5289470.99992077\n",
            "Iteration 145, loss = 5242568.77242223\n",
            "Iteration 146, loss = 5245265.79678500\n",
            "Iteration 147, loss = 5240677.90053039\n",
            "Iteration 148, loss = 5373605.69095317\n",
            "Iteration 149, loss = 5272101.95549035\n",
            "Iteration 150, loss = 5227151.37098473\n",
            "Iteration 151, loss = 5210816.57987241\n",
            "Iteration 152, loss = 5247299.34057876\n",
            "Iteration 153, loss = 5239485.66792497\n",
            "Iteration 154, loss = 5212109.48379670\n",
            "Iteration 155, loss = 5259590.54790409\n",
            "Iteration 156, loss = 5302731.59784621\n",
            "Iteration 157, loss = 5219089.82689354\n",
            "Iteration 158, loss = 5231924.15700878\n",
            "Iteration 159, loss = 5187114.57764650\n",
            "Iteration 160, loss = 5202424.25757315\n",
            "Iteration 161, loss = 5225407.37961083\n",
            "Iteration 162, loss = 5217582.20344767\n",
            "Iteration 163, loss = 5250857.09213068\n",
            "Iteration 164, loss = 5445953.06012161\n",
            "Iteration 165, loss = 5177736.35941583\n",
            "Iteration 166, loss = 5441657.21853863\n",
            "Iteration 167, loss = 5386246.32244746\n",
            "Iteration 168, loss = 5254711.96689987\n",
            "Iteration 169, loss = 5170840.21127488\n",
            "Iteration 170, loss = 5209957.25917233\n",
            "Iteration 171, loss = 5205632.60690553\n",
            "Iteration 172, loss = 5192784.60473272\n",
            "Iteration 173, loss = 5184268.35570004\n",
            "Iteration 174, loss = 5177346.25037135\n",
            "Iteration 175, loss = 5173377.21460847\n",
            "Iteration 176, loss = 5161540.17449805\n",
            "Iteration 177, loss = 5157480.58029668\n",
            "Iteration 178, loss = 5153299.41592319\n",
            "Iteration 179, loss = 5150211.00264081\n",
            "Iteration 180, loss = 5153532.19734359\n",
            "Iteration 181, loss = 5167576.37183056\n",
            "Iteration 182, loss = 5159864.63973540\n",
            "Iteration 183, loss = 5205670.63375798\n",
            "Iteration 184, loss = 5204745.41125059\n",
            "Iteration 185, loss = 5334464.15692855\n",
            "Iteration 186, loss = 5496109.60254448\n",
            "Iteration 187, loss = 5235515.22043873\n",
            "Iteration 188, loss = 5369785.65137103\n",
            "Iteration 189, loss = 5175764.55416372\n",
            "Iteration 190, loss = 5278518.44167323\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538791927.98788929\n",
            "Iteration 2, loss = 1538734626.35341144\n",
            "Iteration 3, loss = 1538676293.89232230\n",
            "Iteration 4, loss = 1538618116.89535689\n",
            "Iteration 5, loss = 1538558758.66657615\n",
            "Iteration 6, loss = 1538498492.70055842\n",
            "Iteration 7, loss = 1538438109.86007595\n",
            "Iteration 8, loss = 1538374054.59284973\n",
            "Iteration 9, loss = 1538310530.39168882\n",
            "Iteration 10, loss = 1538245186.18783903\n",
            "Iteration 11, loss = 1538177355.06508470\n",
            "Iteration 12, loss = 1538106720.09465456\n",
            "Iteration 13, loss = 1538035156.79691839\n",
            "Iteration 14, loss = 1537960891.08175778\n",
            "Iteration 15, loss = 1537885015.99854922\n",
            "Iteration 16, loss = 1537805684.25216031\n",
            "Iteration 17, loss = 1537725355.64483714\n",
            "Iteration 18, loss = 1537643217.06969810\n",
            "Iteration 19, loss = 1537558403.74566340\n",
            "Iteration 20, loss = 1537471741.81318355\n",
            "Iteration 21, loss = 1537384702.78101110\n",
            "Iteration 22, loss = 1537294670.95729923\n",
            "Iteration 23, loss = 1537205499.58098841\n",
            "Iteration 24, loss = 1537112639.25110364\n",
            "Iteration 25, loss = 1537021857.25549030\n",
            "Iteration 26, loss = 1536926033.53933549\n",
            "Iteration 27, loss = 1536832225.29554605\n",
            "Iteration 28, loss = 1536737341.20788074\n",
            "Iteration 29, loss = 1536641078.26257324\n",
            "Iteration 30, loss = 1536544600.78226542\n",
            "Iteration 31, loss = 1536446497.34136367\n",
            "Iteration 32, loss = 1536347197.69628835\n",
            "Iteration 33, loss = 1536249289.73348618\n",
            "Iteration 34, loss = 1536150477.41198611\n",
            "Iteration 35, loss = 1536048780.15181231\n",
            "Iteration 36, loss = 1535949035.84446096\n",
            "Iteration 37, loss = 1535847950.05145240\n",
            "Iteration 38, loss = 1535745185.85057950\n",
            "Iteration 39, loss = 1535643677.82424402\n",
            "Iteration 40, loss = 1535542115.71178198\n",
            "Iteration 41, loss = 1535435950.96688151\n",
            "Iteration 42, loss = 1535332937.96114826\n",
            "Iteration 43, loss = 1535226704.20497131\n",
            "Iteration 44, loss = 1535121420.93745041\n",
            "Iteration 45, loss = 1535012444.34738564\n",
            "Iteration 46, loss = 1534903217.58564305\n",
            "Iteration 47, loss = 1534791432.89916420\n",
            "Iteration 48, loss = 1534678881.63997436\n",
            "Iteration 49, loss = 1534563086.94084716\n",
            "Iteration 50, loss = 1534446397.87665153\n",
            "Iteration 51, loss = 1534326779.64426279\n",
            "Iteration 52, loss = 1534205405.75883794\n",
            "Iteration 53, loss = 1534082461.10703278\n",
            "Iteration 54, loss = 1533956728.45034099\n",
            "Iteration 55, loss = 1533829346.89578128\n",
            "Iteration 56, loss = 1533699956.70142055\n",
            "Iteration 57, loss = 1533568790.80407500\n",
            "Iteration 58, loss = 1533435068.08232307\n",
            "Iteration 59, loss = 1533298887.69682670\n",
            "Iteration 60, loss = 1533161342.88593483\n",
            "Iteration 61, loss = 1533022455.90552330\n",
            "Iteration 62, loss = 1532884007.28632188\n",
            "Iteration 63, loss = 1532743087.13414955\n",
            "Iteration 64, loss = 1532602360.84998488\n",
            "Iteration 65, loss = 1532461232.34021688\n",
            "Iteration 66, loss = 1532319609.83401608\n",
            "Iteration 67, loss = 1532177835.19836855\n",
            "Iteration 68, loss = 1532035629.73775911\n",
            "Iteration 69, loss = 1531893167.19685650\n",
            "Iteration 70, loss = 1531750283.35300064\n",
            "Iteration 71, loss = 1531607762.90017080\n",
            "Iteration 72, loss = 1531465048.50686502\n",
            "Iteration 73, loss = 1531322767.20159006\n",
            "Iteration 74, loss = 1531181018.40373898\n",
            "Iteration 75, loss = 1531037486.58509326\n",
            "Iteration 76, loss = 1530896193.56622672\n",
            "Iteration 77, loss = 1530754068.91641641\n",
            "Iteration 78, loss = 1530612198.92413211\n",
            "Iteration 79, loss = 1530470799.42839074\n",
            "Iteration 80, loss = 1530329478.44426584\n",
            "Iteration 81, loss = 1530188140.24156713\n",
            "Iteration 82, loss = 1530046034.79602051\n",
            "Iteration 83, loss = 1529905675.22404885\n",
            "Iteration 84, loss = 1529763120.00134778\n",
            "Iteration 85, loss = 1529621416.27778840\n",
            "Iteration 86, loss = 1529479461.36695862\n",
            "Iteration 87, loss = 1529338148.54889631\n",
            "Iteration 88, loss = 1529197248.40223670\n",
            "Iteration 89, loss = 1529055603.58164501\n",
            "Iteration 90, loss = 1528914469.65955353\n",
            "Iteration 91, loss = 1528774083.54037237\n",
            "Iteration 92, loss = 1528633287.78716540\n",
            "Iteration 93, loss = 1528492422.52435470\n",
            "Iteration 94, loss = 1528352562.37004828\n",
            "Iteration 95, loss = 1528213027.14220405\n",
            "Iteration 96, loss = 1528072339.45302892\n",
            "Iteration 97, loss = 1527932592.50473833\n",
            "Iteration 98, loss = 1527793368.63724709\n",
            "Iteration 99, loss = 1527654559.48114729\n",
            "Iteration 100, loss = 1527516312.26761413\n",
            "Iteration 101, loss = 1527378080.80629635\n",
            "Iteration 102, loss = 1527240742.98239565\n",
            "Iteration 103, loss = 1527103447.12282038\n",
            "Iteration 104, loss = 1526966887.15043759\n",
            "Iteration 105, loss = 1526829414.74422479\n",
            "Iteration 106, loss = 1526693227.08907342\n",
            "Iteration 107, loss = 1526557107.75801039\n",
            "Iteration 108, loss = 1526420389.69648814\n",
            "Iteration 109, loss = 1526284557.54808140\n",
            "Iteration 110, loss = 1526148868.04402709\n",
            "Iteration 111, loss = 1526012942.68879533\n",
            "Iteration 112, loss = 1525877321.76105142\n",
            "Iteration 113, loss = 1525742465.04240918\n",
            "Iteration 114, loss = 1525607372.90056372\n",
            "Iteration 115, loss = 1525472215.70588374\n",
            "Iteration 116, loss = 1525337732.24819851\n",
            "Iteration 117, loss = 1525204048.88623452\n",
            "Iteration 118, loss = 1525069734.86672735\n",
            "Iteration 119, loss = 1524936837.98697901\n",
            "Iteration 120, loss = 1524802922.23958111\n",
            "Iteration 121, loss = 1524669811.08354259\n",
            "Iteration 122, loss = 1524536486.13185906\n",
            "Iteration 123, loss = 1524403783.90206957\n",
            "Iteration 124, loss = 1524270817.06349206\n",
            "Iteration 125, loss = 1524137095.58611655\n",
            "Iteration 126, loss = 1524004770.96175385\n",
            "Iteration 127, loss = 1523872734.48919320\n",
            "Iteration 128, loss = 1523740081.86098361\n",
            "Iteration 129, loss = 1523608082.33700967\n",
            "Iteration 130, loss = 1523476921.48292637\n",
            "Iteration 131, loss = 1523344992.24716449\n",
            "Iteration 132, loss = 1523215039.68738079\n",
            "Iteration 133, loss = 1523083360.55747104\n",
            "Iteration 134, loss = 1522953066.93185115\n",
            "Iteration 135, loss = 1522821992.75638366\n",
            "Iteration 136, loss = 1522691196.73313689\n",
            "Iteration 137, loss = 1522560471.54163241\n",
            "Iteration 138, loss = 1522429588.93738961\n",
            "Iteration 139, loss = 1522298627.42500877\n",
            "Iteration 140, loss = 1522167872.24953699\n",
            "Iteration 141, loss = 1522038925.56974149\n",
            "Iteration 142, loss = 1521907095.15974832\n",
            "Iteration 143, loss = 1521778015.61519432\n",
            "Iteration 144, loss = 1521648095.60622692\n",
            "Iteration 145, loss = 1521518002.20601678\n",
            "Iteration 146, loss = 1521388957.45799208\n",
            "Iteration 147, loss = 1521258814.96981645\n",
            "Iteration 148, loss = 1521129434.93078613\n",
            "Iteration 149, loss = 1520999894.64190364\n",
            "Iteration 150, loss = 1520871603.72561073\n",
            "Iteration 151, loss = 1520741163.47146106\n",
            "Iteration 152, loss = 1520613484.91781855\n",
            "Iteration 153, loss = 1520484189.25593662\n",
            "Iteration 154, loss = 1520356053.46149540\n",
            "Iteration 155, loss = 1520228041.82464433\n",
            "Iteration 156, loss = 1520100378.82002997\n",
            "Iteration 157, loss = 1519972443.76424575\n",
            "Iteration 158, loss = 1519845163.99744415\n",
            "Iteration 159, loss = 1519717556.43632126\n",
            "Iteration 160, loss = 1519590824.65347004\n",
            "Iteration 161, loss = 1519463097.32706022\n",
            "Iteration 162, loss = 1519336378.79221845\n",
            "Iteration 163, loss = 1519209141.39150143\n",
            "Iteration 164, loss = 1519083337.52697396\n",
            "Iteration 165, loss = 1518955171.69928145\n",
            "Iteration 166, loss = 1518830172.63708639\n",
            "Iteration 167, loss = 1518703009.75592136\n",
            "Iteration 168, loss = 1518577223.29863262\n",
            "Iteration 169, loss = 1518451588.89623857\n",
            "Iteration 170, loss = 1518325228.62767529\n",
            "Iteration 171, loss = 1518199456.83054948\n",
            "Iteration 172, loss = 1518074459.69109368\n",
            "Iteration 173, loss = 1517948570.10791183\n",
            "Iteration 174, loss = 1517822799.43772745\n",
            "Iteration 175, loss = 1517697787.84586668\n",
            "Iteration 176, loss = 1517573229.26357484\n",
            "Iteration 177, loss = 1517447305.74493957\n",
            "Iteration 178, loss = 1517322592.63331079\n",
            "Iteration 179, loss = 1517197552.90958667\n",
            "Iteration 180, loss = 1517073772.77725601\n",
            "Iteration 181, loss = 1516948833.53010321\n",
            "Iteration 182, loss = 1516824783.97870469\n",
            "Iteration 183, loss = 1516700637.86291218\n",
            "Iteration 184, loss = 1516576538.02531195\n",
            "Iteration 185, loss = 1516452677.24979973\n",
            "Iteration 186, loss = 1516328953.60564518\n",
            "Iteration 187, loss = 1516205163.13893461\n",
            "Iteration 188, loss = 1516082196.36305857\n",
            "Iteration 189, loss = 1515958268.85675216\n",
            "Iteration 190, loss = 1515834600.12667251\n",
            "Iteration 191, loss = 1515711523.40548897\n",
            "Iteration 192, loss = 1515588224.06078076\n",
            "Iteration 193, loss = 1515465397.78340054\n",
            "Iteration 194, loss = 1515342315.45816875\n",
            "Iteration 195, loss = 1515219352.73678756\n",
            "Iteration 196, loss = 1515096869.71948624\n",
            "Iteration 197, loss = 1514973908.83463359\n",
            "Iteration 198, loss = 1514852437.88774395\n",
            "Iteration 199, loss = 1514729830.43898225\n",
            "Iteration 200, loss = 1514607541.95301414\n",
            "Iteration 201, loss = 1514485684.10370064\n",
            "Iteration 202, loss = 1514363794.74284768\n",
            "Iteration 203, loss = 1514241920.70331216\n",
            "Iteration 204, loss = 1514120290.74273396\n",
            "Iteration 205, loss = 1513998427.64919639\n",
            "Iteration 206, loss = 1513877065.54009032\n",
            "Iteration 207, loss = 1513755935.68913889\n",
            "Iteration 208, loss = 1513634212.20580506\n",
            "Iteration 209, loss = 1513513706.24069476\n",
            "Iteration 210, loss = 1513392532.01874232\n",
            "Iteration 211, loss = 1513272160.27653360\n",
            "Iteration 212, loss = 1513151037.61255431\n",
            "Iteration 213, loss = 1513030607.48745203\n",
            "Iteration 214, loss = 1512910271.05839348\n",
            "Iteration 215, loss = 1512789030.66044402\n",
            "Iteration 216, loss = 1512669156.94515824\n",
            "Iteration 217, loss = 1512548351.08513212\n",
            "Iteration 218, loss = 1512427753.28145075\n",
            "Iteration 219, loss = 1512307695.56862974\n",
            "Iteration 220, loss = 1512186193.96282458\n",
            "Iteration 221, loss = 1512066827.13807583\n",
            "Iteration 222, loss = 1511945514.86492753\n",
            "Iteration 223, loss = 1511825728.42610931\n",
            "Iteration 224, loss = 1511705049.62868118\n",
            "Iteration 225, loss = 1511584695.97395754\n",
            "Iteration 226, loss = 1511464742.69264317\n",
            "Iteration 227, loss = 1511344245.98085761\n",
            "Iteration 228, loss = 1511224067.75887895\n",
            "Iteration 229, loss = 1511104222.21996236\n",
            "Iteration 230, loss = 1510984721.42994022\n",
            "Iteration 231, loss = 1510864586.10939384\n",
            "Iteration 232, loss = 1510745580.88359356\n",
            "Iteration 233, loss = 1510626375.97382402\n",
            "Iteration 234, loss = 1510506674.36457300\n",
            "Iteration 235, loss = 1510388293.84438753\n",
            "Iteration 236, loss = 1510269035.96393466\n",
            "Iteration 237, loss = 1510150422.83754039\n",
            "Iteration 238, loss = 1510030484.33998656\n",
            "Iteration 239, loss = 1509911734.06837296\n",
            "Iteration 240, loss = 1509793563.70256829\n",
            "Iteration 241, loss = 1509673972.74306512\n",
            "Iteration 242, loss = 1509555155.89497185\n",
            "Iteration 243, loss = 1509436240.81667948\n",
            "Iteration 244, loss = 1509318273.58200598\n",
            "Iteration 245, loss = 1509199488.65849996\n",
            "Iteration 246, loss = 1509081968.17866993\n",
            "Iteration 247, loss = 1508963781.80959320\n",
            "Iteration 248, loss = 1508845525.01123381\n",
            "Iteration 249, loss = 1508728574.78594923\n",
            "Iteration 250, loss = 1508610542.49855947\n",
            "Iteration 251, loss = 1508493471.56368303\n",
            "Iteration 252, loss = 1508375516.75031757\n",
            "Iteration 253, loss = 1508257705.50405836\n",
            "Iteration 254, loss = 1508140894.44662428\n",
            "Iteration 255, loss = 1508022705.64830446\n",
            "Iteration 256, loss = 1507905112.79615855\n",
            "Iteration 257, loss = 1507787763.27362776\n",
            "Iteration 258, loss = 1507671071.30362797\n",
            "Iteration 259, loss = 1507553635.98355508\n",
            "Iteration 260, loss = 1507436137.84399295\n",
            "Iteration 261, loss = 1507319027.42068338\n",
            "Iteration 262, loss = 1507201892.23287868\n",
            "Iteration 263, loss = 1507086368.74612474\n",
            "Iteration 264, loss = 1506969010.67203093\n",
            "Iteration 265, loss = 1506852145.89878416\n",
            "Iteration 266, loss = 1506735600.91074085\n",
            "Iteration 267, loss = 1506620328.19904113\n",
            "Iteration 268, loss = 1506503282.91081786\n",
            "Iteration 269, loss = 1506386676.87742162\n",
            "Iteration 270, loss = 1506271275.33403730\n",
            "Iteration 271, loss = 1506154694.85104847\n",
            "Iteration 272, loss = 1506037641.61724973\n",
            "Iteration 273, loss = 1505922466.23328185\n",
            "Iteration 274, loss = 1505805474.28675675\n",
            "Iteration 275, loss = 1505688851.15970421\n",
            "Iteration 276, loss = 1505572912.95233655\n",
            "Iteration 277, loss = 1505456296.19009566\n",
            "Iteration 278, loss = 1505339371.68170404\n",
            "Iteration 279, loss = 1505223439.25728464\n",
            "Iteration 280, loss = 1505105971.11422920\n",
            "Iteration 281, loss = 1504989656.56671333\n",
            "Iteration 282, loss = 1504873195.15106750\n",
            "Iteration 283, loss = 1504757029.39675713\n",
            "Iteration 284, loss = 1504639704.53137493\n",
            "Iteration 285, loss = 1504524209.07735467\n",
            "Iteration 286, loss = 1504407743.39446998\n",
            "Iteration 287, loss = 1504291703.03161383\n",
            "Iteration 288, loss = 1504175868.56232238\n",
            "Iteration 289, loss = 1504059890.55932260\n",
            "Iteration 290, loss = 1503944425.55205393\n",
            "Iteration 291, loss = 1503828345.07520843\n",
            "Iteration 292, loss = 1503713115.28495288\n",
            "Iteration 293, loss = 1503596618.57686472\n",
            "Iteration 294, loss = 1503482190.57256746\n",
            "Iteration 295, loss = 1503365722.46115088\n",
            "Iteration 296, loss = 1503250179.43768454\n",
            "Iteration 297, loss = 1503134587.17724586\n",
            "Iteration 298, loss = 1503019523.87859297\n",
            "Iteration 299, loss = 1502903490.51417565\n",
            "Iteration 300, loss = 1502788216.70269632\n",
            "Iteration 301, loss = 1502673167.73534298\n",
            "Iteration 302, loss = 1502557654.16926670\n",
            "Iteration 303, loss = 1502442601.49199963\n",
            "Iteration 304, loss = 1502326753.88629866\n",
            "Iteration 305, loss = 1502211846.09615993\n",
            "Iteration 306, loss = 1502095451.24646640\n",
            "Iteration 307, loss = 1501980215.28111339\n",
            "Iteration 308, loss = 1501863509.25450110\n",
            "Iteration 309, loss = 1501748373.47040606\n",
            "Iteration 310, loss = 1501632843.20019650\n",
            "Iteration 311, loss = 1501516812.80188966\n",
            "Iteration 312, loss = 1501401736.87581205\n",
            "Iteration 313, loss = 1501286503.91864705\n",
            "Iteration 314, loss = 1501171968.46257138\n",
            "Iteration 315, loss = 1501056972.69241738\n",
            "Iteration 316, loss = 1500943721.42660356\n",
            "Iteration 317, loss = 1500828421.90869594\n",
            "Iteration 318, loss = 1500714014.79222703\n",
            "Iteration 319, loss = 1500600528.22141218\n",
            "Iteration 320, loss = 1500486277.56036448\n",
            "Iteration 321, loss = 1500371615.96915984\n",
            "Iteration 322, loss = 1500257986.79233909\n",
            "Iteration 323, loss = 1500143141.16387630\n",
            "Iteration 324, loss = 1500030154.10173702\n",
            "Iteration 325, loss = 1499915578.57470918\n",
            "Iteration 326, loss = 1499802289.89459443\n",
            "Iteration 327, loss = 1499688247.75875998\n",
            "Iteration 328, loss = 1499574535.90630889\n",
            "Iteration 329, loss = 1499460847.22330999\n",
            "Iteration 330, loss = 1499346569.96788716\n",
            "Iteration 331, loss = 1499232867.03031039\n",
            "Iteration 332, loss = 1499119259.01361632\n",
            "Iteration 333, loss = 1499005282.97326303\n",
            "Iteration 334, loss = 1498891185.61612701\n",
            "Iteration 335, loss = 1498777698.26672816\n",
            "Iteration 336, loss = 1498663540.18262482\n",
            "Iteration 337, loss = 1498549883.37623644\n",
            "Iteration 338, loss = 1498435950.23623085\n",
            "Iteration 339, loss = 1498322018.72010636\n",
            "Iteration 340, loss = 1498207801.54383826\n",
            "Iteration 341, loss = 1498094627.58173633\n",
            "Iteration 342, loss = 1497980465.33195448\n",
            "Iteration 343, loss = 1497866936.15722966\n",
            "Iteration 344, loss = 1497754014.70366740\n",
            "Iteration 345, loss = 1497640395.53919768\n",
            "Iteration 346, loss = 1497526978.23893642\n",
            "Iteration 347, loss = 1497413928.23117137\n",
            "Iteration 348, loss = 1497300099.86796856\n",
            "Iteration 349, loss = 1497188028.86836195\n",
            "Iteration 350, loss = 1497073491.25521660\n",
            "Iteration 351, loss = 1496960590.97071815\n",
            "Iteration 352, loss = 1496847162.01373172\n",
            "Iteration 353, loss = 1496734500.54516363\n",
            "Iteration 354, loss = 1496621340.83976197\n",
            "Iteration 355, loss = 1496507957.53121042\n",
            "Iteration 356, loss = 1496395432.44496417\n",
            "Iteration 357, loss = 1496282360.25633359\n",
            "Iteration 358, loss = 1496170506.45033860\n",
            "Iteration 359, loss = 1496057000.48203135\n",
            "Iteration 360, loss = 1495944953.74389768\n",
            "Iteration 361, loss = 1495831594.81445718\n",
            "Iteration 362, loss = 1495719291.25555062\n",
            "Iteration 363, loss = 1495606366.11333895\n",
            "Iteration 364, loss = 1495493827.86756253\n",
            "Iteration 365, loss = 1495380874.14765310\n",
            "Iteration 366, loss = 1495268596.30393600\n",
            "Iteration 367, loss = 1495156569.90515471\n",
            "Iteration 368, loss = 1495043751.90389323\n",
            "Iteration 369, loss = 1494931724.06955075\n",
            "Iteration 370, loss = 1494819600.19123411\n",
            "Iteration 371, loss = 1494707364.05554986\n",
            "Iteration 372, loss = 1494594958.05275369\n",
            "Iteration 373, loss = 1494483139.66169310\n",
            "Iteration 374, loss = 1494370297.71053743\n",
            "Iteration 375, loss = 1494257926.69588780\n",
            "Iteration 376, loss = 1494145824.48043561\n",
            "Iteration 377, loss = 1494034053.40942383\n",
            "Iteration 378, loss = 1493921264.82834005\n",
            "Iteration 379, loss = 1493809266.79886389\n",
            "Iteration 380, loss = 1493697182.33437395\n",
            "Iteration 381, loss = 1493584598.77783203\n",
            "Iteration 382, loss = 1493472222.71943307\n",
            "Iteration 383, loss = 1493359730.43339539\n",
            "Iteration 384, loss = 1493247004.96785498\n",
            "Iteration 385, loss = 1493135160.25027919\n",
            "Iteration 386, loss = 1493022316.76219940\n",
            "Iteration 387, loss = 1492910161.50627327\n",
            "Iteration 388, loss = 1492797656.84954071\n",
            "Iteration 389, loss = 1492684932.74729109\n",
            "Iteration 390, loss = 1492573337.19324636\n",
            "Iteration 391, loss = 1492460375.81505084\n",
            "Iteration 392, loss = 1492347916.84399557\n",
            "Iteration 393, loss = 1492236009.05494404\n",
            "Iteration 394, loss = 1492123187.89856601\n",
            "Iteration 395, loss = 1492011213.07004380\n",
            "Iteration 396, loss = 1491899942.80537343\n",
            "Iteration 397, loss = 1491788094.13212633\n",
            "Iteration 398, loss = 1491676119.11597252\n",
            "Iteration 399, loss = 1491565273.42078996\n",
            "Iteration 400, loss = 1491454160.30860019\n",
            "Iteration 401, loss = 1491343255.70367002\n",
            "Iteration 402, loss = 1491232492.57583070\n",
            "Iteration 403, loss = 1491121026.19871044\n",
            "Iteration 404, loss = 1491010699.23521543\n",
            "Iteration 405, loss = 1490899459.72424054\n",
            "Iteration 406, loss = 1490788729.72401834\n",
            "Iteration 407, loss = 1490677689.90764618\n",
            "Iteration 408, loss = 1490566345.31181431\n",
            "Iteration 409, loss = 1490455105.84010148\n",
            "Iteration 410, loss = 1490344534.77531886\n",
            "Iteration 411, loss = 1490233598.62865448\n",
            "Iteration 412, loss = 1490122369.47132611\n",
            "Iteration 413, loss = 1490011481.31765342\n",
            "Iteration 414, loss = 1489900804.46445227\n",
            "Iteration 415, loss = 1489789830.47906017\n",
            "Iteration 416, loss = 1489678966.53986883\n",
            "Iteration 417, loss = 1489568394.37139297\n",
            "Iteration 418, loss = 1489456799.33784819\n",
            "Iteration 419, loss = 1489345765.97113490\n",
            "Iteration 420, loss = 1489235444.38890576\n",
            "Iteration 421, loss = 1489124427.87895894\n",
            "Iteration 422, loss = 1489013801.69884086\n",
            "Iteration 423, loss = 1488902619.07221937\n",
            "Iteration 424, loss = 1488791603.96212173\n",
            "Iteration 425, loss = 1488680865.38581467\n",
            "Iteration 426, loss = 1488570074.64573574\n",
            "Iteration 427, loss = 1488458169.73063326\n",
            "Iteration 428, loss = 1488347371.85003090\n",
            "Iteration 429, loss = 1488235741.17093253\n",
            "Iteration 430, loss = 1488124877.83733845\n",
            "Iteration 431, loss = 1488013152.08604288\n",
            "Iteration 432, loss = 1487901650.18130708\n",
            "Iteration 433, loss = 1487790435.33508587\n",
            "Iteration 434, loss = 1487678905.11881876\n",
            "Iteration 435, loss = 1487567691.13597226\n",
            "Iteration 436, loss = 1487456318.35274506\n",
            "Iteration 437, loss = 1487345415.96853995\n",
            "Iteration 438, loss = 1487233907.49984884\n",
            "Iteration 439, loss = 1487122608.85558701\n",
            "Iteration 440, loss = 1487011744.91623235\n",
            "Iteration 441, loss = 1486900374.80760884\n",
            "Iteration 442, loss = 1486788988.84790349\n",
            "Iteration 443, loss = 1486677923.47389174\n",
            "Iteration 444, loss = 1486567074.07035613\n",
            "Iteration 445, loss = 1486455315.94590235\n",
            "Iteration 446, loss = 1486345132.84818912\n",
            "Iteration 447, loss = 1486233643.11192298\n",
            "Iteration 448, loss = 1486122810.09274578\n",
            "Iteration 449, loss = 1486013293.93680286\n",
            "Iteration 450, loss = 1485901961.82953882\n",
            "Iteration 451, loss = 1485791599.51800036\n",
            "Iteration 452, loss = 1485681038.82260633\n",
            "Iteration 453, loss = 1485570107.39331174\n",
            "Iteration 454, loss = 1485459602.03817344\n",
            "Iteration 455, loss = 1485349238.16648197\n",
            "Iteration 456, loss = 1485238643.12191129\n",
            "Iteration 457, loss = 1485128233.24717426\n",
            "Iteration 458, loss = 1485018161.47007322\n",
            "Iteration 459, loss = 1484907781.15770173\n",
            "Iteration 460, loss = 1484797309.42912960\n",
            "Iteration 461, loss = 1484686846.40713215\n",
            "Iteration 462, loss = 1484576764.86513519\n",
            "Iteration 463, loss = 1484466019.56124067\n",
            "Iteration 464, loss = 1484355402.80989528\n",
            "Iteration 465, loss = 1484245323.74557376\n",
            "Iteration 466, loss = 1484135239.57909179\n",
            "Iteration 467, loss = 1484025225.72375488\n",
            "Iteration 468, loss = 1483915062.41627598\n",
            "Iteration 469, loss = 1483805849.39800286\n",
            "Iteration 470, loss = 1483695521.87558365\n",
            "Iteration 471, loss = 1483586516.53822732\n",
            "Iteration 472, loss = 1483476056.23409534\n",
            "Iteration 473, loss = 1483365874.85777783\n",
            "Iteration 474, loss = 1483256366.10820293\n",
            "Iteration 475, loss = 1483145932.72040844\n",
            "Iteration 476, loss = 1483036330.16261077\n",
            "Iteration 477, loss = 1482926726.55671930\n",
            "Iteration 478, loss = 1482816292.05256987\n",
            "Iteration 479, loss = 1482706833.64144301\n",
            "Iteration 480, loss = 1482597679.03384471\n",
            "Iteration 481, loss = 1482488269.21073174\n",
            "Iteration 482, loss = 1482377755.70217419\n",
            "Iteration 483, loss = 1482268533.45586109\n",
            "Iteration 484, loss = 1482158829.63210821\n",
            "Iteration 485, loss = 1482048841.33711505\n",
            "Iteration 486, loss = 1481939675.98778415\n",
            "Iteration 487, loss = 1481829706.22653437\n",
            "Iteration 488, loss = 1481720060.28161597\n",
            "Iteration 489, loss = 1481610218.38193083\n",
            "Iteration 490, loss = 1481501261.46712399\n",
            "Iteration 491, loss = 1481391170.16923285\n",
            "Iteration 492, loss = 1481282027.94792676\n",
            "Iteration 493, loss = 1481172357.66262269\n",
            "Iteration 494, loss = 1481063669.33168983\n",
            "Iteration 495, loss = 1480953611.28785062\n",
            "Iteration 496, loss = 1480844153.21838188\n",
            "Iteration 497, loss = 1480735022.55773067\n",
            "Iteration 498, loss = 1480625994.78077507\n",
            "Iteration 499, loss = 1480516740.36896133\n",
            "Iteration 500, loss = 1480407291.55941463\n",
            "Iteration 501, loss = 1480297738.11548185\n",
            "Iteration 502, loss = 1480189412.04923415\n",
            "Iteration 503, loss = 1480078993.14589047\n",
            "Iteration 504, loss = 1479970534.50901842\n",
            "Iteration 505, loss = 1479861583.55140948\n",
            "Iteration 506, loss = 1479752118.08670568\n",
            "Iteration 507, loss = 1479642713.63600707\n",
            "Iteration 508, loss = 1479534408.24540734\n",
            "Iteration 509, loss = 1479424476.43906260\n",
            "Iteration 510, loss = 1479317032.10878706\n",
            "Iteration 511, loss = 1479207015.43349457\n",
            "Iteration 512, loss = 1479098662.00748849\n",
            "Iteration 513, loss = 1478990069.29821014\n",
            "Iteration 514, loss = 1478881385.45418024\n",
            "Iteration 515, loss = 1478772475.78664422\n",
            "Iteration 516, loss = 1478664032.57272220\n",
            "Iteration 517, loss = 1478555350.00893211\n",
            "Iteration 518, loss = 1478446331.08040285\n",
            "Iteration 519, loss = 1478338123.69118834\n",
            "Iteration 520, loss = 1478228617.60368705\n",
            "Iteration 521, loss = 1478119827.61287618\n",
            "Iteration 522, loss = 1478010097.47877884\n",
            "Iteration 523, loss = 1477901808.25618362\n",
            "Iteration 524, loss = 1477792117.97900033\n",
            "Iteration 525, loss = 1477683611.91844225\n",
            "Iteration 526, loss = 1477573879.06657028\n",
            "Iteration 527, loss = 1477464602.70598030\n",
            "Iteration 528, loss = 1477356143.76248193\n",
            "Iteration 529, loss = 1477246550.46197963\n",
            "Iteration 530, loss = 1477137273.34291553\n",
            "Iteration 531, loss = 1477028804.03702474\n",
            "Iteration 532, loss = 1476919938.65079093\n",
            "Iteration 533, loss = 1476810860.46706033\n",
            "Iteration 534, loss = 1476702568.90705991\n",
            "Iteration 535, loss = 1476593848.89803600\n",
            "Iteration 536, loss = 1476485459.20034933\n",
            "Iteration 537, loss = 1476376432.13788056\n",
            "Iteration 538, loss = 1476267646.39740658\n",
            "Iteration 539, loss = 1476159191.29435253\n",
            "Iteration 540, loss = 1476050935.76360798\n",
            "Iteration 541, loss = 1475942289.74825072\n",
            "Iteration 542, loss = 1475833903.90618873\n",
            "Iteration 543, loss = 1475724885.72250032\n",
            "Iteration 544, loss = 1475616858.71261144\n",
            "Iteration 545, loss = 1475508389.76436925\n",
            "Iteration 546, loss = 1475399506.50240541\n",
            "Iteration 547, loss = 1475291193.86649895\n",
            "Iteration 548, loss = 1475181946.93333507\n",
            "Iteration 549, loss = 1475073148.48566580\n",
            "Iteration 550, loss = 1474964280.20718360\n",
            "Iteration 551, loss = 1474855464.97700620\n",
            "Iteration 552, loss = 1474746628.15890336\n",
            "Iteration 553, loss = 1474638300.39735866\n",
            "Iteration 554, loss = 1474529029.81789780\n",
            "Iteration 555, loss = 1474420689.48573995\n",
            "Iteration 556, loss = 1474311956.34973478\n",
            "Iteration 557, loss = 1474203152.44991088\n",
            "Iteration 558, loss = 1474095139.04469323\n",
            "Iteration 559, loss = 1473986141.75677586\n",
            "Iteration 560, loss = 1473878436.11256194\n",
            "Iteration 561, loss = 1473769617.98046041\n",
            "Iteration 562, loss = 1473661860.21767616\n",
            "Iteration 563, loss = 1473552874.83957577\n",
            "Iteration 564, loss = 1473445402.02562141\n",
            "Iteration 565, loss = 1473337198.87675953\n",
            "Iteration 566, loss = 1473228649.72586322\n",
            "Iteration 567, loss = 1473120525.29003191\n",
            "Iteration 568, loss = 1473011521.12516975\n",
            "Iteration 569, loss = 1472902913.87479401\n",
            "Iteration 570, loss = 1472794220.19791484\n",
            "Iteration 571, loss = 1472686315.25055504\n",
            "Iteration 572, loss = 1472577000.58079839\n",
            "Iteration 573, loss = 1472468898.09903836\n",
            "Iteration 574, loss = 1472359867.00469160\n",
            "Iteration 575, loss = 1472252828.73922849\n",
            "Iteration 576, loss = 1472144134.80233884\n",
            "Iteration 577, loss = 1472036231.11500716\n",
            "Iteration 578, loss = 1471927664.13059068\n",
            "Iteration 579, loss = 1471820135.24760008\n",
            "Iteration 580, loss = 1471710748.83364511\n",
            "Iteration 581, loss = 1471603835.38020897\n",
            "Iteration 582, loss = 1471494836.84523177\n",
            "Iteration 583, loss = 1471385719.62780261\n",
            "Iteration 584, loss = 1471276896.04948473\n",
            "Iteration 585, loss = 1471169244.40251827\n",
            "Iteration 586, loss = 1471060213.51543927\n",
            "Iteration 587, loss = 1470951524.74680805\n",
            "Iteration 588, loss = 1470842858.30588698\n",
            "Iteration 589, loss = 1470735007.68825150\n",
            "Iteration 590, loss = 1470627206.16582704\n",
            "Iteration 591, loss = 1470518395.13977408\n",
            "Iteration 592, loss = 1470410537.35738516\n",
            "Iteration 593, loss = 1470303090.31647491\n",
            "Iteration 594, loss = 1470194471.93708897\n",
            "Iteration 595, loss = 1470086622.66645694\n",
            "Iteration 596, loss = 1469978954.66248035\n",
            "Iteration 597, loss = 1469870932.47520185\n",
            "Iteration 598, loss = 1469763741.11080790\n",
            "Iteration 599, loss = 1469655816.73225594\n",
            "Iteration 600, loss = 1469548600.01031160\n",
            "Iteration 601, loss = 1469441369.66291499\n",
            "Iteration 602, loss = 1469334117.60390329\n",
            "Iteration 603, loss = 1469226979.58452535\n",
            "Iteration 604, loss = 1469119596.17319465\n",
            "Iteration 605, loss = 1469011777.90706849\n",
            "Iteration 606, loss = 1468904772.82252836\n",
            "Iteration 607, loss = 1468796884.66940069\n",
            "Iteration 608, loss = 1468689633.91289949\n",
            "Iteration 609, loss = 1468581188.89763308\n",
            "Iteration 610, loss = 1468473684.61762142\n",
            "Iteration 611, loss = 1468365595.44864726\n",
            "Iteration 612, loss = 1468258742.43918347\n",
            "Iteration 613, loss = 1468149270.54304957\n",
            "Iteration 614, loss = 1468042467.47735262\n",
            "Iteration 615, loss = 1467934308.09051251\n",
            "Iteration 616, loss = 1467827099.22217941\n",
            "Iteration 617, loss = 1467719108.32159400\n",
            "Iteration 618, loss = 1467612567.23034358\n",
            "Iteration 619, loss = 1467505059.65472984\n",
            "Iteration 620, loss = 1467397897.49836373\n",
            "Iteration 621, loss = 1467290831.59564662\n",
            "Iteration 622, loss = 1467184189.11736584\n",
            "Iteration 623, loss = 1467076935.72628736\n",
            "Iteration 624, loss = 1466970319.40824008\n",
            "Iteration 625, loss = 1466863308.97248697\n",
            "Iteration 626, loss = 1466756669.79754329\n",
            "Iteration 627, loss = 1466649705.47777390\n",
            "Iteration 628, loss = 1466543123.02853203\n",
            "Iteration 629, loss = 1466435816.76857424\n",
            "Iteration 630, loss = 1466329093.73757005\n",
            "Iteration 631, loss = 1466222497.58107424\n",
            "Iteration 632, loss = 1466114625.67759967\n",
            "Iteration 633, loss = 1466007956.75432467\n",
            "Iteration 634, loss = 1465901059.83996868\n",
            "Iteration 635, loss = 1465793570.09904408\n",
            "Iteration 636, loss = 1465686214.45981717\n",
            "Iteration 637, loss = 1465579031.60876942\n",
            "Iteration 638, loss = 1465471309.61604667\n",
            "Iteration 639, loss = 1465363930.21430326\n",
            "Iteration 640, loss = 1465256513.97053909\n",
            "Iteration 641, loss = 1465148744.69450092\n",
            "Iteration 642, loss = 1465040870.37051034\n",
            "Iteration 643, loss = 1464933486.78966069\n",
            "Iteration 644, loss = 1464825691.41704988\n",
            "Iteration 645, loss = 1464717701.51445651\n",
            "Iteration 646, loss = 1464610446.74782157\n",
            "Iteration 647, loss = 1464502285.18018055\n",
            "Iteration 648, loss = 1464394749.68255663\n",
            "Iteration 649, loss = 1464287175.45039153\n",
            "Iteration 650, loss = 1464178951.07260418\n",
            "Iteration 651, loss = 1464071480.24513960\n",
            "Iteration 652, loss = 1463964161.52269053\n",
            "Iteration 653, loss = 1463857027.91476917\n",
            "Iteration 654, loss = 1463749483.70236111\n",
            "Iteration 655, loss = 1463641775.59622979\n",
            "Iteration 656, loss = 1463535112.34593177\n",
            "Iteration 657, loss = 1463428014.42667556\n",
            "Iteration 658, loss = 1463321510.08009529\n",
            "Iteration 659, loss = 1463214501.71299314\n",
            "Iteration 660, loss = 1463107498.34386849\n",
            "Iteration 661, loss = 1463000374.00172567\n",
            "Iteration 662, loss = 1462893876.37579274\n",
            "Iteration 663, loss = 1462786189.10627198\n",
            "Iteration 664, loss = 1462679381.95521355\n",
            "Iteration 665, loss = 1462572262.41956711\n",
            "Iteration 666, loss = 1462464191.36904478\n",
            "Iteration 667, loss = 1462357787.22316623\n",
            "Iteration 668, loss = 1462249887.44096899\n",
            "Iteration 669, loss = 1462141753.14151573\n",
            "Iteration 670, loss = 1462035125.80683732\n",
            "Iteration 671, loss = 1461927080.71002555\n",
            "Iteration 672, loss = 1461819740.85037637\n",
            "Iteration 673, loss = 1461711851.61769104\n",
            "Iteration 674, loss = 1461604160.01282287\n",
            "Iteration 675, loss = 1461496112.51359653\n",
            "Iteration 676, loss = 1461388309.69008160\n",
            "Iteration 677, loss = 1461280841.39630771\n",
            "Iteration 678, loss = 1461173443.37359858\n",
            "Iteration 679, loss = 1461065898.82709670\n",
            "Iteration 680, loss = 1460958518.23897958\n",
            "Iteration 681, loss = 1460852067.97608876\n",
            "Iteration 682, loss = 1460744456.15236521\n",
            "Iteration 683, loss = 1460638249.12620449\n",
            "Iteration 684, loss = 1460531171.30498481\n",
            "Iteration 685, loss = 1460425525.25743175\n",
            "Iteration 686, loss = 1460318096.13383818\n",
            "Iteration 687, loss = 1460212756.65490651\n",
            "Iteration 688, loss = 1460106251.66556811\n",
            "Iteration 689, loss = 1460000089.23287749\n",
            "Iteration 690, loss = 1459893849.72697854\n",
            "Iteration 691, loss = 1459787628.32701635\n",
            "Iteration 692, loss = 1459680907.61229730\n",
            "Iteration 693, loss = 1459575258.70460558\n",
            "Iteration 694, loss = 1459469441.16341901\n",
            "Iteration 695, loss = 1459363178.54361176\n",
            "Iteration 696, loss = 1459256848.80158186\n",
            "Iteration 697, loss = 1459151873.44952488\n",
            "Iteration 698, loss = 1459045693.08322287\n",
            "Iteration 699, loss = 1458939857.81092906\n",
            "Iteration 700, loss = 1458834075.97987604\n",
            "Iteration 701, loss = 1458727924.85447097\n",
            "Iteration 702, loss = 1458622064.57954097\n",
            "Iteration 703, loss = 1458514609.76521897\n",
            "Iteration 704, loss = 1458409516.74083829\n",
            "Iteration 705, loss = 1458302529.09724951\n",
            "Iteration 706, loss = 1458196259.18522644\n",
            "Iteration 707, loss = 1458089500.33793783\n",
            "Iteration 708, loss = 1457982691.85351324\n",
            "Iteration 709, loss = 1457877338.78255486\n",
            "Iteration 710, loss = 1457769363.23731542\n",
            "Iteration 711, loss = 1457663038.30036879\n",
            "Iteration 712, loss = 1457556863.35545731\n",
            "Iteration 713, loss = 1457449918.72345281\n",
            "Iteration 714, loss = 1457343586.04009700\n",
            "Iteration 715, loss = 1457236974.06820011\n",
            "Iteration 716, loss = 1457130763.93263316\n",
            "Iteration 717, loss = 1457024758.02770162\n",
            "Iteration 718, loss = 1456918218.58917284\n",
            "Iteration 719, loss = 1456811826.58790708\n",
            "Iteration 720, loss = 1456705922.27736139\n",
            "Iteration 721, loss = 1456599856.14889717\n",
            "Iteration 722, loss = 1456493611.26302433\n",
            "Iteration 723, loss = 1456386783.42145920\n",
            "Iteration 724, loss = 1456281285.60982680\n",
            "Iteration 725, loss = 1456174464.65497875\n",
            "Iteration 726, loss = 1456067895.43699265\n",
            "Iteration 727, loss = 1455962111.92967820\n",
            "Iteration 728, loss = 1455855170.81171703\n",
            "Iteration 729, loss = 1455749269.62605381\n",
            "Iteration 730, loss = 1455642376.89792442\n",
            "Iteration 731, loss = 1455535946.60030818\n",
            "Iteration 732, loss = 1455430020.57241416\n",
            "Iteration 733, loss = 1455323025.12455750\n",
            "Iteration 734, loss = 1455217075.85148001\n",
            "Iteration 735, loss = 1455109850.25011683\n",
            "Iteration 736, loss = 1455004074.76640439\n",
            "Iteration 737, loss = 1454897502.49788570\n",
            "Iteration 738, loss = 1454791266.79416895\n",
            "Iteration 739, loss = 1454684486.11595392\n",
            "Iteration 740, loss = 1454577875.55812716\n",
            "Iteration 741, loss = 1454471714.64334822\n",
            "Iteration 742, loss = 1454365406.42701888\n",
            "Iteration 743, loss = 1454258202.57431269\n",
            "Iteration 744, loss = 1454152175.80730629\n",
            "Iteration 745, loss = 1454045585.24320149\n",
            "Iteration 746, loss = 1453940314.42316222\n",
            "Iteration 747, loss = 1453833742.48760104\n",
            "Iteration 748, loss = 1453728124.17489505\n",
            "Iteration 749, loss = 1453622685.58546877\n",
            "Iteration 750, loss = 1453516893.91000891\n",
            "Iteration 751, loss = 1453411411.64549065\n",
            "Iteration 752, loss = 1453306362.29890633\n",
            "Iteration 753, loss = 1453200289.04817677\n",
            "Iteration 754, loss = 1453094779.98528337\n",
            "Iteration 755, loss = 1452989261.00084567\n",
            "Iteration 756, loss = 1452884016.23234510\n",
            "Iteration 757, loss = 1452778122.94718170\n",
            "Iteration 758, loss = 1452672942.89012623\n",
            "Iteration 759, loss = 1452567140.47738051\n",
            "Iteration 760, loss = 1452461575.61766601\n",
            "Iteration 761, loss = 1452356221.06963706\n",
            "Iteration 762, loss = 1452250531.43218088\n",
            "Iteration 763, loss = 1452145385.15830660\n",
            "Iteration 764, loss = 1452038962.60857940\n",
            "Iteration 765, loss = 1451933548.36690593\n",
            "Iteration 766, loss = 1451827747.68352628\n",
            "Iteration 767, loss = 1451721527.38676715\n",
            "Iteration 768, loss = 1451615691.29734421\n",
            "Iteration 769, loss = 1451509123.42091608\n",
            "Iteration 770, loss = 1451403111.04594707\n",
            "Iteration 771, loss = 1451296544.39194274\n",
            "Iteration 772, loss = 1451190415.01478362\n",
            "Iteration 773, loss = 1451083933.90186596\n",
            "Iteration 774, loss = 1450977456.97381043\n",
            "Iteration 775, loss = 1450871838.07078123\n",
            "Iteration 776, loss = 1450765426.64467454\n",
            "Iteration 777, loss = 1450660378.53296232\n",
            "Iteration 778, loss = 1450555133.18386459\n",
            "Iteration 779, loss = 1450449304.96860838\n",
            "Iteration 780, loss = 1450344150.63806939\n",
            "Iteration 781, loss = 1450239499.83832097\n",
            "Iteration 782, loss = 1450133642.83418322\n",
            "Iteration 783, loss = 1450029188.09554648\n",
            "Iteration 784, loss = 1449923372.83489871\n",
            "Iteration 785, loss = 1449818632.86406994\n",
            "Iteration 786, loss = 1449712353.13159561\n",
            "Iteration 787, loss = 1449607253.91668105\n",
            "Iteration 788, loss = 1449501981.11118174\n",
            "Iteration 789, loss = 1449396323.69700336\n",
            "Iteration 790, loss = 1449290828.71793628\n",
            "Iteration 791, loss = 1449185423.58276081\n",
            "Iteration 792, loss = 1449080156.21990681\n",
            "Iteration 793, loss = 1448975718.73473525\n",
            "Iteration 794, loss = 1448869329.28145123\n",
            "Iteration 795, loss = 1448764879.01161909\n",
            "Iteration 796, loss = 1448659371.79860306\n",
            "Iteration 797, loss = 1448554175.82129169\n",
            "Iteration 798, loss = 1448449280.77445006\n",
            "Iteration 799, loss = 1448342939.51985502\n",
            "Iteration 800, loss = 1448238016.90326667\n",
            "Iteration 801, loss = 1448132012.76291037\n",
            "Iteration 802, loss = 1448026228.63931108\n",
            "Iteration 803, loss = 1447921061.24684095\n",
            "Iteration 804, loss = 1447815504.74512005\n",
            "Iteration 805, loss = 1447710199.45593238\n",
            "Iteration 806, loss = 1447604485.02336836\n",
            "Iteration 807, loss = 1447499295.06541562\n",
            "Iteration 808, loss = 1447394502.61896801\n",
            "Iteration 809, loss = 1447288889.62246561\n",
            "Iteration 810, loss = 1447183554.22825408\n",
            "Iteration 811, loss = 1447078898.66022086\n",
            "Iteration 812, loss = 1446973319.38153458\n",
            "Iteration 813, loss = 1446868478.10862923\n",
            "Iteration 814, loss = 1446762082.46796227\n",
            "Iteration 815, loss = 1446657267.99539280\n",
            "Iteration 816, loss = 1446551920.14254403\n",
            "Iteration 817, loss = 1446445915.33198547\n",
            "Iteration 818, loss = 1446340333.96602440\n",
            "Iteration 819, loss = 1446235230.78377199\n",
            "Iteration 820, loss = 1446129271.32117295\n",
            "Iteration 821, loss = 1446023711.54759002\n",
            "Iteration 822, loss = 1445918431.72848630\n",
            "Iteration 823, loss = 1445813294.62209368\n",
            "Iteration 824, loss = 1445707621.52979755\n",
            "Iteration 825, loss = 1445602681.98355317\n",
            "Iteration 826, loss = 1445498065.94148755\n",
            "Iteration 827, loss = 1445392493.54488373\n",
            "Iteration 828, loss = 1445287757.93873286\n",
            "Iteration 829, loss = 1445182610.30868077\n",
            "Iteration 830, loss = 1445077872.61066341\n",
            "Iteration 831, loss = 1444972892.37585831\n",
            "Iteration 832, loss = 1444867592.58356714\n",
            "Iteration 833, loss = 1444762881.25533509\n",
            "Iteration 834, loss = 1444657875.21872139\n",
            "Iteration 835, loss = 1444552201.09994340\n",
            "Iteration 836, loss = 1444447568.37203574\n",
            "Iteration 837, loss = 1444342169.30105615\n",
            "Iteration 838, loss = 1444237077.58192611\n",
            "Iteration 839, loss = 1444131762.43486595\n",
            "Iteration 840, loss = 1444025822.65060210\n",
            "Iteration 841, loss = 1443921055.13387418\n",
            "Iteration 842, loss = 1443815726.14899182\n",
            "Iteration 843, loss = 1443710364.32828164\n",
            "Iteration 844, loss = 1443605444.44101334\n",
            "Iteration 845, loss = 1443500160.91242504\n",
            "Iteration 846, loss = 1443395502.78163338\n",
            "Iteration 847, loss = 1443290242.60301137\n",
            "Iteration 848, loss = 1443186077.29775476\n",
            "Iteration 849, loss = 1443080725.30184484\n",
            "Iteration 850, loss = 1442976115.24004078\n",
            "Iteration 851, loss = 1442870704.09953451\n",
            "Iteration 852, loss = 1442765963.48288059\n",
            "Iteration 853, loss = 1442660984.47667575\n",
            "Iteration 854, loss = 1442555768.89586949\n",
            "Iteration 855, loss = 1442451412.95760560\n",
            "Iteration 856, loss = 1442346060.67217851\n",
            "Iteration 857, loss = 1442241281.25024462\n",
            "Iteration 858, loss = 1442136371.52581096\n",
            "Iteration 859, loss = 1442031765.14924669\n",
            "Iteration 860, loss = 1441927177.50165081\n",
            "Iteration 861, loss = 1441822105.33582997\n",
            "Iteration 862, loss = 1441717278.20244050\n",
            "Iteration 863, loss = 1441613049.44515800\n",
            "Iteration 864, loss = 1441507499.65747166\n",
            "Iteration 865, loss = 1441402648.73051214\n",
            "Iteration 866, loss = 1441298264.11838722\n",
            "Iteration 867, loss = 1441191587.27665353\n",
            "Iteration 868, loss = 1441086962.01425886\n",
            "Iteration 869, loss = 1440981885.33600926\n",
            "Iteration 870, loss = 1440875312.90540886\n",
            "Iteration 871, loss = 1440770477.76562452\n",
            "Iteration 872, loss = 1440664379.60979223\n",
            "Iteration 873, loss = 1440558890.17165613\n",
            "Iteration 874, loss = 1440454154.52615380\n",
            "Iteration 875, loss = 1440348086.78753686\n",
            "Iteration 876, loss = 1440242892.40319180\n",
            "Iteration 877, loss = 1440137819.27791762\n",
            "Iteration 878, loss = 1440032710.35092330\n",
            "Iteration 879, loss = 1439927059.86002851\n",
            "Iteration 880, loss = 1439822223.46239305\n",
            "Iteration 881, loss = 1439716980.47612047\n",
            "Iteration 882, loss = 1439612450.47647357\n",
            "Iteration 883, loss = 1439506822.18572593\n",
            "Iteration 884, loss = 1439402135.20855808\n",
            "Iteration 885, loss = 1439297110.94235325\n",
            "Iteration 886, loss = 1439192093.44919086\n",
            "Iteration 887, loss = 1439086851.92343187\n",
            "Iteration 888, loss = 1438981722.44482994\n",
            "Iteration 889, loss = 1438876606.94391775\n",
            "Iteration 890, loss = 1438771457.91180038\n",
            "Iteration 891, loss = 1438665928.02172995\n",
            "Iteration 892, loss = 1438561198.64583826\n",
            "Iteration 893, loss = 1438456160.86391187\n",
            "Iteration 894, loss = 1438351415.66123462\n",
            "Iteration 895, loss = 1438247461.26811957\n",
            "Iteration 896, loss = 1438142122.45981073\n",
            "Iteration 897, loss = 1438038779.74749827\n",
            "Iteration 898, loss = 1437934324.93248940\n",
            "Iteration 899, loss = 1437829564.95093060\n",
            "Iteration 900, loss = 1437725726.15281558\n",
            "Iteration 901, loss = 1437621405.60281634\n",
            "Iteration 902, loss = 1437516716.66278744\n",
            "Iteration 903, loss = 1437412448.07484484\n",
            "Iteration 904, loss = 1437307650.72563434\n",
            "Iteration 905, loss = 1437203450.63254046\n",
            "Iteration 906, loss = 1437098973.45804262\n",
            "Iteration 907, loss = 1436994106.61960387\n",
            "Iteration 908, loss = 1436889899.64321661\n",
            "Iteration 909, loss = 1436785177.80381703\n",
            "Iteration 910, loss = 1436681562.44232035\n",
            "Iteration 911, loss = 1436576863.87159514\n",
            "Iteration 912, loss = 1436473151.92689252\n",
            "Iteration 913, loss = 1436369280.81469631\n",
            "Iteration 914, loss = 1436266030.24220157\n",
            "Iteration 915, loss = 1436162292.33493662\n",
            "Iteration 916, loss = 1436058766.64330387\n",
            "Iteration 917, loss = 1435954773.61042356\n",
            "Iteration 918, loss = 1435850754.57779026\n",
            "Iteration 919, loss = 1435747523.35523701\n",
            "Iteration 920, loss = 1435643309.99201179\n",
            "Iteration 921, loss = 1435539225.16815400\n",
            "Iteration 922, loss = 1435434885.70330143\n",
            "Iteration 923, loss = 1435331273.81693888\n",
            "Iteration 924, loss = 1435227273.38817096\n",
            "Iteration 925, loss = 1435122683.42141938\n",
            "Iteration 926, loss = 1435017954.68933463\n",
            "Iteration 927, loss = 1434915120.64257646\n",
            "Iteration 928, loss = 1434810714.00611711\n",
            "Iteration 929, loss = 1434706422.79850268\n",
            "Iteration 930, loss = 1434603195.34591746\n",
            "Iteration 931, loss = 1434498432.50979042\n",
            "Iteration 932, loss = 1434395422.41077304\n",
            "Iteration 933, loss = 1434291112.85685825\n",
            "Iteration 934, loss = 1434186958.80490971\n",
            "Iteration 935, loss = 1434082622.07529235\n",
            "Iteration 936, loss = 1433979262.36422825\n",
            "Iteration 937, loss = 1433874117.01273036\n",
            "Iteration 938, loss = 1433770849.39678288\n",
            "Iteration 939, loss = 1433665333.00588799\n",
            "Iteration 940, loss = 1433561527.25224280\n",
            "Iteration 941, loss = 1433457569.29424834\n",
            "Iteration 942, loss = 1433353096.85001111\n",
            "Iteration 943, loss = 1433249370.81067443\n",
            "Iteration 944, loss = 1433145318.64747691\n",
            "Iteration 945, loss = 1433041070.84052610\n",
            "Iteration 946, loss = 1432937959.40344286\n",
            "Iteration 947, loss = 1432833631.38365102\n",
            "Iteration 948, loss = 1432729673.98378110\n",
            "Iteration 949, loss = 1432625825.80399108\n",
            "Iteration 950, loss = 1432521994.52873158\n",
            "Iteration 951, loss = 1432417950.82733154\n",
            "Iteration 952, loss = 1432313478.46249819\n",
            "Iteration 953, loss = 1432209415.03346419\n",
            "Iteration 954, loss = 1432105062.29857874\n",
            "Iteration 955, loss = 1432000442.80440402\n",
            "Iteration 956, loss = 1431895961.83766437\n",
            "Iteration 957, loss = 1431791516.22307682\n",
            "Iteration 958, loss = 1431686456.59124088\n",
            "Iteration 959, loss = 1431582147.99510479\n",
            "Iteration 960, loss = 1431477158.93935752\n",
            "Iteration 961, loss = 1431372778.01675630\n",
            "Iteration 962, loss = 1431268009.71073127\n",
            "Iteration 963, loss = 1431164114.31275773\n",
            "Iteration 964, loss = 1431059581.94406748\n",
            "Iteration 965, loss = 1430955090.54494572\n",
            "Iteration 966, loss = 1430851112.14131665\n",
            "Iteration 967, loss = 1430746390.27233005\n",
            "Iteration 968, loss = 1430643122.65937567\n",
            "Iteration 969, loss = 1430538222.25814700\n",
            "Iteration 970, loss = 1430434897.41770291\n",
            "Iteration 971, loss = 1430331073.80524349\n",
            "Iteration 972, loss = 1430227378.44000435\n",
            "Iteration 973, loss = 1430124253.70820713\n",
            "Iteration 974, loss = 1430019602.49172711\n",
            "Iteration 975, loss = 1429916549.02849197\n",
            "Iteration 976, loss = 1429812539.17064714\n",
            "Iteration 977, loss = 1429708778.15233374\n",
            "Iteration 978, loss = 1429604995.01167154\n",
            "Iteration 979, loss = 1429500181.97487521\n",
            "Iteration 980, loss = 1429396391.64516306\n",
            "Iteration 981, loss = 1429292385.54356241\n",
            "Iteration 982, loss = 1429188465.43725634\n",
            "Iteration 983, loss = 1429084023.25718999\n",
            "Iteration 984, loss = 1428980053.60088968\n",
            "Iteration 985, loss = 1428876124.68086290\n",
            "Iteration 986, loss = 1428772559.73905778\n",
            "Iteration 987, loss = 1428667852.19083905\n",
            "Iteration 988, loss = 1428564699.09026766\n",
            "Iteration 989, loss = 1428459756.02526259\n",
            "Iteration 990, loss = 1428356243.86188078\n",
            "Iteration 991, loss = 1428252033.78630233\n",
            "Iteration 992, loss = 1428148282.92272258\n",
            "Iteration 993, loss = 1428043143.71456385\n",
            "Iteration 994, loss = 1427939886.99831653\n",
            "Iteration 995, loss = 1427834973.21617913\n",
            "Iteration 996, loss = 1427731359.90602088\n",
            "Iteration 997, loss = 1427626956.55968523\n",
            "Iteration 998, loss = 1427523384.45815706\n",
            "Iteration 999, loss = 1427419502.93952227\n",
            "Iteration 1000, loss = 1427316183.42795849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1341355140.71593261\n",
            "Iteration 2, loss = 1472484517.29157376\n",
            "Iteration 3, loss = 548411320.51803148\n",
            "Iteration 4, loss = 187783521.17340016\n",
            "Iteration 5, loss = 25289751.03141663\n",
            "Iteration 6, loss = 59514106.95233542\n",
            "Iteration 7, loss = 109366928.67227170\n",
            "Iteration 8, loss = 96537775.35790254\n",
            "Iteration 9, loss = 59596333.04188760\n",
            "Iteration 10, loss = 26555084.45158868\n",
            "Iteration 11, loss = 15468410.77180151\n",
            "Iteration 12, loss = 19485849.04934930\n",
            "Iteration 13, loss = 24001712.45920524\n",
            "Iteration 14, loss = 23074540.52010744\n",
            "Iteration 15, loss = 18393675.23880045\n",
            "Iteration 16, loss = 14097750.74935436\n",
            "Iteration 17, loss = 12452016.94402552\n",
            "Iteration 18, loss = 12576077.31763015\n",
            "Iteration 19, loss = 12865284.57295675\n",
            "Iteration 20, loss = 12785369.57347105\n",
            "Iteration 21, loss = 11659531.40315565\n",
            "Iteration 22, loss = 10643200.62989685\n",
            "Iteration 23, loss = 12239065.72922985\n",
            "Iteration 24, loss = 11279933.66260646\n",
            "Iteration 25, loss = 11061566.68962733\n",
            "Iteration 26, loss = 10817701.64819806\n",
            "Iteration 27, loss = 10450919.87907746\n",
            "Iteration 28, loss = 10165420.51206456\n",
            "Iteration 29, loss = 9812634.66563624\n",
            "Iteration 30, loss = 9549265.03421134\n",
            "Iteration 31, loss = 9314555.86385725\n",
            "Iteration 32, loss = 9098788.76630102\n",
            "Iteration 33, loss = 8881199.25795122\n",
            "Iteration 34, loss = 8636900.17511477\n",
            "Iteration 35, loss = 8321604.63426452\n",
            "Iteration 36, loss = 8169689.46044244\n",
            "Iteration 37, loss = 8168979.90604200\n",
            "Iteration 38, loss = 7985597.10114912\n",
            "Iteration 39, loss = 7881247.06839783\n",
            "Iteration 40, loss = 7864442.60156733\n",
            "Iteration 41, loss = 7516773.05059151\n",
            "Iteration 42, loss = 7266887.06234461\n",
            "Iteration 43, loss = 7128664.10029311\n",
            "Iteration 44, loss = 7070696.98594100\n",
            "Iteration 45, loss = 7115444.82405738\n",
            "Iteration 46, loss = 6903260.85262629\n",
            "Iteration 47, loss = 6711506.86099326\n",
            "Iteration 48, loss = 6794379.07525857\n",
            "Iteration 49, loss = 6609059.69968002\n",
            "Iteration 50, loss = 6716869.20012502\n",
            "Iteration 51, loss = 6559324.82160374\n",
            "Iteration 52, loss = 6539520.03409778\n",
            "Iteration 53, loss = 6431256.63670414\n",
            "Iteration 54, loss = 6390082.62169245\n",
            "Iteration 55, loss = 6344704.29252739\n",
            "Iteration 56, loss = 6307149.60166143\n",
            "Iteration 57, loss = 6278735.13311487\n",
            "Iteration 58, loss = 6280962.82569902\n",
            "Iteration 59, loss = 6188574.24644474\n",
            "Iteration 60, loss = 6202790.76929579\n",
            "Iteration 61, loss = 6166136.64648134\n",
            "Iteration 62, loss = 6136386.84523658\n",
            "Iteration 63, loss = 6108616.83499418\n",
            "Iteration 64, loss = 6126614.43839245\n",
            "Iteration 65, loss = 6102810.41819024\n",
            "Iteration 66, loss = 6081699.31993644\n",
            "Iteration 67, loss = 6081294.85299210\n",
            "Iteration 68, loss = 6029215.56423529\n",
            "Iteration 69, loss = 6003213.59709884\n",
            "Iteration 70, loss = 5986612.18353696\n",
            "Iteration 71, loss = 6048842.06624220\n",
            "Iteration 72, loss = 6143951.69022285\n",
            "Iteration 73, loss = 6407759.33146028\n",
            "Iteration 74, loss = 6501144.96314671\n",
            "Iteration 75, loss = 6470404.57054903\n",
            "Iteration 76, loss = 6472582.37551738\n",
            "Iteration 77, loss = 6477371.54720781\n",
            "Iteration 78, loss = 6470761.12508076\n",
            "Iteration 79, loss = 6390294.25760875\n",
            "Iteration 80, loss = 6356608.27705076\n",
            "Iteration 81, loss = 6356933.93223155\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538845387.62030005\n",
            "Iteration 2, loss = 1538788388.52155995\n",
            "Iteration 3, loss = 1538731279.63207054\n",
            "Iteration 4, loss = 1538673756.49434972\n",
            "Iteration 5, loss = 1538616230.16480064\n",
            "Iteration 6, loss = 1538558082.41857004\n",
            "Iteration 7, loss = 1538498435.53184533\n",
            "Iteration 8, loss = 1538437567.39204550\n",
            "Iteration 9, loss = 1538375255.89601636\n",
            "Iteration 10, loss = 1538311071.30571604\n",
            "Iteration 11, loss = 1538245471.89596772\n",
            "Iteration 12, loss = 1538176522.74238157\n",
            "Iteration 13, loss = 1538106188.60453248\n",
            "Iteration 14, loss = 1538034477.99119020\n",
            "Iteration 15, loss = 1537958821.74026418\n",
            "Iteration 16, loss = 1537880656.15214038\n",
            "Iteration 17, loss = 1537802701.40600657\n",
            "Iteration 18, loss = 1537720438.60210824\n",
            "Iteration 19, loss = 1537638004.65588808\n",
            "Iteration 20, loss = 1537551973.48144293\n",
            "Iteration 21, loss = 1537463589.53475165\n",
            "Iteration 22, loss = 1537375396.25693035\n",
            "Iteration 23, loss = 1537284135.24145889\n",
            "Iteration 24, loss = 1537192554.91687202\n",
            "Iteration 25, loss = 1537097450.59044290\n",
            "Iteration 26, loss = 1537003996.06001496\n",
            "Iteration 27, loss = 1536909462.65009809\n",
            "Iteration 28, loss = 1536814022.65979171\n",
            "Iteration 29, loss = 1536715591.19458699\n",
            "Iteration 30, loss = 1536619452.96971297\n",
            "Iteration 31, loss = 1536524351.13058305\n",
            "Iteration 32, loss = 1536425864.11155081\n",
            "Iteration 33, loss = 1536328173.33673644\n",
            "Iteration 34, loss = 1536230337.98042798\n",
            "Iteration 35, loss = 1536130408.59032202\n",
            "Iteration 36, loss = 1536030159.24655104\n",
            "Iteration 37, loss = 1535930022.56004453\n",
            "Iteration 38, loss = 1535828261.09272504\n",
            "Iteration 39, loss = 1535725943.10161901\n",
            "Iteration 40, loss = 1535621271.79959774\n",
            "Iteration 41, loss = 1535516652.32317638\n",
            "Iteration 42, loss = 1535410195.46568847\n",
            "Iteration 43, loss = 1535303121.70049644\n",
            "Iteration 44, loss = 1535194251.22869515\n",
            "Iteration 45, loss = 1535084642.39882851\n",
            "Iteration 46, loss = 1534972231.23459458\n",
            "Iteration 47, loss = 1534858395.12238574\n",
            "Iteration 48, loss = 1534743428.64612627\n",
            "Iteration 49, loss = 1534626070.82551575\n",
            "Iteration 50, loss = 1534506209.21182799\n",
            "Iteration 51, loss = 1534385377.47976041\n",
            "Iteration 52, loss = 1534262541.16863942\n",
            "Iteration 53, loss = 1534137398.40675139\n",
            "Iteration 54, loss = 1534010607.23016596\n",
            "Iteration 55, loss = 1533882090.19281650\n",
            "Iteration 56, loss = 1533751485.99567437\n",
            "Iteration 57, loss = 1533619358.09980607\n",
            "Iteration 58, loss = 1533485722.82619882\n",
            "Iteration 59, loss = 1533351304.89849257\n",
            "Iteration 60, loss = 1533214267.45209146\n",
            "Iteration 61, loss = 1533076415.81830716\n",
            "Iteration 62, loss = 1532937791.23659301\n",
            "Iteration 63, loss = 1532797782.41508794\n",
            "Iteration 64, loss = 1532657097.58676124\n",
            "Iteration 65, loss = 1532515608.82917833\n",
            "Iteration 66, loss = 1532373767.34721637\n",
            "Iteration 67, loss = 1532231539.87352300\n",
            "Iteration 68, loss = 1532089043.60318756\n",
            "Iteration 69, loss = 1531946381.13501167\n",
            "Iteration 70, loss = 1531803922.94002604\n",
            "Iteration 71, loss = 1531661897.84696865\n",
            "Iteration 72, loss = 1531520210.35443020\n",
            "Iteration 73, loss = 1531378236.42400837\n",
            "Iteration 74, loss = 1531235823.24583244\n",
            "Iteration 75, loss = 1531092817.08670640\n",
            "Iteration 76, loss = 1530949996.49264574\n",
            "Iteration 77, loss = 1530806610.17277861\n",
            "Iteration 78, loss = 1530664423.39119148\n",
            "Iteration 79, loss = 1530521422.79999447\n",
            "Iteration 80, loss = 1530378964.37155247\n",
            "Iteration 81, loss = 1530236557.10174918\n",
            "Iteration 82, loss = 1530094126.06798315\n",
            "Iteration 83, loss = 1529951561.79431343\n",
            "Iteration 84, loss = 1529810680.94288564\n",
            "Iteration 85, loss = 1529668416.68442345\n",
            "Iteration 86, loss = 1529527424.99746370\n",
            "Iteration 87, loss = 1529384847.72767854\n",
            "Iteration 88, loss = 1529243055.78051305\n",
            "Iteration 89, loss = 1529101655.56433249\n",
            "Iteration 90, loss = 1528960897.38034534\n",
            "Iteration 91, loss = 1528820185.55241680\n",
            "Iteration 92, loss = 1528679212.42771173\n",
            "Iteration 93, loss = 1528538919.85542727\n",
            "Iteration 94, loss = 1528399805.71188545\n",
            "Iteration 95, loss = 1528259853.56121182\n",
            "Iteration 96, loss = 1528120483.15832114\n",
            "Iteration 97, loss = 1527981472.26851082\n",
            "Iteration 98, loss = 1527843003.49566555\n",
            "Iteration 99, loss = 1527704388.82371926\n",
            "Iteration 100, loss = 1527566226.90734577\n",
            "Iteration 101, loss = 1527427710.37308073\n",
            "Iteration 102, loss = 1527289028.11095405\n",
            "Iteration 103, loss = 1527151321.98505330\n",
            "Iteration 104, loss = 1527013459.67647362\n",
            "Iteration 105, loss = 1526875569.67483306\n",
            "Iteration 106, loss = 1526738340.44202900\n",
            "Iteration 107, loss = 1526601015.86060596\n",
            "Iteration 108, loss = 1526464087.95202613\n",
            "Iteration 109, loss = 1526327005.97548127\n",
            "Iteration 110, loss = 1526190794.09846759\n",
            "Iteration 111, loss = 1526054376.28070879\n",
            "Iteration 112, loss = 1525917738.78181314\n",
            "Iteration 113, loss = 1525781792.64390516\n",
            "Iteration 114, loss = 1525646744.25172186\n",
            "Iteration 115, loss = 1525510643.57431889\n",
            "Iteration 116, loss = 1525375281.07654572\n",
            "Iteration 117, loss = 1525241034.78397346\n",
            "Iteration 118, loss = 1525106202.47647643\n",
            "Iteration 119, loss = 1524971435.10756087\n",
            "Iteration 120, loss = 1524838420.70172834\n",
            "Iteration 121, loss = 1524703730.54299903\n",
            "Iteration 122, loss = 1524569487.55647564\n",
            "Iteration 123, loss = 1524437025.76696038\n",
            "Iteration 124, loss = 1524302993.50388169\n",
            "Iteration 125, loss = 1524169915.67045307\n",
            "Iteration 126, loss = 1524037454.48382735\n",
            "Iteration 127, loss = 1523904057.43863678\n",
            "Iteration 128, loss = 1523772301.97016883\n",
            "Iteration 129, loss = 1523639992.28331494\n",
            "Iteration 130, loss = 1523507742.51661038\n",
            "Iteration 131, loss = 1523376218.79697323\n",
            "Iteration 132, loss = 1523244185.12096477\n",
            "Iteration 133, loss = 1523113015.23269677\n",
            "Iteration 134, loss = 1522981623.61143947\n",
            "Iteration 135, loss = 1522850500.08384323\n",
            "Iteration 136, loss = 1522719207.47693157\n",
            "Iteration 137, loss = 1522587898.07181096\n",
            "Iteration 138, loss = 1522457933.76802540\n",
            "Iteration 139, loss = 1522328052.95038223\n",
            "Iteration 140, loss = 1522196536.06712890\n",
            "Iteration 141, loss = 1522065931.46429634\n",
            "Iteration 142, loss = 1521937475.53618670\n",
            "Iteration 143, loss = 1521806783.48925591\n",
            "Iteration 144, loss = 1521677982.28919244\n",
            "Iteration 145, loss = 1521549548.33711839\n",
            "Iteration 146, loss = 1521420139.41021562\n",
            "Iteration 147, loss = 1521291830.33999705\n",
            "Iteration 148, loss = 1521164195.66192389\n",
            "Iteration 149, loss = 1521035043.98230219\n",
            "Iteration 150, loss = 1520907499.65952349\n",
            "Iteration 151, loss = 1520780617.10466027\n",
            "Iteration 152, loss = 1520651361.09773803\n",
            "Iteration 153, loss = 1520523685.34408665\n",
            "Iteration 154, loss = 1520397340.63134074\n",
            "Iteration 155, loss = 1520269723.47925186\n",
            "Iteration 156, loss = 1520142486.36481953\n",
            "Iteration 157, loss = 1520014832.45591950\n",
            "Iteration 158, loss = 1519889041.56916094\n",
            "Iteration 159, loss = 1519760876.34930253\n",
            "Iteration 160, loss = 1519634889.02329850\n",
            "Iteration 161, loss = 1519507001.16309166\n",
            "Iteration 162, loss = 1519380312.33449602\n",
            "Iteration 163, loss = 1519254692.27443099\n",
            "Iteration 164, loss = 1519127824.47297096\n",
            "Iteration 165, loss = 1519000499.43176746\n",
            "Iteration 166, loss = 1518875492.48815012\n",
            "Iteration 167, loss = 1518748890.80940247\n",
            "Iteration 168, loss = 1518622553.05631971\n",
            "Iteration 169, loss = 1518497008.55981994\n",
            "Iteration 170, loss = 1518371390.09807849\n",
            "Iteration 171, loss = 1518245335.21675873\n",
            "Iteration 172, loss = 1518120186.37552929\n",
            "Iteration 173, loss = 1517994470.35333586\n",
            "Iteration 174, loss = 1517870430.50568080\n",
            "Iteration 175, loss = 1517745248.19133210\n",
            "Iteration 176, loss = 1517620747.29897928\n",
            "Iteration 177, loss = 1517496609.62999249\n",
            "Iteration 178, loss = 1517372580.76454139\n",
            "Iteration 179, loss = 1517248195.04311275\n",
            "Iteration 180, loss = 1517124195.87193418\n",
            "Iteration 181, loss = 1517000527.37799430\n",
            "Iteration 182, loss = 1516876557.08797765\n",
            "Iteration 183, loss = 1516752475.05938315\n",
            "Iteration 184, loss = 1516629076.52617860\n",
            "Iteration 185, loss = 1516504665.71252012\n",
            "Iteration 186, loss = 1516380927.91817689\n",
            "Iteration 187, loss = 1516257349.75284791\n",
            "Iteration 188, loss = 1516134146.30031395\n",
            "Iteration 189, loss = 1516010111.08311558\n",
            "Iteration 190, loss = 1515887503.26414943\n",
            "Iteration 191, loss = 1515764321.55128884\n",
            "Iteration 192, loss = 1515640739.40386295\n",
            "Iteration 193, loss = 1515518964.52497411\n",
            "Iteration 194, loss = 1515395769.98647976\n",
            "Iteration 195, loss = 1515274053.05839705\n",
            "Iteration 196, loss = 1515151347.32926679\n",
            "Iteration 197, loss = 1515029514.98273516\n",
            "Iteration 198, loss = 1514908127.23464775\n",
            "Iteration 199, loss = 1514786082.52760887\n",
            "Iteration 200, loss = 1514664575.08773160\n",
            "Iteration 201, loss = 1514543837.33817077\n",
            "Iteration 202, loss = 1514421575.32396197\n",
            "Iteration 203, loss = 1514300441.21462774\n",
            "Iteration 204, loss = 1514179125.72144651\n",
            "Iteration 205, loss = 1514057524.92626214\n",
            "Iteration 206, loss = 1513936074.76659465\n",
            "Iteration 207, loss = 1513814681.67967844\n",
            "Iteration 208, loss = 1513693942.21446800\n",
            "Iteration 209, loss = 1513572065.43429637\n",
            "Iteration 210, loss = 1513451726.00907278\n",
            "Iteration 211, loss = 1513330915.94030738\n",
            "Iteration 212, loss = 1513210230.38133097\n",
            "Iteration 213, loss = 1513090265.84822273\n",
            "Iteration 214, loss = 1512969644.47096157\n",
            "Iteration 215, loss = 1512849206.99526167\n",
            "Iteration 216, loss = 1512728823.92383361\n",
            "Iteration 217, loss = 1512608263.78840137\n",
            "Iteration 218, loss = 1512487687.99025345\n",
            "Iteration 219, loss = 1512367323.14285135\n",
            "Iteration 220, loss = 1512246170.24163961\n",
            "Iteration 221, loss = 1512125502.91259766\n",
            "Iteration 222, loss = 1512005003.60817432\n",
            "Iteration 223, loss = 1511883850.14048791\n",
            "Iteration 224, loss = 1511763440.96637225\n",
            "Iteration 225, loss = 1511642999.72008514\n",
            "Iteration 226, loss = 1511522243.03444862\n",
            "Iteration 227, loss = 1511402240.92057157\n",
            "Iteration 228, loss = 1511282017.90769196\n",
            "Iteration 229, loss = 1511162281.62765837\n",
            "Iteration 230, loss = 1511042435.56738091\n",
            "Iteration 231, loss = 1510922827.68205953\n",
            "Iteration 232, loss = 1510803470.28658414\n",
            "Iteration 233, loss = 1510685007.69140148\n",
            "Iteration 234, loss = 1510565707.80663133\n",
            "Iteration 235, loss = 1510446697.09892678\n",
            "Iteration 236, loss = 1510328624.27851009\n",
            "Iteration 237, loss = 1510210260.86146665\n",
            "Iteration 238, loss = 1510092266.73109126\n",
            "Iteration 239, loss = 1509974053.95681119\n",
            "Iteration 240, loss = 1509856259.49264693\n",
            "Iteration 241, loss = 1509738595.77226686\n",
            "Iteration 242, loss = 1509621584.65120697\n",
            "Iteration 243, loss = 1509503600.70252585\n",
            "Iteration 244, loss = 1509385926.79787683\n",
            "Iteration 245, loss = 1509268710.88649106\n",
            "Iteration 246, loss = 1509150545.99313974\n",
            "Iteration 247, loss = 1509033018.86101747\n",
            "Iteration 248, loss = 1508915057.44954896\n",
            "Iteration 249, loss = 1508797430.93754387\n",
            "Iteration 250, loss = 1508679617.54512763\n",
            "Iteration 251, loss = 1508562156.28849363\n",
            "Iteration 252, loss = 1508444981.53752398\n",
            "Iteration 253, loss = 1508327385.04152489\n",
            "Iteration 254, loss = 1508210366.52691507\n",
            "Iteration 255, loss = 1508093635.00099897\n",
            "Iteration 256, loss = 1507976802.80427313\n",
            "Iteration 257, loss = 1507858916.07139516\n",
            "Iteration 258, loss = 1507742676.99405003\n",
            "Iteration 259, loss = 1507625457.28021049\n",
            "Iteration 260, loss = 1507508904.32953000\n",
            "Iteration 261, loss = 1507391927.88434529\n",
            "Iteration 262, loss = 1507275493.01961470\n",
            "Iteration 263, loss = 1507159446.57412100\n",
            "Iteration 264, loss = 1507043142.21341014\n",
            "Iteration 265, loss = 1506925739.60585642\n",
            "Iteration 266, loss = 1506810136.35317278\n",
            "Iteration 267, loss = 1506693636.31956697\n",
            "Iteration 268, loss = 1506577252.48249841\n",
            "Iteration 269, loss = 1506459418.25193906\n",
            "Iteration 270, loss = 1506343562.30947995\n",
            "Iteration 271, loss = 1506227445.67563105\n",
            "Iteration 272, loss = 1506110099.11373687\n",
            "Iteration 273, loss = 1505993377.22263765\n",
            "Iteration 274, loss = 1505877284.26926661\n",
            "Iteration 275, loss = 1505760242.91005278\n",
            "Iteration 276, loss = 1505644264.11279440\n",
            "Iteration 277, loss = 1505527432.15123606\n",
            "Iteration 278, loss = 1505410764.03679323\n",
            "Iteration 279, loss = 1505294575.39203954\n",
            "Iteration 280, loss = 1505178159.32932663\n",
            "Iteration 281, loss = 1505062169.61508012\n",
            "Iteration 282, loss = 1504945876.80509162\n",
            "Iteration 283, loss = 1504829735.42843032\n",
            "Iteration 284, loss = 1504713353.45571542\n",
            "Iteration 285, loss = 1504597763.57688856\n",
            "Iteration 286, loss = 1504481866.80711246\n",
            "Iteration 287, loss = 1504366356.15687394\n",
            "Iteration 288, loss = 1504250627.77820325\n",
            "Iteration 289, loss = 1504134644.23107743\n",
            "Iteration 290, loss = 1504019541.07938266\n",
            "Iteration 291, loss = 1503903072.01070809\n",
            "Iteration 292, loss = 1503787765.72016501\n",
            "Iteration 293, loss = 1503672006.26244187\n",
            "Iteration 294, loss = 1503556418.72890401\n",
            "Iteration 295, loss = 1503439907.27964520\n",
            "Iteration 296, loss = 1503324515.29030132\n",
            "Iteration 297, loss = 1503209121.97529602\n",
            "Iteration 298, loss = 1503093053.26293349\n",
            "Iteration 299, loss = 1502977073.81613302\n",
            "Iteration 300, loss = 1502861421.39444184\n",
            "Iteration 301, loss = 1502745440.71520352\n",
            "Iteration 302, loss = 1502629864.60537362\n",
            "Iteration 303, loss = 1502513773.43277073\n",
            "Iteration 304, loss = 1502398420.10227990\n",
            "Iteration 305, loss = 1502283192.00714684\n",
            "Iteration 306, loss = 1502167397.64237523\n",
            "Iteration 307, loss = 1502052234.28691506\n",
            "Iteration 308, loss = 1501937927.13865376\n",
            "Iteration 309, loss = 1501823001.04128695\n",
            "Iteration 310, loss = 1501708662.79212499\n",
            "Iteration 311, loss = 1501593648.20595527\n",
            "Iteration 312, loss = 1501479859.89023709\n",
            "Iteration 313, loss = 1501365727.69270420\n",
            "Iteration 314, loss = 1501251307.59836388\n",
            "Iteration 315, loss = 1501136743.67326498\n",
            "Iteration 316, loss = 1501022718.90627265\n",
            "Iteration 317, loss = 1500908953.54868340\n",
            "Iteration 318, loss = 1500794932.05335665\n",
            "Iteration 319, loss = 1500680786.40887380\n",
            "Iteration 320, loss = 1500566632.10384035\n",
            "Iteration 321, loss = 1500453324.17077780\n",
            "Iteration 322, loss = 1500338976.96394157\n",
            "Iteration 323, loss = 1500225015.03293419\n",
            "Iteration 324, loss = 1500110305.68521094\n",
            "Iteration 325, loss = 1499996382.37783957\n",
            "Iteration 326, loss = 1499882048.21985579\n",
            "Iteration 327, loss = 1499767623.78945732\n",
            "Iteration 328, loss = 1499653608.66959667\n",
            "Iteration 329, loss = 1499539365.38171124\n",
            "Iteration 330, loss = 1499424935.67698264\n",
            "Iteration 331, loss = 1499311285.37432837\n",
            "Iteration 332, loss = 1499197134.84105492\n",
            "Iteration 333, loss = 1499082636.65606570\n",
            "Iteration 334, loss = 1498967872.30036306\n",
            "Iteration 335, loss = 1498853778.17535639\n",
            "Iteration 336, loss = 1498739251.15678835\n",
            "Iteration 337, loss = 1498624456.78745508\n",
            "Iteration 338, loss = 1498509750.50321627\n",
            "Iteration 339, loss = 1498394664.52811980\n",
            "Iteration 340, loss = 1498279997.70295453\n",
            "Iteration 341, loss = 1498164904.12326241\n",
            "Iteration 342, loss = 1498050248.39246964\n",
            "Iteration 343, loss = 1497935037.80294466\n",
            "Iteration 344, loss = 1497820929.84507132\n",
            "Iteration 345, loss = 1497705962.92636156\n",
            "Iteration 346, loss = 1497591904.41459775\n",
            "Iteration 347, loss = 1497477316.17489481\n",
            "Iteration 348, loss = 1497363241.59788179\n",
            "Iteration 349, loss = 1497249545.18298030\n",
            "Iteration 350, loss = 1497135839.37830663\n",
            "Iteration 351, loss = 1497022219.66641951\n",
            "Iteration 352, loss = 1496908637.65041637\n",
            "Iteration 353, loss = 1496795272.85618424\n",
            "Iteration 354, loss = 1496681760.87283683\n",
            "Iteration 355, loss = 1496568765.92625856\n",
            "Iteration 356, loss = 1496455449.95799804\n",
            "Iteration 357, loss = 1496342004.64493036\n",
            "Iteration 358, loss = 1496229086.76984167\n",
            "Iteration 359, loss = 1496115629.07464576\n",
            "Iteration 360, loss = 1496002676.63420868\n",
            "Iteration 361, loss = 1495889215.00541139\n",
            "Iteration 362, loss = 1495777237.51492286\n",
            "Iteration 363, loss = 1495663812.54862690\n",
            "Iteration 364, loss = 1495551307.06300521\n",
            "Iteration 365, loss = 1495439386.71002555\n",
            "Iteration 366, loss = 1495326954.42413211\n",
            "Iteration 367, loss = 1495215323.45330381\n",
            "Iteration 368, loss = 1495102787.54899025\n",
            "Iteration 369, loss = 1494990988.70105648\n",
            "Iteration 370, loss = 1494878938.86866999\n",
            "Iteration 371, loss = 1494766663.25265741\n",
            "Iteration 372, loss = 1494654302.78524756\n",
            "Iteration 373, loss = 1494541721.02442145\n",
            "Iteration 374, loss = 1494429661.22888350\n",
            "Iteration 375, loss = 1494317328.43175745\n",
            "Iteration 376, loss = 1494205143.06390786\n",
            "Iteration 377, loss = 1494092523.46308398\n",
            "Iteration 378, loss = 1493980446.47628474\n",
            "Iteration 379, loss = 1493868093.15529132\n",
            "Iteration 380, loss = 1493755799.47429228\n",
            "Iteration 381, loss = 1493642790.31863475\n",
            "Iteration 382, loss = 1493530463.15066242\n",
            "Iteration 383, loss = 1493417149.75098562\n",
            "Iteration 384, loss = 1493304554.19266033\n",
            "Iteration 385, loss = 1493191585.55830622\n",
            "Iteration 386, loss = 1493079122.87514424\n",
            "Iteration 387, loss = 1492966345.27951503\n",
            "Iteration 388, loss = 1492854107.99153686\n",
            "Iteration 389, loss = 1492741486.97004223\n",
            "Iteration 390, loss = 1492630008.18131113\n",
            "Iteration 391, loss = 1492518202.96372628\n",
            "Iteration 392, loss = 1492406367.96008968\n",
            "Iteration 393, loss = 1492295077.67658043\n",
            "Iteration 394, loss = 1492183389.65437770\n",
            "Iteration 395, loss = 1492071293.88332939\n",
            "Iteration 396, loss = 1491960261.52411318\n",
            "Iteration 397, loss = 1491848089.78380537\n",
            "Iteration 398, loss = 1491736679.50769973\n",
            "Iteration 399, loss = 1491624308.55414176\n",
            "Iteration 400, loss = 1491512085.72616673\n",
            "Iteration 401, loss = 1491400371.92038918\n",
            "Iteration 402, loss = 1491289038.00647068\n",
            "Iteration 403, loss = 1491176824.84591007\n",
            "Iteration 404, loss = 1491063938.70050812\n",
            "Iteration 405, loss = 1490952286.52349782\n",
            "Iteration 406, loss = 1490840110.41090059\n",
            "Iteration 407, loss = 1490728856.69399667\n",
            "Iteration 408, loss = 1490616093.37992144\n",
            "Iteration 409, loss = 1490503936.14073014\n",
            "Iteration 410, loss = 1490391908.23329234\n",
            "Iteration 411, loss = 1490279685.64400434\n",
            "Iteration 412, loss = 1490168473.33640695\n",
            "Iteration 413, loss = 1490056564.10365081\n",
            "Iteration 414, loss = 1489944820.65794325\n",
            "Iteration 415, loss = 1489832697.74208188\n",
            "Iteration 416, loss = 1489721165.15150428\n",
            "Iteration 417, loss = 1489609989.45882797\n",
            "Iteration 418, loss = 1489498707.98192143\n",
            "Iteration 419, loss = 1489386658.46060395\n",
            "Iteration 420, loss = 1489274807.69739652\n",
            "Iteration 421, loss = 1489163556.76801586\n",
            "Iteration 422, loss = 1489052566.98383164\n",
            "Iteration 423, loss = 1488941190.04514718\n",
            "Iteration 424, loss = 1488830503.50249171\n",
            "Iteration 425, loss = 1488718483.96100259\n",
            "Iteration 426, loss = 1488608870.45408607\n",
            "Iteration 427, loss = 1488497922.31679368\n",
            "Iteration 428, loss = 1488387171.05645561\n",
            "Iteration 429, loss = 1488275823.26850557\n",
            "Iteration 430, loss = 1488166017.70749092\n",
            "Iteration 431, loss = 1488054845.56929111\n",
            "Iteration 432, loss = 1487942824.43898153\n",
            "Iteration 433, loss = 1487833250.42463255\n",
            "Iteration 434, loss = 1487722508.07849622\n",
            "Iteration 435, loss = 1487611179.10247850\n",
            "Iteration 436, loss = 1487500681.24266243\n",
            "Iteration 437, loss = 1487389985.31712413\n",
            "Iteration 438, loss = 1487279471.43056870\n",
            "Iteration 439, loss = 1487168428.91665435\n",
            "Iteration 440, loss = 1487057795.57846045\n",
            "Iteration 441, loss = 1486946028.36805248\n",
            "Iteration 442, loss = 1486834713.26959991\n",
            "Iteration 443, loss = 1486723570.70012188\n",
            "Iteration 444, loss = 1486611560.59386444\n",
            "Iteration 445, loss = 1486500611.30133724\n",
            "Iteration 446, loss = 1486388981.85504913\n",
            "Iteration 447, loss = 1486278214.13268805\n",
            "Iteration 448, loss = 1486167567.85204148\n",
            "Iteration 449, loss = 1486056505.84309912\n",
            "Iteration 450, loss = 1485945866.50918531\n",
            "Iteration 451, loss = 1485835250.95919776\n",
            "Iteration 452, loss = 1485725045.00122190\n",
            "Iteration 453, loss = 1485614914.02513409\n",
            "Iteration 454, loss = 1485504685.05518460\n",
            "Iteration 455, loss = 1485394336.14072275\n",
            "Iteration 456, loss = 1485283673.94762731\n",
            "Iteration 457, loss = 1485174257.83054686\n",
            "Iteration 458, loss = 1485063394.35526180\n",
            "Iteration 459, loss = 1484953196.52808666\n",
            "Iteration 460, loss = 1484843182.11067176\n",
            "Iteration 461, loss = 1484733325.86970949\n",
            "Iteration 462, loss = 1484623021.26296711\n",
            "Iteration 463, loss = 1484513642.74687982\n",
            "Iteration 464, loss = 1484403406.05086803\n",
            "Iteration 465, loss = 1484293789.82187605\n",
            "Iteration 466, loss = 1484183560.89018774\n",
            "Iteration 467, loss = 1484073800.97323012\n",
            "Iteration 468, loss = 1483964206.59150767\n",
            "Iteration 469, loss = 1483854134.98459029\n",
            "Iteration 470, loss = 1483743779.98416352\n",
            "Iteration 471, loss = 1483634188.37159920\n",
            "Iteration 472, loss = 1483524419.39392781\n",
            "Iteration 473, loss = 1483414682.13955092\n",
            "Iteration 474, loss = 1483304997.83592081\n",
            "Iteration 475, loss = 1483195209.30977941\n",
            "Iteration 476, loss = 1483084927.52059722\n",
            "Iteration 477, loss = 1482975306.09936714\n",
            "Iteration 478, loss = 1482865363.32294750\n",
            "Iteration 479, loss = 1482755772.68926501\n",
            "Iteration 480, loss = 1482645389.72801614\n",
            "Iteration 481, loss = 1482535698.02866125\n",
            "Iteration 482, loss = 1482426224.96382236\n",
            "Iteration 483, loss = 1482316607.83223677\n",
            "Iteration 484, loss = 1482206546.23212171\n",
            "Iteration 485, loss = 1482097008.75658536\n",
            "Iteration 486, loss = 1481987617.59910107\n",
            "Iteration 487, loss = 1481878609.50405979\n",
            "Iteration 488, loss = 1481768351.77947783\n",
            "Iteration 489, loss = 1481658981.09836698\n",
            "Iteration 490, loss = 1481549608.46776104\n",
            "Iteration 491, loss = 1481440029.24539161\n",
            "Iteration 492, loss = 1481330044.15157771\n",
            "Iteration 493, loss = 1481220824.53217793\n",
            "Iteration 494, loss = 1481111251.59860897\n",
            "Iteration 495, loss = 1481001587.76119184\n",
            "Iteration 496, loss = 1480891934.65031695\n",
            "Iteration 497, loss = 1480782128.48497748\n",
            "Iteration 498, loss = 1480673026.05306888\n",
            "Iteration 499, loss = 1480562884.15770841\n",
            "Iteration 500, loss = 1480453486.92527509\n",
            "Iteration 501, loss = 1480343920.89174938\n",
            "Iteration 502, loss = 1480234480.67585444\n",
            "Iteration 503, loss = 1480124750.88586783\n",
            "Iteration 504, loss = 1480016111.84095907\n",
            "Iteration 505, loss = 1479906313.79283357\n",
            "Iteration 506, loss = 1479797562.67467833\n",
            "Iteration 507, loss = 1479688662.20475960\n",
            "Iteration 508, loss = 1479579820.80814385\n",
            "Iteration 509, loss = 1479470634.68161416\n",
            "Iteration 510, loss = 1479362068.53796315\n",
            "Iteration 511, loss = 1479252832.98512840\n",
            "Iteration 512, loss = 1479143816.34420896\n",
            "Iteration 513, loss = 1479035184.55156755\n",
            "Iteration 514, loss = 1478925456.12159705\n",
            "Iteration 515, loss = 1478817226.40734816\n",
            "Iteration 516, loss = 1478708336.70381904\n",
            "Iteration 517, loss = 1478599085.72412062\n",
            "Iteration 518, loss = 1478490778.13332033\n",
            "Iteration 519, loss = 1478381662.45688367\n",
            "Iteration 520, loss = 1478273157.16702628\n",
            "Iteration 521, loss = 1478164522.78817487\n",
            "Iteration 522, loss = 1478056214.29853845\n",
            "Iteration 523, loss = 1477947592.14076495\n",
            "Iteration 524, loss = 1477838876.49092054\n",
            "Iteration 525, loss = 1477730451.41404390\n",
            "Iteration 526, loss = 1477621692.52870655\n",
            "Iteration 527, loss = 1477513397.96273160\n",
            "Iteration 528, loss = 1477404101.24621987\n",
            "Iteration 529, loss = 1477295581.28599572\n",
            "Iteration 530, loss = 1477187186.68579030\n",
            "Iteration 531, loss = 1477077957.67912531\n",
            "Iteration 532, loss = 1476968662.14706039\n",
            "Iteration 533, loss = 1476859986.54860592\n",
            "Iteration 534, loss = 1476750564.75042987\n",
            "Iteration 535, loss = 1476641513.46237254\n",
            "Iteration 536, loss = 1476531849.48592114\n",
            "Iteration 537, loss = 1476422557.12012076\n",
            "Iteration 538, loss = 1476313255.67738223\n",
            "Iteration 539, loss = 1476203331.30017328\n",
            "Iteration 540, loss = 1476094077.45210838\n",
            "Iteration 541, loss = 1475983991.98776436\n",
            "Iteration 542, loss = 1475875019.99390125\n",
            "Iteration 543, loss = 1475765213.16898584\n",
            "Iteration 544, loss = 1475656437.28824091\n",
            "Iteration 545, loss = 1475547493.44271636\n",
            "Iteration 546, loss = 1475438156.26163864\n",
            "Iteration 547, loss = 1475329505.85901046\n",
            "Iteration 548, loss = 1475220500.37366223\n",
            "Iteration 549, loss = 1475112313.64120412\n",
            "Iteration 550, loss = 1475003399.14721394\n",
            "Iteration 551, loss = 1474894350.44565630\n",
            "Iteration 552, loss = 1474785809.11195517\n",
            "Iteration 553, loss = 1474677322.77780509\n",
            "Iteration 554, loss = 1474568522.35557222\n",
            "Iteration 555, loss = 1474459787.45936465\n",
            "Iteration 556, loss = 1474351243.89654875\n",
            "Iteration 557, loss = 1474242865.93584847\n",
            "Iteration 558, loss = 1474134106.03900790\n",
            "Iteration 559, loss = 1474025452.36925840\n",
            "Iteration 560, loss = 1473916896.39934254\n",
            "Iteration 561, loss = 1473808764.13893342\n",
            "Iteration 562, loss = 1473700181.44174623\n",
            "Iteration 563, loss = 1473591441.92712784\n",
            "Iteration 564, loss = 1473483651.51796412\n",
            "Iteration 565, loss = 1473374864.72723675\n",
            "Iteration 566, loss = 1473266681.00584292\n",
            "Iteration 567, loss = 1473158798.20711112\n",
            "Iteration 568, loss = 1473049833.71285510\n",
            "Iteration 569, loss = 1472942004.06069040\n",
            "Iteration 570, loss = 1472833609.53473616\n",
            "Iteration 571, loss = 1472724872.05243468\n",
            "Iteration 572, loss = 1472617302.92757726\n",
            "Iteration 573, loss = 1472508442.38861060\n",
            "Iteration 574, loss = 1472400452.76498008\n",
            "Iteration 575, loss = 1472292878.46405864\n",
            "Iteration 576, loss = 1472183622.36008525\n",
            "Iteration 577, loss = 1472076021.19539261\n",
            "Iteration 578, loss = 1471967880.64414167\n",
            "Iteration 579, loss = 1471859505.64354396\n",
            "Iteration 580, loss = 1471751058.15594149\n",
            "Iteration 581, loss = 1471643236.38231397\n",
            "Iteration 582, loss = 1471535125.46531272\n",
            "Iteration 583, loss = 1471427145.11807847\n",
            "Iteration 584, loss = 1471318682.16828370\n",
            "Iteration 585, loss = 1471210116.74449468\n",
            "Iteration 586, loss = 1471102516.58576870\n",
            "Iteration 587, loss = 1470993228.96949482\n",
            "Iteration 588, loss = 1470885182.53134632\n",
            "Iteration 589, loss = 1470776351.93668032\n",
            "Iteration 590, loss = 1470668395.24468350\n",
            "Iteration 591, loss = 1470559158.81331611\n",
            "Iteration 592, loss = 1470451115.75637460\n",
            "Iteration 593, loss = 1470343136.31320930\n",
            "Iteration 594, loss = 1470235196.18155003\n",
            "Iteration 595, loss = 1470126725.09651375\n",
            "Iteration 596, loss = 1470018966.79406929\n",
            "Iteration 597, loss = 1469911091.26359892\n",
            "Iteration 598, loss = 1469803044.81626129\n",
            "Iteration 599, loss = 1469695397.35659695\n",
            "Iteration 600, loss = 1469587182.83201003\n",
            "Iteration 601, loss = 1469479186.12968278\n",
            "Iteration 602, loss = 1469371411.04102921\n",
            "Iteration 603, loss = 1469263814.05384803\n",
            "Iteration 604, loss = 1469155200.88475680\n",
            "Iteration 605, loss = 1469047979.78588581\n",
            "Iteration 606, loss = 1468940128.77734423\n",
            "Iteration 607, loss = 1468832195.26135778\n",
            "Iteration 608, loss = 1468725174.24285030\n",
            "Iteration 609, loss = 1468617188.20580912\n",
            "Iteration 610, loss = 1468509560.69325233\n",
            "Iteration 611, loss = 1468402049.10372543\n",
            "Iteration 612, loss = 1468294419.00104666\n",
            "Iteration 613, loss = 1468187042.02154636\n",
            "Iteration 614, loss = 1468079411.29072857\n",
            "Iteration 615, loss = 1467971658.09978580\n",
            "Iteration 616, loss = 1467864239.41694713\n",
            "Iteration 617, loss = 1467756975.61807013\n",
            "Iteration 618, loss = 1467649099.22337890\n",
            "Iteration 619, loss = 1467541637.92765737\n",
            "Iteration 620, loss = 1467434577.27978134\n",
            "Iteration 621, loss = 1467326468.42946935\n",
            "Iteration 622, loss = 1467218941.62017941\n",
            "Iteration 623, loss = 1467111400.02452064\n",
            "Iteration 624, loss = 1467004307.17492366\n",
            "Iteration 625, loss = 1466896897.37425160\n",
            "Iteration 626, loss = 1466789781.71521449\n",
            "Iteration 627, loss = 1466682408.84189773\n",
            "Iteration 628, loss = 1466575892.89424920\n",
            "Iteration 629, loss = 1466468667.11745501\n",
            "Iteration 630, loss = 1466361885.50154662\n",
            "Iteration 631, loss = 1466255006.29353881\n",
            "Iteration 632, loss = 1466147955.84097981\n",
            "Iteration 633, loss = 1466041161.60301685\n",
            "Iteration 634, loss = 1465933787.10561514\n",
            "Iteration 635, loss = 1465827051.10503674\n",
            "Iteration 636, loss = 1465719818.33806396\n",
            "Iteration 637, loss = 1465612372.52273822\n",
            "Iteration 638, loss = 1465505259.01423502\n",
            "Iteration 639, loss = 1465398211.58547783\n",
            "Iteration 640, loss = 1465290910.47422171\n",
            "Iteration 641, loss = 1465182880.23381090\n",
            "Iteration 642, loss = 1465076404.38743210\n",
            "Iteration 643, loss = 1464969021.30271864\n",
            "Iteration 644, loss = 1464861167.14406300\n",
            "Iteration 645, loss = 1464754273.03850126\n",
            "Iteration 646, loss = 1464646536.01899695\n",
            "Iteration 647, loss = 1464539702.48131895\n",
            "Iteration 648, loss = 1464432077.06176424\n",
            "Iteration 649, loss = 1464324999.11501026\n",
            "Iteration 650, loss = 1464217303.01094627\n",
            "Iteration 651, loss = 1464110182.33126092\n",
            "Iteration 652, loss = 1464003058.76836944\n",
            "Iteration 653, loss = 1463896296.38234735\n",
            "Iteration 654, loss = 1463788335.80598450\n",
            "Iteration 655, loss = 1463681749.20719671\n",
            "Iteration 656, loss = 1463574843.82183075\n",
            "Iteration 657, loss = 1463467816.54962683\n",
            "Iteration 658, loss = 1463360924.16648841\n",
            "Iteration 659, loss = 1463253886.72114897\n",
            "Iteration 660, loss = 1463146713.77095008\n",
            "Iteration 661, loss = 1463039415.05221152\n",
            "Iteration 662, loss = 1462932312.80510664\n",
            "Iteration 663, loss = 1462824744.63411450\n",
            "Iteration 664, loss = 1462716848.59484220\n",
            "Iteration 665, loss = 1462609337.21969438\n",
            "Iteration 666, loss = 1462501993.40565395\n",
            "Iteration 667, loss = 1462394639.10342312\n",
            "Iteration 668, loss = 1462287170.74766111\n",
            "Iteration 669, loss = 1462180318.84551692\n",
            "Iteration 670, loss = 1462073335.88282919\n",
            "Iteration 671, loss = 1461965879.41821933\n",
            "Iteration 672, loss = 1461859389.25525045\n",
            "Iteration 673, loss = 1461753369.59360099\n",
            "Iteration 674, loss = 1461646503.58931828\n",
            "Iteration 675, loss = 1461539844.21271992\n",
            "Iteration 676, loss = 1461433059.73906660\n",
            "Iteration 677, loss = 1461327010.35525179\n",
            "Iteration 678, loss = 1461220539.63510227\n",
            "Iteration 679, loss = 1461113704.76364779\n",
            "Iteration 680, loss = 1461007495.89468789\n",
            "Iteration 681, loss = 1460901164.12180424\n",
            "Iteration 682, loss = 1460793837.75911927\n",
            "Iteration 683, loss = 1460687780.83927774\n",
            "Iteration 684, loss = 1460580899.66738772\n",
            "Iteration 685, loss = 1460474673.71884346\n",
            "Iteration 686, loss = 1460368431.51060987\n",
            "Iteration 687, loss = 1460261632.85034657\n",
            "Iteration 688, loss = 1460155341.65427542\n",
            "Iteration 689, loss = 1460048812.59082961\n",
            "Iteration 690, loss = 1459941923.48409677\n",
            "Iteration 691, loss = 1459835859.77731729\n",
            "Iteration 692, loss = 1459728651.05390763\n",
            "Iteration 693, loss = 1459622422.21493959\n",
            "Iteration 694, loss = 1459515082.76684904\n",
            "Iteration 695, loss = 1459409403.92241335\n",
            "Iteration 696, loss = 1459301631.63564134\n",
            "Iteration 697, loss = 1459195526.22638679\n",
            "Iteration 698, loss = 1459088923.81424427\n",
            "Iteration 699, loss = 1458982021.20416760\n",
            "Iteration 700, loss = 1458875438.69647741\n",
            "Iteration 701, loss = 1458769354.35558391\n",
            "Iteration 702, loss = 1458662842.63817239\n",
            "Iteration 703, loss = 1458556156.01108432\n",
            "Iteration 704, loss = 1458450554.12416291\n",
            "Iteration 705, loss = 1458344096.83409929\n",
            "Iteration 706, loss = 1458238007.84300184\n",
            "Iteration 707, loss = 1458131413.24054909\n",
            "Iteration 708, loss = 1458025259.19670272\n",
            "Iteration 709, loss = 1457918934.96630287\n",
            "Iteration 710, loss = 1457812839.58106351\n",
            "Iteration 711, loss = 1457706641.87676001\n",
            "Iteration 712, loss = 1457600083.37662983\n",
            "Iteration 713, loss = 1457494574.25437069\n",
            "Iteration 714, loss = 1457388284.20587230\n",
            "Iteration 715, loss = 1457282469.51440454\n",
            "Iteration 716, loss = 1457176254.72138500\n",
            "Iteration 717, loss = 1457070620.79734015\n",
            "Iteration 718, loss = 1456964213.27482843\n",
            "Iteration 719, loss = 1456857419.18557239\n",
            "Iteration 720, loss = 1456750774.45546937\n",
            "Iteration 721, loss = 1456644963.87073421\n",
            "Iteration 722, loss = 1456537594.24961400\n",
            "Iteration 723, loss = 1456430791.77190161\n",
            "Iteration 724, loss = 1456323496.32760048\n",
            "Iteration 725, loss = 1456216831.67473555\n",
            "Iteration 726, loss = 1456110736.00356531\n",
            "Iteration 727, loss = 1456003636.22549200\n",
            "Iteration 728, loss = 1455897254.02629089\n",
            "Iteration 729, loss = 1455790530.77656555\n",
            "Iteration 730, loss = 1455684699.73019886\n",
            "Iteration 731, loss = 1455578595.22443509\n",
            "Iteration 732, loss = 1455472251.17174768\n",
            "Iteration 733, loss = 1455366284.36421800\n",
            "Iteration 734, loss = 1455260669.39958429\n",
            "Iteration 735, loss = 1455154877.51489997\n",
            "Iteration 736, loss = 1455048035.81178808\n",
            "Iteration 737, loss = 1454942029.97556591\n",
            "Iteration 738, loss = 1454836365.94797277\n",
            "Iteration 739, loss = 1454729474.90919209\n",
            "Iteration 740, loss = 1454623965.35689473\n",
            "Iteration 741, loss = 1454518084.84036613\n",
            "Iteration 742, loss = 1454411943.84993601\n",
            "Iteration 743, loss = 1454305782.32159877\n",
            "Iteration 744, loss = 1454200225.43022299\n",
            "Iteration 745, loss = 1454094101.40466213\n",
            "Iteration 746, loss = 1453987661.14968014\n",
            "Iteration 747, loss = 1453881791.56830096\n",
            "Iteration 748, loss = 1453775594.89171433\n",
            "Iteration 749, loss = 1453669549.19120955\n",
            "Iteration 750, loss = 1453563918.12843966\n",
            "Iteration 751, loss = 1453457021.20223856\n",
            "Iteration 752, loss = 1453351805.49327135\n",
            "Iteration 753, loss = 1453245044.43846536\n",
            "Iteration 754, loss = 1453138969.94156528\n",
            "Iteration 755, loss = 1453032655.00697756\n",
            "Iteration 756, loss = 1452926498.33379841\n",
            "Iteration 757, loss = 1452820147.20508647\n",
            "Iteration 758, loss = 1452713717.34951639\n",
            "Iteration 759, loss = 1452607861.02436209\n",
            "Iteration 760, loss = 1452501058.39407468\n",
            "Iteration 761, loss = 1452394915.86783910\n",
            "Iteration 762, loss = 1452288350.61819363\n",
            "Iteration 763, loss = 1452182196.94777060\n",
            "Iteration 764, loss = 1452075201.77470589\n",
            "Iteration 765, loss = 1451968898.54318643\n",
            "Iteration 766, loss = 1451863226.19220042\n",
            "Iteration 767, loss = 1451756628.50157428\n",
            "Iteration 768, loss = 1451651007.33983016\n",
            "Iteration 769, loss = 1451544613.85956669\n",
            "Iteration 770, loss = 1451439143.76013350\n",
            "Iteration 771, loss = 1451334308.34738255\n",
            "Iteration 772, loss = 1451227668.06427646\n",
            "Iteration 773, loss = 1451122154.92691541\n",
            "Iteration 774, loss = 1451016155.29603219\n",
            "Iteration 775, loss = 1450911057.94853878\n",
            "Iteration 776, loss = 1450805371.58104658\n",
            "Iteration 777, loss = 1450699491.59217548\n",
            "Iteration 778, loss = 1450594160.42519879\n",
            "Iteration 779, loss = 1450488307.06285167\n",
            "Iteration 780, loss = 1450382789.63771081\n",
            "Iteration 781, loss = 1450277241.76019025\n",
            "Iteration 782, loss = 1450172089.57878661\n",
            "Iteration 783, loss = 1450066380.72055984\n",
            "Iteration 784, loss = 1449960803.58395123\n",
            "Iteration 785, loss = 1449854640.86335707\n",
            "Iteration 786, loss = 1449748965.85039997\n",
            "Iteration 787, loss = 1449643783.30418181\n",
            "Iteration 788, loss = 1449537113.36636376\n",
            "Iteration 789, loss = 1449432180.12062955\n",
            "Iteration 790, loss = 1449325871.39740396\n",
            "Iteration 791, loss = 1449220807.27544761\n",
            "Iteration 792, loss = 1449115656.98020720\n",
            "Iteration 793, loss = 1449011024.39236999\n",
            "Iteration 794, loss = 1448905835.31972075\n",
            "Iteration 795, loss = 1448801085.71372199\n",
            "Iteration 796, loss = 1448696026.11032915\n",
            "Iteration 797, loss = 1448591203.74375820\n",
            "Iteration 798, loss = 1448486230.75691366\n",
            "Iteration 799, loss = 1448380575.36210346\n",
            "Iteration 800, loss = 1448275180.18281555\n",
            "Iteration 801, loss = 1448169549.81604505\n",
            "Iteration 802, loss = 1448063348.46899676\n",
            "Iteration 803, loss = 1447957870.18619037\n",
            "Iteration 804, loss = 1447852194.13909888\n",
            "Iteration 805, loss = 1447746164.55545497\n",
            "Iteration 806, loss = 1447639702.24933434\n",
            "Iteration 807, loss = 1447533398.76253653\n",
            "Iteration 808, loss = 1447427808.96800423\n",
            "Iteration 809, loss = 1447321301.82710028\n",
            "Iteration 810, loss = 1447214350.88282466\n",
            "Iteration 811, loss = 1447108389.68501067\n",
            "Iteration 812, loss = 1447002478.06772375\n",
            "Iteration 813, loss = 1446895931.43792939\n",
            "Iteration 814, loss = 1446789365.13075852\n",
            "Iteration 815, loss = 1446683960.34459162\n",
            "Iteration 816, loss = 1446578006.05277133\n",
            "Iteration 817, loss = 1446472087.81646514\n",
            "Iteration 818, loss = 1446366584.18008327\n",
            "Iteration 819, loss = 1446260755.06400037\n",
            "Iteration 820, loss = 1446155587.24139810\n",
            "Iteration 821, loss = 1446050921.62276649\n",
            "Iteration 822, loss = 1445945972.46099591\n",
            "Iteration 823, loss = 1445840987.88723516\n",
            "Iteration 824, loss = 1445736363.88485885\n",
            "Iteration 825, loss = 1445631417.72518015\n",
            "Iteration 826, loss = 1445527143.47872710\n",
            "Iteration 827, loss = 1445422177.50911975\n",
            "Iteration 828, loss = 1445317219.06435370\n",
            "Iteration 829, loss = 1445212979.14715838\n",
            "Iteration 830, loss = 1445108295.64042377\n",
            "Iteration 831, loss = 1445003231.30509448\n",
            "Iteration 832, loss = 1444898283.31053042\n",
            "Iteration 833, loss = 1444793568.82785940\n",
            "Iteration 834, loss = 1444689286.54049969\n",
            "Iteration 835, loss = 1444583550.41396570\n",
            "Iteration 836, loss = 1444479348.09600782\n",
            "Iteration 837, loss = 1444374602.16537452\n",
            "Iteration 838, loss = 1444270343.97240782\n",
            "Iteration 839, loss = 1444165682.94727325\n",
            "Iteration 840, loss = 1444061493.91447306\n",
            "Iteration 841, loss = 1443956586.96711326\n",
            "Iteration 842, loss = 1443852148.24671555\n",
            "Iteration 843, loss = 1443746530.29362488\n",
            "Iteration 844, loss = 1443641657.04845738\n",
            "Iteration 845, loss = 1443535982.03939390\n",
            "Iteration 846, loss = 1443430160.03185010\n",
            "Iteration 847, loss = 1443325501.52470613\n",
            "Iteration 848, loss = 1443219730.41524172\n",
            "Iteration 849, loss = 1443114429.18799853\n",
            "Iteration 850, loss = 1443009227.12416029\n",
            "Iteration 851, loss = 1442904426.97705007\n",
            "Iteration 852, loss = 1442799780.68751574\n",
            "Iteration 853, loss = 1442694701.68969798\n",
            "Iteration 854, loss = 1442589651.94706202\n",
            "Iteration 855, loss = 1442485264.13409519\n",
            "Iteration 856, loss = 1442380414.52359700\n",
            "Iteration 857, loss = 1442275589.05711341\n",
            "Iteration 858, loss = 1442170334.50430608\n",
            "Iteration 859, loss = 1442064755.53036427\n",
            "Iteration 860, loss = 1441960442.35834646\n",
            "Iteration 861, loss = 1441854700.17617774\n",
            "Iteration 862, loss = 1441749832.42826819\n",
            "Iteration 863, loss = 1441644213.92454672\n",
            "Iteration 864, loss = 1441538927.44664049\n",
            "Iteration 865, loss = 1441433322.00859880\n",
            "Iteration 866, loss = 1441328972.34207916\n",
            "Iteration 867, loss = 1441223216.10763836\n",
            "Iteration 868, loss = 1441118652.95753431\n",
            "Iteration 869, loss = 1441013313.44682050\n",
            "Iteration 870, loss = 1440908873.31225944\n",
            "Iteration 871, loss = 1440803423.19822884\n",
            "Iteration 872, loss = 1440699097.91573834\n",
            "Iteration 873, loss = 1440593988.75826526\n",
            "Iteration 874, loss = 1440488914.09140444\n",
            "Iteration 875, loss = 1440384304.34712648\n",
            "Iteration 876, loss = 1440279066.54729772\n",
            "Iteration 877, loss = 1440174526.73940802\n",
            "Iteration 878, loss = 1440069231.42947221\n",
            "Iteration 879, loss = 1439964996.29664230\n",
            "Iteration 880, loss = 1439860254.77063489\n",
            "Iteration 881, loss = 1439755018.06190228\n",
            "Iteration 882, loss = 1439650833.84192801\n",
            "Iteration 883, loss = 1439545709.44736576\n",
            "Iteration 884, loss = 1439440580.23402095\n",
            "Iteration 885, loss = 1439335262.50985217\n",
            "Iteration 886, loss = 1439230459.99991107\n",
            "Iteration 887, loss = 1439125182.39142752\n",
            "Iteration 888, loss = 1439019779.19211602\n",
            "Iteration 889, loss = 1438915029.91884828\n",
            "Iteration 890, loss = 1438810049.54551578\n",
            "Iteration 891, loss = 1438705896.86269450\n",
            "Iteration 892, loss = 1438600416.16420245\n",
            "Iteration 893, loss = 1438496323.75293803\n",
            "Iteration 894, loss = 1438391830.91237140\n",
            "Iteration 895, loss = 1438286516.17449498\n",
            "Iteration 896, loss = 1438182520.06122923\n",
            "Iteration 897, loss = 1438077853.02536368\n",
            "Iteration 898, loss = 1437972890.57396102\n",
            "Iteration 899, loss = 1437868471.72625804\n",
            "Iteration 900, loss = 1437763952.30926704\n",
            "Iteration 901, loss = 1437659668.47946477\n",
            "Iteration 902, loss = 1437555188.06561351\n",
            "Iteration 903, loss = 1437450310.88703728\n",
            "Iteration 904, loss = 1437346428.49361825\n",
            "Iteration 905, loss = 1437241570.86307287\n",
            "Iteration 906, loss = 1437137075.46861553\n",
            "Iteration 907, loss = 1437032663.30274987\n",
            "Iteration 908, loss = 1436927843.44892311\n",
            "Iteration 909, loss = 1436823549.17640972\n",
            "Iteration 910, loss = 1436718702.73247910\n",
            "Iteration 911, loss = 1436614457.99672699\n",
            "Iteration 912, loss = 1436509802.87492752\n",
            "Iteration 913, loss = 1436405098.21275616\n",
            "Iteration 914, loss = 1436301456.14216328\n",
            "Iteration 915, loss = 1436196349.97342324\n",
            "Iteration 916, loss = 1436092871.37398553\n",
            "Iteration 917, loss = 1435988101.83348680\n",
            "Iteration 918, loss = 1435883524.21960831\n",
            "Iteration 919, loss = 1435780003.52818608\n",
            "Iteration 920, loss = 1435675602.24164677\n",
            "Iteration 921, loss = 1435571106.05771947\n",
            "Iteration 922, loss = 1435466421.99057245\n",
            "Iteration 923, loss = 1435362123.03679228\n",
            "Iteration 924, loss = 1435258292.37247539\n",
            "Iteration 925, loss = 1435153833.07513142\n",
            "Iteration 926, loss = 1435049283.09284353\n",
            "Iteration 927, loss = 1434944814.92873168\n",
            "Iteration 928, loss = 1434840689.25941062\n",
            "Iteration 929, loss = 1434736503.40440774\n",
            "Iteration 930, loss = 1434631915.43330479\n",
            "Iteration 931, loss = 1434527713.81793666\n",
            "Iteration 932, loss = 1434424141.32004690\n",
            "Iteration 933, loss = 1434318628.04997468\n",
            "Iteration 934, loss = 1434215591.67587161\n",
            "Iteration 935, loss = 1434110297.22300959\n",
            "Iteration 936, loss = 1434005936.89277554\n",
            "Iteration 937, loss = 1433901452.42205906\n",
            "Iteration 938, loss = 1433796942.32105279\n",
            "Iteration 939, loss = 1433692217.61331725\n",
            "Iteration 940, loss = 1433586771.91239929\n",
            "Iteration 941, loss = 1433482544.78842425\n",
            "Iteration 942, loss = 1433377557.36166763\n",
            "Iteration 943, loss = 1433272380.60150456\n",
            "Iteration 944, loss = 1433167969.15104318\n",
            "Iteration 945, loss = 1433063142.42978382\n",
            "Iteration 946, loss = 1432958445.93344593\n",
            "Iteration 947, loss = 1432854051.43642902\n",
            "Iteration 948, loss = 1432749692.18768263\n",
            "Iteration 949, loss = 1432644748.06097651\n",
            "Iteration 950, loss = 1432540702.39504576\n",
            "Iteration 951, loss = 1432436704.00827003\n",
            "Iteration 952, loss = 1432331695.42198825\n",
            "Iteration 953, loss = 1432226915.47726703\n",
            "Iteration 954, loss = 1432122985.35302591\n",
            "Iteration 955, loss = 1432018372.38021874\n",
            "Iteration 956, loss = 1431913458.39573193\n",
            "Iteration 957, loss = 1431809519.58864403\n",
            "Iteration 958, loss = 1431705107.38946176\n",
            "Iteration 959, loss = 1431601421.72270441\n",
            "Iteration 960, loss = 1431496248.61378551\n",
            "Iteration 961, loss = 1431391989.83686376\n",
            "Iteration 962, loss = 1431289018.47640800\n",
            "Iteration 963, loss = 1431183496.18551707\n",
            "Iteration 964, loss = 1431079476.93096852\n",
            "Iteration 965, loss = 1430975200.60455728\n",
            "Iteration 966, loss = 1430870717.56458569\n",
            "Iteration 967, loss = 1430767367.98811722\n",
            "Iteration 968, loss = 1430662911.60855937\n",
            "Iteration 969, loss = 1430558819.34907031\n",
            "Iteration 970, loss = 1430455263.44221711\n",
            "Iteration 971, loss = 1430350512.94537330\n",
            "Iteration 972, loss = 1430247216.26340485\n",
            "Iteration 973, loss = 1430142488.65989423\n",
            "Iteration 974, loss = 1430038496.08612108\n",
            "Iteration 975, loss = 1429933835.18616939\n",
            "Iteration 976, loss = 1429829681.65414310\n",
            "Iteration 977, loss = 1429725531.75072289\n",
            "Iteration 978, loss = 1429620848.59035635\n",
            "Iteration 979, loss = 1429517097.85708761\n",
            "Iteration 980, loss = 1429412514.29917049\n",
            "Iteration 981, loss = 1429308505.57620549\n",
            "Iteration 982, loss = 1429204459.06517768\n",
            "Iteration 983, loss = 1429100609.80708861\n",
            "Iteration 984, loss = 1428995727.16148853\n",
            "Iteration 985, loss = 1428892121.05370569\n",
            "Iteration 986, loss = 1428787881.84552860\n",
            "Iteration 987, loss = 1428683793.41973686\n",
            "Iteration 988, loss = 1428579058.89856982\n",
            "Iteration 989, loss = 1428475516.55497718\n",
            "Iteration 990, loss = 1428371387.96825075\n",
            "Iteration 991, loss = 1428266624.62660742\n",
            "Iteration 992, loss = 1428163259.52544594\n",
            "Iteration 993, loss = 1428059579.12532115\n",
            "Iteration 994, loss = 1427955450.54382157\n",
            "Iteration 995, loss = 1427852018.38462281\n",
            "Iteration 996, loss = 1427748424.49369907\n",
            "Iteration 997, loss = 1427644474.85917377\n",
            "Iteration 998, loss = 1427540754.99737716\n",
            "Iteration 999, loss = 1427436762.91230130\n",
            "Iteration 1000, loss = 1427333354.13292432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2327591410863723.50000000\n",
            "Iteration 2, loss = 118033381712920323523455912994040173284459271295713862706623181832719041964589861974498823793219532965112990333913351850138514040709458869111338496201886503664064254812978408588127088639320753427893514336664723994443776.00000000\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (100, 50), relu, 0.0001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538793587.85306668\n",
            "Iteration 2, loss = 1538726113.72319365\n",
            "Iteration 3, loss = 1538639852.01894331\n",
            "Iteration 4, loss = 1538516755.76887178\n",
            "Iteration 5, loss = 1538343098.71732807\n",
            "Iteration 6, loss = 1538103609.45385718\n",
            "Iteration 7, loss = 1537777241.36769891\n",
            "Iteration 8, loss = 1537365220.58268142\n",
            "Iteration 9, loss = 1536820503.24109817\n",
            "Iteration 10, loss = 1536137575.84551215\n",
            "Iteration 11, loss = 1535287859.70233870\n",
            "Iteration 12, loss = 1534258432.55846190\n",
            "Iteration 13, loss = 1532982746.43033743\n",
            "Iteration 14, loss = 1531471504.45364213\n",
            "Iteration 15, loss = 1529643079.78791308\n",
            "Iteration 16, loss = 1527456756.80927658\n",
            "Iteration 17, loss = 1524904945.55639386\n",
            "Iteration 18, loss = 1521905927.27456284\n",
            "Iteration 19, loss = 1518386173.40590906\n",
            "Iteration 20, loss = 1514382519.83297276\n",
            "Iteration 21, loss = 1509851304.42944217\n",
            "Iteration 22, loss = 1504539872.96789718\n",
            "Iteration 23, loss = 1498608452.15468550\n",
            "Iteration 24, loss = 1491912444.05952454\n",
            "Iteration 25, loss = 1484418736.68565726\n",
            "Iteration 26, loss = 1475878262.87754941\n",
            "Iteration 27, loss = 1466428370.25298524\n",
            "Iteration 28, loss = 1456204031.37685037\n",
            "Iteration 29, loss = 1444466880.51181650\n",
            "Iteration 30, loss = 1432055122.38135958\n",
            "Iteration 31, loss = 1418175849.16248870\n",
            "Iteration 32, loss = 1402869872.03481388\n",
            "Iteration 33, loss = 1386584531.51968026\n",
            "Iteration 34, loss = 1368766024.54986143\n",
            "Iteration 35, loss = 1349317825.29960418\n",
            "Iteration 36, loss = 1328242852.44289207\n",
            "Iteration 37, loss = 1305711488.29579282\n",
            "Iteration 38, loss = 1281551121.41372252\n",
            "Iteration 39, loss = 1256057578.04571819\n",
            "Iteration 40, loss = 1228466733.83239365\n",
            "Iteration 41, loss = 1199497059.02134180\n",
            "Iteration 42, loss = 1168337098.83654857\n",
            "Iteration 43, loss = 1136771024.01179671\n",
            "Iteration 44, loss = 1102850468.50378585\n",
            "Iteration 45, loss = 1067588094.97321153\n",
            "Iteration 46, loss = 1030355362.36085808\n",
            "Iteration 47, loss = 993087078.16711640\n",
            "Iteration 48, loss = 953579571.84716964\n",
            "Iteration 49, loss = 912961344.70227504\n",
            "Iteration 50, loss = 871523253.37208867\n",
            "Iteration 51, loss = 829507120.76310158\n",
            "Iteration 52, loss = 786238537.49545872\n",
            "Iteration 53, loss = 743189468.60105562\n",
            "Iteration 54, loss = 699551953.00449467\n",
            "Iteration 55, loss = 656127591.53367233\n",
            "Iteration 56, loss = 612795044.98424089\n",
            "Iteration 57, loss = 570145908.69810998\n",
            "Iteration 58, loss = 528476190.79011881\n",
            "Iteration 59, loss = 487829050.50729036\n",
            "Iteration 60, loss = 448658873.51433688\n",
            "Iteration 61, loss = 411259348.62625325\n",
            "Iteration 62, loss = 375309795.74823213\n",
            "Iteration 63, loss = 341670204.05609220\n",
            "Iteration 64, loss = 310433884.86512393\n",
            "Iteration 65, loss = 281565571.90446836\n",
            "Iteration 66, loss = 254866380.45073605\n",
            "Iteration 67, loss = 231150982.01350182\n",
            "Iteration 68, loss = 209771519.19770226\n",
            "Iteration 69, loss = 190932403.02329311\n",
            "Iteration 70, loss = 174968955.10670325\n",
            "Iteration 71, loss = 161680381.35946870\n",
            "Iteration 72, loss = 149972013.85013488\n",
            "Iteration 73, loss = 140858181.27208048\n",
            "Iteration 74, loss = 133536294.09500459\n",
            "Iteration 75, loss = 127655363.68099612\n",
            "Iteration 76, loss = 123250752.12498754\n",
            "Iteration 77, loss = 120382372.03154463\n",
            "Iteration 78, loss = 118035610.31865464\n",
            "Iteration 79, loss = 116487530.91050997\n",
            "Iteration 80, loss = 115320554.04046841\n",
            "Iteration 81, loss = 114361454.14451936\n",
            "Iteration 82, loss = 113866582.15924723\n",
            "Iteration 83, loss = 113118013.16200168\n",
            "Iteration 84, loss = 112493501.60055597\n",
            "Iteration 85, loss = 111753975.27609310\n",
            "Iteration 86, loss = 111016228.04045042\n",
            "Iteration 87, loss = 110273147.18277787\n",
            "Iteration 88, loss = 109496636.66918157\n",
            "Iteration 89, loss = 108641436.74504852\n",
            "Iteration 90, loss = 107794112.97628826\n",
            "Iteration 91, loss = 106925521.87609045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 92, loss = 106015151.12804525\n",
            "Iteration 93, loss = 105058105.72565374\n",
            "Iteration 94, loss = 104129154.88207260\n",
            "Iteration 95, loss = 103128770.33590719\n",
            "Iteration 96, loss = 102187542.06324379\n",
            "Iteration 97, loss = 101314832.14427444\n",
            "Iteration 98, loss = 100375102.33087765\n",
            "Iteration 99, loss = 99492994.46589972\n",
            "Iteration 100, loss = 98618139.80361231\n",
            "Iteration 101, loss = 97748152.02821712\n",
            "Iteration 102, loss = 96879819.78039204\n",
            "Iteration 103, loss = 95961536.97549371\n",
            "Iteration 104, loss = 95066421.37156710\n",
            "Iteration 105, loss = 94156497.11965239\n",
            "Iteration 106, loss = 93210640.74930976\n",
            "Iteration 107, loss = 92202008.30392517\n",
            "Iteration 108, loss = 91197527.51348618\n",
            "Iteration 109, loss = 90125784.49931340\n",
            "Iteration 110, loss = 89103665.29684475\n",
            "Iteration 111, loss = 88022902.86680326\n",
            "Iteration 112, loss = 86960679.80625784\n",
            "Iteration 113, loss = 85887443.71508430\n",
            "Iteration 114, loss = 84804623.77764253\n",
            "Iteration 115, loss = 83762828.15140188\n",
            "Iteration 116, loss = 82660070.68034421\n",
            "Iteration 117, loss = 81642132.58664840\n",
            "Iteration 118, loss = 80496035.89814377\n",
            "Iteration 119, loss = 79406159.03170106\n",
            "Iteration 120, loss = 78292176.33622773\n",
            "Iteration 121, loss = 77145151.26811865\n",
            "Iteration 122, loss = 76009825.52208048\n",
            "Iteration 123, loss = 74860783.25071917\n",
            "Iteration 124, loss = 73709437.22040890\n",
            "Iteration 125, loss = 72532899.47260356\n",
            "Iteration 126, loss = 71404760.46320090\n",
            "Iteration 127, loss = 70265134.95008098\n",
            "Iteration 128, loss = 69106309.37574080\n",
            "Iteration 129, loss = 67997632.42938294\n",
            "Iteration 130, loss = 66874204.61042584\n",
            "Iteration 131, loss = 65773836.04536255\n",
            "Iteration 132, loss = 64694848.64365508\n",
            "Iteration 133, loss = 63612333.05846654\n",
            "Iteration 134, loss = 62595563.22753976\n",
            "Iteration 135, loss = 61612869.97388959\n",
            "Iteration 136, loss = 60651443.70271758\n",
            "Iteration 137, loss = 59747284.70098533\n",
            "Iteration 138, loss = 58858785.32124478\n",
            "Iteration 139, loss = 58102084.51299458\n",
            "Iteration 140, loss = 57314677.49398501\n",
            "Iteration 141, loss = 56603380.52059068\n",
            "Iteration 142, loss = 55909958.30113193\n",
            "Iteration 143, loss = 55272406.39096161\n",
            "Iteration 144, loss = 54643019.44238764\n",
            "Iteration 145, loss = 54027917.65993480\n",
            "Iteration 146, loss = 53445100.04876497\n",
            "Iteration 147, loss = 52860903.70064180\n",
            "Iteration 148, loss = 52325015.07438321\n",
            "Iteration 149, loss = 51755836.56791655\n",
            "Iteration 150, loss = 51273391.30120719\n",
            "Iteration 151, loss = 50796679.00040807\n",
            "Iteration 152, loss = 50374871.51869275\n",
            "Iteration 153, loss = 49979088.17038963\n",
            "Iteration 154, loss = 49621525.42833220\n",
            "Iteration 155, loss = 49240424.66161143\n",
            "Iteration 156, loss = 48893491.42604563\n",
            "Iteration 157, loss = 48568362.82764798\n",
            "Iteration 158, loss = 48249226.98579101\n",
            "Iteration 159, loss = 47933373.11750100\n",
            "Iteration 160, loss = 47632596.81141081\n",
            "Iteration 161, loss = 47349948.01586852\n",
            "Iteration 162, loss = 47045043.23866495\n",
            "Iteration 163, loss = 46751642.00669356\n",
            "Iteration 164, loss = 46445639.52141410\n",
            "Iteration 165, loss = 46164189.45510837\n",
            "Iteration 166, loss = 45852045.95711789\n",
            "Iteration 167, loss = 45575295.29446723\n",
            "Iteration 168, loss = 45292143.01151627\n",
            "Iteration 169, loss = 44995807.52592761\n",
            "Iteration 170, loss = 44704761.75748013\n",
            "Iteration 171, loss = 44400350.67444608\n",
            "Iteration 172, loss = 44094218.42928010\n",
            "Iteration 173, loss = 43812185.62766913\n",
            "Iteration 174, loss = 43530209.87591556\n",
            "Iteration 175, loss = 43214692.07040647\n",
            "Iteration 176, loss = 42950672.28100574\n",
            "Iteration 177, loss = 42651635.25899785\n",
            "Iteration 178, loss = 42418580.24718922\n",
            "Iteration 179, loss = 42140494.77233793\n",
            "Iteration 180, loss = 41870562.35289289\n",
            "Iteration 181, loss = 41605730.68849018\n",
            "Iteration 182, loss = 41309743.93577518\n",
            "Iteration 183, loss = 41019056.08461002\n",
            "Iteration 184, loss = 40727701.73799001\n",
            "Iteration 185, loss = 40460885.02510393\n",
            "Iteration 186, loss = 40191505.01580142\n",
            "Iteration 187, loss = 39937265.76132587\n",
            "Iteration 188, loss = 39666082.91122139\n",
            "Iteration 189, loss = 39435339.92756182\n",
            "Iteration 190, loss = 39178171.63696279\n",
            "Iteration 191, loss = 38944774.41736282\n",
            "Iteration 192, loss = 38681696.54041555\n",
            "Iteration 193, loss = 38414955.33041023\n",
            "Iteration 194, loss = 38155846.75922525\n",
            "Iteration 195, loss = 37898072.03190488\n",
            "Iteration 196, loss = 37626689.57951219\n",
            "Iteration 197, loss = 37353802.55091134\n",
            "Iteration 198, loss = 37095845.78856126\n",
            "Iteration 199, loss = 36806746.75155696\n",
            "Iteration 200, loss = 36545773.48229416\n",
            "Iteration 201, loss = 36274072.57199685\n",
            "Iteration 202, loss = 36022311.94585056\n",
            "Iteration 203, loss = 35759426.19211029\n",
            "Iteration 204, loss = 35512200.26578481\n",
            "Iteration 205, loss = 35263519.17666649\n",
            "Iteration 206, loss = 35014355.72159179\n",
            "Iteration 207, loss = 34753406.30312680\n",
            "Iteration 208, loss = 34512134.77478433\n",
            "Iteration 209, loss = 34279170.05599480\n",
            "Iteration 210, loss = 33998609.14642866\n",
            "Iteration 211, loss = 33752365.31124239\n",
            "Iteration 212, loss = 33518234.70093079\n",
            "Iteration 213, loss = 33275045.05929726\n",
            "Iteration 214, loss = 33030249.57723098\n",
            "Iteration 215, loss = 32780604.22153381\n",
            "Iteration 216, loss = 32531489.04381243\n",
            "Iteration 217, loss = 32296152.08852659\n",
            "Iteration 218, loss = 32045786.53644483\n",
            "Iteration 219, loss = 31799180.32054469\n",
            "Iteration 220, loss = 31551207.40407313\n",
            "Iteration 221, loss = 31295977.16394836\n",
            "Iteration 222, loss = 31065487.76169613\n",
            "Iteration 223, loss = 30815735.94352500\n",
            "Iteration 224, loss = 30549243.73928781\n",
            "Iteration 225, loss = 30302197.58756671\n",
            "Iteration 226, loss = 30037842.85315806\n",
            "Iteration 227, loss = 29782604.45835287\n",
            "Iteration 228, loss = 29533830.47623232\n",
            "Iteration 229, loss = 29293468.96214310\n",
            "Iteration 230, loss = 29036645.59712697\n",
            "Iteration 231, loss = 28811474.63478759\n",
            "Iteration 232, loss = 28556941.85198835\n",
            "Iteration 233, loss = 28299339.38619473\n",
            "Iteration 234, loss = 28069354.38702480\n",
            "Iteration 235, loss = 27822112.22186800\n",
            "Iteration 236, loss = 27583501.93299263\n",
            "Iteration 237, loss = 27328717.75987450\n",
            "Iteration 238, loss = 27098130.36738549\n",
            "Iteration 239, loss = 26849487.58221292\n",
            "Iteration 240, loss = 26598085.44816897\n",
            "Iteration 241, loss = 26362822.24164969\n",
            "Iteration 242, loss = 26126392.19649075\n",
            "Iteration 243, loss = 25890575.37623890\n",
            "Iteration 244, loss = 25653863.26581217\n",
            "Iteration 245, loss = 25421785.81311532\n",
            "Iteration 246, loss = 25188405.78976288\n",
            "Iteration 247, loss = 24936856.84485665\n",
            "Iteration 248, loss = 24705208.28828342\n",
            "Iteration 249, loss = 24454203.88264125\n",
            "Iteration 250, loss = 24232183.36149012\n",
            "Iteration 251, loss = 23962680.69596899\n",
            "Iteration 252, loss = 23726435.36273491\n",
            "Iteration 253, loss = 23463009.17011562\n",
            "Iteration 254, loss = 23225664.26298522\n",
            "Iteration 255, loss = 22965825.75264018\n",
            "Iteration 256, loss = 22706060.97477257\n",
            "Iteration 257, loss = 22447958.13733309\n",
            "Iteration 258, loss = 22183152.92565968\n",
            "Iteration 259, loss = 21918406.11251787\n",
            "Iteration 260, loss = 21641681.23079448\n",
            "Iteration 261, loss = 21381422.08882328\n",
            "Iteration 262, loss = 21088255.95765031\n",
            "Iteration 263, loss = 20827390.94947332\n",
            "Iteration 264, loss = 20542567.93253811\n",
            "Iteration 265, loss = 20273246.92199015\n",
            "Iteration 266, loss = 19994924.18377698\n",
            "Iteration 267, loss = 19715787.85506835\n",
            "Iteration 268, loss = 19438372.63512173\n",
            "Iteration 269, loss = 19165223.28165365\n",
            "Iteration 270, loss = 18870597.86131443\n",
            "Iteration 271, loss = 18603329.33857558\n",
            "Iteration 272, loss = 18318644.37856846\n",
            "Iteration 273, loss = 18021105.51002967\n",
            "Iteration 274, loss = 17715113.38507454\n",
            "Iteration 275, loss = 17399420.68920096\n",
            "Iteration 276, loss = 17117368.32945167\n",
            "Iteration 277, loss = 16791890.81882820\n",
            "Iteration 278, loss = 16496717.96219150\n",
            "Iteration 279, loss = 16199628.39282020\n",
            "Iteration 280, loss = 15882750.58528735\n",
            "Iteration 281, loss = 15567596.69125151\n",
            "Iteration 282, loss = 15271339.20755760\n",
            "Iteration 283, loss = 14947426.02390676\n",
            "Iteration 284, loss = 14649316.74796931\n",
            "Iteration 285, loss = 14336668.87023389\n",
            "Iteration 286, loss = 14031762.84085129\n",
            "Iteration 287, loss = 13735407.62616462\n",
            "Iteration 288, loss = 13429611.50402321\n",
            "Iteration 289, loss = 13139154.99961784\n",
            "Iteration 290, loss = 12851929.86758087\n",
            "Iteration 291, loss = 12565607.18493299\n",
            "Iteration 292, loss = 12287348.65853082\n",
            "Iteration 293, loss = 12001245.35482552\n",
            "Iteration 294, loss = 11724521.62395130\n",
            "Iteration 295, loss = 11441976.93291987\n",
            "Iteration 296, loss = 11154477.81485486\n",
            "Iteration 297, loss = 10883105.81267632\n",
            "Iteration 298, loss = 10605391.26016322\n",
            "Iteration 299, loss = 10347069.07092019\n",
            "Iteration 300, loss = 10098721.52031725\n",
            "Iteration 301, loss = 9844289.76158802\n",
            "Iteration 302, loss = 9600071.30604940\n",
            "Iteration 303, loss = 9359000.85940200\n",
            "Iteration 304, loss = 9131919.20019399\n",
            "Iteration 305, loss = 8903034.03160844\n",
            "Iteration 306, loss = 8677812.16140059\n",
            "Iteration 307, loss = 8462733.67520346\n",
            "Iteration 308, loss = 8255533.32695842\n",
            "Iteration 309, loss = 8051038.74167443\n",
            "Iteration 310, loss = 7848326.31917158\n",
            "Iteration 311, loss = 7639169.23273048\n",
            "Iteration 312, loss = 7450172.73127889\n",
            "Iteration 313, loss = 7265114.71957537\n",
            "Iteration 314, loss = 7083390.18265992\n",
            "Iteration 315, loss = 6909737.31493746\n",
            "Iteration 316, loss = 6748457.01894086\n",
            "Iteration 317, loss = 6595191.50767415\n",
            "Iteration 318, loss = 6435933.91556654\n",
            "Iteration 319, loss = 6281306.56973449\n",
            "Iteration 320, loss = 6124990.63516797\n",
            "Iteration 321, loss = 5964645.14091616\n",
            "Iteration 322, loss = 5817841.27379881\n",
            "Iteration 323, loss = 5675527.15786660\n",
            "Iteration 324, loss = 5531591.41939540\n",
            "Iteration 325, loss = 5398099.27309696\n",
            "Iteration 326, loss = 5272570.84004835\n",
            "Iteration 327, loss = 5147103.75393112\n",
            "Iteration 328, loss = 5026585.89556893\n",
            "Iteration 329, loss = 4905951.69413042\n",
            "Iteration 330, loss = 4790899.82482972\n",
            "Iteration 331, loss = 4681702.27602014\n",
            "Iteration 332, loss = 4574388.18022767\n",
            "Iteration 333, loss = 4473047.69679074\n",
            "Iteration 334, loss = 4372593.29149958\n",
            "Iteration 335, loss = 4278830.64017127\n",
            "Iteration 336, loss = 4190374.72752465\n",
            "Iteration 337, loss = 4096992.01475804\n",
            "Iteration 338, loss = 4013121.45158179\n",
            "Iteration 339, loss = 3928559.44633187\n",
            "Iteration 340, loss = 3850059.35829509\n",
            "Iteration 341, loss = 3771340.75746281\n",
            "Iteration 342, loss = 3698426.32229420\n",
            "Iteration 343, loss = 3626338.35941204\n",
            "Iteration 344, loss = 3559808.34959901\n",
            "Iteration 345, loss = 3494732.32614848\n",
            "Iteration 346, loss = 3432418.30623385\n",
            "Iteration 347, loss = 3368767.12410408\n",
            "Iteration 348, loss = 3314322.18114791\n",
            "Iteration 349, loss = 3257679.02237920\n",
            "Iteration 350, loss = 3205267.53447653\n",
            "Iteration 351, loss = 3150989.27661985\n",
            "Iteration 352, loss = 3093470.53700018\n",
            "Iteration 353, loss = 3037224.80921732\n",
            "Iteration 354, loss = 2983153.23869468\n",
            "Iteration 355, loss = 2930281.37361894\n",
            "Iteration 356, loss = 2882049.29214036\n",
            "Iteration 357, loss = 2835228.12829874\n",
            "Iteration 358, loss = 2788163.53926857\n",
            "Iteration 359, loss = 2743551.39432913\n",
            "Iteration 360, loss = 2703894.72908421\n",
            "Iteration 361, loss = 2662587.26203360\n",
            "Iteration 362, loss = 2625271.86580689\n",
            "Iteration 363, loss = 2589043.26752409\n",
            "Iteration 364, loss = 2553655.43006971\n",
            "Iteration 365, loss = 2516171.77716221\n",
            "Iteration 366, loss = 2483631.03334465\n",
            "Iteration 367, loss = 2446834.50681800\n",
            "Iteration 368, loss = 2412104.08840848\n",
            "Iteration 369, loss = 2378494.11185346\n",
            "Iteration 370, loss = 2347805.56861999\n",
            "Iteration 371, loss = 2313208.68256079\n",
            "Iteration 372, loss = 2281398.58728600\n",
            "Iteration 373, loss = 2252102.98218100\n",
            "Iteration 374, loss = 2221035.88420886\n",
            "Iteration 375, loss = 2194921.41089865\n",
            "Iteration 376, loss = 2168082.20660433\n",
            "Iteration 377, loss = 2139870.14472307\n",
            "Iteration 378, loss = 2113334.88203421\n",
            "Iteration 379, loss = 2087295.76797804\n",
            "Iteration 380, loss = 2063149.36920110\n",
            "Iteration 381, loss = 2041740.41417828\n",
            "Iteration 382, loss = 2018001.92220503\n",
            "Iteration 383, loss = 1996861.40312528\n",
            "Iteration 384, loss = 1974963.88796605\n",
            "Iteration 385, loss = 1954569.59303930\n",
            "Iteration 386, loss = 1933570.34717931\n",
            "Iteration 387, loss = 1914615.55379461\n",
            "Iteration 388, loss = 1897088.31790629\n",
            "Iteration 389, loss = 1879389.32491936\n",
            "Iteration 390, loss = 1861605.48760725\n",
            "Iteration 391, loss = 1844374.71614627\n",
            "Iteration 392, loss = 1827999.42117495\n",
            "Iteration 393, loss = 1812211.37803208\n",
            "Iteration 394, loss = 1794836.83941732\n",
            "Iteration 395, loss = 1779409.90382502\n",
            "Iteration 396, loss = 1765057.09972292\n",
            "Iteration 397, loss = 1749462.71180810\n",
            "Iteration 398, loss = 1733650.49272593\n",
            "Iteration 399, loss = 1719749.64731506\n",
            "Iteration 400, loss = 1705895.79421862\n",
            "Iteration 401, loss = 1694089.47158686\n",
            "Iteration 402, loss = 1680585.69455206\n",
            "Iteration 403, loss = 1668581.41927370\n",
            "Iteration 404, loss = 1655863.96915606\n",
            "Iteration 405, loss = 1642412.75541583\n",
            "Iteration 406, loss = 1630137.10357409\n",
            "Iteration 407, loss = 1616881.90167971\n",
            "Iteration 408, loss = 1605335.09768483\n",
            "Iteration 409, loss = 1596081.23688319\n",
            "Iteration 410, loss = 1584216.82539469\n",
            "Iteration 411, loss = 1572135.37743706\n",
            "Iteration 412, loss = 1559583.26835346\n",
            "Iteration 413, loss = 1547102.08274756\n",
            "Iteration 414, loss = 1535703.42258408\n",
            "Iteration 415, loss = 1524956.17456829\n",
            "Iteration 416, loss = 1515616.25984095\n",
            "Iteration 417, loss = 1505781.10896230\n",
            "Iteration 418, loss = 1496019.21984295\n",
            "Iteration 419, loss = 1486379.88469564\n",
            "Iteration 420, loss = 1477278.94485711\n",
            "Iteration 421, loss = 1467934.69057588\n",
            "Iteration 422, loss = 1460416.74541884\n",
            "Iteration 423, loss = 1453015.40808369\n",
            "Iteration 424, loss = 1445415.38974726\n",
            "Iteration 425, loss = 1438153.31917643\n",
            "Iteration 426, loss = 1431014.72324655\n",
            "Iteration 427, loss = 1422206.73871878\n",
            "Iteration 428, loss = 1415007.74338391\n",
            "Iteration 429, loss = 1408296.94569164\n",
            "Iteration 430, loss = 1401875.81219931\n",
            "Iteration 431, loss = 1394916.39144359\n",
            "Iteration 432, loss = 1388415.23870737\n",
            "Iteration 433, loss = 1384410.30235938\n",
            "Iteration 434, loss = 1378500.90385308\n",
            "Iteration 435, loss = 1372075.78527930\n",
            "Iteration 436, loss = 1366727.32218490\n",
            "Iteration 437, loss = 1359286.90794296\n",
            "Iteration 438, loss = 1353904.90027311\n",
            "Iteration 439, loss = 1350528.85119144\n",
            "Iteration 440, loss = 1345198.61556390\n",
            "Iteration 441, loss = 1340340.59018026\n",
            "Iteration 442, loss = 1335413.35849435\n",
            "Iteration 443, loss = 1332848.11419345\n",
            "Iteration 444, loss = 1328992.77774104\n",
            "Iteration 445, loss = 1324116.28041461\n",
            "Iteration 446, loss = 1318129.88710080\n",
            "Iteration 447, loss = 1312175.77843904\n",
            "Iteration 448, loss = 1308617.13649878\n",
            "Iteration 449, loss = 1303979.80152938\n",
            "Iteration 450, loss = 1300542.20237346\n",
            "Iteration 451, loss = 1297159.86760071\n",
            "Iteration 452, loss = 1293911.56891139\n",
            "Iteration 453, loss = 1290423.81932008\n",
            "Iteration 454, loss = 1286752.72253476\n",
            "Iteration 455, loss = 1283686.19159579\n",
            "Iteration 456, loss = 1279016.30159884\n",
            "Iteration 457, loss = 1276076.79951686\n",
            "Iteration 458, loss = 1272291.72292276\n",
            "Iteration 459, loss = 1267772.46213691\n",
            "Iteration 460, loss = 1264101.39241047\n",
            "Iteration 461, loss = 1260585.33536934\n",
            "Iteration 462, loss = 1257098.80590253\n",
            "Iteration 463, loss = 1253887.63235015\n",
            "Iteration 464, loss = 1250316.07175593\n",
            "Iteration 465, loss = 1248061.21431407\n",
            "Iteration 466, loss = 1244594.17865662\n",
            "Iteration 467, loss = 1241478.49023524\n",
            "Iteration 468, loss = 1238120.15003698\n",
            "Iteration 469, loss = 1235883.81235612\n",
            "Iteration 470, loss = 1233220.03365356\n",
            "Iteration 471, loss = 1231313.29188698\n",
            "Iteration 472, loss = 1229011.84993899\n",
            "Iteration 473, loss = 1226657.71638714\n",
            "Iteration 474, loss = 1223613.10346016\n",
            "Iteration 475, loss = 1220536.00633431\n",
            "Iteration 476, loss = 1217118.14334715\n",
            "Iteration 477, loss = 1215020.60957699\n",
            "Iteration 478, loss = 1212136.46423026\n",
            "Iteration 479, loss = 1209056.66302189\n",
            "Iteration 480, loss = 1206354.66142980\n",
            "Iteration 481, loss = 1203314.03819193\n",
            "Iteration 482, loss = 1200147.61995011\n",
            "Iteration 483, loss = 1199389.88129605\n",
            "Iteration 484, loss = 1200395.96371695\n",
            "Iteration 485, loss = 1197355.07327595\n",
            "Iteration 486, loss = 1193581.70120097\n",
            "Iteration 487, loss = 1189626.00097721\n",
            "Iteration 488, loss = 1186627.15195245\n",
            "Iteration 489, loss = 1183167.79054115\n",
            "Iteration 490, loss = 1181851.79567166\n",
            "Iteration 491, loss = 1179622.03254225\n",
            "Iteration 492, loss = 1177027.18862042\n",
            "Iteration 493, loss = 1174660.10743254\n",
            "Iteration 494, loss = 1173201.61962285\n",
            "Iteration 495, loss = 1170910.22795710\n",
            "Iteration 496, loss = 1168564.57011029\n",
            "Iteration 497, loss = 1166734.61959939\n",
            "Iteration 498, loss = 1164585.19893400\n",
            "Iteration 499, loss = 1162716.40629803\n",
            "Iteration 500, loss = 1161692.33792489\n",
            "Iteration 501, loss = 1160921.38575410\n",
            "Iteration 502, loss = 1159542.53885103\n",
            "Iteration 503, loss = 1158309.37210227\n",
            "Iteration 504, loss = 1156940.83884700\n",
            "Iteration 505, loss = 1155118.22067833\n",
            "Iteration 506, loss = 1152562.83519526\n",
            "Iteration 507, loss = 1151501.30007414\n",
            "Iteration 508, loss = 1147857.28397973\n",
            "Iteration 509, loss = 1146072.23857444\n",
            "Iteration 510, loss = 1144881.11887094\n",
            "Iteration 511, loss = 1144153.95734328\n",
            "Iteration 512, loss = 1142859.72791417\n",
            "Iteration 513, loss = 1141809.74231525\n",
            "Iteration 514, loss = 1140839.05323580\n",
            "Iteration 515, loss = 1139890.11871741\n",
            "Iteration 516, loss = 1138672.95066768\n",
            "Iteration 517, loss = 1136848.25494298\n",
            "Iteration 518, loss = 1134804.66092177\n",
            "Iteration 519, loss = 1133801.55355605\n",
            "Iteration 520, loss = 1131779.93518700\n",
            "Iteration 521, loss = 1129934.44355628\n",
            "Iteration 522, loss = 1128263.74383975\n",
            "Iteration 523, loss = 1127337.90204366\n",
            "Iteration 524, loss = 1126426.88720830\n",
            "Iteration 525, loss = 1125518.72081764\n",
            "Iteration 526, loss = 1124740.80117479\n",
            "Iteration 527, loss = 1123456.68537359\n",
            "Iteration 528, loss = 1121697.11942336\n",
            "Iteration 529, loss = 1120465.39398436\n",
            "Iteration 530, loss = 1119256.63487262\n",
            "Iteration 531, loss = 1118382.47517891\n",
            "Iteration 532, loss = 1118411.33945399\n",
            "Iteration 533, loss = 1117709.17572289\n",
            "Iteration 534, loss = 1115736.76249515\n",
            "Iteration 535, loss = 1115636.49230532\n",
            "Iteration 536, loss = 1112848.54992774\n",
            "Iteration 537, loss = 1111681.95621787\n",
            "Iteration 538, loss = 1111245.95748315\n",
            "Iteration 539, loss = 1110794.25157719\n",
            "Iteration 540, loss = 1111286.28092994\n",
            "Iteration 541, loss = 1111464.52858117\n",
            "Iteration 542, loss = 1110710.03677209\n",
            "Iteration 543, loss = 1108013.89196363\n",
            "Iteration 544, loss = 1107739.72868344\n",
            "Iteration 545, loss = 1104723.16104558\n",
            "Iteration 546, loss = 1103552.63630065\n",
            "Iteration 547, loss = 1103350.94523794\n",
            "Iteration 548, loss = 1104065.64614340\n",
            "Iteration 549, loss = 1102716.11796502\n",
            "Iteration 550, loss = 1100965.94148417\n",
            "Iteration 551, loss = 1099531.39129367\n",
            "Iteration 552, loss = 1098821.48824479\n",
            "Iteration 553, loss = 1098661.46108602\n",
            "Iteration 554, loss = 1099481.52431449\n",
            "Iteration 555, loss = 1098912.18671549\n",
            "Iteration 556, loss = 1097307.19979703\n",
            "Iteration 557, loss = 1096153.27255415\n",
            "Iteration 558, loss = 1094458.37960673\n",
            "Iteration 559, loss = 1093318.03791254\n",
            "Iteration 560, loss = 1092601.66871550\n",
            "Iteration 561, loss = 1092188.96376918\n",
            "Iteration 562, loss = 1092543.19656143\n",
            "Iteration 563, loss = 1092851.03027378\n",
            "Iteration 564, loss = 1093801.15778127\n",
            "Iteration 565, loss = 1093922.11036063\n",
            "Iteration 566, loss = 1092411.07283979\n",
            "Iteration 567, loss = 1089384.56139075\n",
            "Iteration 568, loss = 1088241.03375265\n",
            "Iteration 569, loss = 1087352.39457980\n",
            "Iteration 570, loss = 1086638.16391609\n",
            "Iteration 571, loss = 1087272.97452462\n",
            "Iteration 572, loss = 1085873.19390247\n",
            "Iteration 573, loss = 1084363.23024875\n",
            "Iteration 574, loss = 1084049.79330771\n",
            "Iteration 575, loss = 1083048.97204361\n",
            "Iteration 576, loss = 1082529.01974827\n",
            "Iteration 577, loss = 1082628.18783059\n",
            "Iteration 578, loss = 1083605.41046222\n",
            "Iteration 579, loss = 1083391.15261374\n",
            "Iteration 580, loss = 1081247.18796491\n",
            "Iteration 581, loss = 1079228.15143336\n",
            "Iteration 582, loss = 1079808.22366169\n",
            "Iteration 583, loss = 1081308.40318632\n",
            "Iteration 584, loss = 1080575.67444985\n",
            "Iteration 585, loss = 1079799.78298793\n",
            "Iteration 586, loss = 1078497.22554826\n",
            "Iteration 587, loss = 1077307.96616715\n",
            "Iteration 588, loss = 1076270.31226609\n",
            "Iteration 589, loss = 1075888.20380221\n",
            "Iteration 590, loss = 1074675.06863342\n",
            "Iteration 591, loss = 1074053.49511340\n",
            "Iteration 592, loss = 1073738.14985923\n",
            "Iteration 593, loss = 1073219.00568491\n",
            "Iteration 594, loss = 1072314.13930957\n",
            "Iteration 595, loss = 1072463.95231762\n",
            "Iteration 596, loss = 1072230.67913679\n",
            "Iteration 597, loss = 1072655.23246209\n",
            "Iteration 598, loss = 1073010.28930857\n",
            "Iteration 599, loss = 1072449.33086904\n",
            "Iteration 600, loss = 1071005.62815012\n",
            "Iteration 601, loss = 1070912.49392104\n",
            "Iteration 602, loss = 1069736.81269565\n",
            "Iteration 603, loss = 1070119.85080413\n",
            "Iteration 604, loss = 1070958.56675828\n",
            "Iteration 605, loss = 1074769.58066993\n",
            "Iteration 606, loss = 1073495.21713608\n",
            "Iteration 607, loss = 1069197.26727100\n",
            "Iteration 608, loss = 1065367.37084879\n",
            "Iteration 609, loss = 1067388.70029214\n",
            "Iteration 610, loss = 1068363.00585908\n",
            "Iteration 611, loss = 1069913.29662358\n",
            "Iteration 612, loss = 1069365.33018638\n",
            "Iteration 613, loss = 1067532.33294940\n",
            "Iteration 614, loss = 1065780.00309324\n",
            "Iteration 615, loss = 1065296.57907576\n",
            "Iteration 616, loss = 1066778.46327729\n",
            "Iteration 617, loss = 1068312.81383208\n",
            "Iteration 618, loss = 1065787.06969879\n",
            "Iteration 619, loss = 1063184.95488190\n",
            "Iteration 620, loss = 1061202.98362666\n",
            "Iteration 621, loss = 1061193.92216506\n",
            "Iteration 622, loss = 1061105.97766709\n",
            "Iteration 623, loss = 1063137.17160782\n",
            "Iteration 624, loss = 1063273.54318870\n",
            "Iteration 625, loss = 1063033.75997079\n",
            "Iteration 626, loss = 1061576.09316731\n",
            "Iteration 627, loss = 1060375.43007533\n",
            "Iteration 628, loss = 1059492.75840612\n",
            "Iteration 629, loss = 1060137.17034636\n",
            "Iteration 630, loss = 1058694.37962552\n",
            "Iteration 631, loss = 1058164.16007940\n",
            "Iteration 632, loss = 1057792.29647736\n",
            "Iteration 633, loss = 1056688.30116449\n",
            "Iteration 634, loss = 1057348.48775062\n",
            "Iteration 635, loss = 1056071.09557978\n",
            "Iteration 636, loss = 1055339.35657955\n",
            "Iteration 637, loss = 1056368.01444334\n",
            "Iteration 638, loss = 1057331.48373473\n",
            "Iteration 639, loss = 1060157.96277334\n",
            "Iteration 640, loss = 1060553.83558624\n",
            "Iteration 641, loss = 1059328.50870643\n",
            "Iteration 642, loss = 1058286.79816323\n",
            "Iteration 643, loss = 1055277.95365018\n",
            "Iteration 644, loss = 1054472.04825744\n",
            "Iteration 645, loss = 1054549.78108629\n",
            "Iteration 646, loss = 1057484.39195901\n",
            "Iteration 647, loss = 1059840.10779012\n",
            "Iteration 648, loss = 1060712.93447771\n",
            "Iteration 649, loss = 1059010.66278313\n",
            "Iteration 650, loss = 1058046.77144429\n",
            "Iteration 651, loss = 1054877.54752175\n",
            "Iteration 652, loss = 1053717.67974569\n",
            "Iteration 653, loss = 1053358.66769956\n",
            "Iteration 654, loss = 1051896.17469145\n",
            "Iteration 655, loss = 1051292.20893124\n",
            "Iteration 656, loss = 1050126.75733493\n",
            "Iteration 657, loss = 1050138.41896873\n",
            "Iteration 658, loss = 1052995.97144937\n",
            "Iteration 659, loss = 1055836.67240286\n",
            "Iteration 660, loss = 1055219.41403571\n",
            "Iteration 661, loss = 1053545.35587877\n",
            "Iteration 662, loss = 1050512.94790886\n",
            "Iteration 663, loss = 1050266.01389532\n",
            "Iteration 664, loss = 1048920.03739201\n",
            "Iteration 665, loss = 1049832.17559724\n",
            "Iteration 666, loss = 1049139.66529404\n",
            "Iteration 667, loss = 1049130.06406683\n",
            "Iteration 668, loss = 1049237.34313198\n",
            "Iteration 669, loss = 1049817.72785679\n",
            "Iteration 670, loss = 1050177.40837787\n",
            "Iteration 671, loss = 1050663.86819027\n",
            "Iteration 672, loss = 1049836.19559722\n",
            "Iteration 673, loss = 1048086.13554676\n",
            "Iteration 674, loss = 1046992.56703835\n",
            "Iteration 675, loss = 1046212.45603245\n",
            "Iteration 676, loss = 1048156.51883124\n",
            "Iteration 677, loss = 1050375.67100529\n",
            "Iteration 678, loss = 1051602.61290328\n",
            "Iteration 679, loss = 1049967.07205953\n",
            "Iteration 680, loss = 1047242.32483865\n",
            "Iteration 681, loss = 1044838.48350976\n",
            "Iteration 682, loss = 1044586.82596629\n",
            "Iteration 683, loss = 1045932.99603963\n",
            "Iteration 684, loss = 1047815.83435227\n",
            "Iteration 685, loss = 1048090.03116081\n",
            "Iteration 686, loss = 1047315.02546194\n",
            "Iteration 687, loss = 1046156.88910468\n",
            "Iteration 688, loss = 1044445.29664604\n",
            "Iteration 689, loss = 1043769.86197173\n",
            "Iteration 690, loss = 1043604.45715702\n",
            "Iteration 691, loss = 1044232.92809593\n",
            "Iteration 692, loss = 1046312.68201702\n",
            "Iteration 693, loss = 1047774.39484007\n",
            "Iteration 694, loss = 1045483.48872921\n",
            "Iteration 695, loss = 1045492.61436697\n",
            "Iteration 696, loss = 1041972.62194191\n",
            "Iteration 697, loss = 1041728.33975969\n",
            "Iteration 698, loss = 1042358.74943488\n",
            "Iteration 699, loss = 1043624.78876739\n",
            "Iteration 700, loss = 1043662.52437497\n",
            "Iteration 701, loss = 1042819.37997962\n",
            "Iteration 702, loss = 1041885.42107913\n",
            "Iteration 703, loss = 1041203.12738794\n",
            "Iteration 704, loss = 1041762.56556315\n",
            "Iteration 705, loss = 1042885.39291639\n",
            "Iteration 706, loss = 1043355.09622473\n",
            "Iteration 707, loss = 1044275.28025758\n",
            "Iteration 708, loss = 1045402.61910223\n",
            "Iteration 709, loss = 1047449.75100840\n",
            "Iteration 710, loss = 1048600.60353507\n",
            "Iteration 711, loss = 1045439.86449194\n",
            "Iteration 712, loss = 1043030.11522343\n",
            "Iteration 713, loss = 1039685.93141230\n",
            "Iteration 714, loss = 1039522.66401926\n",
            "Iteration 715, loss = 1039477.60705657\n",
            "Iteration 716, loss = 1040259.96631137\n",
            "Iteration 717, loss = 1042844.98322860\n",
            "Iteration 718, loss = 1042492.23178034\n",
            "Iteration 719, loss = 1040614.88438983\n",
            "Iteration 720, loss = 1040648.77678235\n",
            "Iteration 721, loss = 1038983.71272537\n",
            "Iteration 722, loss = 1038583.81889787\n",
            "Iteration 723, loss = 1038157.05575505\n",
            "Iteration 724, loss = 1038151.20064683\n",
            "Iteration 725, loss = 1038491.71526796\n",
            "Iteration 726, loss = 1038443.68695303\n",
            "Iteration 727, loss = 1038534.17178570\n",
            "Iteration 728, loss = 1038669.53487263\n",
            "Iteration 729, loss = 1039425.94615476\n",
            "Iteration 730, loss = 1038837.24446942\n",
            "Iteration 731, loss = 1039132.51975131\n",
            "Iteration 732, loss = 1038848.71626960\n",
            "Iteration 733, loss = 1038042.20460333\n",
            "Iteration 734, loss = 1037442.07842155\n",
            "Iteration 735, loss = 1036903.00922720\n",
            "Iteration 736, loss = 1037058.03670407\n",
            "Iteration 737, loss = 1036974.10333313\n",
            "Iteration 738, loss = 1036964.74358448\n",
            "Iteration 739, loss = 1036806.48852093\n",
            "Iteration 740, loss = 1035504.80918599\n",
            "Iteration 741, loss = 1037843.12303667\n",
            "Iteration 742, loss = 1039867.22873593\n",
            "Iteration 743, loss = 1041114.44410177\n",
            "Iteration 744, loss = 1040033.33735473\n",
            "Iteration 745, loss = 1037619.36039817\n",
            "Iteration 746, loss = 1037236.11295440\n",
            "Iteration 747, loss = 1035579.29579715\n",
            "Iteration 748, loss = 1036022.01433313\n",
            "Iteration 749, loss = 1036323.27605556\n",
            "Iteration 750, loss = 1036993.46976301\n",
            "Iteration 751, loss = 1037363.79567290\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 2829103449350898.00000000\n",
            "Iteration 2, loss = 2015198940673219363037368680392161530692404722889365903900724284697223417556893696.00000000\n",
            "Iteration 3, loss = 2853724589081664520859821500100881362598736999415117651113492001346420054227430212459406300283314540059047470194385378651144192.00000000\n",
            "Iteration 4, loss = 15119089729443518559423598523018070574809842643285532214363738448361779385466344276865258051733796631072857582001405197553762304.00000000\n",
            "Iteration 5, loss = 30529843120675183700141590884278743675954758102318866881885780260117493740013959445008486701159950243324409286457879844154769408.00000000\n",
            "Iteration 6, loss = 47023365544324386553683451677713682406262256613678060525861558477696309772475915868305323144376150286019895215519796567857954816.00000000\n",
            "Iteration 7, loss = 63014572275818552264957005044969660912078475299593102684824920741214070763513414404110967428442813047727495482644183733533409280.00000000\n",
            "Iteration 8, loss = 77693902346999696465725834657092489361276752086841120734944131118781810292631577440112250139878872560841835222230190491464368128.00000000\n",
            "Iteration 9, loss = 90716838766202996479199103116329319277321984871532630701104117261949530839133828456191270906579116834847241034954865198166441984.00000000\n",
            "Iteration 10, loss = 102008519929708204745682574596618284396879849169076301922924235615114317688899541664169776458485655393894213679880121230724956160.00000000\n",
            "Iteration 11, loss = 111642282258168567674230226814651583297391476860961121404308310148513994521936608552419268757394253744444375128113902775181508608.00000000\n",
            "Iteration 12, loss = 119765429168391744327006395935716946484778685773168984224571535252893262076095079508197265787864497013704901724568016199268433920.00000000\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538811925.96639276\n",
            "Iteration 2, loss = 1538741951.85318828\n",
            "Iteration 3, loss = 1538647360.29606962\n",
            "Iteration 4, loss = 1538510238.59006381\n",
            "Iteration 5, loss = 1538317618.77551270\n",
            "Iteration 6, loss = 1538046258.52709961\n",
            "Iteration 7, loss = 1537685758.13988042\n",
            "Iteration 8, loss = 1537219400.36052704\n",
            "Iteration 9, loss = 1536611444.03241515\n",
            "Iteration 10, loss = 1535856526.73952389\n",
            "Iteration 11, loss = 1534925481.94801354\n",
            "Iteration 12, loss = 1533769505.63660717\n",
            "Iteration 13, loss = 1532378697.71978736\n",
            "Iteration 14, loss = 1530696289.02729750\n",
            "Iteration 15, loss = 1528706762.79266286\n",
            "Iteration 16, loss = 1526365002.21117973\n",
            "Iteration 17, loss = 1523613002.45629644\n",
            "Iteration 18, loss = 1520389094.52450013\n",
            "Iteration 19, loss = 1516678157.25804591\n",
            "Iteration 20, loss = 1512400904.11638975\n",
            "Iteration 21, loss = 1507543971.41563153\n",
            "Iteration 22, loss = 1501960049.60018086\n",
            "Iteration 23, loss = 1495724534.54145527\n",
            "Iteration 24, loss = 1488611799.09347892\n",
            "Iteration 25, loss = 1480677611.31736636\n",
            "Iteration 26, loss = 1471986389.09425592\n",
            "Iteration 27, loss = 1462091319.08864832\n",
            "Iteration 28, loss = 1451246770.02100182\n",
            "Iteration 29, loss = 1439419297.74309182\n",
            "Iteration 30, loss = 1426610071.52174473\n",
            "Iteration 31, loss = 1412297462.89688611\n",
            "Iteration 32, loss = 1396989655.29162741\n",
            "Iteration 33, loss = 1380204027.69816208\n",
            "Iteration 34, loss = 1362260610.26228237\n",
            "Iteration 35, loss = 1342795764.51544476\n",
            "Iteration 36, loss = 1322029296.93672752\n",
            "Iteration 37, loss = 1299786426.60106182\n",
            "Iteration 38, loss = 1276134464.76745319\n",
            "Iteration 39, loss = 1250867660.89937019\n",
            "Iteration 40, loss = 1224458419.13714051\n",
            "Iteration 41, loss = 1196489854.72264647\n",
            "Iteration 42, loss = 1166733261.33291221\n",
            "Iteration 43, loss = 1136121699.15768266\n",
            "Iteration 44, loss = 1103517261.79069567\n",
            "Iteration 45, loss = 1069859565.58144474\n",
            "Iteration 46, loss = 1035000092.80250263\n",
            "Iteration 47, loss = 998653181.01845253\n",
            "Iteration 48, loss = 961131294.27226734\n",
            "Iteration 49, loss = 922579086.97727978\n",
            "Iteration 50, loss = 883645483.06136703\n",
            "Iteration 51, loss = 843261943.50012696\n",
            "Iteration 52, loss = 803145496.33107579\n",
            "Iteration 53, loss = 762480548.82331645\n",
            "Iteration 54, loss = 722097333.19157207\n",
            "Iteration 55, loss = 680806680.09715605\n",
            "Iteration 56, loss = 640873639.17585301\n",
            "Iteration 57, loss = 601250553.61565506\n",
            "Iteration 58, loss = 561952767.40032411\n",
            "Iteration 59, loss = 524258828.37235647\n",
            "Iteration 60, loss = 486937484.06570411\n",
            "Iteration 61, loss = 451878422.51338339\n",
            "Iteration 62, loss = 417424378.96014696\n",
            "Iteration 63, loss = 385239488.34520787\n",
            "Iteration 64, loss = 354274200.94421166\n",
            "Iteration 65, loss = 326094034.73483795\n",
            "Iteration 66, loss = 299579900.33070856\n",
            "Iteration 67, loss = 275077341.30721503\n",
            "Iteration 68, loss = 252101268.96822184\n",
            "Iteration 69, loss = 231370049.37448430\n",
            "Iteration 70, loss = 213083695.34770864\n",
            "Iteration 71, loss = 196191919.33687103\n",
            "Iteration 72, loss = 181216769.89255184\n",
            "Iteration 73, loss = 168135418.65810692\n",
            "Iteration 74, loss = 156876904.58414301\n",
            "Iteration 75, loss = 147053434.20072791\n",
            "Iteration 76, loss = 138342853.46688852\n",
            "Iteration 77, loss = 131517334.82309689\n",
            "Iteration 78, loss = 125512889.27557153\n",
            "Iteration 79, loss = 120756501.95256159\n",
            "Iteration 80, loss = 116967962.61912026\n",
            "Iteration 81, loss = 113708568.64423634\n",
            "Iteration 82, loss = 111185378.94159424\n",
            "Iteration 83, loss = 109311439.86524972\n",
            "Iteration 84, loss = 107616749.03191943\n",
            "Iteration 85, loss = 106204995.34176412\n",
            "Iteration 86, loss = 104949503.30680689\n",
            "Iteration 87, loss = 103896607.24723321\n",
            "Iteration 88, loss = 103061143.63953377\n",
            "Iteration 89, loss = 102098380.07955520\n",
            "Iteration 90, loss = 101264107.84033209\n",
            "Iteration 91, loss = 100312661.47265653\n",
            "Iteration 92, loss = 99410007.96606910\n",
            "Iteration 93, loss = 98448132.51394197\n",
            "Iteration 94, loss = 97491974.24273208\n",
            "Iteration 95, loss = 96503222.61915584\n",
            "Iteration 96, loss = 95483921.89481510\n",
            "Iteration 97, loss = 94469419.06653453\n",
            "Iteration 98, loss = 93434048.11672519\n",
            "Iteration 99, loss = 92363590.06806552\n",
            "Iteration 100, loss = 91317121.80670537\n",
            "Iteration 101, loss = 90211837.17700951\n",
            "Iteration 102, loss = 89085883.13030143\n",
            "Iteration 103, loss = 87963096.43071954\n",
            "Iteration 104, loss = 86806631.09182020\n",
            "Iteration 105, loss = 85651685.41016649\n",
            "Iteration 106, loss = 84483903.06762922\n",
            "Iteration 107, loss = 83289089.37995048\n",
            "Iteration 108, loss = 82091801.34555808\n",
            "Iteration 109, loss = 80882234.37510686\n",
            "Iteration 110, loss = 79691984.16199166\n",
            "Iteration 111, loss = 78497907.17840457\n",
            "Iteration 112, loss = 77267298.00391017\n",
            "Iteration 113, loss = 76079906.59036855\n",
            "Iteration 114, loss = 74853845.12990832\n",
            "Iteration 115, loss = 73673472.83566540\n",
            "Iteration 116, loss = 72438820.59224179\n",
            "Iteration 117, loss = 71295173.34035343\n",
            "Iteration 118, loss = 70120089.70941664\n",
            "Iteration 119, loss = 68950563.24867003\n",
            "Iteration 120, loss = 67821031.31149067\n",
            "Iteration 121, loss = 66716214.58218777\n",
            "Iteration 122, loss = 65608591.27737567\n",
            "Iteration 123, loss = 64524434.36954905\n",
            "Iteration 124, loss = 63492926.88160300\n",
            "Iteration 125, loss = 62489538.45247270\n",
            "Iteration 126, loss = 61518403.91872045\n",
            "Iteration 127, loss = 60586348.89825935\n",
            "Iteration 128, loss = 59703517.62662236\n",
            "Iteration 129, loss = 58859796.27015127\n",
            "Iteration 130, loss = 58098986.29042355\n",
            "Iteration 131, loss = 57339278.92972474\n",
            "Iteration 132, loss = 56658897.34752765\n",
            "Iteration 133, loss = 55999451.59316272\n",
            "Iteration 134, loss = 55384548.89550544\n",
            "Iteration 135, loss = 54799258.14567119\n",
            "Iteration 136, loss = 54229276.29687884\n",
            "Iteration 137, loss = 53728869.53416355\n",
            "Iteration 138, loss = 53239914.25405263\n",
            "Iteration 139, loss = 52770618.91185804\n",
            "Iteration 140, loss = 52339908.43734437\n",
            "Iteration 141, loss = 51934469.78798254\n",
            "Iteration 142, loss = 51544409.45224881\n",
            "Iteration 143, loss = 51165425.53080422\n",
            "Iteration 144, loss = 50793473.92691118\n",
            "Iteration 145, loss = 50516566.98458006\n",
            "Iteration 146, loss = 50193422.97385938\n",
            "Iteration 147, loss = 49856829.92938527\n",
            "Iteration 148, loss = 49519250.86467090\n",
            "Iteration 149, loss = 49170217.03722934\n",
            "Iteration 150, loss = 48843212.02066191\n",
            "Iteration 151, loss = 48495597.08406047\n",
            "Iteration 152, loss = 48207993.82648697\n",
            "Iteration 153, loss = 47870846.12283944\n",
            "Iteration 154, loss = 47597865.19160156\n",
            "Iteration 155, loss = 47296684.91963407\n",
            "Iteration 156, loss = 47004368.43792765\n",
            "Iteration 157, loss = 46714286.34244247\n",
            "Iteration 158, loss = 46451935.95796172\n",
            "Iteration 159, loss = 46178261.54359907\n",
            "Iteration 160, loss = 45902919.32601484\n",
            "Iteration 161, loss = 45619030.70235658\n",
            "Iteration 162, loss = 45339717.89947237\n",
            "Iteration 163, loss = 45070037.36845239\n",
            "Iteration 164, loss = 44781221.56251855\n",
            "Iteration 165, loss = 44505852.38734289\n",
            "Iteration 166, loss = 44226478.16285127\n",
            "Iteration 167, loss = 43951024.49175689\n",
            "Iteration 168, loss = 43658736.84593821\n",
            "Iteration 169, loss = 43386705.15328752\n",
            "Iteration 170, loss = 43110088.10309211\n",
            "Iteration 171, loss = 42831897.56624635\n",
            "Iteration 172, loss = 42556449.34696781\n",
            "Iteration 173, loss = 42292207.00367402\n",
            "Iteration 174, loss = 42036204.58170297\n",
            "Iteration 175, loss = 41772089.97751697\n",
            "Iteration 176, loss = 41502544.07018105\n",
            "Iteration 177, loss = 41224839.57804818\n",
            "Iteration 178, loss = 40963671.01702821\n",
            "Iteration 179, loss = 40704706.97081964\n",
            "Iteration 180, loss = 40432964.20475131\n",
            "Iteration 181, loss = 40165691.64804190\n",
            "Iteration 182, loss = 39892282.54413354\n",
            "Iteration 183, loss = 39623304.10160884\n",
            "Iteration 184, loss = 39370563.00477586\n",
            "Iteration 185, loss = 39112450.51999520\n",
            "Iteration 186, loss = 38883557.57328489\n",
            "Iteration 187, loss = 38618927.10918989\n",
            "Iteration 188, loss = 38361150.79585480\n",
            "Iteration 189, loss = 38088652.75461524\n",
            "Iteration 190, loss = 37832002.07945395\n",
            "Iteration 191, loss = 37570507.97266008\n",
            "Iteration 192, loss = 37301358.80224156\n",
            "Iteration 193, loss = 37039596.23934634\n",
            "Iteration 194, loss = 36750300.74459859\n",
            "Iteration 195, loss = 36471035.84020101\n",
            "Iteration 196, loss = 36198217.57822747\n",
            "Iteration 197, loss = 35938575.09695131\n",
            "Iteration 198, loss = 35667934.77439567\n",
            "Iteration 199, loss = 35408181.99952635\n",
            "Iteration 200, loss = 35171794.31405702\n",
            "Iteration 201, loss = 34903535.63935030\n",
            "Iteration 202, loss = 34654330.47681786\n",
            "Iteration 203, loss = 34421111.06107011\n",
            "Iteration 204, loss = 34178312.96326810\n",
            "Iteration 205, loss = 33924396.59316356\n",
            "Iteration 206, loss = 33668081.73951636\n",
            "Iteration 207, loss = 33414365.73564235\n",
            "Iteration 208, loss = 33178424.16750353\n",
            "Iteration 209, loss = 32913270.43289455\n",
            "Iteration 210, loss = 32667964.96930195\n",
            "Iteration 211, loss = 32431669.87817921\n",
            "Iteration 212, loss = 32217218.89760048\n",
            "Iteration 213, loss = 32005146.23554159\n",
            "Iteration 214, loss = 31800597.63127906\n",
            "Iteration 215, loss = 31624780.53276193\n",
            "Iteration 216, loss = 31406041.04871869\n",
            "Iteration 217, loss = 31173213.64610143\n",
            "Iteration 218, loss = 30952111.62467407\n",
            "Iteration 219, loss = 30688820.14238633\n",
            "Iteration 220, loss = 30452456.01537745\n",
            "Iteration 221, loss = 30226259.90002481\n",
            "Iteration 222, loss = 29989315.82598691\n",
            "Iteration 223, loss = 29737960.12657068\n",
            "Iteration 224, loss = 29550192.74915523\n",
            "Iteration 225, loss = 29276904.61157398\n",
            "Iteration 226, loss = 29058963.68133967\n",
            "Iteration 227, loss = 28835480.34025598\n",
            "Iteration 228, loss = 28616905.19784871\n",
            "Iteration 229, loss = 28402951.64405039\n",
            "Iteration 230, loss = 28189935.44681871\n",
            "Iteration 231, loss = 27968915.40223971\n",
            "Iteration 232, loss = 27764203.95802514\n",
            "Iteration 233, loss = 27543057.29636825\n",
            "Iteration 234, loss = 27350933.97055211\n",
            "Iteration 235, loss = 27131626.85486370\n",
            "Iteration 236, loss = 26920816.23826994\n",
            "Iteration 237, loss = 26703666.37209722\n",
            "Iteration 238, loss = 26499030.81683743\n",
            "Iteration 239, loss = 26291531.38107534\n",
            "Iteration 240, loss = 26088690.64670235\n",
            "Iteration 241, loss = 25879452.36308079\n",
            "Iteration 242, loss = 25673710.40783286\n",
            "Iteration 243, loss = 25473749.55933711\n",
            "Iteration 244, loss = 25265646.68507788\n",
            "Iteration 245, loss = 25047270.79939268\n",
            "Iteration 246, loss = 24836278.81580325\n",
            "Iteration 247, loss = 24622608.64225533\n",
            "Iteration 248, loss = 24417697.50880985\n",
            "Iteration 249, loss = 24212105.93762096\n",
            "Iteration 250, loss = 24007525.75622346\n",
            "Iteration 251, loss = 23804869.54713294\n",
            "Iteration 252, loss = 23597839.50646102\n",
            "Iteration 253, loss = 23400894.88252425\n",
            "Iteration 254, loss = 23211665.31528997\n",
            "Iteration 255, loss = 23002362.02074140\n",
            "Iteration 256, loss = 22803661.36297944\n",
            "Iteration 257, loss = 22590768.59476671\n",
            "Iteration 258, loss = 22397165.42073603\n",
            "Iteration 259, loss = 22181686.42960775\n",
            "Iteration 260, loss = 21973567.38868029\n",
            "Iteration 261, loss = 21758369.26116072\n",
            "Iteration 262, loss = 21546440.30965878\n",
            "Iteration 263, loss = 21334573.52660299\n",
            "Iteration 264, loss = 21116308.11952204\n",
            "Iteration 265, loss = 20909046.48571451\n",
            "Iteration 266, loss = 20687568.52551333\n",
            "Iteration 267, loss = 20464286.81406747\n",
            "Iteration 268, loss = 20253800.29838785\n",
            "Iteration 269, loss = 20047990.36851841\n",
            "Iteration 270, loss = 19821732.18798337\n",
            "Iteration 271, loss = 19602269.85038961\n",
            "Iteration 272, loss = 19379094.13193457\n",
            "Iteration 273, loss = 19173433.92830496\n",
            "Iteration 274, loss = 18990219.95849605\n",
            "Iteration 275, loss = 18780178.02378316\n",
            "Iteration 276, loss = 18583161.64243918\n",
            "Iteration 277, loss = 18389577.81856507\n",
            "Iteration 278, loss = 18177303.52326460\n",
            "Iteration 279, loss = 17971109.19627019\n",
            "Iteration 280, loss = 17740808.38848967\n",
            "Iteration 281, loss = 17500041.74190770\n",
            "Iteration 282, loss = 17275971.16071604\n",
            "Iteration 283, loss = 17036161.98218975\n",
            "Iteration 284, loss = 16845281.13132396\n",
            "Iteration 285, loss = 16617325.38367651\n",
            "Iteration 286, loss = 16394951.87384095\n",
            "Iteration 287, loss = 16183216.05318571\n",
            "Iteration 288, loss = 15958881.88379397\n",
            "Iteration 289, loss = 15748169.78359473\n",
            "Iteration 290, loss = 15529542.22602752\n",
            "Iteration 291, loss = 15319201.87764587\n",
            "Iteration 292, loss = 15101126.24821381\n",
            "Iteration 293, loss = 14882444.86198247\n",
            "Iteration 294, loss = 14672520.31323101\n",
            "Iteration 295, loss = 14455833.66948046\n",
            "Iteration 296, loss = 14237196.56252739\n",
            "Iteration 297, loss = 14025837.95579709\n",
            "Iteration 298, loss = 13815076.72402860\n",
            "Iteration 299, loss = 13587891.28760164\n",
            "Iteration 300, loss = 13383632.66131316\n",
            "Iteration 301, loss = 13165033.06911563\n",
            "Iteration 302, loss = 12938643.43646787\n",
            "Iteration 303, loss = 12732198.69278204\n",
            "Iteration 304, loss = 12519731.39192680\n",
            "Iteration 305, loss = 12301175.73617611\n",
            "Iteration 306, loss = 12093693.73234577\n",
            "Iteration 307, loss = 11882199.26566080\n",
            "Iteration 308, loss = 11676642.16855189\n",
            "Iteration 309, loss = 11457413.59444722\n",
            "Iteration 310, loss = 11255351.91575686\n",
            "Iteration 311, loss = 11048124.48935844\n",
            "Iteration 312, loss = 10851684.65461243\n",
            "Iteration 313, loss = 10652191.37445810\n",
            "Iteration 314, loss = 10462483.54841197\n",
            "Iteration 315, loss = 10271725.69989245\n",
            "Iteration 316, loss = 10079347.32674354\n",
            "Iteration 317, loss = 9892987.32391617\n",
            "Iteration 318, loss = 9705197.94959507\n",
            "Iteration 319, loss = 9529714.27131747\n",
            "Iteration 320, loss = 9359201.53007167\n",
            "Iteration 321, loss = 9164038.30750285\n",
            "Iteration 322, loss = 8985420.20395738\n",
            "Iteration 323, loss = 8806707.33262550\n",
            "Iteration 324, loss = 8624607.60587362\n",
            "Iteration 325, loss = 8458310.65693840\n",
            "Iteration 326, loss = 8284345.67235247\n",
            "Iteration 327, loss = 8123782.06476579\n",
            "Iteration 328, loss = 7960975.08485338\n",
            "Iteration 329, loss = 7805428.42375872\n",
            "Iteration 330, loss = 7640066.63484199\n",
            "Iteration 331, loss = 7485317.67321565\n",
            "Iteration 332, loss = 7345415.89233430\n",
            "Iteration 333, loss = 7215916.59539289\n",
            "Iteration 334, loss = 7097311.31501436\n",
            "Iteration 335, loss = 6970735.18733236\n",
            "Iteration 336, loss = 6843962.63339931\n",
            "Iteration 337, loss = 6723186.98988835\n",
            "Iteration 338, loss = 6594099.80762251\n",
            "Iteration 339, loss = 6472276.72068342\n",
            "Iteration 340, loss = 6339629.72224483\n",
            "Iteration 341, loss = 6218274.94238275\n",
            "Iteration 342, loss = 6093875.87593789\n",
            "Iteration 343, loss = 5976282.82258245\n",
            "Iteration 344, loss = 5854456.25409757\n",
            "Iteration 345, loss = 5740429.85104171\n",
            "Iteration 346, loss = 5627199.25390348\n",
            "Iteration 347, loss = 5523761.64901864\n",
            "Iteration 348, loss = 5411708.86310668\n",
            "Iteration 349, loss = 5311498.11133940\n",
            "Iteration 350, loss = 5208738.19696715\n",
            "Iteration 351, loss = 5110430.61784088\n",
            "Iteration 352, loss = 5015872.46791436\n",
            "Iteration 353, loss = 4930545.36509685\n",
            "Iteration 354, loss = 4850682.23974205\n",
            "Iteration 355, loss = 4769148.95825489\n",
            "Iteration 356, loss = 4687880.48405813\n",
            "Iteration 357, loss = 4608761.66300240\n",
            "Iteration 358, loss = 4530787.55586407\n",
            "Iteration 359, loss = 4449313.68500311\n",
            "Iteration 360, loss = 4374640.85568259\n",
            "Iteration 361, loss = 4296582.87865639\n",
            "Iteration 362, loss = 4210910.13474198\n",
            "Iteration 363, loss = 4148323.58026033\n",
            "Iteration 364, loss = 4058770.49812281\n",
            "Iteration 365, loss = 3997207.43597477\n",
            "Iteration 366, loss = 3930774.39568593\n",
            "Iteration 367, loss = 3863725.80099590\n",
            "Iteration 368, loss = 3803871.72007812\n",
            "Iteration 369, loss = 3739019.11267527\n",
            "Iteration 370, loss = 3675155.66795600\n",
            "Iteration 371, loss = 3611513.68644566\n",
            "Iteration 372, loss = 3557034.77703317\n",
            "Iteration 373, loss = 3502297.30344694\n",
            "Iteration 374, loss = 3448568.58649055\n",
            "Iteration 375, loss = 3399937.84321763\n",
            "Iteration 376, loss = 3349263.42446679\n",
            "Iteration 377, loss = 3301052.14309654\n",
            "Iteration 378, loss = 3250240.48726388\n",
            "Iteration 379, loss = 3200421.29941012\n",
            "Iteration 380, loss = 3152139.59365037\n",
            "Iteration 381, loss = 3106430.08755541\n",
            "Iteration 382, loss = 3060040.62606388\n",
            "Iteration 383, loss = 3018565.75581712\n",
            "Iteration 384, loss = 2976572.06499662\n",
            "Iteration 385, loss = 2937193.80371627\n",
            "Iteration 386, loss = 2895020.11753165\n",
            "Iteration 387, loss = 2856420.54574795\n",
            "Iteration 388, loss = 2814596.78713700\n",
            "Iteration 389, loss = 2775921.23679264\n",
            "Iteration 390, loss = 2737272.23947016\n",
            "Iteration 391, loss = 2700703.76325221\n",
            "Iteration 392, loss = 2664966.14890141\n",
            "Iteration 393, loss = 2631061.07095246\n",
            "Iteration 394, loss = 2595958.01429253\n",
            "Iteration 395, loss = 2563081.18797377\n",
            "Iteration 396, loss = 2534170.12405875\n",
            "Iteration 397, loss = 2506387.58941662\n",
            "Iteration 398, loss = 2476677.36636532\n",
            "Iteration 399, loss = 2445941.40616469\n",
            "Iteration 400, loss = 2415139.91894858\n",
            "Iteration 401, loss = 2384779.25998927\n",
            "Iteration 402, loss = 2352118.85023340\n",
            "Iteration 403, loss = 2323108.88218554\n",
            "Iteration 404, loss = 2291695.36115010\n",
            "Iteration 405, loss = 2261469.54300979\n",
            "Iteration 406, loss = 2234180.52315018\n",
            "Iteration 407, loss = 2212248.64340872\n",
            "Iteration 408, loss = 2186422.87780721\n",
            "Iteration 409, loss = 2160656.52502534\n",
            "Iteration 410, loss = 2135199.18495992\n",
            "Iteration 411, loss = 2112470.28815563\n",
            "Iteration 412, loss = 2088888.08023949\n",
            "Iteration 413, loss = 2067872.10653423\n",
            "Iteration 414, loss = 2044911.07287171\n",
            "Iteration 415, loss = 2024802.62659818\n",
            "Iteration 416, loss = 2005400.04557239\n",
            "Iteration 417, loss = 1981977.37573588\n",
            "Iteration 418, loss = 1964713.44119687\n",
            "Iteration 419, loss = 1945701.26416792\n",
            "Iteration 420, loss = 1931561.11905531\n",
            "Iteration 421, loss = 1914246.19576865\n",
            "Iteration 422, loss = 1896477.58085661\n",
            "Iteration 423, loss = 1876620.04764827\n",
            "Iteration 424, loss = 1856341.69876778\n",
            "Iteration 425, loss = 1838208.08818052\n",
            "Iteration 426, loss = 1823627.97364005\n",
            "Iteration 427, loss = 1807551.51039635\n",
            "Iteration 428, loss = 1792739.72297076\n",
            "Iteration 429, loss = 1778039.25502893\n",
            "Iteration 430, loss = 1762994.46582637\n",
            "Iteration 431, loss = 1749821.56661293\n",
            "Iteration 432, loss = 1737521.94532854\n",
            "Iteration 433, loss = 1725401.40761968\n",
            "Iteration 434, loss = 1713513.87844837\n",
            "Iteration 435, loss = 1699780.55794683\n",
            "Iteration 436, loss = 1687013.12278774\n",
            "Iteration 437, loss = 1673937.45315976\n",
            "Iteration 438, loss = 1662309.64512111\n",
            "Iteration 439, loss = 1649155.31658753\n",
            "Iteration 440, loss = 1638600.06434838\n",
            "Iteration 441, loss = 1628900.11182741\n",
            "Iteration 442, loss = 1616880.65224543\n",
            "Iteration 443, loss = 1606987.18263432\n",
            "Iteration 444, loss = 1596273.01682446\n",
            "Iteration 445, loss = 1585923.94514940\n",
            "Iteration 446, loss = 1575921.64567590\n",
            "Iteration 447, loss = 1567096.05409576\n",
            "Iteration 448, loss = 1556516.77927659\n",
            "Iteration 449, loss = 1547871.26618990\n",
            "Iteration 450, loss = 1538805.14550469\n",
            "Iteration 451, loss = 1528852.27499206\n",
            "Iteration 452, loss = 1520526.56701056\n",
            "Iteration 453, loss = 1511585.23236338\n",
            "Iteration 454, loss = 1504855.92361779\n",
            "Iteration 455, loss = 1497219.83955978\n",
            "Iteration 456, loss = 1488521.76115051\n",
            "Iteration 457, loss = 1480254.72169234\n",
            "Iteration 458, loss = 1471522.66637811\n",
            "Iteration 459, loss = 1464371.21616227\n",
            "Iteration 460, loss = 1456318.74810431\n",
            "Iteration 461, loss = 1448655.16020171\n",
            "Iteration 462, loss = 1442024.51205494\n",
            "Iteration 463, loss = 1435619.90394712\n",
            "Iteration 464, loss = 1428540.32585536\n",
            "Iteration 465, loss = 1420722.46660211\n",
            "Iteration 466, loss = 1413659.68258952\n",
            "Iteration 467, loss = 1408304.66141202\n",
            "Iteration 468, loss = 1403431.66693176\n",
            "Iteration 469, loss = 1397465.40752686\n",
            "Iteration 470, loss = 1390594.37553655\n",
            "Iteration 471, loss = 1384069.48919978\n",
            "Iteration 472, loss = 1377609.51889975\n",
            "Iteration 473, loss = 1372322.64187963\n",
            "Iteration 474, loss = 1368514.69961204\n",
            "Iteration 475, loss = 1362882.41526413\n",
            "Iteration 476, loss = 1357060.46912043\n",
            "Iteration 477, loss = 1350995.20048097\n",
            "Iteration 478, loss = 1344201.74405322\n",
            "Iteration 479, loss = 1338973.72373100\n",
            "Iteration 480, loss = 1333304.74193712\n",
            "Iteration 481, loss = 1327565.84987071\n",
            "Iteration 482, loss = 1322093.79222686\n",
            "Iteration 483, loss = 1317306.15039553\n",
            "Iteration 484, loss = 1311804.27569261\n",
            "Iteration 485, loss = 1307806.43189296\n",
            "Iteration 486, loss = 1302896.87642536\n",
            "Iteration 487, loss = 1298749.78682712\n",
            "Iteration 488, loss = 1294185.23480871\n",
            "Iteration 489, loss = 1291812.19988730\n",
            "Iteration 490, loss = 1284459.16860474\n",
            "Iteration 491, loss = 1279832.26327733\n",
            "Iteration 492, loss = 1276306.80586262\n",
            "Iteration 493, loss = 1272810.30766264\n",
            "Iteration 494, loss = 1269093.44727902\n",
            "Iteration 495, loss = 1264064.55254635\n",
            "Iteration 496, loss = 1259359.59765968\n",
            "Iteration 497, loss = 1254101.72883947\n",
            "Iteration 498, loss = 1250049.91482686\n",
            "Iteration 499, loss = 1247590.79782342\n",
            "Iteration 500, loss = 1243515.16322276\n",
            "Iteration 501, loss = 1239707.76286992\n",
            "Iteration 502, loss = 1236002.68632725\n",
            "Iteration 503, loss = 1232562.72423523\n",
            "Iteration 504, loss = 1229124.29640983\n",
            "Iteration 505, loss = 1225378.96026515\n",
            "Iteration 506, loss = 1223278.13341141\n",
            "Iteration 507, loss = 1221870.97714923\n",
            "Iteration 508, loss = 1220732.36601339\n",
            "Iteration 509, loss = 1218955.80780242\n",
            "Iteration 510, loss = 1216226.18080978\n",
            "Iteration 511, loss = 1212086.11992374\n",
            "Iteration 512, loss = 1207821.20792653\n",
            "Iteration 513, loss = 1204518.01967019\n",
            "Iteration 514, loss = 1199958.18568125\n",
            "Iteration 515, loss = 1196771.95619754\n",
            "Iteration 516, loss = 1194090.86309362\n",
            "Iteration 517, loss = 1193988.24353441\n",
            "Iteration 518, loss = 1191273.58138849\n",
            "Iteration 519, loss = 1188365.01740229\n",
            "Iteration 520, loss = 1185108.92940932\n",
            "Iteration 521, loss = 1182466.96020849\n",
            "Iteration 522, loss = 1180925.63266886\n",
            "Iteration 523, loss = 1180731.33306993\n",
            "Iteration 524, loss = 1179715.25218485\n",
            "Iteration 525, loss = 1177850.75926546\n",
            "Iteration 526, loss = 1174933.66837788\n",
            "Iteration 527, loss = 1172102.76450942\n",
            "Iteration 528, loss = 1170545.62554036\n",
            "Iteration 529, loss = 1168495.60030445\n",
            "Iteration 530, loss = 1168373.90133041\n",
            "Iteration 531, loss = 1165370.40399351\n",
            "Iteration 532, loss = 1163491.48041317\n",
            "Iteration 533, loss = 1162112.74024553\n",
            "Iteration 534, loss = 1158969.73618199\n",
            "Iteration 535, loss = 1156713.52322572\n",
            "Iteration 536, loss = 1154946.33937415\n",
            "Iteration 537, loss = 1152834.97394339\n",
            "Iteration 538, loss = 1150825.42577541\n",
            "Iteration 539, loss = 1149371.65655935\n",
            "Iteration 540, loss = 1148337.23487661\n",
            "Iteration 541, loss = 1147144.71255833\n",
            "Iteration 542, loss = 1147179.46112153\n",
            "Iteration 543, loss = 1145380.84660811\n",
            "Iteration 544, loss = 1144588.71523937\n",
            "Iteration 545, loss = 1143260.13637457\n",
            "Iteration 546, loss = 1143378.12044413\n",
            "Iteration 547, loss = 1142060.74532932\n",
            "Iteration 548, loss = 1140462.22109992\n",
            "Iteration 549, loss = 1139166.31081524\n",
            "Iteration 550, loss = 1136596.81684114\n",
            "Iteration 551, loss = 1135420.34136254\n",
            "Iteration 552, loss = 1133763.86853782\n",
            "Iteration 553, loss = 1131868.62943674\n",
            "Iteration 554, loss = 1130999.35434746\n",
            "Iteration 555, loss = 1131503.05828123\n",
            "Iteration 556, loss = 1129661.72023855\n",
            "Iteration 557, loss = 1129480.19601906\n",
            "Iteration 558, loss = 1126143.71789615\n",
            "Iteration 559, loss = 1125216.58806570\n",
            "Iteration 560, loss = 1124279.92708114\n",
            "Iteration 561, loss = 1123235.77141341\n",
            "Iteration 562, loss = 1123072.37163683\n",
            "Iteration 563, loss = 1122572.19081414\n",
            "Iteration 564, loss = 1121977.05985010\n",
            "Iteration 565, loss = 1120689.38071126\n",
            "Iteration 566, loss = 1119785.90506156\n",
            "Iteration 567, loss = 1117613.76418128\n",
            "Iteration 568, loss = 1116360.26941102\n",
            "Iteration 569, loss = 1115356.88141085\n",
            "Iteration 570, loss = 1114323.49324747\n",
            "Iteration 571, loss = 1113376.33258461\n",
            "Iteration 572, loss = 1112551.03671794\n",
            "Iteration 573, loss = 1110462.23866857\n",
            "Iteration 574, loss = 1109885.10740609\n",
            "Iteration 575, loss = 1108336.10926947\n",
            "Iteration 576, loss = 1107854.56631720\n",
            "Iteration 577, loss = 1107170.86992622\n",
            "Iteration 578, loss = 1106822.99429489\n",
            "Iteration 579, loss = 1106140.38405249\n",
            "Iteration 580, loss = 1105374.74402843\n",
            "Iteration 581, loss = 1104910.61052918\n",
            "Iteration 582, loss = 1103750.97144242\n",
            "Iteration 583, loss = 1102361.15106663\n",
            "Iteration 584, loss = 1101777.73465758\n",
            "Iteration 585, loss = 1100883.85993139\n",
            "Iteration 586, loss = 1100505.76921023\n",
            "Iteration 587, loss = 1100742.22178360\n",
            "Iteration 588, loss = 1101153.80366086\n",
            "Iteration 589, loss = 1100279.86400401\n",
            "Iteration 590, loss = 1098969.70719203\n",
            "Iteration 591, loss = 1097533.22716045\n",
            "Iteration 592, loss = 1096356.53852710\n",
            "Iteration 593, loss = 1096014.00613888\n",
            "Iteration 594, loss = 1095092.03008983\n",
            "Iteration 595, loss = 1094365.54017142\n",
            "Iteration 596, loss = 1094289.71556892\n",
            "Iteration 597, loss = 1092712.30396603\n",
            "Iteration 598, loss = 1092753.63814102\n",
            "Iteration 599, loss = 1092241.73097613\n",
            "Iteration 600, loss = 1091325.47320715\n",
            "Iteration 601, loss = 1090837.37873652\n",
            "Iteration 602, loss = 1090795.60731236\n",
            "Iteration 603, loss = 1090076.27600382\n",
            "Iteration 604, loss = 1088567.02616521\n",
            "Iteration 605, loss = 1089329.05787741\n",
            "Iteration 606, loss = 1087772.22199052\n",
            "Iteration 607, loss = 1087455.65827862\n",
            "Iteration 608, loss = 1086005.86589762\n",
            "Iteration 609, loss = 1084696.07737093\n",
            "Iteration 610, loss = 1088067.28615449\n",
            "Iteration 611, loss = 1089745.08764512\n",
            "Iteration 612, loss = 1090997.12403981\n",
            "Iteration 613, loss = 1089862.30177272\n",
            "Iteration 614, loss = 1087412.50846027\n",
            "Iteration 615, loss = 1083401.32266732\n",
            "Iteration 616, loss = 1083029.54547179\n",
            "Iteration 617, loss = 1082160.81714093\n",
            "Iteration 618, loss = 1080182.04980644\n",
            "Iteration 619, loss = 1080285.90318631\n",
            "Iteration 620, loss = 1080462.68965780\n",
            "Iteration 621, loss = 1080043.39309344\n",
            "Iteration 622, loss = 1078782.13429325\n",
            "Iteration 623, loss = 1078705.31456842\n",
            "Iteration 624, loss = 1077204.14226218\n",
            "Iteration 625, loss = 1076458.12475566\n",
            "Iteration 626, loss = 1076693.29372323\n",
            "Iteration 627, loss = 1078802.05960727\n",
            "Iteration 628, loss = 1080378.32751941\n",
            "Iteration 629, loss = 1078405.83804377\n",
            "Iteration 630, loss = 1076960.46546043\n",
            "Iteration 631, loss = 1077035.75348310\n",
            "Iteration 632, loss = 1075334.27285147\n",
            "Iteration 633, loss = 1073736.29320190\n",
            "Iteration 634, loss = 1073205.74394192\n",
            "Iteration 635, loss = 1071266.26577253\n",
            "Iteration 636, loss = 1071520.62162455\n",
            "Iteration 637, loss = 1071441.08237910\n",
            "Iteration 638, loss = 1071446.09117667\n",
            "Iteration 639, loss = 1071170.84151302\n",
            "Iteration 640, loss = 1070590.46474408\n",
            "Iteration 641, loss = 1069705.56567538\n",
            "Iteration 642, loss = 1068880.04889110\n",
            "Iteration 643, loss = 1068320.32244249\n",
            "Iteration 644, loss = 1068507.37935739\n",
            "Iteration 645, loss = 1068555.37814780\n",
            "Iteration 646, loss = 1069285.07756355\n",
            "Iteration 647, loss = 1068855.94829709\n",
            "Iteration 648, loss = 1068062.21292101\n",
            "Iteration 649, loss = 1066043.97399861\n",
            "Iteration 650, loss = 1065492.39335383\n",
            "Iteration 651, loss = 1064441.51738186\n",
            "Iteration 652, loss = 1064335.11084058\n",
            "Iteration 653, loss = 1063676.83072762\n",
            "Iteration 654, loss = 1063416.94179785\n",
            "Iteration 655, loss = 1063137.43990747\n",
            "Iteration 656, loss = 1062819.10527075\n",
            "Iteration 657, loss = 1062715.66847416\n",
            "Iteration 658, loss = 1062245.65984843\n",
            "Iteration 659, loss = 1061948.35012590\n",
            "Iteration 660, loss = 1061886.11181827\n",
            "Iteration 661, loss = 1061562.93953221\n",
            "Iteration 662, loss = 1060842.86474438\n",
            "Iteration 663, loss = 1060445.03418386\n",
            "Iteration 664, loss = 1059563.20662176\n",
            "Iteration 665, loss = 1059197.83655679\n",
            "Iteration 666, loss = 1058990.12630655\n",
            "Iteration 667, loss = 1058855.05810604\n",
            "Iteration 668, loss = 1058870.39349702\n",
            "Iteration 669, loss = 1060048.67392736\n",
            "Iteration 670, loss = 1060492.85787488\n",
            "Iteration 671, loss = 1060588.81979687\n",
            "Iteration 672, loss = 1059415.16923630\n",
            "Iteration 673, loss = 1057942.12572765\n",
            "Iteration 674, loss = 1058201.04818947\n",
            "Iteration 675, loss = 1056313.82846308\n",
            "Iteration 676, loss = 1055495.33514263\n",
            "Iteration 677, loss = 1055634.16627711\n",
            "Iteration 678, loss = 1057579.34675781\n",
            "Iteration 679, loss = 1059141.79103941\n",
            "Iteration 680, loss = 1060025.04412212\n",
            "Iteration 681, loss = 1058967.50972143\n",
            "Iteration 682, loss = 1058285.66841742\n",
            "Iteration 683, loss = 1054812.14206519\n",
            "Iteration 684, loss = 1053462.63301577\n",
            "Iteration 685, loss = 1055072.66741640\n",
            "Iteration 686, loss = 1054106.72361232\n",
            "Iteration 687, loss = 1054015.99452685\n",
            "Iteration 688, loss = 1053428.91055182\n",
            "Iteration 689, loss = 1052993.30013661\n",
            "Iteration 690, loss = 1052368.36344098\n",
            "Iteration 691, loss = 1051963.07827671\n",
            "Iteration 692, loss = 1052149.51506725\n",
            "Iteration 693, loss = 1052835.29138061\n",
            "Iteration 694, loss = 1053070.51425279\n",
            "Iteration 695, loss = 1053157.89046505\n",
            "Iteration 696, loss = 1052231.14373571\n",
            "Iteration 697, loss = 1052169.01349746\n",
            "Iteration 698, loss = 1050885.14192357\n",
            "Iteration 699, loss = 1050484.55283464\n",
            "Iteration 700, loss = 1050246.35979951\n",
            "Iteration 701, loss = 1050020.10074794\n",
            "Iteration 702, loss = 1049955.16076209\n",
            "Iteration 703, loss = 1050576.79977733\n",
            "Iteration 704, loss = 1051122.00551462\n",
            "Iteration 705, loss = 1051714.59811747\n",
            "Iteration 706, loss = 1053170.68245352\n",
            "Iteration 707, loss = 1053150.67604800\n",
            "Iteration 708, loss = 1053132.12066376\n",
            "Iteration 709, loss = 1050761.00730843\n",
            "Iteration 710, loss = 1050417.60558553\n",
            "Iteration 711, loss = 1049990.48594461\n",
            "Iteration 712, loss = 1049534.41014075\n",
            "Iteration 713, loss = 1048929.57075996\n",
            "Iteration 714, loss = 1049685.47923116\n",
            "Iteration 715, loss = 1049010.80933553\n",
            "Iteration 716, loss = 1049895.39637676\n",
            "Iteration 717, loss = 1049877.95020885\n",
            "Iteration 718, loss = 1049056.30604777\n",
            "Iteration 719, loss = 1048158.48487266\n",
            "Iteration 720, loss = 1047319.92547132\n",
            "Iteration 721, loss = 1048592.26187198\n",
            "Iteration 722, loss = 1048361.72800927\n",
            "Iteration 723, loss = 1048375.20071714\n",
            "Iteration 724, loss = 1048162.11420601\n",
            "Iteration 725, loss = 1047927.14428852\n",
            "Iteration 726, loss = 1047212.37300968\n",
            "Iteration 727, loss = 1046979.77471257\n",
            "Iteration 728, loss = 1045541.44010686\n",
            "Iteration 729, loss = 1044725.03848676\n",
            "Iteration 730, loss = 1045132.62571905\n",
            "Iteration 731, loss = 1045387.20536093\n",
            "Iteration 732, loss = 1046419.18099995\n",
            "Iteration 733, loss = 1047695.67944746\n",
            "Iteration 734, loss = 1046470.64256211\n",
            "Iteration 735, loss = 1045691.12414168\n",
            "Iteration 736, loss = 1044125.72594510\n",
            "Iteration 737, loss = 1045096.49542425\n",
            "Iteration 738, loss = 1044284.44822400\n",
            "Iteration 739, loss = 1043493.92207771\n",
            "Iteration 740, loss = 1042886.99389066\n",
            "Iteration 741, loss = 1043905.14360662\n",
            "Iteration 742, loss = 1044467.20353665\n",
            "Iteration 743, loss = 1044195.55284342\n",
            "Iteration 744, loss = 1043317.26066442\n",
            "Iteration 745, loss = 1042731.36114039\n",
            "Iteration 746, loss = 1042509.44394041\n",
            "Iteration 747, loss = 1042121.78158565\n",
            "Iteration 748, loss = 1042171.71061927\n",
            "Iteration 749, loss = 1042049.89800954\n",
            "Iteration 750, loss = 1041860.80131498\n",
            "Iteration 751, loss = 1041540.94762227\n",
            "Iteration 752, loss = 1041255.39416200\n",
            "Iteration 753, loss = 1042402.78396292\n",
            "Iteration 754, loss = 1042950.19242353\n",
            "Iteration 755, loss = 1042817.43074684\n",
            "Iteration 756, loss = 1041991.40818078\n",
            "Iteration 757, loss = 1041438.30057095\n",
            "Iteration 758, loss = 1040827.33752610\n",
            "Iteration 759, loss = 1040713.10461146\n",
            "Iteration 760, loss = 1041445.36192264\n",
            "Iteration 761, loss = 1042765.26565936\n",
            "Iteration 762, loss = 1043047.78241380\n",
            "Iteration 763, loss = 1042065.01189506\n",
            "Iteration 764, loss = 1042120.02253424\n",
            "Iteration 765, loss = 1042303.10212179\n",
            "Iteration 766, loss = 1041417.42076432\n",
            "Iteration 767, loss = 1040105.88785462\n",
            "Iteration 768, loss = 1039524.40090324\n",
            "Iteration 769, loss = 1039456.08631851\n",
            "Iteration 770, loss = 1040316.87701433\n",
            "Iteration 771, loss = 1042453.77291647\n",
            "Iteration 772, loss = 1043254.32402976\n",
            "Iteration 773, loss = 1040830.85999416\n",
            "Iteration 774, loss = 1040411.56674320\n",
            "Iteration 775, loss = 1039288.65372040\n",
            "Iteration 776, loss = 1040067.13804965\n",
            "Iteration 777, loss = 1039769.04684551\n",
            "Iteration 778, loss = 1039461.16165513\n",
            "Iteration 779, loss = 1039574.68095004\n",
            "Iteration 780, loss = 1038956.05820879\n",
            "Iteration 781, loss = 1038764.12818826\n",
            "Iteration 782, loss = 1038206.55638711\n",
            "Iteration 783, loss = 1038356.54169286\n",
            "Iteration 784, loss = 1037674.23288032\n",
            "Iteration 785, loss = 1037493.96892455\n",
            "Iteration 786, loss = 1037453.95151277\n",
            "Iteration 787, loss = 1037330.99297235\n",
            "Iteration 788, loss = 1038554.37398244\n",
            "Iteration 789, loss = 1038275.86042908\n",
            "Iteration 790, loss = 1038841.46858961\n",
            "Iteration 791, loss = 1039184.84423267\n",
            "Iteration 792, loss = 1038702.92139215\n",
            "Iteration 793, loss = 1038361.65731672\n",
            "Iteration 794, loss = 1037339.73066620\n",
            "Iteration 795, loss = 1036731.68871445\n",
            "Iteration 796, loss = 1036026.32690968\n",
            "Iteration 797, loss = 1037602.50231746\n",
            "Iteration 798, loss = 1037349.68534762\n",
            "Iteration 799, loss = 1037317.09628297\n",
            "Iteration 800, loss = 1036758.43858025\n",
            "Iteration 801, loss = 1036712.52329264\n",
            "Iteration 802, loss = 1036231.85316270\n",
            "Iteration 803, loss = 1036248.09141785\n",
            "Iteration 804, loss = 1035780.38954297\n",
            "Iteration 805, loss = 1038180.15198977\n",
            "Iteration 806, loss = 1039091.65436208\n",
            "Iteration 807, loss = 1038126.53568498\n",
            "Iteration 808, loss = 1036335.52766960\n",
            "Iteration 809, loss = 1035705.50145994\n",
            "Iteration 810, loss = 1036997.56129396\n",
            "Iteration 811, loss = 1036719.29869218\n",
            "Iteration 812, loss = 1036668.75478077\n",
            "Iteration 813, loss = 1035506.83503276\n",
            "Iteration 814, loss = 1034713.22853808\n",
            "Iteration 815, loss = 1034095.22585652\n",
            "Iteration 816, loss = 1034722.38564411\n",
            "Iteration 817, loss = 1034807.04286794\n",
            "Iteration 818, loss = 1035748.83809956\n",
            "Iteration 819, loss = 1035522.43834867\n",
            "Iteration 820, loss = 1034725.82557202\n",
            "Iteration 821, loss = 1034335.09463750\n",
            "Iteration 822, loss = 1033393.39413280\n",
            "Iteration 823, loss = 1035058.14207806\n",
            "Iteration 824, loss = 1034656.22030622\n",
            "Iteration 825, loss = 1034638.98481347\n",
            "Iteration 826, loss = 1033265.62659722\n",
            "Iteration 827, loss = 1032656.66787610\n",
            "Iteration 828, loss = 1034281.76646450\n",
            "Iteration 829, loss = 1032866.84359934\n",
            "Iteration 830, loss = 1032912.34597967\n",
            "Iteration 831, loss = 1035158.11470514\n",
            "Iteration 832, loss = 1036268.36268837\n",
            "Iteration 833, loss = 1035355.19974481\n",
            "Iteration 834, loss = 1033604.20205743\n",
            "Iteration 835, loss = 1033410.60536382\n",
            "Iteration 836, loss = 1032104.94347942\n",
            "Iteration 837, loss = 1032594.52698921\n",
            "Iteration 838, loss = 1032872.81942809\n",
            "Iteration 839, loss = 1032664.07870330\n",
            "Iteration 840, loss = 1032532.28531539\n",
            "Iteration 841, loss = 1032265.35395429\n",
            "Iteration 842, loss = 1033232.60269438\n",
            "Iteration 843, loss = 1033315.95342058\n",
            "Iteration 844, loss = 1033065.34369208\n",
            "Iteration 845, loss = 1032198.55417225\n",
            "Iteration 846, loss = 1032501.94538919\n",
            "Iteration 847, loss = 1030514.20541154\n",
            "Iteration 848, loss = 1031104.76879637\n",
            "Iteration 849, loss = 1032534.11651473\n",
            "Iteration 850, loss = 1034258.76534551\n",
            "Iteration 851, loss = 1033809.13902524\n",
            "Iteration 852, loss = 1032238.84721700\n",
            "Iteration 853, loss = 1030357.91153034\n",
            "Iteration 854, loss = 1030684.31418447\n",
            "Iteration 855, loss = 1032562.90421179\n",
            "Iteration 856, loss = 1035991.36552944\n",
            "Iteration 857, loss = 1036586.81362840\n",
            "Iteration 858, loss = 1033238.02474059\n",
            "Iteration 859, loss = 1033140.57234378\n",
            "Iteration 860, loss = 1031506.67095997\n",
            "Iteration 861, loss = 1031728.45725526\n",
            "Iteration 862, loss = 1031957.07582376\n",
            "Iteration 863, loss = 1031587.00419769\n",
            "Iteration 864, loss = 1029859.30911014\n",
            "Iteration 865, loss = 1030832.61355498\n",
            "Iteration 866, loss = 1030854.68675732\n",
            "Iteration 867, loss = 1032563.23273796\n",
            "Iteration 868, loss = 1032657.56033775\n",
            "Iteration 869, loss = 1031751.77010167\n",
            "Iteration 870, loss = 1032266.95919127\n",
            "Iteration 871, loss = 1030550.57486440\n",
            "Iteration 872, loss = 1029865.47902892\n",
            "Iteration 873, loss = 1029538.27375957\n",
            "Iteration 874, loss = 1030624.68375324\n",
            "Iteration 875, loss = 1033295.64937492\n",
            "Iteration 876, loss = 1037511.66721027\n",
            "Iteration 877, loss = 1038762.77730977\n",
            "Iteration 878, loss = 1035541.95817953\n",
            "Iteration 879, loss = 1031465.49405289\n",
            "Iteration 880, loss = 1027999.19043325\n",
            "Iteration 881, loss = 1031874.72334948\n",
            "Iteration 882, loss = 1034517.39170350\n",
            "Iteration 883, loss = 1035905.20756630\n",
            "Iteration 884, loss = 1035527.99086673\n",
            "Iteration 885, loss = 1034659.67559610\n",
            "Iteration 886, loss = 1033249.38698968\n",
            "Iteration 887, loss = 1031615.03353338\n",
            "Iteration 888, loss = 1029504.98899734\n",
            "Iteration 889, loss = 1029065.98740213\n",
            "Iteration 890, loss = 1028512.25150891\n",
            "Iteration 891, loss = 1028601.53267279\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 15356921459308440.00000000\n",
            "Iteration 2, loss = 991472289129093190936481179640415086691337848227404109817545471149447638589997885690384428655198277800475266839827603331278070523967404609863599484323772452119034452673053902930419272526102630990451125475574292178089357726810038599680.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = inf\n",
            "Iteration 5, loss = inf\n",
            "Iteration 6, loss = inf\n",
            "Iteration 7, loss = inf\n",
            "Iteration 8, loss = inf\n",
            "Iteration 9, loss = inf\n",
            "Iteration 10, loss = inf\n",
            "Iteration 11, loss = inf\n",
            "Iteration 12, loss = inf\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538813733.98500228\n",
            "Iteration 2, loss = 1538743888.73396087\n",
            "Iteration 3, loss = 1538665916.38721490\n",
            "Iteration 4, loss = 1538551428.31090879\n",
            "Iteration 5, loss = 1538392243.47945786\n",
            "Iteration 6, loss = 1538168373.74217200\n",
            "Iteration 7, loss = 1537863318.19954681\n",
            "Iteration 8, loss = 1537458517.12150216\n",
            "Iteration 9, loss = 1536939530.04648352\n",
            "Iteration 10, loss = 1536276778.79663563\n",
            "Iteration 11, loss = 1535442800.90304446\n",
            "Iteration 12, loss = 1534449757.37958646\n",
            "Iteration 13, loss = 1533233587.19007444\n",
            "Iteration 14, loss = 1531722363.84507132\n",
            "Iteration 15, loss = 1529952128.50954676\n",
            "Iteration 16, loss = 1527779698.52536631\n",
            "Iteration 17, loss = 1525337966.13145757\n",
            "Iteration 18, loss = 1522367662.85714602\n",
            "Iteration 19, loss = 1518958172.66872787\n",
            "Iteration 20, loss = 1514950437.01709890\n",
            "Iteration 21, loss = 1510433876.97003293\n",
            "Iteration 22, loss = 1505260910.10395885\n",
            "Iteration 23, loss = 1499390999.18372989\n",
            "Iteration 24, loss = 1492675295.18089366\n",
            "Iteration 25, loss = 1485117368.08527207\n",
            "Iteration 26, loss = 1476761488.65067124\n",
            "Iteration 27, loss = 1467233289.67220855\n",
            "Iteration 28, loss = 1456885237.29265094\n",
            "Iteration 29, loss = 1445260737.74593663\n",
            "Iteration 30, loss = 1432438735.77237606\n",
            "Iteration 31, loss = 1418491770.13175416\n",
            "Iteration 32, loss = 1403104940.13562250\n",
            "Iteration 33, loss = 1386678430.39590049\n",
            "Iteration 34, loss = 1368033718.84849858\n",
            "Iteration 35, loss = 1349043762.45906091\n",
            "Iteration 36, loss = 1327322509.48890972\n",
            "Iteration 37, loss = 1305110968.30494595\n",
            "Iteration 38, loss = 1280581847.29309416\n",
            "Iteration 39, loss = 1255383469.66241431\n",
            "Iteration 40, loss = 1227480432.69930673\n",
            "Iteration 41, loss = 1198628511.36062407\n",
            "Iteration 42, loss = 1168093436.97124934\n",
            "Iteration 43, loss = 1136124310.61825156\n",
            "Iteration 44, loss = 1102496065.99028349\n",
            "Iteration 45, loss = 1067698570.53302050\n",
            "Iteration 46, loss = 1030967589.38916087\n",
            "Iteration 47, loss = 993544266.03980899\n",
            "Iteration 48, loss = 954860305.54789996\n",
            "Iteration 49, loss = 914704320.24033248\n",
            "Iteration 50, loss = 874418882.31727433\n",
            "Iteration 51, loss = 832156044.20414174\n",
            "Iteration 52, loss = 790154852.76160479\n",
            "Iteration 53, loss = 747919000.00421679\n",
            "Iteration 54, loss = 704991200.47558010\n",
            "Iteration 55, loss = 661667185.16576028\n",
            "Iteration 56, loss = 619204145.54674935\n",
            "Iteration 57, loss = 576518182.43941033\n",
            "Iteration 58, loss = 534681065.46263522\n",
            "Iteration 59, loss = 494001113.67843264\n",
            "Iteration 60, loss = 454112404.43232310\n",
            "Iteration 61, loss = 415749453.62006384\n",
            "Iteration 62, loss = 378946349.79292744\n",
            "Iteration 63, loss = 344549384.81926870\n",
            "Iteration 64, loss = 311789296.12232274\n",
            "Iteration 65, loss = 281987232.28365552\n",
            "Iteration 66, loss = 254532656.12905246\n",
            "Iteration 67, loss = 229981319.54232603\n",
            "Iteration 68, loss = 208083096.03477424\n",
            "Iteration 69, loss = 188444284.96914753\n",
            "Iteration 70, loss = 172497864.49902233\n",
            "Iteration 71, loss = 158523485.22041348\n",
            "Iteration 72, loss = 147554232.38891163\n",
            "Iteration 73, loss = 138449607.65670511\n",
            "Iteration 74, loss = 131429578.68364199\n",
            "Iteration 75, loss = 126147773.62907754\n",
            "Iteration 76, loss = 122302902.14138517\n",
            "Iteration 77, loss = 119986965.82305734\n",
            "Iteration 78, loss = 118281993.32941353\n",
            "Iteration 79, loss = 117278717.63876253\n",
            "Iteration 80, loss = 116737089.16952121\n",
            "Iteration 81, loss = 116188491.88561375\n",
            "Iteration 82, loss = 116083604.57687001\n",
            "Iteration 83, loss = 115785605.75539322\n",
            "Iteration 84, loss = 115464643.88349319\n",
            "Iteration 85, loss = 115085527.68802981\n",
            "Iteration 86, loss = 114567765.21842538\n",
            "Iteration 87, loss = 114005565.66157277\n",
            "Iteration 88, loss = 113304562.00498977\n",
            "Iteration 89, loss = 112600322.77457629\n",
            "Iteration 90, loss = 111806459.25665155\n",
            "Iteration 91, loss = 111083023.66547009\n",
            "Iteration 92, loss = 110336498.21905427\n",
            "Iteration 93, loss = 109642477.87810695\n",
            "Iteration 94, loss = 108951759.15818833\n",
            "Iteration 95, loss = 108286454.01750220\n",
            "Iteration 96, loss = 107636328.57623918\n",
            "Iteration 97, loss = 107018585.59047110\n",
            "Iteration 98, loss = 106369106.73439306\n",
            "Iteration 99, loss = 105709723.38778187\n",
            "Iteration 100, loss = 105060974.94342116\n",
            "Iteration 101, loss = 104425284.81515706\n",
            "Iteration 102, loss = 103730386.78990579\n",
            "Iteration 103, loss = 103080467.03224617\n",
            "Iteration 104, loss = 102412679.60726075\n",
            "Iteration 105, loss = 101707608.72454701\n",
            "Iteration 106, loss = 101015453.40281281\n",
            "Iteration 107, loss = 100280592.01960933\n",
            "Iteration 108, loss = 99593304.99658638\n",
            "Iteration 109, loss = 98839535.77653521\n",
            "Iteration 110, loss = 98140849.72061111\n",
            "Iteration 111, loss = 97395773.19496344\n",
            "Iteration 112, loss = 96654416.00522973\n",
            "Iteration 113, loss = 95932195.81126958\n",
            "Iteration 114, loss = 95215307.99085499\n",
            "Iteration 115, loss = 94481449.25148508\n",
            "Iteration 116, loss = 93725980.70717825\n",
            "Iteration 117, loss = 93016874.50134473\n",
            "Iteration 118, loss = 92243140.23677792\n",
            "Iteration 119, loss = 91504322.51746245\n",
            "Iteration 120, loss = 90740416.85964096\n",
            "Iteration 121, loss = 89953014.19395590\n",
            "Iteration 122, loss = 89196532.84190395\n",
            "Iteration 123, loss = 88401559.65493114\n",
            "Iteration 124, loss = 87595487.58307132\n",
            "Iteration 125, loss = 86737116.53398676\n",
            "Iteration 126, loss = 85947004.25547408\n",
            "Iteration 127, loss = 85075284.66895007\n",
            "Iteration 128, loss = 84215760.91366547\n",
            "Iteration 129, loss = 83343055.41919184\n",
            "Iteration 130, loss = 82461588.36830479\n",
            "Iteration 131, loss = 81599948.85713202\n",
            "Iteration 132, loss = 80732722.61424695\n",
            "Iteration 133, loss = 79824373.57745351\n",
            "Iteration 134, loss = 78939671.72112513\n",
            "Iteration 135, loss = 78023910.70701073\n",
            "Iteration 136, loss = 77129959.63420951\n",
            "Iteration 137, loss = 76188783.28579959\n",
            "Iteration 138, loss = 75259589.68385738\n",
            "Iteration 139, loss = 74344225.59282233\n",
            "Iteration 140, loss = 73373869.84672619\n",
            "Iteration 141, loss = 72438050.22567856\n",
            "Iteration 142, loss = 71513651.53212899\n",
            "Iteration 143, loss = 70604993.05810496\n",
            "Iteration 144, loss = 69689290.39963730\n",
            "Iteration 145, loss = 68767031.43142073\n",
            "Iteration 146, loss = 67869999.08892862\n",
            "Iteration 147, loss = 66972464.85529229\n",
            "Iteration 148, loss = 66050820.20994583\n",
            "Iteration 149, loss = 65154856.22480499\n",
            "Iteration 150, loss = 64250117.74352173\n",
            "Iteration 151, loss = 63357334.48318106\n",
            "Iteration 152, loss = 62484785.40236459\n",
            "Iteration 153, loss = 61607963.74629431\n",
            "Iteration 154, loss = 60752221.25458907\n",
            "Iteration 155, loss = 59911162.54313086\n",
            "Iteration 156, loss = 59087845.23876215\n",
            "Iteration 157, loss = 58286336.69194417\n",
            "Iteration 158, loss = 57499693.35099585\n",
            "Iteration 159, loss = 56739780.34948977\n",
            "Iteration 160, loss = 56011055.94786157\n",
            "Iteration 161, loss = 55257526.94409892\n",
            "Iteration 162, loss = 54582886.04202764\n",
            "Iteration 163, loss = 53933010.56952480\n",
            "Iteration 164, loss = 53287208.19225431\n",
            "Iteration 165, loss = 52706814.45963793\n",
            "Iteration 166, loss = 52119633.98105621\n",
            "Iteration 167, loss = 51582272.87585527\n",
            "Iteration 168, loss = 51057770.87391800\n",
            "Iteration 169, loss = 50548566.84947900\n",
            "Iteration 170, loss = 50045383.75568669\n",
            "Iteration 171, loss = 49589974.01727235\n",
            "Iteration 172, loss = 49121927.31410036\n",
            "Iteration 173, loss = 48681184.83060485\n",
            "Iteration 174, loss = 48266591.71438535\n",
            "Iteration 175, loss = 47840339.29593283\n",
            "Iteration 176, loss = 47464859.03384937\n",
            "Iteration 177, loss = 47062341.67845613\n",
            "Iteration 178, loss = 46687767.98087852\n",
            "Iteration 179, loss = 46318539.56781071\n",
            "Iteration 180, loss = 45943627.89579859\n",
            "Iteration 181, loss = 45632143.91886301\n",
            "Iteration 182, loss = 45287576.47294894\n",
            "Iteration 183, loss = 45042426.54063007\n",
            "Iteration 184, loss = 44692203.44947749\n",
            "Iteration 185, loss = 44396660.03685859\n",
            "Iteration 186, loss = 44124892.49297014\n",
            "Iteration 187, loss = 43847388.32117569\n",
            "Iteration 188, loss = 43594894.86591080\n",
            "Iteration 189, loss = 43331526.43849035\n",
            "Iteration 190, loss = 43067017.20122800\n",
            "Iteration 191, loss = 42819108.23351873\n",
            "Iteration 192, loss = 42552106.27766092\n",
            "Iteration 193, loss = 42292123.78543102\n",
            "Iteration 194, loss = 42024928.78450804\n",
            "Iteration 195, loss = 41739640.53422007\n",
            "Iteration 196, loss = 41453735.47583860\n",
            "Iteration 197, loss = 41182095.63409770\n",
            "Iteration 198, loss = 40894743.66967470\n",
            "Iteration 199, loss = 40601439.64511818\n",
            "Iteration 200, loss = 40324346.60837875\n",
            "Iteration 201, loss = 40059684.95937201\n",
            "Iteration 202, loss = 39762244.94668271\n",
            "Iteration 203, loss = 39501337.33590546\n",
            "Iteration 204, loss = 39213249.13439482\n",
            "Iteration 205, loss = 38935342.55417571\n",
            "Iteration 206, loss = 38655237.43408311\n",
            "Iteration 207, loss = 38368890.41175593\n",
            "Iteration 208, loss = 38084479.51581888\n",
            "Iteration 209, loss = 37772126.05510279\n",
            "Iteration 210, loss = 37506197.11645935\n",
            "Iteration 211, loss = 37217703.31134523\n",
            "Iteration 212, loss = 36940855.14150822\n",
            "Iteration 213, loss = 36665669.89786903\n",
            "Iteration 214, loss = 36382299.31389967\n",
            "Iteration 215, loss = 36096206.58959164\n",
            "Iteration 216, loss = 35803292.40127219\n",
            "Iteration 217, loss = 35509868.64865763\n",
            "Iteration 218, loss = 35197447.16483761\n",
            "Iteration 219, loss = 34878760.79919983\n",
            "Iteration 220, loss = 34554122.56491848\n",
            "Iteration 221, loss = 34198247.10004950\n",
            "Iteration 222, loss = 33854614.72049030\n",
            "Iteration 223, loss = 33527619.10454586\n",
            "Iteration 224, loss = 33228351.81923228\n",
            "Iteration 225, loss = 32873454.78567210\n",
            "Iteration 226, loss = 32552290.25445966\n",
            "Iteration 227, loss = 32232845.52759722\n",
            "Iteration 228, loss = 31913960.69309772\n",
            "Iteration 229, loss = 31591895.49584076\n",
            "Iteration 230, loss = 31257036.91592789\n",
            "Iteration 231, loss = 30916412.31578479\n",
            "Iteration 232, loss = 30592914.09555327\n",
            "Iteration 233, loss = 30245457.63586412\n",
            "Iteration 234, loss = 29894687.20491663\n",
            "Iteration 235, loss = 29535145.96391716\n",
            "Iteration 236, loss = 29166204.16515391\n",
            "Iteration 237, loss = 28804670.59007268\n",
            "Iteration 238, loss = 28433435.01328215\n",
            "Iteration 239, loss = 28069114.75755832\n",
            "Iteration 240, loss = 27706404.54152160\n",
            "Iteration 241, loss = 27339844.54187786\n",
            "Iteration 242, loss = 26961283.17295150\n",
            "Iteration 243, loss = 26620279.38823272\n",
            "Iteration 244, loss = 26226015.98107659\n",
            "Iteration 245, loss = 25859042.03337242\n",
            "Iteration 246, loss = 25480429.05713770\n",
            "Iteration 247, loss = 25094912.00407731\n",
            "Iteration 248, loss = 24711039.37231251\n",
            "Iteration 249, loss = 24316647.17490131\n",
            "Iteration 250, loss = 23917188.94804651\n",
            "Iteration 251, loss = 23515521.45538498\n",
            "Iteration 252, loss = 23111847.22227696\n",
            "Iteration 253, loss = 22720900.51641715\n",
            "Iteration 254, loss = 22288947.44538842\n",
            "Iteration 255, loss = 21888572.10182485\n",
            "Iteration 256, loss = 21475710.96280671\n",
            "Iteration 257, loss = 21064183.47367910\n",
            "Iteration 258, loss = 20647419.64078560\n",
            "Iteration 259, loss = 20211681.57887806\n",
            "Iteration 260, loss = 19813839.34834364\n",
            "Iteration 261, loss = 19384944.86369746\n",
            "Iteration 262, loss = 18966818.82361677\n",
            "Iteration 263, loss = 18526294.93834002\n",
            "Iteration 264, loss = 18130206.38536027\n",
            "Iteration 265, loss = 17692916.57197690\n",
            "Iteration 266, loss = 17286464.90405506\n",
            "Iteration 267, loss = 16880292.29521685\n",
            "Iteration 268, loss = 16484031.07420376\n",
            "Iteration 269, loss = 16088189.28854546\n",
            "Iteration 270, loss = 15711818.21903469\n",
            "Iteration 271, loss = 15336429.23879407\n",
            "Iteration 272, loss = 14968252.69035769\n",
            "Iteration 273, loss = 14623043.31464048\n",
            "Iteration 274, loss = 14254334.60288563\n",
            "Iteration 275, loss = 13882541.89211759\n",
            "Iteration 276, loss = 13531249.94734498\n",
            "Iteration 277, loss = 13192148.67254458\n",
            "Iteration 278, loss = 12831043.94732334\n",
            "Iteration 279, loss = 12500050.07513955\n",
            "Iteration 280, loss = 12163549.65023649\n",
            "Iteration 281, loss = 11841446.55975309\n",
            "Iteration 282, loss = 11534243.22655397\n",
            "Iteration 283, loss = 11217981.39582237\n",
            "Iteration 284, loss = 10913639.99631310\n",
            "Iteration 285, loss = 10621289.43985662\n",
            "Iteration 286, loss = 10333338.13640557\n",
            "Iteration 287, loss = 10049045.57524797\n",
            "Iteration 288, loss = 9782480.29391681\n",
            "Iteration 289, loss = 9521859.44701991\n",
            "Iteration 290, loss = 9264875.41158900\n",
            "Iteration 291, loss = 9020518.94421256\n",
            "Iteration 292, loss = 8789152.23365177\n",
            "Iteration 293, loss = 8544030.77254572\n",
            "Iteration 294, loss = 8326000.01208306\n",
            "Iteration 295, loss = 8100300.11417428\n",
            "Iteration 296, loss = 7882213.51808531\n",
            "Iteration 297, loss = 7682234.15251101\n",
            "Iteration 298, loss = 7471811.72090241\n",
            "Iteration 299, loss = 7268901.95954139\n",
            "Iteration 300, loss = 7080161.78644479\n",
            "Iteration 301, loss = 6892873.81661572\n",
            "Iteration 302, loss = 6707770.50841931\n",
            "Iteration 303, loss = 6519910.30454900\n",
            "Iteration 304, loss = 6353360.83799915\n",
            "Iteration 305, loss = 6179834.69285172\n",
            "Iteration 306, loss = 6012639.43658689\n",
            "Iteration 307, loss = 5853382.17660362\n",
            "Iteration 308, loss = 5695597.58616971\n",
            "Iteration 309, loss = 5547477.46158834\n",
            "Iteration 310, loss = 5397887.36232301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 311, loss = 5256558.86435999\n",
            "Iteration 312, loss = 5123615.96057000\n",
            "Iteration 313, loss = 4992329.98967644\n",
            "Iteration 314, loss = 4870059.57367596\n",
            "Iteration 315, loss = 4753895.58881073\n",
            "Iteration 316, loss = 4640516.53818551\n",
            "Iteration 317, loss = 4527743.94167138\n",
            "Iteration 318, loss = 4421298.18278650\n",
            "Iteration 319, loss = 4317068.43758146\n",
            "Iteration 320, loss = 4210439.79749790\n",
            "Iteration 321, loss = 4111080.33799262\n",
            "Iteration 322, loss = 4015275.92886357\n",
            "Iteration 323, loss = 3923203.63898404\n",
            "Iteration 324, loss = 3834977.27456737\n",
            "Iteration 325, loss = 3749532.65460896\n",
            "Iteration 326, loss = 3677742.52664335\n",
            "Iteration 327, loss = 3595993.20482417\n",
            "Iteration 328, loss = 3520686.34948906\n",
            "Iteration 329, loss = 3454281.41804531\n",
            "Iteration 330, loss = 3384480.27679450\n",
            "Iteration 331, loss = 3322339.22800775\n",
            "Iteration 332, loss = 3260127.57524036\n",
            "Iteration 333, loss = 3198509.51453573\n",
            "Iteration 334, loss = 3140460.97859837\n",
            "Iteration 335, loss = 3083624.43024931\n",
            "Iteration 336, loss = 3031387.14512461\n",
            "Iteration 337, loss = 2974294.46540270\n",
            "Iteration 338, loss = 2921614.11191790\n",
            "Iteration 339, loss = 2872674.57192948\n",
            "Iteration 340, loss = 2823185.99739056\n",
            "Iteration 341, loss = 2777670.64205142\n",
            "Iteration 342, loss = 2731420.22769722\n",
            "Iteration 343, loss = 2685364.51389465\n",
            "Iteration 344, loss = 2642471.74974043\n",
            "Iteration 345, loss = 2598413.89609797\n",
            "Iteration 346, loss = 2556855.97883637\n",
            "Iteration 347, loss = 2516066.98241369\n",
            "Iteration 348, loss = 2478137.15990033\n",
            "Iteration 349, loss = 2440592.59440157\n",
            "Iteration 350, loss = 2404015.14182366\n",
            "Iteration 351, loss = 2366460.80114590\n",
            "Iteration 352, loss = 2332798.68716625\n",
            "Iteration 353, loss = 2296417.50721546\n",
            "Iteration 354, loss = 2261787.68361661\n",
            "Iteration 355, loss = 2229780.43958558\n",
            "Iteration 356, loss = 2196625.97717234\n",
            "Iteration 357, loss = 2170658.92632633\n",
            "Iteration 358, loss = 2139342.38848887\n",
            "Iteration 359, loss = 2111802.87025270\n",
            "Iteration 360, loss = 2084957.31520932\n",
            "Iteration 361, loss = 2058126.18669668\n",
            "Iteration 362, loss = 2034575.43131357\n",
            "Iteration 363, loss = 2011371.86391215\n",
            "Iteration 364, loss = 1990676.43029522\n",
            "Iteration 365, loss = 1969431.13700306\n",
            "Iteration 366, loss = 1949867.77680421\n",
            "Iteration 367, loss = 1930637.93658965\n",
            "Iteration 368, loss = 1913196.01654872\n",
            "Iteration 369, loss = 1895487.80929908\n",
            "Iteration 370, loss = 1880631.49633003\n",
            "Iteration 371, loss = 1866843.29223784\n",
            "Iteration 372, loss = 1851562.48391414\n",
            "Iteration 373, loss = 1835486.50379935\n",
            "Iteration 374, loss = 1819504.67579916\n",
            "Iteration 375, loss = 1803710.57145016\n",
            "Iteration 376, loss = 1788926.46560701\n",
            "Iteration 377, loss = 1774812.66085892\n",
            "Iteration 378, loss = 1761878.53236624\n",
            "Iteration 379, loss = 1749164.79377891\n",
            "Iteration 380, loss = 1736311.72028500\n",
            "Iteration 381, loss = 1724311.95245848\n",
            "Iteration 382, loss = 1712213.34556343\n",
            "Iteration 383, loss = 1700361.15197820\n",
            "Iteration 384, loss = 1688973.88585625\n",
            "Iteration 385, loss = 1677010.58577322\n",
            "Iteration 386, loss = 1666358.40052122\n",
            "Iteration 387, loss = 1655543.57235925\n",
            "Iteration 388, loss = 1645156.05294942\n",
            "Iteration 389, loss = 1634993.96375442\n",
            "Iteration 390, loss = 1626431.15319809\n",
            "Iteration 391, loss = 1617046.31148535\n",
            "Iteration 392, loss = 1607849.30421826\n",
            "Iteration 393, loss = 1598240.96435872\n",
            "Iteration 394, loss = 1588331.32147018\n",
            "Iteration 395, loss = 1578747.76941669\n",
            "Iteration 396, loss = 1567799.25601492\n",
            "Iteration 397, loss = 1558725.79388659\n",
            "Iteration 398, loss = 1549499.06945375\n",
            "Iteration 399, loss = 1540114.12666619\n",
            "Iteration 400, loss = 1532352.33290757\n",
            "Iteration 401, loss = 1524259.34735763\n",
            "Iteration 402, loss = 1516497.05699210\n",
            "Iteration 403, loss = 1509074.56265660\n",
            "Iteration 404, loss = 1500360.56329603\n",
            "Iteration 405, loss = 1493113.92143936\n",
            "Iteration 406, loss = 1486191.64351533\n",
            "Iteration 407, loss = 1478582.37676754\n",
            "Iteration 408, loss = 1470442.68563207\n",
            "Iteration 409, loss = 1463250.88791584\n",
            "Iteration 410, loss = 1456115.35948690\n",
            "Iteration 411, loss = 1448360.20969868\n",
            "Iteration 412, loss = 1442762.12282763\n",
            "Iteration 413, loss = 1434288.80894609\n",
            "Iteration 414, loss = 1427628.76483960\n",
            "Iteration 415, loss = 1421029.40148508\n",
            "Iteration 416, loss = 1415801.19939820\n",
            "Iteration 417, loss = 1408674.78665929\n",
            "Iteration 418, loss = 1402573.86386742\n",
            "Iteration 419, loss = 1397016.78371056\n",
            "Iteration 420, loss = 1390835.35272544\n",
            "Iteration 421, loss = 1384898.98653849\n",
            "Iteration 422, loss = 1378718.47379630\n",
            "Iteration 423, loss = 1372843.65727705\n",
            "Iteration 424, loss = 1367202.85780950\n",
            "Iteration 425, loss = 1361208.32529948\n",
            "Iteration 426, loss = 1356010.32268255\n",
            "Iteration 427, loss = 1350689.57805318\n",
            "Iteration 428, loss = 1344890.56087741\n",
            "Iteration 429, loss = 1340487.85617602\n",
            "Iteration 430, loss = 1334923.11201449\n",
            "Iteration 431, loss = 1329606.64708702\n",
            "Iteration 432, loss = 1325419.00505667\n",
            "Iteration 433, loss = 1320007.04963637\n",
            "Iteration 434, loss = 1314974.75285082\n",
            "Iteration 435, loss = 1310548.71273894\n",
            "Iteration 436, loss = 1305831.81754247\n",
            "Iteration 437, loss = 1301042.78477599\n",
            "Iteration 438, loss = 1297090.86091251\n",
            "Iteration 439, loss = 1291963.15878554\n",
            "Iteration 440, loss = 1287532.13467818\n",
            "Iteration 441, loss = 1283642.51060994\n",
            "Iteration 442, loss = 1278988.71965751\n",
            "Iteration 443, loss = 1274293.53371260\n",
            "Iteration 444, loss = 1269640.29408809\n",
            "Iteration 445, loss = 1265538.45770257\n",
            "Iteration 446, loss = 1261313.96587348\n",
            "Iteration 447, loss = 1257218.13944294\n",
            "Iteration 448, loss = 1253081.05372926\n",
            "Iteration 449, loss = 1249170.57154074\n",
            "Iteration 450, loss = 1245085.86964001\n",
            "Iteration 451, loss = 1241883.63789068\n",
            "Iteration 452, loss = 1237825.66740730\n",
            "Iteration 453, loss = 1233984.85383738\n",
            "Iteration 454, loss = 1229966.05880924\n",
            "Iteration 455, loss = 1226083.81391248\n",
            "Iteration 456, loss = 1222856.37178812\n",
            "Iteration 457, loss = 1219169.50707498\n",
            "Iteration 458, loss = 1215758.07100378\n",
            "Iteration 459, loss = 1212273.96512932\n",
            "Iteration 460, loss = 1209766.37202472\n",
            "Iteration 461, loss = 1206769.16864387\n",
            "Iteration 462, loss = 1203977.30322054\n",
            "Iteration 463, loss = 1201484.53116569\n",
            "Iteration 464, loss = 1198866.12945104\n",
            "Iteration 465, loss = 1195676.87194911\n",
            "Iteration 466, loss = 1194281.46927496\n",
            "Iteration 467, loss = 1190141.72605331\n",
            "Iteration 468, loss = 1187718.83083304\n",
            "Iteration 469, loss = 1185368.61945478\n",
            "Iteration 470, loss = 1183029.02440322\n",
            "Iteration 471, loss = 1180759.05920744\n",
            "Iteration 472, loss = 1177947.79074871\n",
            "Iteration 473, loss = 1175567.25225298\n",
            "Iteration 474, loss = 1172562.12021454\n",
            "Iteration 475, loss = 1170248.94852919\n",
            "Iteration 476, loss = 1171192.39865340\n",
            "Iteration 477, loss = 1169464.08923653\n",
            "Iteration 478, loss = 1167751.73873937\n",
            "Iteration 479, loss = 1166032.12631209\n",
            "Iteration 480, loss = 1162637.64835580\n",
            "Iteration 481, loss = 1160368.16812366\n",
            "Iteration 482, loss = 1156240.92776786\n",
            "Iteration 483, loss = 1153974.01044890\n",
            "Iteration 484, loss = 1151285.44609779\n",
            "Iteration 485, loss = 1149759.27714591\n",
            "Iteration 486, loss = 1147731.74237949\n",
            "Iteration 487, loss = 1145627.19714388\n",
            "Iteration 488, loss = 1143495.46348300\n",
            "Iteration 489, loss = 1141189.27087943\n",
            "Iteration 490, loss = 1139491.60254264\n",
            "Iteration 491, loss = 1137357.06753488\n",
            "Iteration 492, loss = 1135563.45456167\n",
            "Iteration 493, loss = 1134915.03176702\n",
            "Iteration 494, loss = 1133679.15714927\n",
            "Iteration 495, loss = 1133231.33094810\n",
            "Iteration 496, loss = 1129528.45047824\n",
            "Iteration 497, loss = 1128103.64475326\n",
            "Iteration 498, loss = 1125648.72096884\n",
            "Iteration 499, loss = 1122769.57930211\n",
            "Iteration 500, loss = 1121530.16625885\n",
            "Iteration 501, loss = 1120159.50520133\n",
            "Iteration 502, loss = 1118230.22006284\n",
            "Iteration 503, loss = 1116471.69005283\n",
            "Iteration 504, loss = 1114707.91552448\n",
            "Iteration 505, loss = 1113548.32361187\n",
            "Iteration 506, loss = 1111678.15722922\n",
            "Iteration 507, loss = 1110456.29713787\n",
            "Iteration 508, loss = 1109930.06790851\n",
            "Iteration 509, loss = 1108456.18707205\n",
            "Iteration 510, loss = 1107509.92524523\n",
            "Iteration 511, loss = 1106898.31558995\n",
            "Iteration 512, loss = 1106374.55052319\n",
            "Iteration 513, loss = 1104185.28216781\n",
            "Iteration 514, loss = 1101595.98263149\n",
            "Iteration 515, loss = 1100364.85422465\n",
            "Iteration 516, loss = 1101423.69176901\n",
            "Iteration 517, loss = 1102791.04021956\n",
            "Iteration 518, loss = 1107292.67706083\n",
            "Iteration 519, loss = 1110823.27246963\n",
            "Iteration 520, loss = 1107944.60235509\n",
            "Iteration 521, loss = 1102346.72461418\n",
            "Iteration 522, loss = 1097480.29378506\n",
            "Iteration 523, loss = 1095243.10268492\n",
            "Iteration 524, loss = 1093493.84807041\n",
            "Iteration 525, loss = 1092514.19729266\n",
            "Iteration 526, loss = 1092083.40512127\n",
            "Iteration 527, loss = 1091984.55243725\n",
            "Iteration 528, loss = 1090617.67497232\n",
            "Iteration 529, loss = 1089639.70813467\n",
            "Iteration 530, loss = 1088441.05155377\n",
            "Iteration 531, loss = 1087643.77082240\n",
            "Iteration 532, loss = 1087850.27811449\n",
            "Iteration 533, loss = 1086988.53997903\n",
            "Iteration 534, loss = 1087489.96708720\n",
            "Iteration 535, loss = 1088320.45470646\n",
            "Iteration 536, loss = 1087587.93673969\n",
            "Iteration 537, loss = 1086617.77784926\n",
            "Iteration 538, loss = 1084940.19638344\n",
            "Iteration 539, loss = 1083735.30896971\n",
            "Iteration 540, loss = 1082453.85150417\n",
            "Iteration 541, loss = 1080687.84564785\n",
            "Iteration 542, loss = 1079695.76541178\n",
            "Iteration 543, loss = 1078720.05466951\n",
            "Iteration 544, loss = 1078951.87572344\n",
            "Iteration 545, loss = 1079096.63803642\n",
            "Iteration 546, loss = 1080265.13752540\n",
            "Iteration 547, loss = 1078963.92694535\n",
            "Iteration 548, loss = 1076895.53815925\n",
            "Iteration 549, loss = 1075108.81370011\n",
            "Iteration 550, loss = 1074450.07731420\n",
            "Iteration 551, loss = 1075620.41376702\n",
            "Iteration 552, loss = 1076902.82098052\n",
            "Iteration 553, loss = 1078001.49534706\n",
            "Iteration 554, loss = 1078542.92911169\n",
            "Iteration 555, loss = 1078332.36746960\n",
            "Iteration 556, loss = 1074964.53452861\n",
            "Iteration 557, loss = 1070980.85413190\n",
            "Iteration 558, loss = 1069949.81966348\n",
            "Iteration 559, loss = 1069660.41226536\n",
            "Iteration 560, loss = 1073628.48577386\n",
            "Iteration 561, loss = 1079279.75029919\n",
            "Iteration 562, loss = 1078388.82531592\n",
            "Iteration 563, loss = 1074345.06724512\n",
            "Iteration 564, loss = 1069940.99378769\n",
            "Iteration 565, loss = 1067810.59734257\n",
            "Iteration 566, loss = 1066208.09895864\n",
            "Iteration 567, loss = 1067469.16519093\n",
            "Iteration 568, loss = 1068318.39715849\n",
            "Iteration 569, loss = 1068732.30346202\n",
            "Iteration 570, loss = 1068146.31280369\n",
            "Iteration 571, loss = 1066493.09267797\n",
            "Iteration 572, loss = 1064886.04873570\n",
            "Iteration 573, loss = 1064047.83117830\n",
            "Iteration 574, loss = 1062657.50287319\n",
            "Iteration 575, loss = 1061941.16740381\n",
            "Iteration 576, loss = 1062138.64906057\n",
            "Iteration 577, loss = 1062019.48007895\n",
            "Iteration 578, loss = 1060895.63328861\n",
            "Iteration 579, loss = 1061363.45748146\n",
            "Iteration 580, loss = 1060610.52837783\n",
            "Iteration 581, loss = 1060158.24989312\n",
            "Iteration 582, loss = 1059879.70242243\n",
            "Iteration 583, loss = 1059436.08859180\n",
            "Iteration 584, loss = 1058877.70614136\n",
            "Iteration 585, loss = 1058059.24528485\n",
            "Iteration 586, loss = 1057977.97128608\n",
            "Iteration 587, loss = 1057945.43529815\n",
            "Iteration 588, loss = 1058175.06256736\n",
            "Iteration 589, loss = 1057861.00440817\n",
            "Iteration 590, loss = 1057586.42433810\n",
            "Iteration 591, loss = 1056854.38118960\n",
            "Iteration 592, loss = 1055867.10114530\n",
            "Iteration 593, loss = 1055461.22172270\n",
            "Iteration 594, loss = 1054974.52779275\n",
            "Iteration 595, loss = 1054578.80029137\n",
            "Iteration 596, loss = 1054252.29149944\n",
            "Iteration 597, loss = 1053626.67267176\n",
            "Iteration 598, loss = 1053843.70771714\n",
            "Iteration 599, loss = 1053512.03103795\n",
            "Iteration 600, loss = 1055090.48466413\n",
            "Iteration 601, loss = 1054250.58605151\n",
            "Iteration 602, loss = 1053221.60796892\n",
            "Iteration 603, loss = 1052526.27513396\n",
            "Iteration 604, loss = 1051456.11095523\n",
            "Iteration 605, loss = 1051504.62432338\n",
            "Iteration 606, loss = 1051619.36305236\n",
            "Iteration 607, loss = 1051191.33285500\n",
            "Iteration 608, loss = 1050909.13712503\n",
            "Iteration 609, loss = 1050208.06691608\n",
            "Iteration 610, loss = 1049534.35577494\n",
            "Iteration 611, loss = 1049609.46732131\n",
            "Iteration 612, loss = 1049429.86932786\n",
            "Iteration 613, loss = 1049837.61444260\n",
            "Iteration 614, loss = 1049937.46779578\n",
            "Iteration 615, loss = 1049826.87368815\n",
            "Iteration 616, loss = 1049420.41882947\n",
            "Iteration 617, loss = 1049464.91819040\n",
            "Iteration 618, loss = 1048754.38593577\n",
            "Iteration 619, loss = 1047800.54111804\n",
            "Iteration 620, loss = 1047234.57940666\n",
            "Iteration 621, loss = 1047083.16256550\n",
            "Iteration 622, loss = 1047562.42086899\n",
            "Iteration 623, loss = 1047449.14941499\n",
            "Iteration 624, loss = 1047123.22302112\n",
            "Iteration 625, loss = 1046917.66883256\n",
            "Iteration 626, loss = 1045742.00940783\n",
            "Iteration 627, loss = 1045361.55224691\n",
            "Iteration 628, loss = 1045215.80189357\n",
            "Iteration 629, loss = 1045681.72602304\n",
            "Iteration 630, loss = 1045239.49975783\n",
            "Iteration 631, loss = 1044979.43684530\n",
            "Iteration 632, loss = 1044229.36877380\n",
            "Iteration 633, loss = 1043767.95470026\n",
            "Iteration 634, loss = 1043757.29262257\n",
            "Iteration 635, loss = 1043044.93902010\n",
            "Iteration 636, loss = 1043107.16746534\n",
            "Iteration 637, loss = 1043423.29856489\n",
            "Iteration 638, loss = 1043372.46602461\n",
            "Iteration 639, loss = 1043006.90225613\n",
            "Iteration 640, loss = 1043178.02624251\n",
            "Iteration 641, loss = 1042813.02733764\n",
            "Iteration 642, loss = 1043284.71431432\n",
            "Iteration 643, loss = 1042167.18949772\n",
            "Iteration 644, loss = 1041251.16570559\n",
            "Iteration 645, loss = 1041660.77809398\n",
            "Iteration 646, loss = 1043211.94697806\n",
            "Iteration 647, loss = 1043867.84428614\n",
            "Iteration 648, loss = 1042833.18525495\n",
            "Iteration 649, loss = 1041679.41767858\n",
            "Iteration 650, loss = 1040402.85779691\n",
            "Iteration 651, loss = 1040809.10133795\n",
            "Iteration 652, loss = 1041211.26557939\n",
            "Iteration 653, loss = 1041113.58289469\n",
            "Iteration 654, loss = 1040859.64535065\n",
            "Iteration 655, loss = 1040170.54630864\n",
            "Iteration 656, loss = 1039462.30404444\n",
            "Iteration 657, loss = 1038716.70233087\n",
            "Iteration 658, loss = 1039485.39961243\n",
            "Iteration 659, loss = 1038618.14300022\n",
            "Iteration 660, loss = 1038133.50425473\n",
            "Iteration 661, loss = 1038895.82459710\n",
            "Iteration 662, loss = 1037765.74214589\n",
            "Iteration 663, loss = 1037480.77359368\n",
            "Iteration 664, loss = 1037066.17675782\n",
            "Iteration 665, loss = 1037094.54304315\n",
            "Iteration 666, loss = 1037265.85283474\n",
            "Iteration 667, loss = 1037379.27685378\n",
            "Iteration 668, loss = 1037557.03852291\n",
            "Iteration 669, loss = 1037158.40530834\n",
            "Iteration 670, loss = 1037507.70830122\n",
            "Iteration 671, loss = 1038839.47051575\n",
            "Iteration 672, loss = 1039160.38055142\n",
            "Iteration 673, loss = 1038886.65569975\n",
            "Iteration 674, loss = 1038247.75732880\n",
            "Iteration 675, loss = 1038321.11866862\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1522115059.72576714\n",
            "Iteration 2, loss = 1069658298.60100901\n",
            "Iteration 3, loss = 383694505.02902585\n",
            "Iteration 4, loss = 265435577.69064829\n",
            "Iteration 5, loss = 133886559.61880443\n",
            "Iteration 6, loss = 78644316.73144946\n",
            "Iteration 7, loss = 44173053.81246132\n",
            "Iteration 8, loss = 14039081.11199517\n",
            "Iteration 9, loss = 8375350.97962210\n",
            "Iteration 10, loss = 11480776.01836012\n",
            "Iteration 11, loss = 14936190.63447325\n",
            "Iteration 12, loss = 21123340.75629072\n",
            "Iteration 13, loss = 21830617.40919027\n",
            "Iteration 14, loss = 18303769.76436422\n",
            "Iteration 15, loss = 16824862.36824673\n",
            "Iteration 16, loss = 18813931.76768177\n",
            "Iteration 17, loss = 31176452.94612477\n",
            "Iteration 18, loss = 24733024.73556171\n",
            "Iteration 19, loss = 16891335.99497385\n",
            "Iteration 20, loss = 14653973.10370732\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538792840.76793909\n",
            "Iteration 2, loss = 1538639836.35905480\n",
            "Iteration 3, loss = 1538509704.91353488\n",
            "Iteration 4, loss = 1538392005.11511898\n",
            "Iteration 5, loss = 1538266815.01336455\n",
            "Iteration 6, loss = 1538158252.94280982\n",
            "Iteration 7, loss = 1538079657.34654593\n",
            "Iteration 8, loss = 1538012342.08523917\n",
            "Iteration 9, loss = 1537948243.69105458\n",
            "Iteration 10, loss = 1537885303.17502260\n",
            "Iteration 11, loss = 1537824251.91505003\n",
            "Iteration 12, loss = 1537763894.28712630\n",
            "Iteration 13, loss = 1537703368.41248631\n",
            "Iteration 14, loss = 1537643641.51441860\n",
            "Iteration 15, loss = 1537583343.02145195\n",
            "Iteration 16, loss = 1537523862.49617290\n",
            "Iteration 17, loss = 1537463931.45815802\n",
            "Iteration 18, loss = 1537404316.66783690\n",
            "Iteration 19, loss = 1537344958.84590077\n",
            "Iteration 20, loss = 1537285463.21419430\n",
            "Iteration 21, loss = 1537226186.12002826\n",
            "Iteration 22, loss = 1537167198.17813373\n",
            "Iteration 23, loss = 1537107931.93786979\n",
            "Iteration 24, loss = 1537049214.04097533\n",
            "Iteration 25, loss = 1536990811.16763353\n",
            "Iteration 26, loss = 1536932088.91621542\n",
            "Iteration 27, loss = 1536873650.65931726\n",
            "Iteration 28, loss = 1536815391.19564104\n",
            "Iteration 29, loss = 1536757517.87244463\n",
            "Iteration 30, loss = 1536699385.26488924\n",
            "Iteration 31, loss = 1536641520.56766748\n",
            "Iteration 32, loss = 1536583964.41873980\n",
            "Iteration 33, loss = 1536526159.41724467\n",
            "Iteration 34, loss = 1536468907.57921624\n",
            "Iteration 35, loss = 1536411193.46773601\n",
            "Iteration 36, loss = 1536354172.87192369\n",
            "Iteration 37, loss = 1536296922.89682984\n",
            "Iteration 38, loss = 1536239990.76373339\n",
            "Iteration 39, loss = 1536182712.46114135\n",
            "Iteration 40, loss = 1536126305.56316876\n",
            "Iteration 41, loss = 1536069511.36317039\n",
            "Iteration 42, loss = 1536012477.91631818\n",
            "Iteration 43, loss = 1535956117.33510280\n",
            "Iteration 44, loss = 1535899925.12515855\n",
            "Iteration 45, loss = 1535843435.15444660\n",
            "Iteration 46, loss = 1535787220.94514537\n",
            "Iteration 47, loss = 1535730761.95996571\n",
            "Iteration 48, loss = 1535674743.14701915\n",
            "Iteration 49, loss = 1535618683.62393045\n",
            "Iteration 50, loss = 1535562067.61205506\n",
            "Iteration 51, loss = 1535505949.60983253\n",
            "Iteration 52, loss = 1535449948.04866838\n",
            "Iteration 53, loss = 1535393392.15528011\n",
            "Iteration 54, loss = 1535337249.49512959\n",
            "Iteration 55, loss = 1535280978.79847717\n",
            "Iteration 56, loss = 1535224820.39154863\n",
            "Iteration 57, loss = 1535168644.38135743\n",
            "Iteration 58, loss = 1535112405.30878997\n",
            "Iteration 59, loss = 1535056567.49451542\n",
            "Iteration 60, loss = 1535000533.15503788\n",
            "Iteration 61, loss = 1534944009.54635501\n",
            "Iteration 62, loss = 1534888394.68798423\n",
            "Iteration 63, loss = 1534832304.60608864\n",
            "Iteration 64, loss = 1534775991.05477023\n",
            "Iteration 65, loss = 1534719734.23917723\n",
            "Iteration 66, loss = 1534663655.96833754\n",
            "Iteration 67, loss = 1534607448.87763977\n",
            "Iteration 68, loss = 1534550896.50436687\n",
            "Iteration 69, loss = 1534495017.94831705\n",
            "Iteration 70, loss = 1534438682.77290106\n",
            "Iteration 71, loss = 1534382263.10726094\n",
            "Iteration 72, loss = 1534326128.77328873\n",
            "Iteration 73, loss = 1534269934.65442610\n",
            "Iteration 74, loss = 1534214093.51918364\n",
            "Iteration 75, loss = 1534157786.81814909\n",
            "Iteration 76, loss = 1534101622.29776144\n",
            "Iteration 77, loss = 1534045768.56101227\n",
            "Iteration 78, loss = 1533990006.66707587\n",
            "Iteration 79, loss = 1533933689.93086958\n",
            "Iteration 80, loss = 1533878309.27201843\n",
            "Iteration 81, loss = 1533822279.31368661\n",
            "Iteration 82, loss = 1533766402.37433076\n",
            "Iteration 83, loss = 1533710913.64609289\n",
            "Iteration 84, loss = 1533654909.93721366\n",
            "Iteration 85, loss = 1533599383.01112294\n",
            "Iteration 86, loss = 1533543407.22080135\n",
            "Iteration 87, loss = 1533487788.81056356\n",
            "Iteration 88, loss = 1533431785.95314050\n",
            "Iteration 89, loss = 1533376142.80842066\n",
            "Iteration 90, loss = 1533320323.83347821\n",
            "Iteration 91, loss = 1533264465.74599624\n",
            "Iteration 92, loss = 1533209060.11979079\n",
            "Iteration 93, loss = 1533153446.44658303\n",
            "Iteration 94, loss = 1533097877.13836455\n",
            "Iteration 95, loss = 1533042598.57250381\n",
            "Iteration 96, loss = 1532987277.91481733\n",
            "Iteration 97, loss = 1532932089.11729598\n",
            "Iteration 98, loss = 1532876625.89502048\n",
            "Iteration 99, loss = 1532821424.79907560\n",
            "Iteration 100, loss = 1532766453.52238107\n",
            "Iteration 101, loss = 1532710714.90791106\n",
            "Iteration 102, loss = 1532655144.54538584\n",
            "Iteration 103, loss = 1532600010.78634238\n",
            "Iteration 104, loss = 1532544544.92048717\n",
            "Iteration 105, loss = 1532488877.17513132\n",
            "Iteration 106, loss = 1532433284.46448779\n",
            "Iteration 107, loss = 1532377811.87462354\n",
            "Iteration 108, loss = 1532322229.71781325\n",
            "Iteration 109, loss = 1532266514.83246756\n",
            "Iteration 110, loss = 1532210866.21850848\n",
            "Iteration 111, loss = 1532155474.95078564\n",
            "Iteration 112, loss = 1532099959.65999031\n",
            "Iteration 113, loss = 1532044209.30174255\n",
            "Iteration 114, loss = 1531988921.86929440\n",
            "Iteration 115, loss = 1531933232.37863612\n",
            "Iteration 116, loss = 1531878021.49927616\n",
            "Iteration 117, loss = 1531822629.41689777\n",
            "Iteration 118, loss = 1531767110.94955683\n",
            "Iteration 119, loss = 1531711478.74339938\n",
            "Iteration 120, loss = 1531656423.56975532\n",
            "Iteration 121, loss = 1531601207.37398267\n",
            "Iteration 122, loss = 1531545812.33119678\n",
            "Iteration 123, loss = 1531490649.94535041\n",
            "Iteration 124, loss = 1531435492.20267749\n",
            "Iteration 125, loss = 1531380319.70749068\n",
            "Iteration 126, loss = 1531325279.44379210\n",
            "Iteration 127, loss = 1531270150.62369514\n",
            "Iteration 128, loss = 1531215088.59484673\n",
            "Iteration 129, loss = 1531159919.15810299\n",
            "Iteration 130, loss = 1531104783.19427133\n",
            "Iteration 131, loss = 1531049909.40450120\n",
            "Iteration 132, loss = 1530994584.00082684\n",
            "Iteration 133, loss = 1530939399.42609501\n",
            "Iteration 134, loss = 1530884477.71767712\n",
            "Iteration 135, loss = 1530829356.81505919\n",
            "Iteration 136, loss = 1530773876.99891210\n",
            "Iteration 137, loss = 1530718753.19875455\n",
            "Iteration 138, loss = 1530663372.15647793\n",
            "Iteration 139, loss = 1530608047.39082670\n",
            "Iteration 140, loss = 1530552990.05287576\n",
            "Iteration 141, loss = 1530497234.03920341\n",
            "Iteration 142, loss = 1530442164.42204642\n",
            "Iteration 143, loss = 1530386751.58122325\n",
            "Iteration 144, loss = 1530331682.42173505\n",
            "Iteration 145, loss = 1530276289.18072629\n",
            "Iteration 146, loss = 1530221156.14553452\n",
            "Iteration 147, loss = 1530166296.40393472\n",
            "Iteration 148, loss = 1530110877.18762779\n",
            "Iteration 149, loss = 1530055803.78026414\n",
            "Iteration 150, loss = 1530000955.36672330\n",
            "Iteration 151, loss = 1529945923.75017190\n",
            "Iteration 152, loss = 1529890770.98354626\n",
            "Iteration 153, loss = 1529835449.65826011\n",
            "Iteration 154, loss = 1529780611.16284037\n",
            "Iteration 155, loss = 1529725259.13340545\n",
            "Iteration 156, loss = 1529670074.07947993\n",
            "Iteration 157, loss = 1529615254.52917933\n",
            "Iteration 158, loss = 1529559949.42814970\n",
            "Iteration 159, loss = 1529504788.74296784\n",
            "Iteration 160, loss = 1529449748.15868878\n",
            "Iteration 161, loss = 1529394223.95242023\n",
            "Iteration 162, loss = 1529339234.97603345\n",
            "Iteration 163, loss = 1529284208.45747161\n",
            "Iteration 164, loss = 1529228904.02630997\n",
            "Iteration 165, loss = 1529173882.91127539\n",
            "Iteration 166, loss = 1529118826.64647913\n",
            "Iteration 167, loss = 1529063727.30797553\n",
            "Iteration 168, loss = 1529009355.08731294\n",
            "Iteration 169, loss = 1528954212.22438765\n",
            "Iteration 170, loss = 1528899236.78923202\n",
            "Iteration 171, loss = 1528844636.50935102\n",
            "Iteration 172, loss = 1528789642.57500362\n",
            "Iteration 173, loss = 1528734570.38461208\n",
            "Iteration 174, loss = 1528679686.66892624\n",
            "Iteration 175, loss = 1528624528.52279019\n",
            "Iteration 176, loss = 1528569580.17080045\n",
            "Iteration 177, loss = 1528514486.44257593\n",
            "Iteration 178, loss = 1528459681.15821385\n",
            "Iteration 179, loss = 1528404451.32892585\n",
            "Iteration 180, loss = 1528349494.21608806\n",
            "Iteration 181, loss = 1528294583.15362000\n",
            "Iteration 182, loss = 1528239912.14347291\n",
            "Iteration 183, loss = 1528184652.71733522\n",
            "Iteration 184, loss = 1528129745.78631043\n",
            "Iteration 185, loss = 1528075124.21247697\n",
            "Iteration 186, loss = 1528020008.42175055\n",
            "Iteration 187, loss = 1527965033.22086215\n",
            "Iteration 188, loss = 1527910302.19672203\n",
            "Iteration 189, loss = 1527855181.67375255\n",
            "Iteration 190, loss = 1527800443.60109162\n",
            "Iteration 191, loss = 1527745315.01330614\n",
            "Iteration 192, loss = 1527690219.12903404\n",
            "Iteration 193, loss = 1527635427.02093625\n",
            "Iteration 194, loss = 1527580751.76373577\n",
            "Iteration 195, loss = 1527525913.28106856\n",
            "Iteration 196, loss = 1527471011.49498796\n",
            "Iteration 197, loss = 1527416553.72932291\n",
            "Iteration 198, loss = 1527362198.70804787\n",
            "Iteration 199, loss = 1527307626.31253552\n",
            "Iteration 200, loss = 1527253298.90078306\n",
            "Iteration 201, loss = 1527198698.82056737\n",
            "Iteration 202, loss = 1527144444.99982190\n",
            "Iteration 203, loss = 1527089764.52736402\n",
            "Iteration 204, loss = 1527035403.98268795\n",
            "Iteration 205, loss = 1526980575.77197599\n",
            "Iteration 206, loss = 1526925979.54895043\n",
            "Iteration 207, loss = 1526871329.50606942\n",
            "Iteration 208, loss = 1526816570.59430385\n",
            "Iteration 209, loss = 1526761956.36831307\n",
            "Iteration 210, loss = 1526706986.30092716\n",
            "Iteration 211, loss = 1526652257.09964061\n",
            "Iteration 212, loss = 1526597444.89955258\n",
            "Iteration 213, loss = 1526542821.37059069\n",
            "Iteration 214, loss = 1526487658.06713104\n",
            "Iteration 215, loss = 1526432948.42364335\n",
            "Iteration 216, loss = 1526377708.53608179\n",
            "Iteration 217, loss = 1526323094.39507151\n",
            "Iteration 218, loss = 1526267580.93405056\n",
            "Iteration 219, loss = 1526212639.75773954\n",
            "Iteration 220, loss = 1526157688.04521728\n",
            "Iteration 221, loss = 1526102638.26982474\n",
            "Iteration 222, loss = 1526047620.87339759\n",
            "Iteration 223, loss = 1525992591.89140558\n",
            "Iteration 224, loss = 1525937676.79592752\n",
            "Iteration 225, loss = 1525882761.66667318\n",
            "Iteration 226, loss = 1525827619.41940975\n",
            "Iteration 227, loss = 1525772696.38113308\n",
            "Iteration 228, loss = 1525717708.30344319\n",
            "Iteration 229, loss = 1525662881.05698633\n",
            "Iteration 230, loss = 1525607993.42875433\n",
            "Iteration 231, loss = 1525553136.20410585\n",
            "Iteration 232, loss = 1525498350.07287884\n",
            "Iteration 233, loss = 1525443408.89965487\n",
            "Iteration 234, loss = 1525389006.30519104\n",
            "Iteration 235, loss = 1525334118.32735562\n",
            "Iteration 236, loss = 1525279504.36527729\n",
            "Iteration 237, loss = 1525224799.55200505\n",
            "Iteration 238, loss = 1525170335.50481772\n",
            "Iteration 239, loss = 1525115794.33663201\n",
            "Iteration 240, loss = 1525061285.54087305\n",
            "Iteration 241, loss = 1525007296.13438225\n",
            "Iteration 242, loss = 1524952808.29139614\n",
            "Iteration 243, loss = 1524898489.56412911\n",
            "Iteration 244, loss = 1524844429.54479861\n",
            "Iteration 245, loss = 1524789725.08017087\n",
            "Iteration 246, loss = 1524735440.26079416\n",
            "Iteration 247, loss = 1524681051.05797982\n",
            "Iteration 248, loss = 1524626492.44260359\n",
            "Iteration 249, loss = 1524571901.54662323\n",
            "Iteration 250, loss = 1524517485.85935926\n",
            "Iteration 251, loss = 1524462966.23308992\n",
            "Iteration 252, loss = 1524408320.39676976\n",
            "Iteration 253, loss = 1524353777.46424961\n",
            "Iteration 254, loss = 1524299233.96625996\n",
            "Iteration 255, loss = 1524244547.29629159\n",
            "Iteration 256, loss = 1524189604.54197025\n",
            "Iteration 257, loss = 1524135195.03215122\n",
            "Iteration 258, loss = 1524080313.47812629\n",
            "Iteration 259, loss = 1524025370.77223682\n",
            "Iteration 260, loss = 1523970673.80958414\n",
            "Iteration 261, loss = 1523915660.12215114\n",
            "Iteration 262, loss = 1523861029.53956270\n",
            "Iteration 263, loss = 1523805805.24660993\n",
            "Iteration 264, loss = 1523751527.67336440\n",
            "Iteration 265, loss = 1523695894.66391802\n",
            "Iteration 266, loss = 1523641705.58454728\n",
            "Iteration 267, loss = 1523586459.20920753\n",
            "Iteration 268, loss = 1523531753.53930426\n",
            "Iteration 269, loss = 1523477300.72015119\n",
            "Iteration 270, loss = 1523422342.03168464\n",
            "Iteration 271, loss = 1523367330.38639092\n",
            "Iteration 272, loss = 1523312687.60878992\n",
            "Iteration 273, loss = 1523257998.67045307\n",
            "Iteration 274, loss = 1523202773.01271772\n",
            "Iteration 275, loss = 1523147966.43841577\n",
            "Iteration 276, loss = 1523093362.30307579\n",
            "Iteration 277, loss = 1523038212.19525290\n",
            "Iteration 278, loss = 1522983334.80773520\n",
            "Iteration 279, loss = 1522928638.89976478\n",
            "Iteration 280, loss = 1522873862.24203038\n",
            "Iteration 281, loss = 1522818983.27078724\n",
            "Iteration 282, loss = 1522764163.05011296\n",
            "Iteration 283, loss = 1522709632.65736914\n",
            "Iteration 284, loss = 1522654704.51610613\n",
            "Iteration 285, loss = 1522600118.43972826\n",
            "Iteration 286, loss = 1522545412.34444547\n",
            "Iteration 287, loss = 1522490730.75961971\n",
            "Iteration 288, loss = 1522436321.56420851\n",
            "Iteration 289, loss = 1522381784.67299509\n",
            "Iteration 290, loss = 1522327166.03436923\n",
            "Iteration 291, loss = 1522272463.24127746\n",
            "Iteration 292, loss = 1522217950.33533168\n",
            "Iteration 293, loss = 1522163428.63123035\n",
            "Iteration 294, loss = 1522108926.76357341\n",
            "Iteration 295, loss = 1522054172.25404167\n",
            "Iteration 296, loss = 1521999632.26702142\n",
            "Iteration 297, loss = 1521944857.95963550\n",
            "Iteration 298, loss = 1521890559.51495266\n",
            "Iteration 299, loss = 1521836016.95349598\n",
            "Iteration 300, loss = 1521781134.33850050\n",
            "Iteration 301, loss = 1521726746.82331204\n",
            "Iteration 302, loss = 1521672543.84752202\n",
            "Iteration 303, loss = 1521617975.59519196\n",
            "Iteration 304, loss = 1521563805.68890882\n",
            "Iteration 305, loss = 1521508983.38100052\n",
            "Iteration 306, loss = 1521454358.38327980\n",
            "Iteration 307, loss = 1521400339.56860924\n",
            "Iteration 308, loss = 1521345357.79979134\n",
            "Iteration 309, loss = 1521290736.71334505\n",
            "Iteration 310, loss = 1521235900.74282193\n",
            "Iteration 311, loss = 1521181188.61855412\n",
            "Iteration 312, loss = 1521126146.62141609\n",
            "Iteration 313, loss = 1521071952.70633435\n",
            "Iteration 314, loss = 1521016733.90431118\n",
            "Iteration 315, loss = 1520962291.43551445\n",
            "Iteration 316, loss = 1520907615.79872799\n",
            "Iteration 317, loss = 1520853118.56153464\n",
            "Iteration 318, loss = 1520798250.49050045\n",
            "Iteration 319, loss = 1520743660.17925501\n",
            "Iteration 320, loss = 1520689213.21562433\n",
            "Iteration 321, loss = 1520634939.61201262\n",
            "Iteration 322, loss = 1520580027.04433608\n",
            "Iteration 323, loss = 1520526021.95321131\n",
            "Iteration 324, loss = 1520471600.20468307\n",
            "Iteration 325, loss = 1520416931.93380070\n",
            "Iteration 326, loss = 1520362517.92634106\n",
            "Iteration 327, loss = 1520307980.42209959\n",
            "Iteration 328, loss = 1520253421.40743494\n",
            "Iteration 329, loss = 1520198603.10072899\n",
            "Iteration 330, loss = 1520143985.99710393\n",
            "Iteration 331, loss = 1520089129.37690282\n",
            "Iteration 332, loss = 1520034807.01972032\n",
            "Iteration 333, loss = 1519980277.63405824\n",
            "Iteration 334, loss = 1519925553.74243808\n",
            "Iteration 335, loss = 1519871369.93826556\n",
            "Iteration 336, loss = 1519816534.17351985\n",
            "Iteration 337, loss = 1519762192.42795181\n",
            "Iteration 338, loss = 1519707909.64331150\n",
            "Iteration 339, loss = 1519653285.35720897\n",
            "Iteration 340, loss = 1519598574.62710333\n",
            "Iteration 341, loss = 1519544148.17331266\n",
            "Iteration 342, loss = 1519489664.42762160\n",
            "Iteration 343, loss = 1519435088.92626977\n",
            "Iteration 344, loss = 1519380376.14813900\n",
            "Iteration 345, loss = 1519325986.06743574\n",
            "Iteration 346, loss = 1519271132.30752015\n",
            "Iteration 347, loss = 1519216491.74360061\n",
            "Iteration 348, loss = 1519161852.10736108\n",
            "Iteration 349, loss = 1519107107.66513777\n",
            "Iteration 350, loss = 1519052354.39218378\n",
            "Iteration 351, loss = 1518997432.37166023\n",
            "Iteration 352, loss = 1518942693.60403275\n",
            "Iteration 353, loss = 1518887990.39174533\n",
            "Iteration 354, loss = 1518833420.26733160\n",
            "Iteration 355, loss = 1518778648.26327825\n",
            "Iteration 356, loss = 1518724103.14045286\n",
            "Iteration 357, loss = 1518670012.90804887\n",
            "Iteration 358, loss = 1518615523.52695537\n",
            "Iteration 359, loss = 1518561049.77316999\n",
            "Iteration 360, loss = 1518506941.87127352\n",
            "Iteration 361, loss = 1518453050.45295739\n",
            "Iteration 362, loss = 1518398580.59812021\n",
            "Iteration 363, loss = 1518344042.30219007\n",
            "Iteration 364, loss = 1518289411.27513027\n",
            "Iteration 365, loss = 1518235106.26731348\n",
            "Iteration 366, loss = 1518180480.17118430\n",
            "Iteration 367, loss = 1518125630.89439368\n",
            "Iteration 368, loss = 1518071027.01684999\n",
            "Iteration 369, loss = 1518016012.14747071\n",
            "Iteration 370, loss = 1517961709.89736414\n",
            "Iteration 371, loss = 1517907060.58115888\n",
            "Iteration 372, loss = 1517852652.01309276\n",
            "Iteration 373, loss = 1517797738.37350249\n",
            "Iteration 374, loss = 1517743141.84028149\n",
            "Iteration 375, loss = 1517688573.66946816\n",
            "Iteration 376, loss = 1517634387.32378888\n",
            "Iteration 377, loss = 1517579498.74760532\n",
            "Iteration 378, loss = 1517525210.86109519\n",
            "Iteration 379, loss = 1517471076.24176073\n",
            "Iteration 380, loss = 1517416286.57362556\n",
            "Iteration 381, loss = 1517362358.53041053\n",
            "Iteration 382, loss = 1517308138.29217672\n",
            "Iteration 383, loss = 1517253575.14667654\n",
            "Iteration 384, loss = 1517199604.03938246\n",
            "Iteration 385, loss = 1517145210.12719679\n",
            "Iteration 386, loss = 1517090980.79344749\n",
            "Iteration 387, loss = 1517036507.31864738\n",
            "Iteration 388, loss = 1516982034.68559408\n",
            "Iteration 389, loss = 1516928060.14411187\n",
            "Iteration 390, loss = 1516873532.83490658\n",
            "Iteration 391, loss = 1516819255.64121723\n",
            "Iteration 392, loss = 1516764766.76435781\n",
            "Iteration 393, loss = 1516710588.51724505\n",
            "Iteration 394, loss = 1516656267.54224753\n",
            "Iteration 395, loss = 1516601759.73595262\n",
            "Iteration 396, loss = 1516547690.93783593\n",
            "Iteration 397, loss = 1516493303.29469872\n",
            "Iteration 398, loss = 1516439165.44750190\n",
            "Iteration 399, loss = 1516384864.79713058\n",
            "Iteration 400, loss = 1516330631.22244477\n",
            "Iteration 401, loss = 1516276916.73027611\n",
            "Iteration 402, loss = 1516222570.53604078\n",
            "Iteration 403, loss = 1516168478.80692697\n",
            "Iteration 404, loss = 1516114589.35116792\n",
            "Iteration 405, loss = 1516060270.38788772\n",
            "Iteration 406, loss = 1516006062.75722957\n",
            "Iteration 407, loss = 1515951736.05190611\n",
            "Iteration 408, loss = 1515897401.88744402\n",
            "Iteration 409, loss = 1515842999.27349687\n",
            "Iteration 410, loss = 1515788446.95090508\n",
            "Iteration 411, loss = 1515733507.15410876\n",
            "Iteration 412, loss = 1515679520.45077610\n",
            "Iteration 413, loss = 1515624342.61945152\n",
            "Iteration 414, loss = 1515569980.69988012\n",
            "Iteration 415, loss = 1515515008.93915105\n",
            "Iteration 416, loss = 1515460773.60428381\n",
            "Iteration 417, loss = 1515406055.44572091\n",
            "Iteration 418, loss = 1515351633.89720464\n",
            "Iteration 419, loss = 1515297011.10417008\n",
            "Iteration 420, loss = 1515242965.45224881\n",
            "Iteration 421, loss = 1515188129.28998017\n",
            "Iteration 422, loss = 1515133945.76657820\n",
            "Iteration 423, loss = 1515079404.50216508\n",
            "Iteration 424, loss = 1515024672.13481331\n",
            "Iteration 425, loss = 1514970170.46628094\n",
            "Iteration 426, loss = 1514915592.32410455\n",
            "Iteration 427, loss = 1514860937.80955052\n",
            "Iteration 428, loss = 1514806656.36897230\n",
            "Iteration 429, loss = 1514752185.45859289\n",
            "Iteration 430, loss = 1514697806.34051204\n",
            "Iteration 431, loss = 1514643451.41999722\n",
            "Iteration 432, loss = 1514589406.47429824\n",
            "Iteration 433, loss = 1514534949.61493635\n",
            "Iteration 434, loss = 1514480388.23752379\n",
            "Iteration 435, loss = 1514426267.52187920\n",
            "Iteration 436, loss = 1514371984.07804656\n",
            "Iteration 437, loss = 1514317618.68809319\n",
            "Iteration 438, loss = 1514263143.66079259\n",
            "Iteration 439, loss = 1514208813.12144351\n",
            "Iteration 440, loss = 1514154495.78134346\n",
            "Iteration 441, loss = 1514100254.28365183\n",
            "Iteration 442, loss = 1514045580.76654029\n",
            "Iteration 443, loss = 1513991435.19657350\n",
            "Iteration 444, loss = 1513936885.35622644\n",
            "Iteration 445, loss = 1513882627.51988554\n",
            "Iteration 446, loss = 1513828215.30664730\n",
            "Iteration 447, loss = 1513773957.44292736\n",
            "Iteration 448, loss = 1513719592.33221555\n",
            "Iteration 449, loss = 1513665600.77353334\n",
            "Iteration 450, loss = 1513611147.18249178\n",
            "Iteration 451, loss = 1513556549.77975798\n",
            "Iteration 452, loss = 1513502834.40921783\n",
            "Iteration 453, loss = 1513448344.27940154\n",
            "Iteration 454, loss = 1513394171.93600845\n",
            "Iteration 455, loss = 1513339707.95820808\n",
            "Iteration 456, loss = 1513285652.12492681\n",
            "Iteration 457, loss = 1513231223.06603026\n",
            "Iteration 458, loss = 1513177032.00032210\n",
            "Iteration 459, loss = 1513123071.26422882\n",
            "Iteration 460, loss = 1513068774.42908859\n",
            "Iteration 461, loss = 1513014564.25090051\n",
            "Iteration 462, loss = 1512960644.36883497\n",
            "Iteration 463, loss = 1512906270.02729392\n",
            "Iteration 464, loss = 1512852293.32164645\n",
            "Iteration 465, loss = 1512798111.14906311\n",
            "Iteration 466, loss = 1512744007.87281728\n",
            "Iteration 467, loss = 1512690024.55298972\n",
            "Iteration 468, loss = 1512635751.35962605\n",
            "Iteration 469, loss = 1512581547.19948745\n",
            "Iteration 470, loss = 1512527607.07784057\n",
            "Iteration 471, loss = 1512473313.78788376\n",
            "Iteration 472, loss = 1512419193.92111611\n",
            "Iteration 473, loss = 1512364929.73944736\n",
            "Iteration 474, loss = 1512311193.86384010\n",
            "Iteration 475, loss = 1512256977.72410369\n",
            "Iteration 476, loss = 1512202926.24144769\n",
            "Iteration 477, loss = 1512148709.72304344\n",
            "Iteration 478, loss = 1512094980.88208675\n",
            "Iteration 479, loss = 1512041158.77449393\n",
            "Iteration 480, loss = 1511986790.88217402\n",
            "Iteration 481, loss = 1511933024.74316168\n",
            "Iteration 482, loss = 1511879556.73716903\n",
            "Iteration 483, loss = 1511825374.17073894\n",
            "Iteration 484, loss = 1511771382.06515336\n",
            "Iteration 485, loss = 1511718011.39517856\n",
            "Iteration 486, loss = 1511664129.90543437\n",
            "Iteration 487, loss = 1511610159.15553308\n",
            "Iteration 488, loss = 1511556286.67051363\n",
            "Iteration 489, loss = 1511502142.58126235\n",
            "Iteration 490, loss = 1511448269.36394048\n",
            "Iteration 491, loss = 1511394197.20910716\n",
            "Iteration 492, loss = 1511340088.31402063\n",
            "Iteration 493, loss = 1511286154.65026426\n",
            "Iteration 494, loss = 1511232651.04679132\n",
            "Iteration 495, loss = 1511178496.75162268\n",
            "Iteration 496, loss = 1511124690.17877960\n",
            "Iteration 497, loss = 1511070849.91273570\n",
            "Iteration 498, loss = 1511017032.38682866\n",
            "Iteration 499, loss = 1510963214.48011160\n",
            "Iteration 500, loss = 1510909340.26338243\n",
            "Iteration 501, loss = 1510855290.69190955\n",
            "Iteration 502, loss = 1510801509.01521111\n",
            "Iteration 503, loss = 1510747538.28649187\n",
            "Iteration 504, loss = 1510693532.29642534\n",
            "Iteration 505, loss = 1510639638.80928779\n",
            "Iteration 506, loss = 1510585820.78665018\n",
            "Iteration 507, loss = 1510532046.07275200\n",
            "Iteration 508, loss = 1510478241.25895143\n",
            "Iteration 509, loss = 1510424250.29861045\n",
            "Iteration 510, loss = 1510370875.11085105\n",
            "Iteration 511, loss = 1510317070.01288056\n",
            "Iteration 512, loss = 1510263327.34748745\n",
            "Iteration 513, loss = 1510209306.37247872\n",
            "Iteration 514, loss = 1510155397.59076881\n",
            "Iteration 515, loss = 1510101808.99261236\n",
            "Iteration 516, loss = 1510047710.23067260\n",
            "Iteration 517, loss = 1509993795.52471471\n",
            "Iteration 518, loss = 1509939675.50048256\n",
            "Iteration 519, loss = 1509885978.66060209\n",
            "Iteration 520, loss = 1509831798.50192618\n",
            "Iteration 521, loss = 1509777823.74284077\n",
            "Iteration 522, loss = 1509724103.29964828\n",
            "Iteration 523, loss = 1509669851.91691232\n",
            "Iteration 524, loss = 1509616004.06783009\n",
            "Iteration 525, loss = 1509562004.57290268\n",
            "Iteration 526, loss = 1509508022.60350800\n",
            "Iteration 527, loss = 1509453701.66694355\n",
            "Iteration 528, loss = 1509399755.00742054\n",
            "Iteration 529, loss = 1509345591.16674638\n",
            "Iteration 530, loss = 1509291667.69444394\n",
            "Iteration 531, loss = 1509237402.76783586\n",
            "Iteration 532, loss = 1509183412.18813920\n",
            "Iteration 533, loss = 1509129300.61051106\n",
            "Iteration 534, loss = 1509075181.98446226\n",
            "Iteration 535, loss = 1509021220.57197690\n",
            "Iteration 536, loss = 1508967164.12334251\n",
            "Iteration 537, loss = 1508913026.67511797\n",
            "Iteration 538, loss = 1508859069.37689614\n",
            "Iteration 539, loss = 1508805058.40922022\n",
            "Iteration 540, loss = 1508750961.16810822\n",
            "Iteration 541, loss = 1508696857.78947043\n",
            "Iteration 542, loss = 1508642678.54181767\n",
            "Iteration 543, loss = 1508588542.34077263\n",
            "Iteration 544, loss = 1508534285.30188036\n",
            "Iteration 545, loss = 1508479442.63965321\n",
            "Iteration 546, loss = 1508425088.83761954\n",
            "Iteration 547, loss = 1508370630.74706984\n",
            "Iteration 548, loss = 1508315793.17803359\n",
            "Iteration 549, loss = 1508261157.45953441\n",
            "Iteration 550, loss = 1508206562.16646791\n",
            "Iteration 551, loss = 1508151760.04847932\n",
            "Iteration 552, loss = 1508097509.36945605\n",
            "Iteration 553, loss = 1508042542.69028187\n",
            "Iteration 554, loss = 1507988378.81307673\n",
            "Iteration 555, loss = 1507934060.36447954\n",
            "Iteration 556, loss = 1507879747.50563669\n",
            "Iteration 557, loss = 1507826043.33833742\n",
            "Iteration 558, loss = 1507771455.39267921\n",
            "Iteration 559, loss = 1507717670.34275341\n",
            "Iteration 560, loss = 1507663741.49802375\n",
            "Iteration 561, loss = 1507609457.11108732\n",
            "Iteration 562, loss = 1507555542.16516805\n",
            "Iteration 563, loss = 1507501476.94447327\n",
            "Iteration 564, loss = 1507447427.60179472\n",
            "Iteration 565, loss = 1507393385.71189404\n",
            "Iteration 566, loss = 1507339497.97630811\n",
            "Iteration 567, loss = 1507285150.37170744\n",
            "Iteration 568, loss = 1507231301.25282621\n",
            "Iteration 569, loss = 1507176944.40703750\n",
            "Iteration 570, loss = 1507123092.44669080\n",
            "Iteration 571, loss = 1507068899.42408252\n",
            "Iteration 572, loss = 1507014622.25549412\n",
            "Iteration 573, loss = 1506960625.30763841\n",
            "Iteration 574, loss = 1506906775.65407658\n",
            "Iteration 575, loss = 1506852533.39627934\n",
            "Iteration 576, loss = 1506798777.83696365\n",
            "Iteration 577, loss = 1506744789.75629878\n",
            "Iteration 578, loss = 1506690817.37363625\n",
            "Iteration 579, loss = 1506637029.28986430\n",
            "Iteration 580, loss = 1506582961.62177563\n",
            "Iteration 581, loss = 1506528923.44145703\n",
            "Iteration 582, loss = 1506474934.26680017\n",
            "Iteration 583, loss = 1506420929.71431208\n",
            "Iteration 584, loss = 1506366897.41042852\n",
            "Iteration 585, loss = 1506312650.82652617\n",
            "Iteration 586, loss = 1506258506.97392893\n",
            "Iteration 587, loss = 1506204657.67939425\n",
            "Iteration 588, loss = 1506150369.48535013\n",
            "Iteration 589, loss = 1506096726.86424184\n",
            "Iteration 590, loss = 1506042588.16488767\n",
            "Iteration 591, loss = 1505988608.85709310\n",
            "Iteration 592, loss = 1505934794.99756670\n",
            "Iteration 593, loss = 1505880991.10361457\n",
            "Iteration 594, loss = 1505826922.84404922\n",
            "Iteration 595, loss = 1505772957.47187972\n",
            "Iteration 596, loss = 1505719670.75934958\n",
            "Iteration 597, loss = 1505665311.87686253\n",
            "Iteration 598, loss = 1505612074.43512201\n",
            "Iteration 599, loss = 1505557881.95839453\n",
            "Iteration 600, loss = 1505504189.52506828\n",
            "Iteration 601, loss = 1505450711.37915492\n",
            "Iteration 602, loss = 1505396878.46984148\n",
            "Iteration 603, loss = 1505342863.44738269\n",
            "Iteration 604, loss = 1505289233.91624475\n",
            "Iteration 605, loss = 1505235631.03630829\n",
            "Iteration 606, loss = 1505181651.25578213\n",
            "Iteration 607, loss = 1505128270.15574455\n",
            "Iteration 608, loss = 1505074390.41588449\n",
            "Iteration 609, loss = 1505020722.28710437\n",
            "Iteration 610, loss = 1504967016.23659134\n",
            "Iteration 611, loss = 1504913118.40761638\n",
            "Iteration 612, loss = 1504859265.75876760\n",
            "Iteration 613, loss = 1504805447.15328193\n",
            "Iteration 614, loss = 1504751559.76392770\n",
            "Iteration 615, loss = 1504697338.67514586\n",
            "Iteration 616, loss = 1504643428.18393326\n",
            "Iteration 617, loss = 1504589450.95429468\n",
            "Iteration 618, loss = 1504535225.78345108\n",
            "Iteration 619, loss = 1504481068.46897650\n",
            "Iteration 620, loss = 1504426921.17741799\n",
            "Iteration 621, loss = 1504373031.99854422\n",
            "Iteration 622, loss = 1504318943.23183632\n",
            "Iteration 623, loss = 1504264844.79354692\n",
            "Iteration 624, loss = 1504210799.19831657\n",
            "Iteration 625, loss = 1504157279.41743016\n",
            "Iteration 626, loss = 1504103216.46287107\n",
            "Iteration 627, loss = 1504049147.05702686\n",
            "Iteration 628, loss = 1503995199.94249272\n",
            "Iteration 629, loss = 1503941514.55329323\n",
            "Iteration 630, loss = 1503887392.44606185\n",
            "Iteration 631, loss = 1503833551.39622951\n",
            "Iteration 632, loss = 1503779635.70777154\n",
            "Iteration 633, loss = 1503725330.97216058\n",
            "Iteration 634, loss = 1503671805.34071088\n",
            "Iteration 635, loss = 1503617532.81870174\n",
            "Iteration 636, loss = 1503563317.03587532\n",
            "Iteration 637, loss = 1503509456.47054744\n",
            "Iteration 638, loss = 1503455364.61275578\n",
            "Iteration 639, loss = 1503401408.09916186\n",
            "Iteration 640, loss = 1503347356.80562282\n",
            "Iteration 641, loss = 1503293421.56760836\n",
            "Iteration 642, loss = 1503239185.46427512\n",
            "Iteration 643, loss = 1503185606.29344010\n",
            "Iteration 644, loss = 1503131623.83802056\n",
            "Iteration 645, loss = 1503077358.15410137\n",
            "Iteration 646, loss = 1503023557.15190721\n",
            "Iteration 647, loss = 1502969692.35799098\n",
            "Iteration 648, loss = 1502915667.11949325\n",
            "Iteration 649, loss = 1502861726.78715420\n",
            "Iteration 650, loss = 1502807879.46940184\n",
            "Iteration 651, loss = 1502753831.20096421\n",
            "Iteration 652, loss = 1502700358.66290069\n",
            "Iteration 653, loss = 1502646239.23512006\n",
            "Iteration 654, loss = 1502592421.34424973\n",
            "Iteration 655, loss = 1502538440.76559830\n",
            "Iteration 656, loss = 1502484428.96855688\n",
            "Iteration 657, loss = 1502430668.42310548\n",
            "Iteration 658, loss = 1502376395.29630637\n",
            "Iteration 659, loss = 1502322683.70006776\n",
            "Iteration 660, loss = 1502268318.92679429\n",
            "Iteration 661, loss = 1502214937.79122353\n",
            "Iteration 662, loss = 1502160629.56445837\n",
            "Iteration 663, loss = 1502106655.23720908\n",
            "Iteration 664, loss = 1502053230.84733820\n",
            "Iteration 665, loss = 1501999432.68392086\n",
            "Iteration 666, loss = 1501944957.97446704\n",
            "Iteration 667, loss = 1501891620.10577846\n",
            "Iteration 668, loss = 1501838002.53073573\n",
            "Iteration 669, loss = 1501783996.49257374\n",
            "Iteration 670, loss = 1501730383.35681415\n",
            "Iteration 671, loss = 1501676711.73172617\n",
            "Iteration 672, loss = 1501622852.90168881\n",
            "Iteration 673, loss = 1501569064.81211257\n",
            "Iteration 674, loss = 1501515115.78907752\n",
            "Iteration 675, loss = 1501461368.69828415\n",
            "Iteration 676, loss = 1501407297.57831144\n",
            "Iteration 677, loss = 1501353538.99713588\n",
            "Iteration 678, loss = 1501299628.33012629\n",
            "Iteration 679, loss = 1501245785.93858933\n",
            "Iteration 680, loss = 1501192098.56945729\n",
            "Iteration 681, loss = 1501138045.38519144\n",
            "Iteration 682, loss = 1501084360.13538337\n",
            "Iteration 683, loss = 1501030600.60101032\n",
            "Iteration 684, loss = 1500976998.70166802\n",
            "Iteration 685, loss = 1500922938.08345866\n",
            "Iteration 686, loss = 1500869310.25135016\n",
            "Iteration 687, loss = 1500815444.11287642\n",
            "Iteration 688, loss = 1500762087.37032819\n",
            "Iteration 689, loss = 1500707891.83270526\n",
            "Iteration 690, loss = 1500654229.04223633\n",
            "Iteration 691, loss = 1500600647.03030896\n",
            "Iteration 692, loss = 1500547021.85686898\n",
            "Iteration 693, loss = 1500492792.33843946\n",
            "Iteration 694, loss = 1500439211.82020378\n",
            "Iteration 695, loss = 1500384939.29253411\n",
            "Iteration 696, loss = 1500331583.95218039\n",
            "Iteration 697, loss = 1500277487.54357100\n",
            "Iteration 698, loss = 1500223399.65212870\n",
            "Iteration 699, loss = 1500169709.18840861\n",
            "Iteration 700, loss = 1500115819.64040112\n",
            "Iteration 701, loss = 1500061799.40901160\n",
            "Iteration 702, loss = 1500007853.50975990\n",
            "Iteration 703, loss = 1499953931.98895383\n",
            "Iteration 704, loss = 1499900054.48376274\n",
            "Iteration 705, loss = 1499845801.52694917\n",
            "Iteration 706, loss = 1499791969.32138848\n",
            "Iteration 707, loss = 1499738071.54534054\n",
            "Iteration 708, loss = 1499684378.47910118\n",
            "Iteration 709, loss = 1499630368.15139103\n",
            "Iteration 710, loss = 1499576646.42689943\n",
            "Iteration 711, loss = 1499523111.53012776\n",
            "Iteration 712, loss = 1499468682.90925813\n",
            "Iteration 713, loss = 1499415319.68465161\n",
            "Iteration 714, loss = 1499361793.86195588\n",
            "Iteration 715, loss = 1499307565.35605001\n",
            "Iteration 716, loss = 1499254055.60403466\n",
            "Iteration 717, loss = 1499200469.49131870\n",
            "Iteration 718, loss = 1499146556.74712038\n",
            "Iteration 719, loss = 1499092871.07461715\n",
            "Iteration 720, loss = 1499039384.19740200\n",
            "Iteration 721, loss = 1498985481.89035702\n",
            "Iteration 722, loss = 1498931754.95989275\n",
            "Iteration 723, loss = 1498878047.71709013\n",
            "Iteration 724, loss = 1498824789.35491157\n",
            "Iteration 725, loss = 1498770831.50701356\n",
            "Iteration 726, loss = 1498717235.90810776\n",
            "Iteration 727, loss = 1498663720.18965483\n",
            "Iteration 728, loss = 1498610138.41894674\n",
            "Iteration 729, loss = 1498556781.58586645\n",
            "Iteration 730, loss = 1498503305.08338857\n",
            "Iteration 731, loss = 1498449683.29201031\n",
            "Iteration 732, loss = 1498396577.28788590\n",
            "Iteration 733, loss = 1498343496.48502111\n",
            "Iteration 734, loss = 1498289666.94099450\n",
            "Iteration 735, loss = 1498236285.22365427\n",
            "Iteration 736, loss = 1498183285.08766341\n",
            "Iteration 737, loss = 1498129774.71689939\n",
            "Iteration 738, loss = 1498076198.77353644\n",
            "Iteration 739, loss = 1498022797.97334480\n",
            "Iteration 740, loss = 1497969406.64818859\n",
            "Iteration 741, loss = 1497916304.25517488\n",
            "Iteration 742, loss = 1497862584.34214306\n",
            "Iteration 743, loss = 1497809522.71013284\n",
            "Iteration 744, loss = 1497756119.39726686\n",
            "Iteration 745, loss = 1497702592.88563800\n",
            "Iteration 746, loss = 1497649201.70512462\n",
            "Iteration 747, loss = 1497595422.64892173\n",
            "Iteration 748, loss = 1497542180.32235360\n",
            "Iteration 749, loss = 1497488453.54017091\n",
            "Iteration 750, loss = 1497434985.39383483\n",
            "Iteration 751, loss = 1497381609.10591769\n",
            "Iteration 752, loss = 1497328061.00169230\n",
            "Iteration 753, loss = 1497275028.38324857\n",
            "Iteration 754, loss = 1497221184.31139040\n",
            "Iteration 755, loss = 1497168099.25121140\n",
            "Iteration 756, loss = 1497114536.73938036\n",
            "Iteration 757, loss = 1497060977.24539351\n",
            "Iteration 758, loss = 1497007298.03579164\n",
            "Iteration 759, loss = 1496953400.50156546\n",
            "Iteration 760, loss = 1496899144.25056219\n",
            "Iteration 761, loss = 1496845689.85845470\n",
            "Iteration 762, loss = 1496791349.07091355\n",
            "Iteration 763, loss = 1496737343.31683445\n",
            "Iteration 764, loss = 1496683443.11918759\n",
            "Iteration 765, loss = 1496629321.68028498\n",
            "Iteration 766, loss = 1496575644.07330346\n",
            "Iteration 767, loss = 1496521404.53719449\n",
            "Iteration 768, loss = 1496468337.24812222\n",
            "Iteration 769, loss = 1496413626.91624427\n",
            "Iteration 770, loss = 1496360205.86469412\n",
            "Iteration 771, loss = 1496306214.09865236\n",
            "Iteration 772, loss = 1496252236.42845178\n",
            "Iteration 773, loss = 1496198430.08142924\n",
            "Iteration 774, loss = 1496144394.32617211\n",
            "Iteration 775, loss = 1496090492.45610332\n",
            "Iteration 776, loss = 1496036318.50985527\n",
            "Iteration 777, loss = 1495982325.69205594\n",
            "Iteration 778, loss = 1495928283.32464457\n",
            "Iteration 779, loss = 1495874044.65009880\n",
            "Iteration 780, loss = 1495819750.10393977\n",
            "Iteration 781, loss = 1495765597.17228770\n",
            "Iteration 782, loss = 1495711338.46979499\n",
            "Iteration 783, loss = 1495657457.92234993\n",
            "Iteration 784, loss = 1495602788.10469270\n",
            "Iteration 785, loss = 1495548809.37956810\n",
            "Iteration 786, loss = 1495494640.31452513\n",
            "Iteration 787, loss = 1495440527.79617429\n",
            "Iteration 788, loss = 1495386483.46731901\n",
            "Iteration 789, loss = 1495332187.83943534\n",
            "Iteration 790, loss = 1495278529.30767775\n",
            "Iteration 791, loss = 1495224071.30301690\n",
            "Iteration 792, loss = 1495170197.02447867\n",
            "Iteration 793, loss = 1495116629.17475605\n",
            "Iteration 794, loss = 1495062471.58037996\n",
            "Iteration 795, loss = 1495008600.36606479\n",
            "Iteration 796, loss = 1494954816.64928603\n",
            "Iteration 797, loss = 1494900727.38791847\n",
            "Iteration 798, loss = 1494847499.68944955\n",
            "Iteration 799, loss = 1494793253.11225677\n",
            "Iteration 800, loss = 1494739655.08620238\n",
            "Iteration 801, loss = 1494686158.05701947\n",
            "Iteration 802, loss = 1494632425.64533854\n",
            "Iteration 803, loss = 1494579027.15933537\n",
            "Iteration 804, loss = 1494525198.14357471\n",
            "Iteration 805, loss = 1494471916.09399152\n",
            "Iteration 806, loss = 1494417944.48985219\n",
            "Iteration 807, loss = 1494364414.97988391\n",
            "Iteration 808, loss = 1494310551.18114853\n",
            "Iteration 809, loss = 1494256905.01582479\n",
            "Iteration 810, loss = 1494203106.41116190\n",
            "Iteration 811, loss = 1494149535.46186018\n",
            "Iteration 812, loss = 1494095663.47295618\n",
            "Iteration 813, loss = 1494042279.84828544\n",
            "Iteration 814, loss = 1493988328.63753366\n",
            "Iteration 815, loss = 1493934668.83616638\n",
            "Iteration 816, loss = 1493880941.15269876\n",
            "Iteration 817, loss = 1493827738.07693386\n",
            "Iteration 818, loss = 1493773452.42935228\n",
            "Iteration 819, loss = 1493719842.73430800\n",
            "Iteration 820, loss = 1493666156.14426923\n",
            "Iteration 821, loss = 1493612253.35020757\n",
            "Iteration 822, loss = 1493558626.33471918\n",
            "Iteration 823, loss = 1493504612.95678878\n",
            "Iteration 824, loss = 1493450639.05057907\n",
            "Iteration 825, loss = 1493396824.20059609\n",
            "Iteration 826, loss = 1493342798.71383357\n",
            "Iteration 827, loss = 1493288477.35862803\n",
            "Iteration 828, loss = 1493234779.32535267\n",
            "Iteration 829, loss = 1493180875.16856456\n",
            "Iteration 830, loss = 1493126856.20631456\n",
            "Iteration 831, loss = 1493072545.45472836\n",
            "Iteration 832, loss = 1493018967.98691821\n",
            "Iteration 833, loss = 1492965043.58596087\n",
            "Iteration 834, loss = 1492911005.27246308\n",
            "Iteration 835, loss = 1492856988.52111936\n",
            "Iteration 836, loss = 1492803035.32571697\n",
            "Iteration 837, loss = 1492749119.90274739\n",
            "Iteration 838, loss = 1492695395.22731566\n",
            "Iteration 839, loss = 1492641540.73021293\n",
            "Iteration 840, loss = 1492587372.45503879\n",
            "Iteration 841, loss = 1492533958.10051203\n",
            "Iteration 842, loss = 1492480427.96670580\n",
            "Iteration 843, loss = 1492426462.54815912\n",
            "Iteration 844, loss = 1492372745.12776780\n",
            "Iteration 845, loss = 1492319250.18771577\n",
            "Iteration 846, loss = 1492265678.19945645\n",
            "Iteration 847, loss = 1492212015.05996132\n",
            "Iteration 848, loss = 1492158378.45340896\n",
            "Iteration 849, loss = 1492104537.19691968\n",
            "Iteration 850, loss = 1492051064.39762831\n",
            "Iteration 851, loss = 1491997645.65511584\n",
            "Iteration 852, loss = 1491943785.37548637\n",
            "Iteration 853, loss = 1491890357.19894242\n",
            "Iteration 854, loss = 1491836808.88115716\n",
            "Iteration 855, loss = 1491782998.36978388\n",
            "Iteration 856, loss = 1491729479.68018889\n",
            "Iteration 857, loss = 1491675821.40718508\n",
            "Iteration 858, loss = 1491622102.62175798\n",
            "Iteration 859, loss = 1491568304.66760397\n",
            "Iteration 860, loss = 1491514657.17997837\n",
            "Iteration 861, loss = 1491460675.07690787\n",
            "Iteration 862, loss = 1491406960.83068299\n",
            "Iteration 863, loss = 1491353370.47389936\n",
            "Iteration 864, loss = 1491299543.23974895\n",
            "Iteration 865, loss = 1491246130.91316390\n",
            "Iteration 866, loss = 1491192177.47604036\n",
            "Iteration 867, loss = 1491138877.96097541\n",
            "Iteration 868, loss = 1491085669.82780099\n",
            "Iteration 869, loss = 1491031920.53326464\n",
            "Iteration 870, loss = 1490978523.00944805\n",
            "Iteration 871, loss = 1490925360.24859452\n",
            "Iteration 872, loss = 1490871838.29462671\n",
            "Iteration 873, loss = 1490818551.86217332\n",
            "Iteration 874, loss = 1490765475.60212278\n",
            "Iteration 875, loss = 1490712132.24006033\n",
            "Iteration 876, loss = 1490658429.46972799\n",
            "Iteration 877, loss = 1490605381.97296047\n",
            "Iteration 878, loss = 1490552171.64121914\n",
            "Iteration 879, loss = 1490498400.89931297\n",
            "Iteration 880, loss = 1490444984.65242171\n",
            "Iteration 881, loss = 1490391282.11340737\n",
            "Iteration 882, loss = 1490337904.99251318\n",
            "Iteration 883, loss = 1490284479.65812492\n",
            "Iteration 884, loss = 1490230362.32189059\n",
            "Iteration 885, loss = 1490176948.12481809\n",
            "Iteration 886, loss = 1490123232.47116041\n",
            "Iteration 887, loss = 1490069599.28918123\n",
            "Iteration 888, loss = 1490015631.56986713\n",
            "Iteration 889, loss = 1489962026.65329361\n",
            "Iteration 890, loss = 1489908285.35584617\n",
            "Iteration 891, loss = 1489854433.94103980\n",
            "Iteration 892, loss = 1489800851.72720218\n",
            "Iteration 893, loss = 1489746952.58400321\n",
            "Iteration 894, loss = 1489693690.17396879\n",
            "Iteration 895, loss = 1489639770.06103039\n",
            "Iteration 896, loss = 1489586303.90566134\n",
            "Iteration 897, loss = 1489532905.78382015\n",
            "Iteration 898, loss = 1489479547.90851974\n",
            "Iteration 899, loss = 1489426013.85083938\n",
            "Iteration 900, loss = 1489372697.34185266\n",
            "Iteration 901, loss = 1489318868.01058888\n",
            "Iteration 902, loss = 1489265448.67448664\n",
            "Iteration 903, loss = 1489212123.27909708\n",
            "Iteration 904, loss = 1489158558.01760340\n",
            "Iteration 905, loss = 1489104825.60958505\n",
            "Iteration 906, loss = 1489051732.68480921\n",
            "Iteration 907, loss = 1488997942.31550765\n",
            "Iteration 908, loss = 1488944693.72149158\n",
            "Iteration 909, loss = 1488891343.58100843\n",
            "Iteration 910, loss = 1488837298.01101851\n",
            "Iteration 911, loss = 1488783927.99504709\n",
            "Iteration 912, loss = 1488730532.75377202\n",
            "Iteration 913, loss = 1488676277.90746927\n",
            "Iteration 914, loss = 1488623146.07521701\n",
            "Iteration 915, loss = 1488569266.97699833\n",
            "Iteration 916, loss = 1488515822.62121367\n",
            "Iteration 917, loss = 1488462167.90240383\n",
            "Iteration 918, loss = 1488409019.72978973\n",
            "Iteration 919, loss = 1488355302.24938893\n",
            "Iteration 920, loss = 1488301600.86606050\n",
            "Iteration 921, loss = 1488248596.56585431\n",
            "Iteration 922, loss = 1488194744.58375764\n",
            "Iteration 923, loss = 1488141313.80593014\n",
            "Iteration 924, loss = 1488087561.72681332\n",
            "Iteration 925, loss = 1488034424.91060066\n",
            "Iteration 926, loss = 1487980834.86475706\n",
            "Iteration 927, loss = 1487927312.06950760\n",
            "Iteration 928, loss = 1487873873.25099921\n",
            "Iteration 929, loss = 1487820458.55787063\n",
            "Iteration 930, loss = 1487767122.63607979\n",
            "Iteration 931, loss = 1487713692.56194592\n",
            "Iteration 932, loss = 1487660123.63900161\n",
            "Iteration 933, loss = 1487606837.13808918\n",
            "Iteration 934, loss = 1487553686.40147924\n",
            "Iteration 935, loss = 1487499870.51618004\n",
            "Iteration 936, loss = 1487446881.12554908\n",
            "Iteration 937, loss = 1487393112.28108644\n",
            "Iteration 938, loss = 1487340092.11652398\n",
            "Iteration 939, loss = 1487286632.13238144\n",
            "Iteration 940, loss = 1487232893.95011950\n",
            "Iteration 941, loss = 1487179804.16268659\n",
            "Iteration 942, loss = 1487126077.96197438\n",
            "Iteration 943, loss = 1487072216.66584826\n",
            "Iteration 944, loss = 1487018849.20862103\n",
            "Iteration 945, loss = 1486964938.89285636\n",
            "Iteration 946, loss = 1486911234.87503481\n",
            "Iteration 947, loss = 1486857669.86234260\n",
            "Iteration 948, loss = 1486804096.86559153\n",
            "Iteration 949, loss = 1486750157.60589123\n",
            "Iteration 950, loss = 1486696649.65525746\n",
            "Iteration 951, loss = 1486643318.61415601\n",
            "Iteration 952, loss = 1486589704.72040176\n",
            "Iteration 953, loss = 1486535926.81170917\n",
            "Iteration 954, loss = 1486482410.19966960\n",
            "Iteration 955, loss = 1486429081.06264138\n",
            "Iteration 956, loss = 1486375625.22426939\n",
            "Iteration 957, loss = 1486321875.66523314\n",
            "Iteration 958, loss = 1486268432.86055923\n",
            "Iteration 959, loss = 1486215377.97427893\n",
            "Iteration 960, loss = 1486161648.10666323\n",
            "Iteration 961, loss = 1486108317.29563880\n",
            "Iteration 962, loss = 1486055085.09924340\n",
            "Iteration 963, loss = 1486001698.12277007\n",
            "Iteration 964, loss = 1485948381.67975163\n",
            "Iteration 965, loss = 1485895164.01854682\n",
            "Iteration 966, loss = 1485842093.91935849\n",
            "Iteration 967, loss = 1485788846.34144235\n",
            "Iteration 968, loss = 1485735930.42332697\n",
            "Iteration 969, loss = 1485682739.83251810\n",
            "Iteration 970, loss = 1485629650.88246322\n",
            "Iteration 971, loss = 1485576597.83551574\n",
            "Iteration 972, loss = 1485523430.30014753\n",
            "Iteration 973, loss = 1485470093.23832679\n",
            "Iteration 974, loss = 1485416903.44176078\n",
            "Iteration 975, loss = 1485363375.09284520\n",
            "Iteration 976, loss = 1485310085.96943426\n",
            "Iteration 977, loss = 1485256396.26197338\n",
            "Iteration 978, loss = 1485203390.01769614\n",
            "Iteration 979, loss = 1485149370.08000374\n",
            "Iteration 980, loss = 1485096275.71523070\n",
            "Iteration 981, loss = 1485043232.90525246\n",
            "Iteration 982, loss = 1484989753.38169003\n",
            "Iteration 983, loss = 1484936841.12919164\n",
            "Iteration 984, loss = 1484883481.71416140\n",
            "Iteration 985, loss = 1484830431.50650859\n",
            "Iteration 986, loss = 1484777606.61962700\n",
            "Iteration 987, loss = 1484724579.85874677\n",
            "Iteration 988, loss = 1484671220.36130667\n",
            "Iteration 989, loss = 1484618135.05850434\n",
            "Iteration 990, loss = 1484565139.86613059\n",
            "Iteration 991, loss = 1484511786.40396190\n",
            "Iteration 992, loss = 1484458724.59039688\n",
            "Iteration 993, loss = 1484405279.77659750\n",
            "Iteration 994, loss = 1484352201.53837299\n",
            "Iteration 995, loss = 1484298827.27861881\n",
            "Iteration 996, loss = 1484245140.54938293\n",
            "Iteration 997, loss = 1484192003.74516201\n",
            "Iteration 998, loss = 1484138504.23062658\n",
            "Iteration 999, loss = 1484084629.36853266\n",
            "Iteration 1000, loss = 1484031301.26422644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1538963389.41551256\n",
            "Iteration 2, loss = 997125883.95910573\n",
            "Iteration 3, loss = 505446243.29250407\n",
            "Iteration 4, loss = 610308754.32625115\n",
            "Iteration 5, loss = 467653278.88884372\n",
            "Iteration 6, loss = 444681481.92104322\n",
            "Iteration 7, loss = 424312468.45790833\n",
            "Iteration 8, loss = 434726853.22891378\n",
            "Iteration 9, loss = 400018188.22062427\n",
            "Iteration 10, loss = 414824898.24357480\n",
            "Iteration 11, loss = 426541221.05055451\n",
            "Iteration 12, loss = 443432363.04848999\n",
            "Iteration 13, loss = 457741013.07527179\n",
            "Iteration 14, loss = 471743251.53312391\n",
            "Iteration 15, loss = 483307994.96271479\n",
            "Iteration 16, loss = 492037120.20209068\n",
            "Iteration 17, loss = 499694404.83906513\n",
            "Iteration 18, loss = 503945698.48639899\n",
            "Iteration 19, loss = 507361284.30277377\n",
            "Iteration 20, loss = 510187769.99053359\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538807917.65281868\n",
            "Iteration 2, loss = 1538670113.25677586\n",
            "Iteration 3, loss = 1538536527.50451136\n",
            "Iteration 4, loss = 1538418954.14639807\n",
            "Iteration 5, loss = 1538305677.23267245\n",
            "Iteration 6, loss = 1538205981.09053087\n",
            "Iteration 7, loss = 1538128056.71753144\n",
            "Iteration 8, loss = 1538060667.82591414\n",
            "Iteration 9, loss = 1537996780.55997992\n",
            "Iteration 10, loss = 1537934902.14425564\n",
            "Iteration 11, loss = 1537874805.05442476\n",
            "Iteration 12, loss = 1537814752.77568412\n",
            "Iteration 13, loss = 1537754597.04459214\n",
            "Iteration 14, loss = 1537694449.15363598\n",
            "Iteration 15, loss = 1537634686.63744092\n",
            "Iteration 16, loss = 1537574638.53556323\n",
            "Iteration 17, loss = 1537515070.59722924\n",
            "Iteration 18, loss = 1537455294.91321540\n",
            "Iteration 19, loss = 1537395952.08148098\n",
            "Iteration 20, loss = 1537336274.23849034\n",
            "Iteration 21, loss = 1537277428.17657113\n",
            "Iteration 22, loss = 1537218116.46177793\n",
            "Iteration 23, loss = 1537159589.16945362\n",
            "Iteration 24, loss = 1537100589.86644793\n",
            "Iteration 25, loss = 1537042516.10231256\n",
            "Iteration 26, loss = 1536984037.55655599\n",
            "Iteration 27, loss = 1536925997.97136688\n",
            "Iteration 28, loss = 1536867814.47508407\n",
            "Iteration 29, loss = 1536809946.04054689\n",
            "Iteration 30, loss = 1536752401.28680897\n",
            "Iteration 31, loss = 1536694437.44539642\n",
            "Iteration 32, loss = 1536636820.43234134\n",
            "Iteration 33, loss = 1536578943.60445762\n",
            "Iteration 34, loss = 1536521693.91468406\n",
            "Iteration 35, loss = 1536463913.37142348\n",
            "Iteration 36, loss = 1536406519.74959183\n",
            "Iteration 37, loss = 1536349393.50208163\n",
            "Iteration 38, loss = 1536292107.91261411\n",
            "Iteration 39, loss = 1536234817.05054164\n",
            "Iteration 40, loss = 1536177666.88251615\n",
            "Iteration 41, loss = 1536120873.50119495\n",
            "Iteration 42, loss = 1536064130.50503063\n",
            "Iteration 43, loss = 1536006867.14862418\n",
            "Iteration 44, loss = 1535950319.77626967\n",
            "Iteration 45, loss = 1535893398.08074927\n",
            "Iteration 46, loss = 1535836772.84455109\n",
            "Iteration 47, loss = 1535779948.40175843\n",
            "Iteration 48, loss = 1535723339.55370355\n",
            "Iteration 49, loss = 1535666938.40130782\n",
            "Iteration 50, loss = 1535610335.86550283\n",
            "Iteration 51, loss = 1535553256.36514330\n",
            "Iteration 52, loss = 1535497241.68924975\n",
            "Iteration 53, loss = 1535440288.08057117\n",
            "Iteration 54, loss = 1535383862.45118499\n",
            "Iteration 55, loss = 1535327573.05801892\n",
            "Iteration 56, loss = 1535271154.54776335\n",
            "Iteration 57, loss = 1535214445.14933109\n",
            "Iteration 58, loss = 1535158088.69452214\n",
            "Iteration 59, loss = 1535102203.36069870\n",
            "Iteration 60, loss = 1535045688.06553888\n",
            "Iteration 61, loss = 1534989637.24365997\n",
            "Iteration 62, loss = 1534933540.06761408\n",
            "Iteration 63, loss = 1534877369.87804008\n",
            "Iteration 64, loss = 1534821198.95422745\n",
            "Iteration 65, loss = 1534765350.66985106\n",
            "Iteration 66, loss = 1534709303.36292315\n",
            "Iteration 67, loss = 1534653222.34929705\n",
            "Iteration 68, loss = 1534597185.42652082\n",
            "Iteration 69, loss = 1534541207.46082187\n",
            "Iteration 70, loss = 1534485450.93709779\n",
            "Iteration 71, loss = 1534429277.44852614\n",
            "Iteration 72, loss = 1534373488.86927438\n",
            "Iteration 73, loss = 1534317636.34781408\n",
            "Iteration 74, loss = 1534261661.74730873\n",
            "Iteration 75, loss = 1534205539.39200330\n",
            "Iteration 76, loss = 1534150126.26686049\n",
            "Iteration 77, loss = 1534093876.83344936\n",
            "Iteration 78, loss = 1534038151.84551644\n",
            "Iteration 79, loss = 1533982126.03399158\n",
            "Iteration 80, loss = 1533926927.96250868\n",
            "Iteration 81, loss = 1533870472.19936228\n",
            "Iteration 82, loss = 1533815269.02132678\n",
            "Iteration 83, loss = 1533759458.65465665\n",
            "Iteration 84, loss = 1533703826.40110803\n",
            "Iteration 85, loss = 1533648437.02627087\n",
            "Iteration 86, loss = 1533592806.19717717\n",
            "Iteration 87, loss = 1533537400.22257900\n",
            "Iteration 88, loss = 1533481952.21050549\n",
            "Iteration 89, loss = 1533426582.47804809\n",
            "Iteration 90, loss = 1533371203.32932758\n",
            "Iteration 91, loss = 1533315836.49807620\n",
            "Iteration 92, loss = 1533260274.64509869\n",
            "Iteration 93, loss = 1533205015.23880458\n",
            "Iteration 94, loss = 1533149854.75809550\n",
            "Iteration 95, loss = 1533094509.74967456\n",
            "Iteration 96, loss = 1533038983.40185213\n",
            "Iteration 97, loss = 1532983610.11866188\n",
            "Iteration 98, loss = 1532928433.07970762\n",
            "Iteration 99, loss = 1532873006.70382380\n",
            "Iteration 100, loss = 1532817422.37163830\n",
            "Iteration 101, loss = 1532762116.09462261\n",
            "Iteration 102, loss = 1532706040.45659161\n",
            "Iteration 103, loss = 1532650854.65100193\n",
            "Iteration 104, loss = 1532594922.90198255\n",
            "Iteration 105, loss = 1532539286.85421824\n",
            "Iteration 106, loss = 1532483492.97640896\n",
            "Iteration 107, loss = 1532428276.95412302\n",
            "Iteration 108, loss = 1532372478.30983257\n",
            "Iteration 109, loss = 1532316937.47217178\n",
            "Iteration 110, loss = 1532261720.71755409\n",
            "Iteration 111, loss = 1532206148.25803804\n",
            "Iteration 112, loss = 1532151321.64690852\n",
            "Iteration 113, loss = 1532095669.73375940\n",
            "Iteration 114, loss = 1532040729.42925572\n",
            "Iteration 115, loss = 1531985591.05728555\n",
            "Iteration 116, loss = 1531930381.09324431\n",
            "Iteration 117, loss = 1531875645.18879819\n",
            "Iteration 118, loss = 1531820260.72083807\n",
            "Iteration 119, loss = 1531765328.27275038\n",
            "Iteration 120, loss = 1531710563.88465452\n",
            "Iteration 121, loss = 1531655132.46210694\n",
            "Iteration 122, loss = 1531600535.85108066\n",
            "Iteration 123, loss = 1531545103.82378054\n",
            "Iteration 124, loss = 1531490245.14436316\n",
            "Iteration 125, loss = 1531435200.90738010\n",
            "Iteration 126, loss = 1531380194.48752999\n",
            "Iteration 127, loss = 1531325121.13624096\n",
            "Iteration 128, loss = 1531270240.37728667\n",
            "Iteration 129, loss = 1531215242.66612387\n",
            "Iteration 130, loss = 1531160080.55696344\n",
            "Iteration 131, loss = 1531105313.41755700\n",
            "Iteration 132, loss = 1531050352.94065690\n",
            "Iteration 133, loss = 1530995378.90083861\n",
            "Iteration 134, loss = 1530940428.62498903\n",
            "Iteration 135, loss = 1530885358.20929217\n",
            "Iteration 136, loss = 1530830250.67551589\n",
            "Iteration 137, loss = 1530775458.23969364\n",
            "Iteration 138, loss = 1530720449.94626474\n",
            "Iteration 139, loss = 1530665487.36508322\n",
            "Iteration 140, loss = 1530610501.58092141\n",
            "Iteration 141, loss = 1530555992.25680900\n",
            "Iteration 142, loss = 1530500939.73720217\n",
            "Iteration 143, loss = 1530446360.62178731\n",
            "Iteration 144, loss = 1530391596.33896255\n",
            "Iteration 145, loss = 1530337151.12169266\n",
            "Iteration 146, loss = 1530282353.49685144\n",
            "Iteration 147, loss = 1530227648.03397012\n",
            "Iteration 148, loss = 1530172503.62287235\n",
            "Iteration 149, loss = 1530117618.76408315\n",
            "Iteration 150, loss = 1530062464.78464746\n",
            "Iteration 151, loss = 1530007811.59963036\n",
            "Iteration 152, loss = 1529951949.53401041\n",
            "Iteration 153, loss = 1529897267.90644026\n",
            "Iteration 154, loss = 1529842318.93828344\n",
            "Iteration 155, loss = 1529786858.31469560\n",
            "Iteration 156, loss = 1529731785.89858198\n",
            "Iteration 157, loss = 1529676770.27437639\n",
            "Iteration 158, loss = 1529621572.72674870\n",
            "Iteration 159, loss = 1529566551.18281841\n",
            "Iteration 160, loss = 1529511502.18857479\n",
            "Iteration 161, loss = 1529456078.83305550\n",
            "Iteration 162, loss = 1529400830.61015368\n",
            "Iteration 163, loss = 1529345569.22326994\n",
            "Iteration 164, loss = 1529290612.32277298\n",
            "Iteration 165, loss = 1529235223.08651829\n",
            "Iteration 166, loss = 1529180118.11916757\n",
            "Iteration 167, loss = 1529124629.93115878\n",
            "Iteration 168, loss = 1529069478.93256879\n",
            "Iteration 169, loss = 1529014518.69020700\n",
            "Iteration 170, loss = 1528959224.99949884\n",
            "Iteration 171, loss = 1528904177.39485812\n",
            "Iteration 172, loss = 1528849425.17778325\n",
            "Iteration 173, loss = 1528794350.05442238\n",
            "Iteration 174, loss = 1528739448.09906411\n",
            "Iteration 175, loss = 1528684735.63300276\n",
            "Iteration 176, loss = 1528629989.17779016\n",
            "Iteration 177, loss = 1528574922.26685977\n",
            "Iteration 178, loss = 1528520215.88711214\n",
            "Iteration 179, loss = 1528465339.39039373\n",
            "Iteration 180, loss = 1528410216.64776587\n",
            "Iteration 181, loss = 1528355709.11824584\n",
            "Iteration 182, loss = 1528300547.46663880\n",
            "Iteration 183, loss = 1528245885.19819975\n",
            "Iteration 184, loss = 1528190704.82004356\n",
            "Iteration 185, loss = 1528135573.71900105\n",
            "Iteration 186, loss = 1528081255.53897476\n",
            "Iteration 187, loss = 1528025814.21419191\n",
            "Iteration 188, loss = 1527971012.12021828\n",
            "Iteration 189, loss = 1527915698.46209836\n",
            "Iteration 190, loss = 1527861156.56863976\n",
            "Iteration 191, loss = 1527805688.98996019\n",
            "Iteration 192, loss = 1527750956.29300976\n",
            "Iteration 193, loss = 1527695678.28937864\n",
            "Iteration 194, loss = 1527640882.20641875\n",
            "Iteration 195, loss = 1527585418.99668980\n",
            "Iteration 196, loss = 1527530642.97696018\n",
            "Iteration 197, loss = 1527475417.45197916\n",
            "Iteration 198, loss = 1527420997.75658488\n",
            "Iteration 199, loss = 1527365827.14943647\n",
            "Iteration 200, loss = 1527311200.86844993\n",
            "Iteration 201, loss = 1527256644.01161885\n",
            "Iteration 202, loss = 1527201877.30462289\n",
            "Iteration 203, loss = 1527147460.90955639\n",
            "Iteration 204, loss = 1527092497.61486244\n",
            "Iteration 205, loss = 1527037796.56787944\n",
            "Iteration 206, loss = 1526983195.79478693\n",
            "Iteration 207, loss = 1526928696.78703237\n",
            "Iteration 208, loss = 1526873514.41020775\n",
            "Iteration 209, loss = 1526819294.43055892\n",
            "Iteration 210, loss = 1526764845.58626580\n",
            "Iteration 211, loss = 1526709852.27716041\n",
            "Iteration 212, loss = 1526655741.92185140\n",
            "Iteration 213, loss = 1526601319.78070831\n",
            "Iteration 214, loss = 1526546621.80339575\n",
            "Iteration 215, loss = 1526492162.04611683\n",
            "Iteration 216, loss = 1526437312.44818473\n",
            "Iteration 217, loss = 1526382815.18775105\n",
            "Iteration 218, loss = 1526328265.14164948\n",
            "Iteration 219, loss = 1526273265.98215389\n",
            "Iteration 220, loss = 1526218365.84811640\n",
            "Iteration 221, loss = 1526163914.19029999\n",
            "Iteration 222, loss = 1526108782.58360124\n",
            "Iteration 223, loss = 1526053939.49849558\n",
            "Iteration 224, loss = 1525999302.59386325\n",
            "Iteration 225, loss = 1525944440.96645355\n",
            "Iteration 226, loss = 1525889266.13744283\n",
            "Iteration 227, loss = 1525834391.23888302\n",
            "Iteration 228, loss = 1525779912.81046820\n",
            "Iteration 229, loss = 1525724839.01286244\n",
            "Iteration 230, loss = 1525670164.68308091\n",
            "Iteration 231, loss = 1525615428.82035780\n",
            "Iteration 232, loss = 1525560816.46000719\n",
            "Iteration 233, loss = 1525506080.18922424\n",
            "Iteration 234, loss = 1525451619.52622414\n",
            "Iteration 235, loss = 1525397123.80810285\n",
            "Iteration 236, loss = 1525341959.89121032\n",
            "Iteration 237, loss = 1525287652.31907916\n",
            "Iteration 238, loss = 1525233324.55934715\n",
            "Iteration 239, loss = 1525178344.71183085\n",
            "Iteration 240, loss = 1525123839.88635540\n",
            "Iteration 241, loss = 1525069130.08832860\n",
            "Iteration 242, loss = 1525014256.63117218\n",
            "Iteration 243, loss = 1524959628.28749824\n",
            "Iteration 244, loss = 1524905028.42716837\n",
            "Iteration 245, loss = 1524849843.98298001\n",
            "Iteration 246, loss = 1524795137.60504007\n",
            "Iteration 247, loss = 1524740257.13857794\n",
            "Iteration 248, loss = 1524685400.55877805\n",
            "Iteration 249, loss = 1524630732.66863751\n",
            "Iteration 250, loss = 1524575518.52716589\n",
            "Iteration 251, loss = 1524521314.66907334\n",
            "Iteration 252, loss = 1524466214.01395273\n",
            "Iteration 253, loss = 1524411543.92070651\n",
            "Iteration 254, loss = 1524356835.76211357\n",
            "Iteration 255, loss = 1524302016.38427234\n",
            "Iteration 256, loss = 1524247318.70585537\n",
            "Iteration 257, loss = 1524192712.92133141\n",
            "Iteration 258, loss = 1524137783.82254958\n",
            "Iteration 259, loss = 1524083091.86373067\n",
            "Iteration 260, loss = 1524028593.22943020\n",
            "Iteration 261, loss = 1523974087.65059471\n",
            "Iteration 262, loss = 1523919609.92964602\n",
            "Iteration 263, loss = 1523864717.76745057\n",
            "Iteration 264, loss = 1523810688.90960288\n",
            "Iteration 265, loss = 1523755966.97931600\n",
            "Iteration 266, loss = 1523701231.31365085\n",
            "Iteration 267, loss = 1523646594.40011930\n",
            "Iteration 268, loss = 1523592171.39535260\n",
            "Iteration 269, loss = 1523537660.97569561\n",
            "Iteration 270, loss = 1523482682.11240625\n",
            "Iteration 271, loss = 1523427976.23749757\n",
            "Iteration 272, loss = 1523373309.58187699\n",
            "Iteration 273, loss = 1523318402.33921242\n",
            "Iteration 274, loss = 1523263529.50707555\n",
            "Iteration 275, loss = 1523208962.96114516\n",
            "Iteration 276, loss = 1523153784.01221275\n",
            "Iteration 277, loss = 1523099040.25488138\n",
            "Iteration 278, loss = 1523044670.01085830\n",
            "Iteration 279, loss = 1522989435.19923782\n",
            "Iteration 280, loss = 1522934886.48929739\n",
            "Iteration 281, loss = 1522880645.99284029\n",
            "Iteration 282, loss = 1522825473.23587751\n",
            "Iteration 283, loss = 1522771075.48727894\n",
            "Iteration 284, loss = 1522716286.90021062\n",
            "Iteration 285, loss = 1522661255.94554043\n",
            "Iteration 286, loss = 1522606532.83661199\n",
            "Iteration 287, loss = 1522551927.21811581\n",
            "Iteration 288, loss = 1522496901.75509477\n",
            "Iteration 289, loss = 1522442283.11978030\n",
            "Iteration 290, loss = 1522387638.35505915\n",
            "Iteration 291, loss = 1522332844.46324587\n",
            "Iteration 292, loss = 1522278112.17322278\n",
            "Iteration 293, loss = 1522223835.39345217\n",
            "Iteration 294, loss = 1522168850.67804527\n",
            "Iteration 295, loss = 1522114159.42485428\n",
            "Iteration 296, loss = 1522059445.59028959\n",
            "Iteration 297, loss = 1522004775.91436315\n",
            "Iteration 298, loss = 1521950004.46174645\n",
            "Iteration 299, loss = 1521895018.02678680\n",
            "Iteration 300, loss = 1521840267.03256559\n",
            "Iteration 301, loss = 1521785800.46382070\n",
            "Iteration 302, loss = 1521730945.28340101\n",
            "Iteration 303, loss = 1521676380.18758321\n",
            "Iteration 304, loss = 1521621547.75368023\n",
            "Iteration 305, loss = 1521567266.07106996\n",
            "Iteration 306, loss = 1521512454.55348969\n",
            "Iteration 307, loss = 1521458414.40758252\n",
            "Iteration 308, loss = 1521403909.23070073\n",
            "Iteration 309, loss = 1521349557.81998610\n",
            "Iteration 310, loss = 1521295222.46867871\n",
            "Iteration 311, loss = 1521240949.93826723\n",
            "Iteration 312, loss = 1521186413.92909360\n",
            "Iteration 313, loss = 1521131935.92136121\n",
            "Iteration 314, loss = 1521077423.73129773\n",
            "Iteration 315, loss = 1521022870.27482748\n",
            "Iteration 316, loss = 1520968078.08792901\n",
            "Iteration 317, loss = 1520913647.21977735\n",
            "Iteration 318, loss = 1520858880.53449750\n",
            "Iteration 319, loss = 1520804313.23090720\n",
            "Iteration 320, loss = 1520750083.51462150\n",
            "Iteration 321, loss = 1520695330.64567518\n",
            "Iteration 322, loss = 1520640767.80116463\n",
            "Iteration 323, loss = 1520586730.88813782\n",
            "Iteration 324, loss = 1520532164.84958792\n",
            "Iteration 325, loss = 1520477815.74917674\n",
            "Iteration 326, loss = 1520423467.51616573\n",
            "Iteration 327, loss = 1520369223.34070063\n",
            "Iteration 328, loss = 1520314808.78985333\n",
            "Iteration 329, loss = 1520260652.56424189\n",
            "Iteration 330, loss = 1520206010.56272197\n",
            "Iteration 331, loss = 1520151757.86950970\n",
            "Iteration 332, loss = 1520097307.78203630\n",
            "Iteration 333, loss = 1520043007.51235008\n",
            "Iteration 334, loss = 1519988856.58651614\n",
            "Iteration 335, loss = 1519933878.83982873\n",
            "Iteration 336, loss = 1519879550.22581863\n",
            "Iteration 337, loss = 1519825371.87377834\n",
            "Iteration 338, loss = 1519770548.62248588\n",
            "Iteration 339, loss = 1519716265.72597361\n",
            "Iteration 340, loss = 1519661641.48808789\n",
            "Iteration 341, loss = 1519607067.86885309\n",
            "Iteration 342, loss = 1519552772.96974635\n",
            "Iteration 343, loss = 1519498383.70524597\n",
            "Iteration 344, loss = 1519443859.95259213\n",
            "Iteration 345, loss = 1519389600.28955770\n",
            "Iteration 346, loss = 1519335335.28222847\n",
            "Iteration 347, loss = 1519280861.96297526\n",
            "Iteration 348, loss = 1519226479.00959587\n",
            "Iteration 349, loss = 1519172031.16906571\n",
            "Iteration 350, loss = 1519117443.28449869\n",
            "Iteration 351, loss = 1519063054.93190074\n",
            "Iteration 352, loss = 1519008265.32743359\n",
            "Iteration 353, loss = 1518953916.90016055\n",
            "Iteration 354, loss = 1518899228.39162111\n",
            "Iteration 355, loss = 1518844672.41866970\n",
            "Iteration 356, loss = 1518790308.31711555\n",
            "Iteration 357, loss = 1518735894.76378131\n",
            "Iteration 358, loss = 1518681729.56266165\n",
            "Iteration 359, loss = 1518627398.79034257\n",
            "Iteration 360, loss = 1518573097.14774299\n",
            "Iteration 361, loss = 1518519150.49071479\n",
            "Iteration 362, loss = 1518464797.67757440\n",
            "Iteration 363, loss = 1518410821.67571688\n",
            "Iteration 364, loss = 1518356890.53620243\n",
            "Iteration 365, loss = 1518302602.38838434\n",
            "Iteration 366, loss = 1518248853.07704234\n",
            "Iteration 367, loss = 1518194606.01353860\n",
            "Iteration 368, loss = 1518140915.64385819\n",
            "Iteration 369, loss = 1518086465.25256944\n",
            "Iteration 370, loss = 1518032435.61299849\n",
            "Iteration 371, loss = 1517978365.91211438\n",
            "Iteration 372, loss = 1517924359.25344324\n",
            "Iteration 373, loss = 1517869566.27142787\n",
            "Iteration 374, loss = 1517815508.14932346\n",
            "Iteration 375, loss = 1517760818.71114707\n",
            "Iteration 376, loss = 1517706917.21658683\n",
            "Iteration 377, loss = 1517652573.40166163\n",
            "Iteration 378, loss = 1517598110.11636257\n",
            "Iteration 379, loss = 1517543767.93884563\n",
            "Iteration 380, loss = 1517489684.83735371\n",
            "Iteration 381, loss = 1517435013.60014558\n",
            "Iteration 382, loss = 1517380731.12479329\n",
            "Iteration 383, loss = 1517326533.84835219\n",
            "Iteration 384, loss = 1517271798.10941434\n",
            "Iteration 385, loss = 1517217074.99780679\n",
            "Iteration 386, loss = 1517163031.60751319\n",
            "Iteration 387, loss = 1517108398.60734749\n",
            "Iteration 388, loss = 1517054141.97698998\n",
            "Iteration 389, loss = 1516999746.63832545\n",
            "Iteration 390, loss = 1516945241.50164032\n",
            "Iteration 391, loss = 1516891024.89402914\n",
            "Iteration 392, loss = 1516836604.38185477\n",
            "Iteration 393, loss = 1516782104.76650906\n",
            "Iteration 394, loss = 1516727580.29670262\n",
            "Iteration 395, loss = 1516673362.52067137\n",
            "Iteration 396, loss = 1516618625.79198122\n",
            "Iteration 397, loss = 1516563990.09472179\n",
            "Iteration 398, loss = 1516510087.34967542\n",
            "Iteration 399, loss = 1516455409.93380666\n",
            "Iteration 400, loss = 1516401139.62889075\n",
            "Iteration 401, loss = 1516347208.87784648\n",
            "Iteration 402, loss = 1516292964.60226727\n",
            "Iteration 403, loss = 1516238720.28979158\n",
            "Iteration 404, loss = 1516184324.54665995\n",
            "Iteration 405, loss = 1516130679.20798469\n",
            "Iteration 406, loss = 1516076289.68345404\n",
            "Iteration 407, loss = 1516022104.39266109\n",
            "Iteration 408, loss = 1515968034.72230673\n",
            "Iteration 409, loss = 1515913985.42372632\n",
            "Iteration 410, loss = 1515859908.87904787\n",
            "Iteration 411, loss = 1515805850.75624800\n",
            "Iteration 412, loss = 1515751957.41032696\n",
            "Iteration 413, loss = 1515697741.86894798\n",
            "Iteration 414, loss = 1515643611.57282019\n",
            "Iteration 415, loss = 1515589783.54134893\n",
            "Iteration 416, loss = 1515535503.76737976\n",
            "Iteration 417, loss = 1515481086.58300924\n",
            "Iteration 418, loss = 1515427249.47944927\n",
            "Iteration 419, loss = 1515373170.47022271\n",
            "Iteration 420, loss = 1515318751.86495852\n",
            "Iteration 421, loss = 1515264588.60805082\n",
            "Iteration 422, loss = 1515210765.57050133\n",
            "Iteration 423, loss = 1515156203.96822453\n",
            "Iteration 424, loss = 1515102425.68437529\n",
            "Iteration 425, loss = 1515048062.21774530\n",
            "Iteration 426, loss = 1514993516.15211701\n",
            "Iteration 427, loss = 1514939427.33358335\n",
            "Iteration 428, loss = 1514885344.08209062\n",
            "Iteration 429, loss = 1514830686.88169479\n",
            "Iteration 430, loss = 1514776251.18256092\n",
            "Iteration 431, loss = 1514722245.26560020\n",
            "Iteration 432, loss = 1514667886.38964033\n",
            "Iteration 433, loss = 1514613456.75500774\n",
            "Iteration 434, loss = 1514559644.06313348\n",
            "Iteration 435, loss = 1514505173.43710423\n",
            "Iteration 436, loss = 1514450999.61057138\n",
            "Iteration 437, loss = 1514397011.39608502\n",
            "Iteration 438, loss = 1514342722.34752822\n",
            "Iteration 439, loss = 1514288617.97760773\n",
            "Iteration 440, loss = 1514234189.16896081\n",
            "Iteration 441, loss = 1514180111.10322189\n",
            "Iteration 442, loss = 1514125607.16007042\n",
            "Iteration 443, loss = 1514071321.91532350\n",
            "Iteration 444, loss = 1514017047.50454187\n",
            "Iteration 445, loss = 1513962775.64268327\n",
            "Iteration 446, loss = 1513908151.03616357\n",
            "Iteration 447, loss = 1513853928.22087812\n",
            "Iteration 448, loss = 1513799455.78885436\n",
            "Iteration 449, loss = 1513745150.72724628\n",
            "Iteration 450, loss = 1513690780.91885996\n",
            "Iteration 451, loss = 1513636520.02418327\n",
            "Iteration 452, loss = 1513582161.57135606\n",
            "Iteration 453, loss = 1513527957.25760603\n",
            "Iteration 454, loss = 1513473691.95399022\n",
            "Iteration 455, loss = 1513419704.15211391\n",
            "Iteration 456, loss = 1513365923.52606654\n",
            "Iteration 457, loss = 1513311793.78205061\n",
            "Iteration 458, loss = 1513258010.94566822\n",
            "Iteration 459, loss = 1513203923.63363981\n",
            "Iteration 460, loss = 1513150133.96595407\n",
            "Iteration 461, loss = 1513096221.87167883\n",
            "Iteration 462, loss = 1513042338.48560643\n",
            "Iteration 463, loss = 1512988026.24354720\n",
            "Iteration 464, loss = 1512934452.17874098\n",
            "Iteration 465, loss = 1512880028.90613294\n",
            "Iteration 466, loss = 1512826632.97312856\n",
            "Iteration 467, loss = 1512772139.66769218\n",
            "Iteration 468, loss = 1512718672.68987036\n",
            "Iteration 469, loss = 1512664776.17970181\n",
            "Iteration 470, loss = 1512610567.53032565\n",
            "Iteration 471, loss = 1512557006.56819439\n",
            "Iteration 472, loss = 1512502886.64041591\n",
            "Iteration 473, loss = 1512449450.71605754\n",
            "Iteration 474, loss = 1512395013.96274924\n",
            "Iteration 475, loss = 1512341200.77857876\n",
            "Iteration 476, loss = 1512287038.27423072\n",
            "Iteration 477, loss = 1512233066.23895669\n",
            "Iteration 478, loss = 1512179085.97137260\n",
            "Iteration 479, loss = 1512124821.23734212\n",
            "Iteration 480, loss = 1512070490.71913218\n",
            "Iteration 481, loss = 1512016414.97120118\n",
            "Iteration 482, loss = 1511962436.57704592\n",
            "Iteration 483, loss = 1511908226.85918331\n",
            "Iteration 484, loss = 1511854129.95773554\n",
            "Iteration 485, loss = 1511799669.89276147\n",
            "Iteration 486, loss = 1511745630.04783487\n",
            "Iteration 487, loss = 1511691388.51417375\n",
            "Iteration 488, loss = 1511637342.44682407\n",
            "Iteration 489, loss = 1511582723.26367140\n",
            "Iteration 490, loss = 1511528686.86495399\n",
            "Iteration 491, loss = 1511474536.04893088\n",
            "Iteration 492, loss = 1511420512.85062623\n",
            "Iteration 493, loss = 1511366188.76259065\n",
            "Iteration 494, loss = 1511311920.90054584\n",
            "Iteration 495, loss = 1511258018.33230090\n",
            "Iteration 496, loss = 1511204030.42309308\n",
            "Iteration 497, loss = 1511150072.39127088\n",
            "Iteration 498, loss = 1511095334.90192866\n",
            "Iteration 499, loss = 1511041898.01835132\n",
            "Iteration 500, loss = 1510987787.62667871\n",
            "Iteration 501, loss = 1510933843.66639495\n",
            "Iteration 502, loss = 1510879929.68076849\n",
            "Iteration 503, loss = 1510825972.16633201\n",
            "Iteration 504, loss = 1510772263.69838595\n",
            "Iteration 505, loss = 1510718173.21595049\n",
            "Iteration 506, loss = 1510664317.71393991\n",
            "Iteration 507, loss = 1510610651.72100067\n",
            "Iteration 508, loss = 1510556404.18645597\n",
            "Iteration 509, loss = 1510502348.70648742\n",
            "Iteration 510, loss = 1510448345.48213601\n",
            "Iteration 511, loss = 1510394074.01175952\n",
            "Iteration 512, loss = 1510340168.59514117\n",
            "Iteration 513, loss = 1510285996.60279751\n",
            "Iteration 514, loss = 1510231835.21135426\n",
            "Iteration 515, loss = 1510177984.75203872\n",
            "Iteration 516, loss = 1510123960.51835632\n",
            "Iteration 517, loss = 1510070184.65203118\n",
            "Iteration 518, loss = 1510016051.65141964\n",
            "Iteration 519, loss = 1509962356.68349218\n",
            "Iteration 520, loss = 1509908146.20953918\n",
            "Iteration 521, loss = 1509854281.72025132\n",
            "Iteration 522, loss = 1509800375.78263259\n",
            "Iteration 523, loss = 1509746060.40816021\n",
            "Iteration 524, loss = 1509691848.24210000\n",
            "Iteration 525, loss = 1509637625.09668064\n",
            "Iteration 526, loss = 1509583248.02965403\n",
            "Iteration 527, loss = 1509528953.79283404\n",
            "Iteration 528, loss = 1509474467.56410646\n",
            "Iteration 529, loss = 1509419976.34705663\n",
            "Iteration 530, loss = 1509365535.51318312\n",
            "Iteration 531, loss = 1509311262.98122358\n",
            "Iteration 532, loss = 1509257142.38759303\n",
            "Iteration 533, loss = 1509202448.05640435\n",
            "Iteration 534, loss = 1509148459.69384789\n",
            "Iteration 535, loss = 1509093965.95423937\n",
            "Iteration 536, loss = 1509040046.28751040\n",
            "Iteration 537, loss = 1508985448.58915710\n",
            "Iteration 538, loss = 1508931696.70979667\n",
            "Iteration 539, loss = 1508877221.55418539\n",
            "Iteration 540, loss = 1508823117.89818621\n",
            "Iteration 541, loss = 1508769236.62130904\n",
            "Iteration 542, loss = 1508715076.88598418\n",
            "Iteration 543, loss = 1508661016.16251135\n",
            "Iteration 544, loss = 1508607257.35682535\n",
            "Iteration 545, loss = 1508553036.74633956\n",
            "Iteration 546, loss = 1508498939.72144938\n",
            "Iteration 547, loss = 1508444739.30131578\n",
            "Iteration 548, loss = 1508390653.34805322\n",
            "Iteration 549, loss = 1508336368.49243951\n",
            "Iteration 550, loss = 1508282284.80666685\n",
            "Iteration 551, loss = 1508227990.93903780\n",
            "Iteration 552, loss = 1508173940.37263250\n",
            "Iteration 553, loss = 1508119682.87062645\n",
            "Iteration 554, loss = 1508065490.67893648\n",
            "Iteration 555, loss = 1508011560.98830795\n",
            "Iteration 556, loss = 1507957136.75360012\n",
            "Iteration 557, loss = 1507903231.67474055\n",
            "Iteration 558, loss = 1507848765.66224718\n",
            "Iteration 559, loss = 1507794847.31904984\n",
            "Iteration 560, loss = 1507740414.18569493\n",
            "Iteration 561, loss = 1507686070.19541717\n",
            "Iteration 562, loss = 1507631899.04438949\n",
            "Iteration 563, loss = 1507577574.04893327\n",
            "Iteration 564, loss = 1507523504.13896894\n",
            "Iteration 565, loss = 1507469160.91379642\n",
            "Iteration 566, loss = 1507414969.13901448\n",
            "Iteration 567, loss = 1507360766.19209528\n",
            "Iteration 568, loss = 1507306600.68641615\n",
            "Iteration 569, loss = 1507252621.86483860\n",
            "Iteration 570, loss = 1507198834.74414968\n",
            "Iteration 571, loss = 1507144657.38572431\n",
            "Iteration 572, loss = 1507090657.28766942\n",
            "Iteration 573, loss = 1507036545.53391886\n",
            "Iteration 574, loss = 1506982678.85018373\n",
            "Iteration 575, loss = 1506928841.15519166\n",
            "Iteration 576, loss = 1506874277.19197798\n",
            "Iteration 577, loss = 1506820165.61587548\n",
            "Iteration 578, loss = 1506766011.27974391\n",
            "Iteration 579, loss = 1506711621.62725544\n",
            "Iteration 580, loss = 1506657708.86682796\n",
            "Iteration 581, loss = 1506603415.35038662\n",
            "Iteration 582, loss = 1506548931.39504337\n",
            "Iteration 583, loss = 1506495290.59076190\n",
            "Iteration 584, loss = 1506440819.92605400\n",
            "Iteration 585, loss = 1506386930.67527103\n",
            "Iteration 586, loss = 1506332435.61175036\n",
            "Iteration 587, loss = 1506278445.26974797\n",
            "Iteration 588, loss = 1506224404.45923543\n",
            "Iteration 589, loss = 1506170035.34196663\n",
            "Iteration 590, loss = 1506115967.27989888\n",
            "Iteration 591, loss = 1506062028.74509001\n",
            "Iteration 592, loss = 1506008115.85018969\n",
            "Iteration 593, loss = 1505953858.20820522\n",
            "Iteration 594, loss = 1505900112.44317317\n",
            "Iteration 595, loss = 1505846058.85227466\n",
            "Iteration 596, loss = 1505791947.08885789\n",
            "Iteration 597, loss = 1505737964.49662399\n",
            "Iteration 598, loss = 1505683995.88147545\n",
            "Iteration 599, loss = 1505629535.43655467\n",
            "Iteration 600, loss = 1505575627.93414283\n",
            "Iteration 601, loss = 1505521314.55017829\n",
            "Iteration 602, loss = 1505467336.59283185\n",
            "Iteration 603, loss = 1505412791.04282355\n",
            "Iteration 604, loss = 1505358680.45000792\n",
            "Iteration 605, loss = 1505304601.64038372\n",
            "Iteration 606, loss = 1505250146.25779819\n",
            "Iteration 607, loss = 1505195931.09690833\n",
            "Iteration 608, loss = 1505141856.66149521\n",
            "Iteration 609, loss = 1505087560.17359281\n",
            "Iteration 610, loss = 1505033404.63352489\n",
            "Iteration 611, loss = 1504979057.35782361\n",
            "Iteration 612, loss = 1504925169.20994210\n",
            "Iteration 613, loss = 1504870864.59922385\n",
            "Iteration 614, loss = 1504816835.48656297\n",
            "Iteration 615, loss = 1504762394.39853477\n",
            "Iteration 616, loss = 1504708766.31073141\n",
            "Iteration 617, loss = 1504654420.45659757\n",
            "Iteration 618, loss = 1504600665.14773369\n",
            "Iteration 619, loss = 1504546781.40706563\n",
            "Iteration 620, loss = 1504492885.09693885\n",
            "Iteration 621, loss = 1504439103.88455224\n",
            "Iteration 622, loss = 1504385315.46340179\n",
            "Iteration 623, loss = 1504331749.79587936\n",
            "Iteration 624, loss = 1504278194.88422012\n",
            "Iteration 625, loss = 1504224431.15150666\n",
            "Iteration 626, loss = 1504170341.12482595\n",
            "Iteration 627, loss = 1504117027.99673843\n",
            "Iteration 628, loss = 1504062971.49652219\n",
            "Iteration 629, loss = 1504009164.94885063\n",
            "Iteration 630, loss = 1503954878.13217688\n",
            "Iteration 631, loss = 1503901044.71009541\n",
            "Iteration 632, loss = 1503847042.46233630\n",
            "Iteration 633, loss = 1503792911.31175351\n",
            "Iteration 634, loss = 1503738277.06156158\n",
            "Iteration 635, loss = 1503684519.05306220\n",
            "Iteration 636, loss = 1503630246.70165539\n",
            "Iteration 637, loss = 1503576005.41158080\n",
            "Iteration 638, loss = 1503522179.43130660\n",
            "Iteration 639, loss = 1503467944.04034519\n",
            "Iteration 640, loss = 1503414365.50078583\n",
            "Iteration 641, loss = 1503360284.24928880\n",
            "Iteration 642, loss = 1503306698.68403053\n",
            "Iteration 643, loss = 1503252620.38431096\n",
            "Iteration 644, loss = 1503199237.91375804\n",
            "Iteration 645, loss = 1503145064.86011910\n",
            "Iteration 646, loss = 1503091376.76360679\n",
            "Iteration 647, loss = 1503037521.15555096\n",
            "Iteration 648, loss = 1502983598.05639529\n",
            "Iteration 649, loss = 1502929631.57356501\n",
            "Iteration 650, loss = 1502875701.12533808\n",
            "Iteration 651, loss = 1502821882.72885942\n",
            "Iteration 652, loss = 1502768118.27861714\n",
            "Iteration 653, loss = 1502713802.69978929\n",
            "Iteration 654, loss = 1502660093.34922314\n",
            "Iteration 655, loss = 1502605910.24644446\n",
            "Iteration 656, loss = 1502551890.45238924\n",
            "Iteration 657, loss = 1502497821.98305511\n",
            "Iteration 658, loss = 1502443920.72441983\n",
            "Iteration 659, loss = 1502390165.02696419\n",
            "Iteration 660, loss = 1502336139.95084381\n",
            "Iteration 661, loss = 1502282251.68242407\n",
            "Iteration 662, loss = 1502228490.14484048\n",
            "Iteration 663, loss = 1502174594.25061679\n",
            "Iteration 664, loss = 1502120859.98729396\n",
            "Iteration 665, loss = 1502066543.83003855\n",
            "Iteration 666, loss = 1502013089.47515368\n",
            "Iteration 667, loss = 1501958448.78555727\n",
            "Iteration 668, loss = 1501904901.02594543\n",
            "Iteration 669, loss = 1501850648.40146875\n",
            "Iteration 670, loss = 1501796691.68285489\n",
            "Iteration 671, loss = 1501742720.76911592\n",
            "Iteration 672, loss = 1501689362.36376882\n",
            "Iteration 673, loss = 1501635309.42246461\n",
            "Iteration 674, loss = 1501581175.29195547\n",
            "Iteration 675, loss = 1501527551.39647460\n",
            "Iteration 676, loss = 1501473621.29376101\n",
            "Iteration 677, loss = 1501419897.82139468\n",
            "Iteration 678, loss = 1501365716.31727290\n",
            "Iteration 679, loss = 1501311703.96939874\n",
            "Iteration 680, loss = 1501257926.65915465\n",
            "Iteration 681, loss = 1501203836.20565176\n",
            "Iteration 682, loss = 1501149921.51673627\n",
            "Iteration 683, loss = 1501095808.88105631\n",
            "Iteration 684, loss = 1501041856.12031555\n",
            "Iteration 685, loss = 1500987265.44799018\n",
            "Iteration 686, loss = 1500933536.70835876\n",
            "Iteration 687, loss = 1500879419.55498457\n",
            "Iteration 688, loss = 1500825236.88659573\n",
            "Iteration 689, loss = 1500771310.32063556\n",
            "Iteration 690, loss = 1500717555.03860784\n",
            "Iteration 691, loss = 1500663453.01575780\n",
            "Iteration 692, loss = 1500609800.65440965\n",
            "Iteration 693, loss = 1500556105.64690614\n",
            "Iteration 694, loss = 1500501742.44019866\n",
            "Iteration 695, loss = 1500448366.24225307\n",
            "Iteration 696, loss = 1500394417.79193115\n",
            "Iteration 697, loss = 1500340604.35056877\n",
            "Iteration 698, loss = 1500286462.37093616\n",
            "Iteration 699, loss = 1500232869.97862840\n",
            "Iteration 700, loss = 1500178854.78927398\n",
            "Iteration 701, loss = 1500125415.02244067\n",
            "Iteration 702, loss = 1500071239.81484103\n",
            "Iteration 703, loss = 1500017590.83520842\n",
            "Iteration 704, loss = 1499963856.87985635\n",
            "Iteration 705, loss = 1499910140.45120955\n",
            "Iteration 706, loss = 1499856262.59800267\n",
            "Iteration 707, loss = 1499802362.57975483\n",
            "Iteration 708, loss = 1499748678.89144993\n",
            "Iteration 709, loss = 1499694802.68195868\n",
            "Iteration 710, loss = 1499640920.24400735\n",
            "Iteration 711, loss = 1499587096.22173500\n",
            "Iteration 712, loss = 1499533204.30209136\n",
            "Iteration 713, loss = 1499479315.36140108\n",
            "Iteration 714, loss = 1499425678.68413043\n",
            "Iteration 715, loss = 1499371549.15899634\n",
            "Iteration 716, loss = 1499317514.91724753\n",
            "Iteration 717, loss = 1499263768.87508583\n",
            "Iteration 718, loss = 1499209827.77377582\n",
            "Iteration 719, loss = 1499155679.90968895\n",
            "Iteration 720, loss = 1499101808.52171946\n",
            "Iteration 721, loss = 1499047301.14506364\n",
            "Iteration 722, loss = 1498993292.44360852\n",
            "Iteration 723, loss = 1498938990.69194889\n",
            "Iteration 724, loss = 1498884758.27000093\n",
            "Iteration 725, loss = 1498830774.85713291\n",
            "Iteration 726, loss = 1498776330.40671301\n",
            "Iteration 727, loss = 1498722562.14866447\n",
            "Iteration 728, loss = 1498668260.51838326\n",
            "Iteration 729, loss = 1498614437.13708496\n",
            "Iteration 730, loss = 1498560523.53777933\n",
            "Iteration 731, loss = 1498506457.95762944\n",
            "Iteration 732, loss = 1498452418.50625420\n",
            "Iteration 733, loss = 1498398864.68809795\n",
            "Iteration 734, loss = 1498344545.94780540\n",
            "Iteration 735, loss = 1498290954.05844164\n",
            "Iteration 736, loss = 1498236574.83693171\n",
            "Iteration 737, loss = 1498183070.71096516\n",
            "Iteration 738, loss = 1498129024.12167311\n",
            "Iteration 739, loss = 1498075056.15660167\n",
            "Iteration 740, loss = 1498021056.26280880\n",
            "Iteration 741, loss = 1497967262.43090630\n",
            "Iteration 742, loss = 1497913368.72087908\n",
            "Iteration 743, loss = 1497859187.91313386\n",
            "Iteration 744, loss = 1497805855.52206111\n",
            "Iteration 745, loss = 1497751775.47582531\n",
            "Iteration 746, loss = 1497698298.97996378\n",
            "Iteration 747, loss = 1497644799.90670180\n",
            "Iteration 748, loss = 1497591119.84161472\n",
            "Iteration 749, loss = 1497537467.49264479\n",
            "Iteration 750, loss = 1497484116.82231045\n",
            "Iteration 751, loss = 1497430103.63564610\n",
            "Iteration 752, loss = 1497376543.14329886\n",
            "Iteration 753, loss = 1497322462.21525121\n",
            "Iteration 754, loss = 1497268693.31953573\n",
            "Iteration 755, loss = 1497214699.05688977\n",
            "Iteration 756, loss = 1497160893.40215707\n",
            "Iteration 757, loss = 1497107087.79314804\n",
            "Iteration 758, loss = 1497053175.31066656\n",
            "Iteration 759, loss = 1496999713.37295103\n",
            "Iteration 760, loss = 1496945698.72896767\n",
            "Iteration 761, loss = 1496892176.51929140\n",
            "Iteration 762, loss = 1496838384.67794728\n",
            "Iteration 763, loss = 1496784735.30072737\n",
            "Iteration 764, loss = 1496730739.02607822\n",
            "Iteration 765, loss = 1496677199.42538595\n",
            "Iteration 766, loss = 1496623012.15911198\n",
            "Iteration 767, loss = 1496569261.35409212\n",
            "Iteration 768, loss = 1496515032.27087784\n",
            "Iteration 769, loss = 1496461409.88823318\n",
            "Iteration 770, loss = 1496407062.33494473\n",
            "Iteration 771, loss = 1496353272.88576007\n",
            "Iteration 772, loss = 1496298873.21944880\n",
            "Iteration 773, loss = 1496245331.52363992\n",
            "Iteration 774, loss = 1496190881.78847361\n",
            "Iteration 775, loss = 1496137095.73050427\n",
            "Iteration 776, loss = 1496082976.71150017\n",
            "Iteration 777, loss = 1496029128.17039704\n",
            "Iteration 778, loss = 1495975480.56007242\n",
            "Iteration 779, loss = 1495921566.99151397\n",
            "Iteration 780, loss = 1495867747.22012973\n",
            "Iteration 781, loss = 1495814205.38233137\n",
            "Iteration 782, loss = 1495760860.13887525\n",
            "Iteration 783, loss = 1495706848.04023027\n",
            "Iteration 784, loss = 1495652801.92298770\n",
            "Iteration 785, loss = 1495599357.17353559\n",
            "Iteration 786, loss = 1495545550.82959485\n",
            "Iteration 787, loss = 1495491294.81541967\n",
            "Iteration 788, loss = 1495437469.26275945\n",
            "Iteration 789, loss = 1495383954.06008458\n",
            "Iteration 790, loss = 1495329643.76105094\n",
            "Iteration 791, loss = 1495275867.14332557\n",
            "Iteration 792, loss = 1495221837.67001176\n",
            "Iteration 793, loss = 1495168180.44880605\n",
            "Iteration 794, loss = 1495114629.80892229\n",
            "Iteration 795, loss = 1495060835.26262975\n",
            "Iteration 796, loss = 1495006972.18749356\n",
            "Iteration 797, loss = 1494953578.13635588\n",
            "Iteration 798, loss = 1494900017.70398378\n",
            "Iteration 799, loss = 1494846549.05935121\n",
            "Iteration 800, loss = 1494792576.99548340\n",
            "Iteration 801, loss = 1494739200.64748979\n",
            "Iteration 802, loss = 1494685430.87220955\n",
            "Iteration 803, loss = 1494631584.02283216\n",
            "Iteration 804, loss = 1494577716.30496287\n",
            "Iteration 805, loss = 1494524080.30860019\n",
            "Iteration 806, loss = 1494470383.73765230\n",
            "Iteration 807, loss = 1494416466.65489721\n",
            "Iteration 808, loss = 1494362296.85025263\n",
            "Iteration 809, loss = 1494308537.77723074\n",
            "Iteration 810, loss = 1494254525.42807651\n",
            "Iteration 811, loss = 1494200368.72236013\n",
            "Iteration 812, loss = 1494146139.00239515\n",
            "Iteration 813, loss = 1494092222.65831876\n",
            "Iteration 814, loss = 1494037608.25941348\n",
            "Iteration 815, loss = 1493984029.36840391\n",
            "Iteration 816, loss = 1493929509.90554762\n",
            "Iteration 817, loss = 1493875475.03066635\n",
            "Iteration 818, loss = 1493821507.56207514\n",
            "Iteration 819, loss = 1493767266.58511496\n",
            "Iteration 820, loss = 1493713549.33705664\n",
            "Iteration 821, loss = 1493659670.58612323\n",
            "Iteration 822, loss = 1493605536.75770998\n",
            "Iteration 823, loss = 1493551932.05630064\n",
            "Iteration 824, loss = 1493498165.32692170\n",
            "Iteration 825, loss = 1493444182.68361974\n",
            "Iteration 826, loss = 1493390379.55145431\n",
            "Iteration 827, loss = 1493336782.21334434\n",
            "Iteration 828, loss = 1493282861.74799538\n",
            "Iteration 829, loss = 1493229058.15650773\n",
            "Iteration 830, loss = 1493175100.02664685\n",
            "Iteration 831, loss = 1493121491.58041954\n",
            "Iteration 832, loss = 1493067793.00625944\n",
            "Iteration 833, loss = 1493013888.71291804\n",
            "Iteration 834, loss = 1492960232.25731039\n",
            "Iteration 835, loss = 1492906857.72513127\n",
            "Iteration 836, loss = 1492853004.21033740\n",
            "Iteration 837, loss = 1492799239.14801502\n",
            "Iteration 838, loss = 1492745896.64485383\n",
            "Iteration 839, loss = 1492692663.74570155\n",
            "Iteration 840, loss = 1492638756.54407263\n",
            "Iteration 841, loss = 1492585190.99512315\n",
            "Iteration 842, loss = 1492531772.22927594\n",
            "Iteration 843, loss = 1492478141.54293084\n",
            "Iteration 844, loss = 1492424794.57636309\n",
            "Iteration 845, loss = 1492370940.81871033\n",
            "Iteration 846, loss = 1492317427.32543564\n",
            "Iteration 847, loss = 1492264024.72522569\n",
            "Iteration 848, loss = 1492210525.34984875\n",
            "Iteration 849, loss = 1492157158.38038588\n",
            "Iteration 850, loss = 1492103514.43164325\n",
            "Iteration 851, loss = 1492050292.38696980\n",
            "Iteration 852, loss = 1491996501.29371357\n",
            "Iteration 853, loss = 1491943310.67042542\n",
            "Iteration 854, loss = 1491889743.07558036\n",
            "Iteration 855, loss = 1491836043.19857979\n",
            "Iteration 856, loss = 1491782625.89523506\n",
            "Iteration 857, loss = 1491729098.42414713\n",
            "Iteration 858, loss = 1491675733.14754224\n",
            "Iteration 859, loss = 1491622124.65756488\n",
            "Iteration 860, loss = 1491568835.50072742\n",
            "Iteration 861, loss = 1491515139.00472403\n",
            "Iteration 862, loss = 1491461913.13870835\n",
            "Iteration 863, loss = 1491408289.80584550\n",
            "Iteration 864, loss = 1491354880.87977076\n",
            "Iteration 865, loss = 1491300875.37784576\n",
            "Iteration 866, loss = 1491247466.47259927\n",
            "Iteration 867, loss = 1491193832.01486969\n",
            "Iteration 868, loss = 1491140133.38678169\n",
            "Iteration 869, loss = 1491086637.69787073\n",
            "Iteration 870, loss = 1491032646.93599725\n",
            "Iteration 871, loss = 1490979345.72646475\n",
            "Iteration 872, loss = 1490925817.98388481\n",
            "Iteration 873, loss = 1490872240.73883176\n",
            "Iteration 874, loss = 1490818542.84308314\n",
            "Iteration 875, loss = 1490764613.24969745\n",
            "Iteration 876, loss = 1490711399.34482098\n",
            "Iteration 877, loss = 1490657654.95875835\n",
            "Iteration 878, loss = 1490603865.24214745\n",
            "Iteration 879, loss = 1490550138.44206858\n",
            "Iteration 880, loss = 1490496585.05580139\n",
            "Iteration 881, loss = 1490442675.83141685\n",
            "Iteration 882, loss = 1490389397.99173999\n",
            "Iteration 883, loss = 1490335521.71486449\n",
            "Iteration 884, loss = 1490281614.96630716\n",
            "Iteration 885, loss = 1490228300.05522871\n",
            "Iteration 886, loss = 1490174323.08562970\n",
            "Iteration 887, loss = 1490120414.72572517\n",
            "Iteration 888, loss = 1490066876.89549804\n",
            "Iteration 889, loss = 1490012923.47397757\n",
            "Iteration 890, loss = 1489958906.93251204\n",
            "Iteration 891, loss = 1489905370.31224799\n",
            "Iteration 892, loss = 1489851360.45520020\n",
            "Iteration 893, loss = 1489797612.39526939\n",
            "Iteration 894, loss = 1489744023.78368068\n",
            "Iteration 895, loss = 1489690192.34924984\n",
            "Iteration 896, loss = 1489636442.27818561\n",
            "Iteration 897, loss = 1489582826.07727480\n",
            "Iteration 898, loss = 1489529289.44395328\n",
            "Iteration 899, loss = 1489475334.51387548\n",
            "Iteration 900, loss = 1489422010.21217036\n",
            "Iteration 901, loss = 1489368073.17684913\n",
            "Iteration 902, loss = 1489314356.04156303\n",
            "Iteration 903, loss = 1489260919.39742136\n",
            "Iteration 904, loss = 1489206705.82995319\n",
            "Iteration 905, loss = 1489153175.82873940\n",
            "Iteration 906, loss = 1489099260.65529537\n",
            "Iteration 907, loss = 1489045351.00527096\n",
            "Iteration 908, loss = 1488991758.39930081\n",
            "Iteration 909, loss = 1488937919.52506042\n",
            "Iteration 910, loss = 1488883886.38150001\n",
            "Iteration 911, loss = 1488830597.02518559\n",
            "Iteration 912, loss = 1488776858.44646478\n",
            "Iteration 913, loss = 1488723488.98890281\n",
            "Iteration 914, loss = 1488669887.92545390\n",
            "Iteration 915, loss = 1488616168.49253178\n",
            "Iteration 916, loss = 1488562765.19182420\n",
            "Iteration 917, loss = 1488509321.01903415\n",
            "Iteration 918, loss = 1488455553.51487732\n",
            "Iteration 919, loss = 1488402584.12690425\n",
            "Iteration 920, loss = 1488348906.13175702\n",
            "Iteration 921, loss = 1488295347.60387468\n",
            "Iteration 922, loss = 1488242614.61569834\n",
            "Iteration 923, loss = 1488189149.89661241\n",
            "Iteration 924, loss = 1488135903.58776188\n",
            "Iteration 925, loss = 1488082695.92904282\n",
            "Iteration 926, loss = 1488029096.17785907\n",
            "Iteration 927, loss = 1487976203.80811262\n",
            "Iteration 928, loss = 1487922685.15517759\n",
            "Iteration 929, loss = 1487869169.27697754\n",
            "Iteration 930, loss = 1487816102.46367955\n",
            "Iteration 931, loss = 1487762707.83947873\n",
            "Iteration 932, loss = 1487709470.12278485\n",
            "Iteration 933, loss = 1487656506.07826519\n",
            "Iteration 934, loss = 1487603142.78409910\n",
            "Iteration 935, loss = 1487549481.77601743\n",
            "Iteration 936, loss = 1487496393.74588418\n",
            "Iteration 937, loss = 1487442941.32638597\n",
            "Iteration 938, loss = 1487389123.76047373\n",
            "Iteration 939, loss = 1487335863.40171337\n",
            "Iteration 940, loss = 1487282316.03846550\n",
            "Iteration 941, loss = 1487228033.23882198\n",
            "Iteration 942, loss = 1487174718.23583531\n",
            "Iteration 943, loss = 1487121216.61927962\n",
            "Iteration 944, loss = 1487067431.84306502\n",
            "Iteration 945, loss = 1487013684.27824974\n",
            "Iteration 946, loss = 1486960432.59998631\n",
            "Iteration 947, loss = 1486907025.04122424\n",
            "Iteration 948, loss = 1486853517.40262556\n",
            "Iteration 949, loss = 1486800267.48728395\n",
            "Iteration 950, loss = 1486746773.18638206\n",
            "Iteration 951, loss = 1486693661.75091529\n",
            "Iteration 952, loss = 1486640140.51780200\n",
            "Iteration 953, loss = 1486587253.67973948\n",
            "Iteration 954, loss = 1486533718.37140012\n",
            "Iteration 955, loss = 1486481038.35234261\n",
            "Iteration 956, loss = 1486427287.33237767\n",
            "Iteration 957, loss = 1486374654.61749458\n",
            "Iteration 958, loss = 1486321533.83856535\n",
            "Iteration 959, loss = 1486268047.45100737\n",
            "Iteration 960, loss = 1486214844.39519286\n",
            "Iteration 961, loss = 1486162171.38808298\n",
            "Iteration 962, loss = 1486108881.15582275\n",
            "Iteration 963, loss = 1486055015.83149099\n",
            "Iteration 964, loss = 1486002138.58152390\n",
            "Iteration 965, loss = 1485948756.09529471\n",
            "Iteration 966, loss = 1485895336.24607253\n",
            "Iteration 967, loss = 1485841920.66349673\n",
            "Iteration 968, loss = 1485788597.65186429\n",
            "Iteration 969, loss = 1485734922.27110744\n",
            "Iteration 970, loss = 1485681832.94871688\n",
            "Iteration 971, loss = 1485628242.58978295\n",
            "Iteration 972, loss = 1485574952.75204945\n",
            "Iteration 973, loss = 1485521457.10322809\n",
            "Iteration 974, loss = 1485468304.21960258\n",
            "Iteration 975, loss = 1485414764.42090535\n",
            "Iteration 976, loss = 1485361351.74890590\n",
            "Iteration 977, loss = 1485308280.95689058\n",
            "Iteration 978, loss = 1485254928.21053576\n",
            "Iteration 979, loss = 1485201825.36979771\n",
            "Iteration 980, loss = 1485148491.87181926\n",
            "Iteration 981, loss = 1485095228.34241700\n",
            "Iteration 982, loss = 1485042068.03642082\n",
            "Iteration 983, loss = 1484988675.48441267\n",
            "Iteration 984, loss = 1484935501.64548707\n",
            "Iteration 985, loss = 1484882103.68707442\n",
            "Iteration 986, loss = 1484828372.75468755\n",
            "Iteration 987, loss = 1484775140.42226505\n",
            "Iteration 988, loss = 1484721533.96637011\n",
            "Iteration 989, loss = 1484667970.98242712\n",
            "Iteration 990, loss = 1484614717.76333475\n",
            "Iteration 991, loss = 1484561139.31220937\n",
            "Iteration 992, loss = 1484507580.66729689\n",
            "Iteration 993, loss = 1484454286.65742636\n",
            "Iteration 994, loss = 1484401105.93590140\n",
            "Iteration 995, loss = 1484347721.30715346\n",
            "Iteration 996, loss = 1484294516.95226884\n",
            "Iteration 997, loss = 1484241328.27529621\n",
            "Iteration 998, loss = 1484188090.65815187\n",
            "Iteration 999, loss = 1484134584.36781931\n",
            "Iteration 1000, loss = 1484081466.03385210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1530514591.61071920\n",
            "Iteration 2, loss = 1422326541.95389652\n",
            "Iteration 3, loss = 503961894.92939472\n",
            "Iteration 4, loss = 267077597.23965716\n",
            "Iteration 5, loss = 192960272.38749260\n",
            "Iteration 6, loss = 183769999.69464535\n",
            "Iteration 7, loss = 195307168.82651824\n",
            "Iteration 8, loss = 221320408.93554631\n",
            "Iteration 9, loss = 241714590.18320960\n",
            "Iteration 10, loss = 253079059.54351079\n",
            "Iteration 11, loss = 261354710.00382161\n",
            "Iteration 12, loss = 270858443.21944672\n",
            "Iteration 13, loss = 282878999.01058191\n",
            "Iteration 14, loss = 295228541.23523891\n",
            "Iteration 15, loss = 306386803.92956287\n",
            "Iteration 16, loss = 315316483.85149848\n",
            "Iteration 17, loss = 321698463.99785882\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538828343.50377131\n",
            "Iteration 2, loss = 1538687942.01962304\n",
            "Iteration 3, loss = 1538563215.45882440\n",
            "Iteration 4, loss = 1538453309.28599477\n",
            "Iteration 5, loss = 1538332962.23698711\n",
            "Iteration 6, loss = 1538219092.57611609\n",
            "Iteration 7, loss = 1538135653.35516858\n",
            "Iteration 8, loss = 1538063114.83454967\n",
            "Iteration 9, loss = 1537993234.81776357\n",
            "Iteration 10, loss = 1537927670.89830446\n",
            "Iteration 11, loss = 1537865558.88288617\n",
            "Iteration 12, loss = 1537803852.70638418\n",
            "Iteration 13, loss = 1537742571.02830291\n",
            "Iteration 14, loss = 1537682450.15104914\n",
            "Iteration 15, loss = 1537621132.46027207\n",
            "Iteration 16, loss = 1537560437.80929685\n",
            "Iteration 17, loss = 1537500258.36902738\n",
            "Iteration 18, loss = 1537439621.81715226\n",
            "Iteration 19, loss = 1537379615.29001212\n",
            "Iteration 20, loss = 1537319603.40282631\n",
            "Iteration 21, loss = 1537259384.69967580\n",
            "Iteration 22, loss = 1537200382.86606598\n",
            "Iteration 23, loss = 1537140315.87726212\n",
            "Iteration 24, loss = 1537081383.54621911\n",
            "Iteration 25, loss = 1537022398.67003679\n",
            "Iteration 26, loss = 1536963530.49110818\n",
            "Iteration 27, loss = 1536904322.57841444\n",
            "Iteration 28, loss = 1536845988.44939303\n",
            "Iteration 29, loss = 1536787560.53368855\n",
            "Iteration 30, loss = 1536729076.62987304\n",
            "Iteration 31, loss = 1536670884.12640023\n",
            "Iteration 32, loss = 1536612813.06925821\n",
            "Iteration 33, loss = 1536554874.26709008\n",
            "Iteration 34, loss = 1536496737.39635229\n",
            "Iteration 35, loss = 1536439146.13719153\n",
            "Iteration 36, loss = 1536381629.19606233\n",
            "Iteration 37, loss = 1536323789.66566348\n",
            "Iteration 38, loss = 1536266233.52580309\n",
            "Iteration 39, loss = 1536208790.59180021\n",
            "Iteration 40, loss = 1536151416.74478793\n",
            "Iteration 41, loss = 1536094426.82989383\n",
            "Iteration 42, loss = 1536037135.25632358\n",
            "Iteration 43, loss = 1535980133.16874790\n",
            "Iteration 44, loss = 1535923479.09925985\n",
            "Iteration 45, loss = 1535866706.43965244\n",
            "Iteration 46, loss = 1535810050.72932434\n",
            "Iteration 47, loss = 1535753494.10224390\n",
            "Iteration 48, loss = 1535696503.66866016\n",
            "Iteration 49, loss = 1535640268.49055886\n",
            "Iteration 50, loss = 1535583400.18492961\n",
            "Iteration 51, loss = 1535526638.92084241\n",
            "Iteration 52, loss = 1535469908.26757002\n",
            "Iteration 53, loss = 1535413420.72874999\n",
            "Iteration 54, loss = 1535357067.45131755\n",
            "Iteration 55, loss = 1535300302.98943210\n",
            "Iteration 56, loss = 1535244421.37866926\n",
            "Iteration 57, loss = 1535187675.76953959\n",
            "Iteration 58, loss = 1535131811.19853187\n",
            "Iteration 59, loss = 1535075470.44266272\n",
            "Iteration 60, loss = 1535019578.85278463\n",
            "Iteration 61, loss = 1534963492.92870927\n",
            "Iteration 62, loss = 1534907516.61785960\n",
            "Iteration 63, loss = 1534851438.36197352\n",
            "Iteration 64, loss = 1534795578.97059202\n",
            "Iteration 65, loss = 1534739485.25680375\n",
            "Iteration 66, loss = 1534683787.02151942\n",
            "Iteration 67, loss = 1534627265.36180019\n",
            "Iteration 68, loss = 1534571280.13066840\n",
            "Iteration 69, loss = 1534515539.67140961\n",
            "Iteration 70, loss = 1534459067.45923138\n",
            "Iteration 71, loss = 1534403002.87022233\n",
            "Iteration 72, loss = 1534346836.33964729\n",
            "Iteration 73, loss = 1534290939.69147038\n",
            "Iteration 74, loss = 1534234992.88162923\n",
            "Iteration 75, loss = 1534178988.35386395\n",
            "Iteration 76, loss = 1534122843.30533719\n",
            "Iteration 77, loss = 1534067385.46912050\n",
            "Iteration 78, loss = 1534011268.98946404\n",
            "Iteration 79, loss = 1533955523.07058334\n",
            "Iteration 80, loss = 1533899610.23578072\n",
            "Iteration 81, loss = 1533843671.22762299\n",
            "Iteration 82, loss = 1533787779.41964531\n",
            "Iteration 83, loss = 1533731934.92861223\n",
            "Iteration 84, loss = 1533676003.56521869\n",
            "Iteration 85, loss = 1533620403.38559914\n",
            "Iteration 86, loss = 1533564522.52436018\n",
            "Iteration 87, loss = 1533508992.22048855\n",
            "Iteration 88, loss = 1533453161.70432758\n",
            "Iteration 89, loss = 1533397826.92860532\n",
            "Iteration 90, loss = 1533341817.89210629\n",
            "Iteration 91, loss = 1533286394.86496115\n",
            "Iteration 92, loss = 1533230590.81269336\n",
            "Iteration 93, loss = 1533175346.09151030\n",
            "Iteration 94, loss = 1533119284.88730049\n",
            "Iteration 95, loss = 1533063768.07600784\n",
            "Iteration 96, loss = 1533008424.44499826\n",
            "Iteration 97, loss = 1532952438.00452352\n",
            "Iteration 98, loss = 1532897207.07107925\n",
            "Iteration 99, loss = 1532841114.42947268\n",
            "Iteration 100, loss = 1532785801.93974209\n",
            "Iteration 101, loss = 1532729853.21552896\n",
            "Iteration 102, loss = 1532674195.24250364\n",
            "Iteration 103, loss = 1532618354.22549653\n",
            "Iteration 104, loss = 1532562590.10582185\n",
            "Iteration 105, loss = 1532506917.92213655\n",
            "Iteration 106, loss = 1532451012.38136005\n",
            "Iteration 107, loss = 1532395459.40881181\n",
            "Iteration 108, loss = 1532339479.76742601\n",
            "Iteration 109, loss = 1532283811.29917431\n",
            "Iteration 110, loss = 1532228302.73472786\n",
            "Iteration 111, loss = 1532172331.75387216\n",
            "Iteration 112, loss = 1532116896.70626664\n",
            "Iteration 113, loss = 1532061187.93150496\n",
            "Iteration 114, loss = 1532005655.99049139\n",
            "Iteration 115, loss = 1531950114.99252629\n",
            "Iteration 116, loss = 1531894394.74647570\n",
            "Iteration 117, loss = 1531838691.38350415\n",
            "Iteration 118, loss = 1531783410.10723162\n",
            "Iteration 119, loss = 1531727851.97031164\n",
            "Iteration 120, loss = 1531672121.39611483\n",
            "Iteration 121, loss = 1531616465.12821031\n",
            "Iteration 122, loss = 1531561317.88010120\n",
            "Iteration 123, loss = 1531505842.95994067\n",
            "Iteration 124, loss = 1531450091.78816986\n",
            "Iteration 125, loss = 1531395029.34542346\n",
            "Iteration 126, loss = 1531339626.56213665\n",
            "Iteration 127, loss = 1531283983.54363632\n",
            "Iteration 128, loss = 1531228623.85701156\n",
            "Iteration 129, loss = 1531173676.66739035\n",
            "Iteration 130, loss = 1531118146.49560356\n",
            "Iteration 131, loss = 1531062613.47093678\n",
            "Iteration 132, loss = 1531007293.53415442\n",
            "Iteration 133, loss = 1530952079.55670738\n",
            "Iteration 134, loss = 1530896560.74909806\n",
            "Iteration 135, loss = 1530841696.19102097\n",
            "Iteration 136, loss = 1530786301.20562530\n",
            "Iteration 137, loss = 1530731110.21127224\n",
            "Iteration 138, loss = 1530675890.17885566\n",
            "Iteration 139, loss = 1530620434.08202195\n",
            "Iteration 140, loss = 1530565508.47098517\n",
            "Iteration 141, loss = 1530510169.44283295\n",
            "Iteration 142, loss = 1530454652.54550934\n",
            "Iteration 143, loss = 1530399648.26309800\n",
            "Iteration 144, loss = 1530344121.44368339\n",
            "Iteration 145, loss = 1530289031.18779731\n",
            "Iteration 146, loss = 1530234031.60163498\n",
            "Iteration 147, loss = 1530178606.50549245\n",
            "Iteration 148, loss = 1530123649.73982692\n",
            "Iteration 149, loss = 1530068769.01793385\n",
            "Iteration 150, loss = 1530013944.42957997\n",
            "Iteration 151, loss = 1529958634.79072118\n",
            "Iteration 152, loss = 1529903708.25615644\n",
            "Iteration 153, loss = 1529848837.05522823\n",
            "Iteration 154, loss = 1529793680.07648849\n",
            "Iteration 155, loss = 1529738810.70104408\n",
            "Iteration 156, loss = 1529683900.98356247\n",
            "Iteration 157, loss = 1529628882.33868480\n",
            "Iteration 158, loss = 1529574045.26100039\n",
            "Iteration 159, loss = 1529518872.03123999\n",
            "Iteration 160, loss = 1529464135.54732871\n",
            "Iteration 161, loss = 1529409173.00888920\n",
            "Iteration 162, loss = 1529354038.22082043\n",
            "Iteration 163, loss = 1529299016.73968720\n",
            "Iteration 164, loss = 1529243966.44699717\n",
            "Iteration 165, loss = 1529189040.39657831\n",
            "Iteration 166, loss = 1529133697.94958758\n",
            "Iteration 167, loss = 1529078825.94039941\n",
            "Iteration 168, loss = 1529023800.23051262\n",
            "Iteration 169, loss = 1528968915.86563993\n",
            "Iteration 170, loss = 1528914159.11508560\n",
            "Iteration 171, loss = 1528859032.28185225\n",
            "Iteration 172, loss = 1528804298.40009499\n",
            "Iteration 173, loss = 1528749060.27482367\n",
            "Iteration 174, loss = 1528694432.68517804\n",
            "Iteration 175, loss = 1528639398.39184451\n",
            "Iteration 176, loss = 1528584593.01430416\n",
            "Iteration 177, loss = 1528528998.41885281\n",
            "Iteration 178, loss = 1528474126.66898966\n",
            "Iteration 179, loss = 1528419296.90023661\n",
            "Iteration 180, loss = 1528364014.64282417\n",
            "Iteration 181, loss = 1528309016.11783552\n",
            "Iteration 182, loss = 1528254024.50387216\n",
            "Iteration 183, loss = 1528198916.37575293\n",
            "Iteration 184, loss = 1528144106.00428629\n",
            "Iteration 185, loss = 1528089254.40834880\n",
            "Iteration 186, loss = 1528033943.81481290\n",
            "Iteration 187, loss = 1527979178.70544600\n",
            "Iteration 188, loss = 1527924081.94195175\n",
            "Iteration 189, loss = 1527868940.14931297\n",
            "Iteration 190, loss = 1527814084.93025255\n",
            "Iteration 191, loss = 1527758837.64483929\n",
            "Iteration 192, loss = 1527703967.63102531\n",
            "Iteration 193, loss = 1527648873.97916031\n",
            "Iteration 194, loss = 1527593772.52839494\n",
            "Iteration 195, loss = 1527539288.74478197\n",
            "Iteration 196, loss = 1527484371.41360974\n",
            "Iteration 197, loss = 1527429439.37802410\n",
            "Iteration 198, loss = 1527374550.51430798\n",
            "Iteration 199, loss = 1527320376.95098233\n",
            "Iteration 200, loss = 1527265449.89671564\n",
            "Iteration 201, loss = 1527210651.85238051\n",
            "Iteration 202, loss = 1527155969.89782286\n",
            "Iteration 203, loss = 1527101275.81314111\n",
            "Iteration 204, loss = 1527046261.36035466\n",
            "Iteration 205, loss = 1526991774.99866009\n",
            "Iteration 206, loss = 1526936075.74290371\n",
            "Iteration 207, loss = 1526881530.14136696\n",
            "Iteration 208, loss = 1526826537.05883646\n",
            "Iteration 209, loss = 1526771290.69115829\n",
            "Iteration 210, loss = 1526716307.53284073\n",
            "Iteration 211, loss = 1526661101.28745604\n",
            "Iteration 212, loss = 1526606335.03711128\n",
            "Iteration 213, loss = 1526551298.35082221\n",
            "Iteration 214, loss = 1526496489.88707709\n",
            "Iteration 215, loss = 1526441344.24212122\n",
            "Iteration 216, loss = 1526386626.17303205\n",
            "Iteration 217, loss = 1526332032.01739049\n",
            "Iteration 218, loss = 1526277157.25203681\n",
            "Iteration 219, loss = 1526222545.22608280\n",
            "Iteration 220, loss = 1526167792.56835365\n",
            "Iteration 221, loss = 1526113478.02251935\n",
            "Iteration 222, loss = 1526058751.96938300\n",
            "Iteration 223, loss = 1526004628.31199622\n",
            "Iteration 224, loss = 1525950208.05360389\n",
            "Iteration 225, loss = 1525896170.73160243\n",
            "Iteration 226, loss = 1525841446.46000814\n",
            "Iteration 227, loss = 1525787487.56069565\n",
            "Iteration 228, loss = 1525733025.86699748\n",
            "Iteration 229, loss = 1525679071.14440608\n",
            "Iteration 230, loss = 1525624807.79494667\n",
            "Iteration 231, loss = 1525569760.46376801\n",
            "Iteration 232, loss = 1525515787.88608742\n",
            "Iteration 233, loss = 1525461172.74708009\n",
            "Iteration 234, loss = 1525406572.51126552\n",
            "Iteration 235, loss = 1525351667.66021228\n",
            "Iteration 236, loss = 1525296922.60336399\n",
            "Iteration 237, loss = 1525242453.87434387\n",
            "Iteration 238, loss = 1525187242.97077632\n",
            "Iteration 239, loss = 1525132582.65245843\n",
            "Iteration 240, loss = 1525077859.00587654\n",
            "Iteration 241, loss = 1525023138.55227876\n",
            "Iteration 242, loss = 1524968385.75379205\n",
            "Iteration 243, loss = 1524913888.47141218\n",
            "Iteration 244, loss = 1524858761.58371425\n",
            "Iteration 245, loss = 1524804228.87526798\n",
            "Iteration 246, loss = 1524749897.71742773\n",
            "Iteration 247, loss = 1524695008.54726648\n",
            "Iteration 248, loss = 1524640017.54108715\n",
            "Iteration 249, loss = 1524585943.72192144\n",
            "Iteration 250, loss = 1524531000.68069029\n",
            "Iteration 251, loss = 1524476410.19259739\n",
            "Iteration 252, loss = 1524421842.21125436\n",
            "Iteration 253, loss = 1524367055.06885028\n",
            "Iteration 254, loss = 1524312187.18433809\n",
            "Iteration 255, loss = 1524257780.48152256\n",
            "Iteration 256, loss = 1524203049.21535468\n",
            "Iteration 257, loss = 1524148280.49789858\n",
            "Iteration 258, loss = 1524094048.98024583\n",
            "Iteration 259, loss = 1524039221.02303195\n",
            "Iteration 260, loss = 1523984663.24711204\n",
            "Iteration 261, loss = 1523930193.01755857\n",
            "Iteration 262, loss = 1523875716.31753111\n",
            "Iteration 263, loss = 1523820840.76670909\n",
            "Iteration 264, loss = 1523766465.74511170\n",
            "Iteration 265, loss = 1523711971.64820123\n",
            "Iteration 266, loss = 1523657260.17640948\n",
            "Iteration 267, loss = 1523602761.10712075\n",
            "Iteration 268, loss = 1523548167.21056628\n",
            "Iteration 269, loss = 1523493756.34247494\n",
            "Iteration 270, loss = 1523439145.74938536\n",
            "Iteration 271, loss = 1523384484.50212646\n",
            "Iteration 272, loss = 1523329638.36368060\n",
            "Iteration 273, loss = 1523275156.30352950\n",
            "Iteration 274, loss = 1523219852.72655964\n",
            "Iteration 275, loss = 1523165183.10422468\n",
            "Iteration 276, loss = 1523110394.73780990\n",
            "Iteration 277, loss = 1523055612.90543723\n",
            "Iteration 278, loss = 1523000818.54384685\n",
            "Iteration 279, loss = 1522946351.08932924\n",
            "Iteration 280, loss = 1522892004.20588684\n",
            "Iteration 281, loss = 1522837481.05343270\n",
            "Iteration 282, loss = 1522782775.02069998\n",
            "Iteration 283, loss = 1522728611.04407644\n",
            "Iteration 284, loss = 1522673751.58567452\n",
            "Iteration 285, loss = 1522619044.21672201\n",
            "Iteration 286, loss = 1522564551.62622762\n",
            "Iteration 287, loss = 1522509467.59116364\n",
            "Iteration 288, loss = 1522454610.53455329\n",
            "Iteration 289, loss = 1522400054.42643666\n",
            "Iteration 290, loss = 1522345128.07198310\n",
            "Iteration 291, loss = 1522290427.78708887\n",
            "Iteration 292, loss = 1522235397.55021667\n",
            "Iteration 293, loss = 1522180914.89178753\n",
            "Iteration 294, loss = 1522126091.17979074\n",
            "Iteration 295, loss = 1522071277.31401515\n",
            "Iteration 296, loss = 1522016679.97942686\n",
            "Iteration 297, loss = 1521961514.71203089\n",
            "Iteration 298, loss = 1521907188.95528722\n",
            "Iteration 299, loss = 1521852540.62838888\n",
            "Iteration 300, loss = 1521797550.42342806\n",
            "Iteration 301, loss = 1521743183.66508484\n",
            "Iteration 302, loss = 1521688588.85700130\n",
            "Iteration 303, loss = 1521633699.16377783\n",
            "Iteration 304, loss = 1521579009.90071988\n",
            "Iteration 305, loss = 1521524782.52166510\n",
            "Iteration 306, loss = 1521470035.49241662\n",
            "Iteration 307, loss = 1521415487.02694607\n",
            "Iteration 308, loss = 1521360817.00151753\n",
            "Iteration 309, loss = 1521306230.08442426\n",
            "Iteration 310, loss = 1521251598.84844041\n",
            "Iteration 311, loss = 1521196645.38687181\n",
            "Iteration 312, loss = 1521142315.85388708\n",
            "Iteration 313, loss = 1521087201.67624521\n",
            "Iteration 314, loss = 1521032703.19695091\n",
            "Iteration 315, loss = 1520977841.04591966\n",
            "Iteration 316, loss = 1520922691.96989965\n",
            "Iteration 317, loss = 1520868654.20272279\n",
            "Iteration 318, loss = 1520813552.78397393\n",
            "Iteration 319, loss = 1520759162.98024797\n",
            "Iteration 320, loss = 1520704656.63084722\n",
            "Iteration 321, loss = 1520650154.22196436\n",
            "Iteration 322, loss = 1520595797.29405475\n",
            "Iteration 323, loss = 1520541621.07499075\n",
            "Iteration 324, loss = 1520486999.06678295\n",
            "Iteration 325, loss = 1520432832.50808477\n",
            "Iteration 326, loss = 1520378280.67721343\n",
            "Iteration 327, loss = 1520324078.10237861\n",
            "Iteration 328, loss = 1520269693.24247527\n",
            "Iteration 329, loss = 1520215130.95622921\n",
            "Iteration 330, loss = 1520160539.56300163\n",
            "Iteration 331, loss = 1520106008.00042820\n",
            "Iteration 332, loss = 1520051851.23025060\n",
            "Iteration 333, loss = 1519997437.95830894\n",
            "Iteration 334, loss = 1519942527.47589231\n",
            "Iteration 335, loss = 1519888276.39140177\n",
            "Iteration 336, loss = 1519834116.67489910\n",
            "Iteration 337, loss = 1519779158.72029567\n",
            "Iteration 338, loss = 1519724837.11770463\n",
            "Iteration 339, loss = 1519670489.15855384\n",
            "Iteration 340, loss = 1519615885.02653503\n",
            "Iteration 341, loss = 1519561784.49847984\n",
            "Iteration 342, loss = 1519506825.36364841\n",
            "Iteration 343, loss = 1519452448.06633496\n",
            "Iteration 344, loss = 1519397923.19455099\n",
            "Iteration 345, loss = 1519343544.08727360\n",
            "Iteration 346, loss = 1519288594.63191152\n",
            "Iteration 347, loss = 1519234211.47446012\n",
            "Iteration 348, loss = 1519179630.64001703\n",
            "Iteration 349, loss = 1519124834.28105354\n",
            "Iteration 350, loss = 1519070474.53433895\n",
            "Iteration 351, loss = 1519015850.99080276\n",
            "Iteration 352, loss = 1518961095.86044621\n",
            "Iteration 353, loss = 1518906526.27082610\n",
            "Iteration 354, loss = 1518852537.83546615\n",
            "Iteration 355, loss = 1518797334.48631048\n",
            "Iteration 356, loss = 1518743037.96283340\n",
            "Iteration 357, loss = 1518688564.58798051\n",
            "Iteration 358, loss = 1518634056.56158113\n",
            "Iteration 359, loss = 1518579433.11688161\n",
            "Iteration 360, loss = 1518524697.91430092\n",
            "Iteration 361, loss = 1518470348.30148411\n",
            "Iteration 362, loss = 1518415029.13231540\n",
            "Iteration 363, loss = 1518360500.18786144\n",
            "Iteration 364, loss = 1518305721.97686362\n",
            "Iteration 365, loss = 1518250818.29457521\n",
            "Iteration 366, loss = 1518196052.10856104\n",
            "Iteration 367, loss = 1518141036.45020556\n",
            "Iteration 368, loss = 1518086541.39458227\n",
            "Iteration 369, loss = 1518031574.77634978\n",
            "Iteration 370, loss = 1517977162.69410706\n",
            "Iteration 371, loss = 1517922612.17037344\n",
            "Iteration 372, loss = 1517868143.00399160\n",
            "Iteration 373, loss = 1517813686.75803518\n",
            "Iteration 374, loss = 1517759367.18793917\n",
            "Iteration 375, loss = 1517705065.14553428\n",
            "Iteration 376, loss = 1517650648.06265759\n",
            "Iteration 377, loss = 1517596478.67045093\n",
            "Iteration 378, loss = 1517541859.45608473\n",
            "Iteration 379, loss = 1517487250.54516673\n",
            "Iteration 380, loss = 1517433052.09633136\n",
            "Iteration 381, loss = 1517378042.39261413\n",
            "Iteration 382, loss = 1517323776.12917590\n",
            "Iteration 383, loss = 1517268904.44597006\n",
            "Iteration 384, loss = 1517214826.58123994\n",
            "Iteration 385, loss = 1517159954.16267800\n",
            "Iteration 386, loss = 1517105408.29545307\n",
            "Iteration 387, loss = 1517051102.04228306\n",
            "Iteration 388, loss = 1516996819.11759567\n",
            "Iteration 389, loss = 1516941900.36764765\n",
            "Iteration 390, loss = 1516887561.22120643\n",
            "Iteration 391, loss = 1516832977.27321076\n",
            "Iteration 392, loss = 1516778632.48633862\n",
            "Iteration 393, loss = 1516724446.21163487\n",
            "Iteration 394, loss = 1516669608.57933259\n",
            "Iteration 395, loss = 1516616196.15818858\n",
            "Iteration 396, loss = 1516561447.66872048\n",
            "Iteration 397, loss = 1516507917.01824355\n",
            "Iteration 398, loss = 1516453309.11735034\n",
            "Iteration 399, loss = 1516399901.90829134\n",
            "Iteration 400, loss = 1516345542.94971752\n",
            "Iteration 401, loss = 1516291443.39115381\n",
            "Iteration 402, loss = 1516237696.51579714\n",
            "Iteration 403, loss = 1516183608.11982679\n",
            "Iteration 404, loss = 1516129082.58584309\n",
            "Iteration 405, loss = 1516074972.56122231\n",
            "Iteration 406, loss = 1516020697.36291265\n",
            "Iteration 407, loss = 1515966435.80190659\n",
            "Iteration 408, loss = 1515912189.20732832\n",
            "Iteration 409, loss = 1515857598.26330566\n",
            "Iteration 410, loss = 1515803394.53723955\n",
            "Iteration 411, loss = 1515749453.66798759\n",
            "Iteration 412, loss = 1515695042.59130096\n",
            "Iteration 413, loss = 1515641068.63616276\n",
            "Iteration 414, loss = 1515586930.57768464\n",
            "Iteration 415, loss = 1515532977.13431549\n",
            "Iteration 416, loss = 1515478671.16387033\n",
            "Iteration 417, loss = 1515424939.14687157\n",
            "Iteration 418, loss = 1515370456.44339800\n",
            "Iteration 419, loss = 1515316353.69472575\n",
            "Iteration 420, loss = 1515261976.54860115\n",
            "Iteration 421, loss = 1515207825.75867462\n",
            "Iteration 422, loss = 1515153328.96467781\n",
            "Iteration 423, loss = 1515098582.43128753\n",
            "Iteration 424, loss = 1515044468.65545917\n",
            "Iteration 425, loss = 1514990027.07747912\n",
            "Iteration 426, loss = 1514935697.20948529\n",
            "Iteration 427, loss = 1514881374.62478924\n",
            "Iteration 428, loss = 1514826989.49539018\n",
            "Iteration 429, loss = 1514772918.83259726\n",
            "Iteration 430, loss = 1514718529.33749795\n",
            "Iteration 431, loss = 1514664223.74759316\n",
            "Iteration 432, loss = 1514610138.05929494\n",
            "Iteration 433, loss = 1514555545.51387548\n",
            "Iteration 434, loss = 1514501407.61812949\n",
            "Iteration 435, loss = 1514447126.02603555\n",
            "Iteration 436, loss = 1514392879.90363884\n",
            "Iteration 437, loss = 1514338658.26949191\n",
            "Iteration 438, loss = 1514284172.02780509\n",
            "Iteration 439, loss = 1514229729.49359155\n",
            "Iteration 440, loss = 1514175629.56313014\n",
            "Iteration 441, loss = 1514121362.45546818\n",
            "Iteration 442, loss = 1514066453.00468206\n",
            "Iteration 443, loss = 1514011849.39991593\n",
            "Iteration 444, loss = 1513957461.68184757\n",
            "Iteration 445, loss = 1513902902.58800149\n",
            "Iteration 446, loss = 1513847971.96198988\n",
            "Iteration 447, loss = 1513793307.28404713\n",
            "Iteration 448, loss = 1513738863.10783029\n",
            "Iteration 449, loss = 1513684090.62862730\n",
            "Iteration 450, loss = 1513629889.80654097\n",
            "Iteration 451, loss = 1513575354.95977592\n",
            "Iteration 452, loss = 1513521191.12177706\n",
            "Iteration 453, loss = 1513467233.30887008\n",
            "Iteration 454, loss = 1513413005.33069491\n",
            "Iteration 455, loss = 1513359186.20758510\n",
            "Iteration 456, loss = 1513305064.27447271\n",
            "Iteration 457, loss = 1513251137.46347857\n",
            "Iteration 458, loss = 1513196910.66937280\n",
            "Iteration 459, loss = 1513143236.56036234\n",
            "Iteration 460, loss = 1513088535.88740230\n",
            "Iteration 461, loss = 1513034483.63381672\n",
            "Iteration 462, loss = 1512980086.13922668\n",
            "Iteration 463, loss = 1512925769.52949286\n",
            "Iteration 464, loss = 1512871667.26588655\n",
            "Iteration 465, loss = 1512817603.44592094\n",
            "Iteration 466, loss = 1512763087.74855804\n",
            "Iteration 467, loss = 1512709169.78180218\n",
            "Iteration 468, loss = 1512655339.29323196\n",
            "Iteration 469, loss = 1512601360.57679939\n",
            "Iteration 470, loss = 1512547270.52748609\n",
            "Iteration 471, loss = 1512493577.61791563\n",
            "Iteration 472, loss = 1512439463.37945151\n",
            "Iteration 473, loss = 1512385563.30507231\n",
            "Iteration 474, loss = 1512331765.17985511\n",
            "Iteration 475, loss = 1512277678.47982097\n",
            "Iteration 476, loss = 1512224018.51638198\n",
            "Iteration 477, loss = 1512169935.57922173\n",
            "Iteration 478, loss = 1512116077.19248152\n",
            "Iteration 479, loss = 1512062326.63696647\n",
            "Iteration 480, loss = 1512008862.21183109\n",
            "Iteration 481, loss = 1511954497.01873016\n",
            "Iteration 482, loss = 1511900828.32759833\n",
            "Iteration 483, loss = 1511847057.03152823\n",
            "Iteration 484, loss = 1511793167.07561445\n",
            "Iteration 485, loss = 1511739107.03477931\n",
            "Iteration 486, loss = 1511685317.86044145\n",
            "Iteration 487, loss = 1511631425.53758121\n",
            "Iteration 488, loss = 1511577302.60631919\n",
            "Iteration 489, loss = 1511523412.33624578\n",
            "Iteration 490, loss = 1511469319.28435683\n",
            "Iteration 491, loss = 1511415232.13715625\n",
            "Iteration 492, loss = 1511361141.68147564\n",
            "Iteration 493, loss = 1511306965.92398190\n",
            "Iteration 494, loss = 1511252529.29189706\n",
            "Iteration 495, loss = 1511198503.94733644\n",
            "Iteration 496, loss = 1511143931.60194278\n",
            "Iteration 497, loss = 1511089801.17023611\n",
            "Iteration 498, loss = 1511035570.20539379\n",
            "Iteration 499, loss = 1510980973.82614946\n",
            "Iteration 500, loss = 1510927041.22775388\n",
            "Iteration 501, loss = 1510872858.83872271\n",
            "Iteration 502, loss = 1510818880.99540782\n",
            "Iteration 503, loss = 1510764600.73418403\n",
            "Iteration 504, loss = 1510710800.67812109\n",
            "Iteration 505, loss = 1510656593.81214690\n",
            "Iteration 506, loss = 1510602591.99242425\n",
            "Iteration 507, loss = 1510548349.59554958\n",
            "Iteration 508, loss = 1510494555.05380750\n",
            "Iteration 509, loss = 1510440081.37035394\n",
            "Iteration 510, loss = 1510386008.70376730\n",
            "Iteration 511, loss = 1510331712.65256381\n",
            "Iteration 512, loss = 1510277448.06762195\n",
            "Iteration 513, loss = 1510223530.29785109\n",
            "Iteration 514, loss = 1510168830.13169360\n",
            "Iteration 515, loss = 1510114673.90671587\n",
            "Iteration 516, loss = 1510060877.76477385\n",
            "Iteration 517, loss = 1510006045.70586491\n",
            "Iteration 518, loss = 1509952130.82809281\n",
            "Iteration 519, loss = 1509897581.56667089\n",
            "Iteration 520, loss = 1509843762.30254149\n",
            "Iteration 521, loss = 1509789298.41106319\n",
            "Iteration 522, loss = 1509734956.42712712\n",
            "Iteration 523, loss = 1509680673.67614985\n",
            "Iteration 524, loss = 1509626597.41056609\n",
            "Iteration 525, loss = 1509572522.81332254\n",
            "Iteration 526, loss = 1509518223.41120672\n",
            "Iteration 527, loss = 1509463663.97671032\n",
            "Iteration 528, loss = 1509410098.95799279\n",
            "Iteration 529, loss = 1509355905.63453054\n",
            "Iteration 530, loss = 1509302033.81407428\n",
            "Iteration 531, loss = 1509247896.15655088\n",
            "Iteration 532, loss = 1509194035.03989840\n",
            "Iteration 533, loss = 1509139730.20098901\n",
            "Iteration 534, loss = 1509085828.90551615\n",
            "Iteration 535, loss = 1509032078.34485412\n",
            "Iteration 536, loss = 1508977520.82677412\n",
            "Iteration 537, loss = 1508923592.60698032\n",
            "Iteration 538, loss = 1508869486.13582587\n",
            "Iteration 539, loss = 1508815309.31214762\n",
            "Iteration 540, loss = 1508760599.85141683\n",
            "Iteration 541, loss = 1508706594.46130514\n",
            "Iteration 542, loss = 1508652080.08253169\n",
            "Iteration 543, loss = 1508597550.99425554\n",
            "Iteration 544, loss = 1508542721.71371603\n",
            "Iteration 545, loss = 1508488596.08747625\n",
            "Iteration 546, loss = 1508434092.60256481\n",
            "Iteration 547, loss = 1508379867.12683082\n",
            "Iteration 548, loss = 1508325462.14295697\n",
            "Iteration 549, loss = 1508271204.22766042\n",
            "Iteration 550, loss = 1508216934.89593530\n",
            "Iteration 551, loss = 1508162918.97490907\n",
            "Iteration 552, loss = 1508108637.31187892\n",
            "Iteration 553, loss = 1508054065.93547010\n",
            "Iteration 554, loss = 1507999984.16948795\n",
            "Iteration 555, loss = 1507945431.59552908\n",
            "Iteration 556, loss = 1507891099.82316065\n",
            "Iteration 557, loss = 1507837091.39108038\n",
            "Iteration 558, loss = 1507782318.34628916\n",
            "Iteration 559, loss = 1507727701.55844569\n",
            "Iteration 560, loss = 1507674086.79762530\n",
            "Iteration 561, loss = 1507619133.05618930\n",
            "Iteration 562, loss = 1507565265.85780072\n",
            "Iteration 563, loss = 1507510802.59604812\n",
            "Iteration 564, loss = 1507456784.22363162\n",
            "Iteration 565, loss = 1507402302.08594680\n",
            "Iteration 566, loss = 1507348500.01114011\n",
            "Iteration 567, loss = 1507293866.02353764\n",
            "Iteration 568, loss = 1507239873.42587161\n",
            "Iteration 569, loss = 1507185620.57169914\n",
            "Iteration 570, loss = 1507131233.45890355\n",
            "Iteration 571, loss = 1507077029.46947479\n",
            "Iteration 572, loss = 1507022831.55370665\n",
            "Iteration 573, loss = 1506968475.40093946\n",
            "Iteration 574, loss = 1506914437.77062464\n",
            "Iteration 575, loss = 1506860070.47478962\n",
            "Iteration 576, loss = 1506806048.26862550\n",
            "Iteration 577, loss = 1506751829.92365837\n",
            "Iteration 578, loss = 1506697419.03394461\n",
            "Iteration 579, loss = 1506643124.83105087\n",
            "Iteration 580, loss = 1506589019.78768611\n",
            "Iteration 581, loss = 1506534714.84699535\n",
            "Iteration 582, loss = 1506480718.85215259\n",
            "Iteration 583, loss = 1506426484.93971872\n",
            "Iteration 584, loss = 1506372298.76362729\n",
            "Iteration 585, loss = 1506318357.10192084\n",
            "Iteration 586, loss = 1506264056.54273510\n",
            "Iteration 587, loss = 1506210024.42059755\n",
            "Iteration 588, loss = 1506156128.92919755\n",
            "Iteration 589, loss = 1506101972.58476114\n",
            "Iteration 590, loss = 1506048024.21240520\n",
            "Iteration 591, loss = 1505993932.47334290\n",
            "Iteration 592, loss = 1505939976.59327602\n",
            "Iteration 593, loss = 1505886028.64807224\n",
            "Iteration 594, loss = 1505831969.85340357\n",
            "Iteration 595, loss = 1505778282.16628981\n",
            "Iteration 596, loss = 1505724175.84113908\n",
            "Iteration 597, loss = 1505670688.35582638\n",
            "Iteration 598, loss = 1505616610.84703875\n",
            "Iteration 599, loss = 1505562994.32772946\n",
            "Iteration 600, loss = 1505509102.65153098\n",
            "Iteration 601, loss = 1505455696.63548970\n",
            "Iteration 602, loss = 1505402098.75829291\n",
            "Iteration 603, loss = 1505348224.05081129\n",
            "Iteration 604, loss = 1505295002.13170600\n",
            "Iteration 605, loss = 1505241255.32697868\n",
            "Iteration 606, loss = 1505187767.55593777\n",
            "Iteration 607, loss = 1505134382.86628532\n",
            "Iteration 608, loss = 1505080416.81554174\n",
            "Iteration 609, loss = 1505027161.59691644\n",
            "Iteration 610, loss = 1504973167.34935856\n",
            "Iteration 611, loss = 1504919505.44391465\n",
            "Iteration 612, loss = 1504865525.80141449\n",
            "Iteration 613, loss = 1504811975.14398026\n",
            "Iteration 614, loss = 1504757824.74428368\n",
            "Iteration 615, loss = 1504703912.62270784\n",
            "Iteration 616, loss = 1504650132.78063631\n",
            "Iteration 617, loss = 1504596217.66606569\n",
            "Iteration 618, loss = 1504542135.47871637\n",
            "Iteration 619, loss = 1504488387.09057069\n",
            "Iteration 620, loss = 1504434422.03092933\n",
            "Iteration 621, loss = 1504380498.66452813\n",
            "Iteration 622, loss = 1504326431.64247322\n",
            "Iteration 623, loss = 1504272439.81656861\n",
            "Iteration 624, loss = 1504218735.51249266\n",
            "Iteration 625, loss = 1504164446.91363406\n",
            "Iteration 626, loss = 1504110744.46928358\n",
            "Iteration 627, loss = 1504056839.20410991\n",
            "Iteration 628, loss = 1504002817.52706766\n",
            "Iteration 629, loss = 1503948988.21734452\n",
            "Iteration 630, loss = 1503895240.85752964\n",
            "Iteration 631, loss = 1503841428.82621241\n",
            "Iteration 632, loss = 1503787833.10137868\n",
            "Iteration 633, loss = 1503734017.74193692\n",
            "Iteration 634, loss = 1503680638.71117282\n",
            "Iteration 635, loss = 1503626640.18631434\n",
            "Iteration 636, loss = 1503573354.47196221\n",
            "Iteration 637, loss = 1503519255.07129145\n",
            "Iteration 638, loss = 1503465798.61575031\n",
            "Iteration 639, loss = 1503412143.47231245\n",
            "Iteration 640, loss = 1503358168.83080959\n",
            "Iteration 641, loss = 1503304085.24971581\n",
            "Iteration 642, loss = 1503250413.60697508\n",
            "Iteration 643, loss = 1503196534.21217322\n",
            "Iteration 644, loss = 1503142287.05983543\n",
            "Iteration 645, loss = 1503088633.30201888\n",
            "Iteration 646, loss = 1503034737.89441514\n",
            "Iteration 647, loss = 1502980802.83297896\n",
            "Iteration 648, loss = 1502927278.28421688\n",
            "Iteration 649, loss = 1502873287.70634317\n",
            "Iteration 650, loss = 1502820010.49921918\n",
            "Iteration 651, loss = 1502766073.33470011\n",
            "Iteration 652, loss = 1502712846.56389165\n",
            "Iteration 653, loss = 1502659047.75754571\n",
            "Iteration 654, loss = 1502605256.63600779\n",
            "Iteration 655, loss = 1502551533.58786058\n",
            "Iteration 656, loss = 1502498146.49440265\n",
            "Iteration 657, loss = 1502444430.46896100\n",
            "Iteration 658, loss = 1502390319.11765885\n",
            "Iteration 659, loss = 1502336824.08399916\n",
            "Iteration 660, loss = 1502282964.53362441\n",
            "Iteration 661, loss = 1502229113.62451530\n",
            "Iteration 662, loss = 1502175341.49827719\n",
            "Iteration 663, loss = 1502121844.16298246\n",
            "Iteration 664, loss = 1502067831.43027067\n",
            "Iteration 665, loss = 1502014262.74575496\n",
            "Iteration 666, loss = 1501960540.21407104\n",
            "Iteration 667, loss = 1501906820.45048189\n",
            "Iteration 668, loss = 1501853315.85153389\n",
            "Iteration 669, loss = 1501799300.41690612\n",
            "Iteration 670, loss = 1501745835.11500096\n",
            "Iteration 671, loss = 1501692369.27707720\n",
            "Iteration 672, loss = 1501638147.94001722\n",
            "Iteration 673, loss = 1501584928.60217619\n",
            "Iteration 674, loss = 1501530783.84294176\n",
            "Iteration 675, loss = 1501477531.19554329\n",
            "Iteration 676, loss = 1501423551.83979130\n",
            "Iteration 677, loss = 1501370015.33396459\n",
            "Iteration 678, loss = 1501316317.28669477\n",
            "Iteration 679, loss = 1501262110.23844361\n",
            "Iteration 680, loss = 1501208983.48338056\n",
            "Iteration 681, loss = 1501154903.99759746\n",
            "Iteration 682, loss = 1501100970.19662523\n",
            "Iteration 683, loss = 1501047523.92240119\n",
            "Iteration 684, loss = 1500993721.81389594\n",
            "Iteration 685, loss = 1500939891.55291414\n",
            "Iteration 686, loss = 1500886204.46902823\n",
            "Iteration 687, loss = 1500832431.22905588\n",
            "Iteration 688, loss = 1500778593.64706516\n",
            "Iteration 689, loss = 1500725112.27777100\n",
            "Iteration 690, loss = 1500671157.58546591\n",
            "Iteration 691, loss = 1500617576.33832335\n",
            "Iteration 692, loss = 1500563868.54251218\n",
            "Iteration 693, loss = 1500510470.71242881\n",
            "Iteration 694, loss = 1500456852.38017154\n",
            "Iteration 695, loss = 1500403188.39585900\n",
            "Iteration 696, loss = 1500349947.34530830\n",
            "Iteration 697, loss = 1500296490.65279984\n",
            "Iteration 698, loss = 1500242742.17002821\n",
            "Iteration 699, loss = 1500189313.10176635\n",
            "Iteration 700, loss = 1500135579.88524508\n",
            "Iteration 701, loss = 1500081894.82277608\n",
            "Iteration 702, loss = 1500028400.21785378\n",
            "Iteration 703, loss = 1499974888.12007022\n",
            "Iteration 704, loss = 1499921317.77163720\n",
            "Iteration 705, loss = 1499867667.37133670\n",
            "Iteration 706, loss = 1499814193.32233906\n",
            "Iteration 707, loss = 1499760886.54472494\n",
            "Iteration 708, loss = 1499707680.99984002\n",
            "Iteration 709, loss = 1499654017.01645303\n",
            "Iteration 710, loss = 1499600915.08291984\n",
            "Iteration 711, loss = 1499547035.41407561\n",
            "Iteration 712, loss = 1499493780.23974800\n",
            "Iteration 713, loss = 1499440269.96909428\n",
            "Iteration 714, loss = 1499386793.75468516\n",
            "Iteration 715, loss = 1499333262.29303646\n",
            "Iteration 716, loss = 1499279926.68499684\n",
            "Iteration 717, loss = 1499226616.10272193\n",
            "Iteration 718, loss = 1499172815.92332578\n",
            "Iteration 719, loss = 1499119697.63698983\n",
            "Iteration 720, loss = 1499065982.84835052\n",
            "Iteration 721, loss = 1499012294.97773480\n",
            "Iteration 722, loss = 1498958700.36125326\n",
            "Iteration 723, loss = 1498904861.27104950\n",
            "Iteration 724, loss = 1498851044.90210366\n",
            "Iteration 725, loss = 1498797422.65003181\n",
            "Iteration 726, loss = 1498743268.05451512\n",
            "Iteration 727, loss = 1498689443.97448874\n",
            "Iteration 728, loss = 1498635609.06354213\n",
            "Iteration 729, loss = 1498581648.99160337\n",
            "Iteration 730, loss = 1498527865.25391960\n",
            "Iteration 731, loss = 1498473838.98910141\n",
            "Iteration 732, loss = 1498420040.15836692\n",
            "Iteration 733, loss = 1498366296.87062335\n",
            "Iteration 734, loss = 1498312455.45140743\n",
            "Iteration 735, loss = 1498258711.64739537\n",
            "Iteration 736, loss = 1498205011.71389484\n",
            "Iteration 737, loss = 1498150867.15823221\n",
            "Iteration 738, loss = 1498096996.94370246\n",
            "Iteration 739, loss = 1498043342.04721713\n",
            "Iteration 740, loss = 1497989414.33518124\n",
            "Iteration 741, loss = 1497935207.93721914\n",
            "Iteration 742, loss = 1497881267.26681256\n",
            "Iteration 743, loss = 1497827460.01190495\n",
            "Iteration 744, loss = 1497773919.83394551\n",
            "Iteration 745, loss = 1497719865.66720414\n",
            "Iteration 746, loss = 1497665873.72738862\n",
            "Iteration 747, loss = 1497612140.71426225\n",
            "Iteration 748, loss = 1497558514.04056978\n",
            "Iteration 749, loss = 1497504327.96565008\n",
            "Iteration 750, loss = 1497450186.22138286\n",
            "Iteration 751, loss = 1497396523.93378854\n",
            "Iteration 752, loss = 1497342414.02479219\n",
            "Iteration 753, loss = 1497288670.32127595\n",
            "Iteration 754, loss = 1497234633.22832775\n",
            "Iteration 755, loss = 1497180914.43968201\n",
            "Iteration 756, loss = 1497127093.99446702\n",
            "Iteration 757, loss = 1497073386.91000938\n",
            "Iteration 758, loss = 1497019584.40148783\n",
            "Iteration 759, loss = 1496965553.87022042\n",
            "Iteration 760, loss = 1496911703.21225786\n",
            "Iteration 761, loss = 1496858083.26119041\n",
            "Iteration 762, loss = 1496803843.67162561\n",
            "Iteration 763, loss = 1496749965.37810969\n",
            "Iteration 764, loss = 1496696014.68464565\n",
            "Iteration 765, loss = 1496642512.47579765\n",
            "Iteration 766, loss = 1496588545.22178793\n",
            "Iteration 767, loss = 1496534770.83431625\n",
            "Iteration 768, loss = 1496481166.45765686\n",
            "Iteration 769, loss = 1496427126.28950262\n",
            "Iteration 770, loss = 1496373703.68131304\n",
            "Iteration 771, loss = 1496319577.31914067\n",
            "Iteration 772, loss = 1496265749.27888131\n",
            "Iteration 773, loss = 1496212106.57082605\n",
            "Iteration 774, loss = 1496158015.87599659\n",
            "Iteration 775, loss = 1496104691.12046337\n",
            "Iteration 776, loss = 1496050434.39089561\n",
            "Iteration 777, loss = 1495996913.72834802\n",
            "Iteration 778, loss = 1495943961.96578169\n",
            "Iteration 779, loss = 1495889992.76859164\n",
            "Iteration 780, loss = 1495836282.04419351\n",
            "Iteration 781, loss = 1495783334.67115569\n",
            "Iteration 782, loss = 1495729666.01478505\n",
            "Iteration 783, loss = 1495676198.69168496\n",
            "Iteration 784, loss = 1495622776.97831535\n",
            "Iteration 785, loss = 1495569431.60091877\n",
            "Iteration 786, loss = 1495515844.84903240\n",
            "Iteration 787, loss = 1495462353.89728785\n",
            "Iteration 788, loss = 1495409070.65772700\n",
            "Iteration 789, loss = 1495356046.78357911\n",
            "Iteration 790, loss = 1495302205.46896935\n",
            "Iteration 791, loss = 1495249120.08199954\n",
            "Iteration 792, loss = 1495195734.19121718\n",
            "Iteration 793, loss = 1495142276.17604351\n",
            "Iteration 794, loss = 1495089078.78963399\n",
            "Iteration 795, loss = 1495035878.28357768\n",
            "Iteration 796, loss = 1494982202.82772303\n",
            "Iteration 797, loss = 1494928596.26584649\n",
            "Iteration 798, loss = 1494875035.80109787\n",
            "Iteration 799, loss = 1494821581.07839823\n",
            "Iteration 800, loss = 1494767919.37465620\n",
            "Iteration 801, loss = 1494713804.63099623\n",
            "Iteration 802, loss = 1494660097.03653264\n",
            "Iteration 803, loss = 1494606264.19397259\n",
            "Iteration 804, loss = 1494552702.48194718\n",
            "Iteration 805, loss = 1494498506.89909172\n",
            "Iteration 806, loss = 1494444832.72929025\n",
            "Iteration 807, loss = 1494391254.23301244\n",
            "Iteration 808, loss = 1494337022.44507241\n",
            "Iteration 809, loss = 1494283720.53600192\n",
            "Iteration 810, loss = 1494229839.83615351\n",
            "Iteration 811, loss = 1494176040.57602835\n",
            "Iteration 812, loss = 1494122575.25034666\n",
            "Iteration 813, loss = 1494068999.52567959\n",
            "Iteration 814, loss = 1494015370.33212328\n",
            "Iteration 815, loss = 1493962092.03944182\n",
            "Iteration 816, loss = 1493908137.19728351\n",
            "Iteration 817, loss = 1493855119.35321879\n",
            "Iteration 818, loss = 1493801317.73908234\n",
            "Iteration 819, loss = 1493747698.64860272\n",
            "Iteration 820, loss = 1493694157.55110145\n",
            "Iteration 821, loss = 1493640353.39884782\n",
            "Iteration 822, loss = 1493586898.67952681\n",
            "Iteration 823, loss = 1493533093.54664397\n",
            "Iteration 824, loss = 1493479585.42033768\n",
            "Iteration 825, loss = 1493425702.73689604\n",
            "Iteration 826, loss = 1493372160.35591030\n",
            "Iteration 827, loss = 1493318107.06786847\n",
            "Iteration 828, loss = 1493264462.49351954\n",
            "Iteration 829, loss = 1493210609.53219914\n",
            "Iteration 830, loss = 1493156918.09510875\n",
            "Iteration 831, loss = 1493102899.84126782\n",
            "Iteration 832, loss = 1493049365.16994333\n",
            "Iteration 833, loss = 1492995707.97317481\n",
            "Iteration 834, loss = 1492941793.71898866\n",
            "Iteration 835, loss = 1492888133.67563367\n",
            "Iteration 836, loss = 1492834652.15162110\n",
            "Iteration 837, loss = 1492780779.71840858\n",
            "Iteration 838, loss = 1492727208.46405840\n",
            "Iteration 839, loss = 1492673425.79996657\n",
            "Iteration 840, loss = 1492619641.79622984\n",
            "Iteration 841, loss = 1492566135.87306046\n",
            "Iteration 842, loss = 1492512635.18913698\n",
            "Iteration 843, loss = 1492458766.16607976\n",
            "Iteration 844, loss = 1492405238.81416726\n",
            "Iteration 845, loss = 1492351805.04573464\n",
            "Iteration 846, loss = 1492297734.85638118\n",
            "Iteration 847, loss = 1492244137.03584099\n",
            "Iteration 848, loss = 1492190406.76294136\n",
            "Iteration 849, loss = 1492136329.10161972\n",
            "Iteration 850, loss = 1492082505.45210528\n",
            "Iteration 851, loss = 1492028415.90456057\n",
            "Iteration 852, loss = 1491974543.45919538\n",
            "Iteration 853, loss = 1491920516.76075339\n",
            "Iteration 854, loss = 1491866974.23087573\n",
            "Iteration 855, loss = 1491813192.79326272\n",
            "Iteration 856, loss = 1491759457.70686698\n",
            "Iteration 857, loss = 1491705788.30908418\n",
            "Iteration 858, loss = 1491651871.56141043\n",
            "Iteration 859, loss = 1491598841.76952720\n",
            "Iteration 860, loss = 1491544654.82525802\n",
            "Iteration 861, loss = 1491491427.84215379\n",
            "Iteration 862, loss = 1491437202.90106034\n",
            "Iteration 863, loss = 1491383604.12422466\n",
            "Iteration 864, loss = 1491329662.78543210\n",
            "Iteration 865, loss = 1491275624.19654250\n",
            "Iteration 866, loss = 1491221469.03085470\n",
            "Iteration 867, loss = 1491167248.41077495\n",
            "Iteration 868, loss = 1491113252.82057571\n",
            "Iteration 869, loss = 1491058846.24721622\n",
            "Iteration 870, loss = 1491004934.75772548\n",
            "Iteration 871, loss = 1490950619.66558933\n",
            "Iteration 872, loss = 1490896770.54177284\n",
            "Iteration 873, loss = 1490843177.42078686\n",
            "Iteration 874, loss = 1490788869.53639102\n",
            "Iteration 875, loss = 1490735179.85937905\n",
            "Iteration 876, loss = 1490681909.66081142\n",
            "Iteration 877, loss = 1490627928.61912942\n",
            "Iteration 878, loss = 1490574583.79221320\n",
            "Iteration 879, loss = 1490520594.88204360\n",
            "Iteration 880, loss = 1490467321.63015676\n",
            "Iteration 881, loss = 1490413584.59097862\n",
            "Iteration 882, loss = 1490360068.51362038\n",
            "Iteration 883, loss = 1490306376.35725880\n",
            "Iteration 884, loss = 1490252815.52133942\n",
            "Iteration 885, loss = 1490199584.64072609\n",
            "Iteration 886, loss = 1490145748.59244800\n",
            "Iteration 887, loss = 1490092446.58274269\n",
            "Iteration 888, loss = 1490039077.61788845\n",
            "Iteration 889, loss = 1489985713.65114760\n",
            "Iteration 890, loss = 1489932365.53133893\n",
            "Iteration 891, loss = 1489878884.99748373\n",
            "Iteration 892, loss = 1489825318.11180568\n",
            "Iteration 893, loss = 1489771779.44840074\n",
            "Iteration 894, loss = 1489718505.39041233\n",
            "Iteration 895, loss = 1489664864.82869649\n",
            "Iteration 896, loss = 1489611254.09665751\n",
            "Iteration 897, loss = 1489557383.76677656\n",
            "Iteration 898, loss = 1489504339.18160915\n",
            "Iteration 899, loss = 1489450798.17165542\n",
            "Iteration 900, loss = 1489396987.70258856\n",
            "Iteration 901, loss = 1489343539.00056314\n",
            "Iteration 902, loss = 1489290094.96109295\n",
            "Iteration 903, loss = 1489236310.70150876\n",
            "Iteration 904, loss = 1489182922.51770401\n",
            "Iteration 905, loss = 1489129191.54856348\n",
            "Iteration 906, loss = 1489075509.09934735\n",
            "Iteration 907, loss = 1489022125.21567392\n",
            "Iteration 908, loss = 1488968455.67817020\n",
            "Iteration 909, loss = 1488914889.15663576\n",
            "Iteration 910, loss = 1488861400.94065356\n",
            "Iteration 911, loss = 1488807832.24232984\n",
            "Iteration 912, loss = 1488753751.98281717\n",
            "Iteration 913, loss = 1488700464.83732200\n",
            "Iteration 914, loss = 1488646246.82077050\n",
            "Iteration 915, loss = 1488592582.45754719\n",
            "Iteration 916, loss = 1488538450.53294396\n",
            "Iteration 917, loss = 1488484397.88007045\n",
            "Iteration 918, loss = 1488430557.24994445\n",
            "Iteration 919, loss = 1488376250.38519120\n",
            "Iteration 920, loss = 1488322772.16675210\n",
            "Iteration 921, loss = 1488268318.16371870\n",
            "Iteration 922, loss = 1488214515.78959632\n",
            "Iteration 923, loss = 1488160731.70820308\n",
            "Iteration 924, loss = 1488107104.57566905\n",
            "Iteration 925, loss = 1488053195.78370571\n",
            "Iteration 926, loss = 1487999423.42846537\n",
            "Iteration 927, loss = 1487945990.78926611\n",
            "Iteration 928, loss = 1487892259.55481339\n",
            "Iteration 929, loss = 1487838585.87384915\n",
            "Iteration 930, loss = 1487784884.82288313\n",
            "Iteration 931, loss = 1487731378.32776308\n",
            "Iteration 932, loss = 1487677862.72427821\n",
            "Iteration 933, loss = 1487624128.08332038\n",
            "Iteration 934, loss = 1487570607.25261045\n",
            "Iteration 935, loss = 1487517182.98903251\n",
            "Iteration 936, loss = 1487464070.65115976\n",
            "Iteration 937, loss = 1487410037.53342319\n",
            "Iteration 938, loss = 1487357208.35601974\n",
            "Iteration 939, loss = 1487303800.55172157\n",
            "Iteration 940, loss = 1487250783.10190153\n",
            "Iteration 941, loss = 1487197484.67605996\n",
            "Iteration 942, loss = 1487144721.46701384\n",
            "Iteration 943, loss = 1487091254.54321194\n",
            "Iteration 944, loss = 1487038499.05559516\n",
            "Iteration 945, loss = 1486985157.75521040\n",
            "Iteration 946, loss = 1486931996.29429770\n",
            "Iteration 947, loss = 1486878743.99178910\n",
            "Iteration 948, loss = 1486825915.99763989\n",
            "Iteration 949, loss = 1486772508.26242757\n",
            "Iteration 950, loss = 1486719449.45733237\n",
            "Iteration 951, loss = 1486666753.03145552\n",
            "Iteration 952, loss = 1486612996.69141650\n",
            "Iteration 953, loss = 1486560471.56712222\n",
            "Iteration 954, loss = 1486507453.06594396\n",
            "Iteration 955, loss = 1486454285.59665155\n",
            "Iteration 956, loss = 1486401035.08762169\n",
            "Iteration 957, loss = 1486347753.06132865\n",
            "Iteration 958, loss = 1486294901.74944854\n",
            "Iteration 959, loss = 1486241496.90423298\n",
            "Iteration 960, loss = 1486188066.99207473\n",
            "Iteration 961, loss = 1486134843.67028761\n",
            "Iteration 962, loss = 1486081385.59806848\n",
            "Iteration 963, loss = 1486027972.64714384\n",
            "Iteration 964, loss = 1485974708.82381892\n",
            "Iteration 965, loss = 1485921131.49929881\n",
            "Iteration 966, loss = 1485867617.94417262\n",
            "Iteration 967, loss = 1485814090.02175856\n",
            "Iteration 968, loss = 1485760932.32225609\n",
            "Iteration 969, loss = 1485707262.03590417\n",
            "Iteration 970, loss = 1485654085.19585013\n",
            "Iteration 971, loss = 1485600566.21959805\n",
            "Iteration 972, loss = 1485547319.01818562\n",
            "Iteration 973, loss = 1485493629.44300675\n",
            "Iteration 974, loss = 1485440596.81280208\n",
            "Iteration 975, loss = 1485387007.88133025\n",
            "Iteration 976, loss = 1485333841.29056048\n",
            "Iteration 977, loss = 1485280270.58105683\n",
            "Iteration 978, loss = 1485226907.77325392\n",
            "Iteration 979, loss = 1485173515.79816318\n",
            "Iteration 980, loss = 1485120145.92451429\n",
            "Iteration 981, loss = 1485066672.89369392\n",
            "Iteration 982, loss = 1485013334.71605873\n",
            "Iteration 983, loss = 1484959641.66356993\n",
            "Iteration 984, loss = 1484906536.13179898\n",
            "Iteration 985, loss = 1484852867.39870214\n",
            "Iteration 986, loss = 1484799386.85136580\n",
            "Iteration 987, loss = 1484746064.54009986\n",
            "Iteration 988, loss = 1484692530.48928046\n",
            "Iteration 989, loss = 1484638857.79667234\n",
            "Iteration 990, loss = 1484585203.27344441\n",
            "Iteration 991, loss = 1484531951.65074849\n",
            "Iteration 992, loss = 1484478262.20004106\n",
            "Iteration 993, loss = 1484424603.71431327\n",
            "Iteration 994, loss = 1484371316.59102154\n",
            "Iteration 995, loss = 1484317687.23556232\n",
            "Iteration 996, loss = 1484264685.88978004\n",
            "Iteration 997, loss = 1484211372.36298347\n",
            "Iteration 998, loss = 1484157836.04581332\n",
            "Iteration 999, loss = 1484105053.47205806\n",
            "Iteration 1000, loss = 1484051912.49183631\n",
            "Iteration 1, loss = 1397602284.63835073\n",
            "Iteration 2, loss = 161452897.28085983\n",
            "Iteration 3, loss = 312583048.62620866\n",
            "Iteration 4, loss = 220799131.09657994\n",
            "Iteration 5, loss = 97019474.56356642\n",
            "Iteration 6, loss = 119083062.35290402\n",
            "Iteration 7, loss = 108235087.29782867\n",
            "Iteration 8, loss = 95755641.45737273\n",
            "Iteration 9, loss = 98139833.16615935\n",
            "Iteration 10, loss = 96212395.32167995\n",
            "Iteration 11, loss = 95626141.87300731\n",
            "Iteration 12, loss = 96352504.90494350\n",
            "Iteration 13, loss = 96342046.83827394\n",
            "Iteration 14, loss = 96557595.49556963\n",
            "Iteration 15, loss = 96223737.76545955\n",
            "Iteration 16, loss = 96202697.34384167\n",
            "Iteration 17, loss = 95747519.81416427\n",
            "Iteration 18, loss = 95934041.61538002\n",
            "Iteration 19, loss = 96105706.71240996\n",
            "Iteration 20, loss = 96467002.55410837\n",
            "Iteration 21, loss = 96980035.66121048\n",
            "Iteration 22, loss = 96272797.70091075\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538850624.09458256\n",
            "Iteration 2, loss = 1538774685.48820257\n",
            "Iteration 3, loss = 1538721519.05800915\n",
            "Iteration 4, loss = 1538685741.62212944\n",
            "Iteration 5, loss = 1538657738.41487718\n",
            "Iteration 6, loss = 1538632294.05532002\n",
            "Iteration 7, loss = 1538606080.97548532\n",
            "Iteration 8, loss = 1538577851.41353750\n",
            "Iteration 9, loss = 1538548566.73554182\n",
            "Iteration 10, loss = 1538518501.63250923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 11, loss = 1538486915.96858764\n",
            "Iteration 12, loss = 1538453168.74889398\n",
            "Iteration 13, loss = 1538419021.89540958\n",
            "Iteration 14, loss = 1538385456.43953896\n",
            "Iteration 15, loss = 1538352456.99023080\n",
            "Iteration 16, loss = 1538319850.30196762\n",
            "Iteration 17, loss = 1538286616.40245008\n",
            "Iteration 18, loss = 1538252214.52851534\n",
            "Iteration 19, loss = 1538218332.28230524\n",
            "Iteration 20, loss = 1538184812.52420664\n",
            "Iteration 21, loss = 1538151433.13911819\n",
            "Iteration 22, loss = 1538118312.36983562\n",
            "Iteration 23, loss = 1538084918.75319171\n",
            "Iteration 24, loss = 1538051693.38703847\n",
            "Iteration 25, loss = 1538017836.00621367\n",
            "Iteration 26, loss = 1537983285.40817952\n",
            "Iteration 27, loss = 1537947242.05756378\n",
            "Iteration 28, loss = 1537911401.17973900\n",
            "Iteration 29, loss = 1537875415.94132805\n",
            "Iteration 30, loss = 1537837655.22351980\n",
            "Iteration 31, loss = 1537800687.80430651\n",
            "Iteration 32, loss = 1537764077.96071577\n",
            "Iteration 33, loss = 1537727690.72115254\n",
            "Iteration 34, loss = 1537690110.01912165\n",
            "Iteration 35, loss = 1537650849.20132565\n",
            "Iteration 36, loss = 1537611973.88180351\n",
            "Iteration 37, loss = 1537573788.18089724\n",
            "Iteration 38, loss = 1537534511.42165804\n",
            "Iteration 39, loss = 1537493736.12431097\n",
            "Iteration 40, loss = 1537451921.22613597\n",
            "Iteration 41, loss = 1537409351.12926030\n",
            "Iteration 42, loss = 1537366603.00533223\n",
            "Iteration 43, loss = 1537324972.77979183\n",
            "Iteration 44, loss = 1537283762.87035418\n",
            "Iteration 45, loss = 1537242442.73714876\n",
            "Iteration 46, loss = 1537201361.11809993\n",
            "Iteration 47, loss = 1537160454.97526932\n",
            "Iteration 48, loss = 1537119311.97095990\n",
            "Iteration 49, loss = 1537078679.70400977\n",
            "Iteration 50, loss = 1537037144.90491414\n",
            "Iteration 51, loss = 1536994078.18719554\n",
            "Iteration 52, loss = 1536947266.60127544\n",
            "Iteration 53, loss = 1536900280.11358142\n",
            "Iteration 54, loss = 1536854362.65937853\n",
            "Iteration 55, loss = 1536806568.20021963\n",
            "Iteration 56, loss = 1536758568.18870473\n",
            "Iteration 57, loss = 1536711892.58133554\n",
            "Iteration 58, loss = 1536665241.48361635\n",
            "Iteration 59, loss = 1536618978.61902618\n",
            "Iteration 60, loss = 1536572186.26764083\n",
            "Iteration 61, loss = 1536526010.61836696\n",
            "Iteration 62, loss = 1536479783.94029117\n",
            "Iteration 63, loss = 1536433364.69127822\n",
            "Iteration 64, loss = 1536387471.82798767\n",
            "Iteration 65, loss = 1536341901.33711195\n",
            "Iteration 66, loss = 1536296218.75700974\n",
            "Iteration 67, loss = 1536250780.10413790\n",
            "Iteration 68, loss = 1536205528.21903253\n",
            "Iteration 69, loss = 1536160300.05787563\n",
            "Iteration 70, loss = 1536115416.86967540\n",
            "Iteration 71, loss = 1536070169.85023189\n",
            "Iteration 72, loss = 1536023341.71843576\n",
            "Iteration 73, loss = 1535975193.67581391\n",
            "Iteration 74, loss = 1535927202.70476198\n",
            "Iteration 75, loss = 1535878045.18171167\n",
            "Iteration 76, loss = 1535825151.20886922\n",
            "Iteration 77, loss = 1535772155.80750489\n",
            "Iteration 78, loss = 1535720682.66514611\n",
            "Iteration 79, loss = 1535669621.20668364\n",
            "Iteration 80, loss = 1535618743.86424541\n",
            "Iteration 81, loss = 1535567166.95691729\n",
            "Iteration 82, loss = 1535516295.37642550\n",
            "Iteration 83, loss = 1535465798.60473990\n",
            "Iteration 84, loss = 1535414881.82427526\n",
            "Iteration 85, loss = 1535364574.26648092\n",
            "Iteration 86, loss = 1535314331.42295671\n",
            "Iteration 87, loss = 1535264208.46939349\n",
            "Iteration 88, loss = 1535214546.78439736\n",
            "Iteration 89, loss = 1535164929.10491943\n",
            "Iteration 90, loss = 1535115231.28869629\n",
            "Iteration 91, loss = 1535064517.09593511\n",
            "Iteration 92, loss = 1535011496.44128275\n",
            "Iteration 93, loss = 1534958761.87839746\n",
            "Iteration 94, loss = 1534907370.79364920\n",
            "Iteration 95, loss = 1534855880.21447110\n",
            "Iteration 96, loss = 1534804656.32666039\n",
            "Iteration 97, loss = 1534753509.95104623\n",
            "Iteration 98, loss = 1534702642.37691760\n",
            "Iteration 99, loss = 1534651579.42849374\n",
            "Iteration 100, loss = 1534600624.08869171\n",
            "Iteration 101, loss = 1534549943.29420209\n",
            "Iteration 102, loss = 1534499275.25180507\n",
            "Iteration 103, loss = 1534448793.99900699\n",
            "Iteration 104, loss = 1534398544.01044893\n",
            "Iteration 105, loss = 1534347832.62114429\n",
            "Iteration 106, loss = 1534297881.09648323\n",
            "Iteration 107, loss = 1534247282.53039551\n",
            "Iteration 108, loss = 1534194987.16703606\n",
            "Iteration 109, loss = 1534141134.60271215\n",
            "Iteration 110, loss = 1534088345.38434792\n",
            "Iteration 111, loss = 1534035916.92967010\n",
            "Iteration 112, loss = 1533983320.38700819\n",
            "Iteration 113, loss = 1533929781.45035768\n",
            "Iteration 114, loss = 1533873968.19885540\n",
            "Iteration 115, loss = 1533817347.49717331\n",
            "Iteration 116, loss = 1533762637.87490010\n",
            "Iteration 117, loss = 1533707630.04304504\n",
            "Iteration 118, loss = 1533652998.80909371\n",
            "Iteration 119, loss = 1533598322.24877596\n",
            "Iteration 120, loss = 1533543699.08332539\n",
            "Iteration 121, loss = 1533489638.59926057\n",
            "Iteration 122, loss = 1533435591.14833736\n",
            "Iteration 123, loss = 1533381832.72704720\n",
            "Iteration 124, loss = 1533328056.39177251\n",
            "Iteration 125, loss = 1533274628.56656337\n",
            "Iteration 126, loss = 1533221450.95219231\n",
            "Iteration 127, loss = 1533168471.76890922\n",
            "Iteration 128, loss = 1533115615.73573923\n",
            "Iteration 129, loss = 1533062980.67131400\n",
            "Iteration 130, loss = 1533010689.55550218\n",
            "Iteration 131, loss = 1532958358.94448137\n",
            "Iteration 132, loss = 1532906227.53376675\n",
            "Iteration 133, loss = 1532854413.42667413\n",
            "Iteration 134, loss = 1532802281.82264423\n",
            "Iteration 135, loss = 1532750874.65385103\n",
            "Iteration 136, loss = 1532699323.04856253\n",
            "Iteration 137, loss = 1532648191.79465246\n",
            "Iteration 138, loss = 1532596731.57421517\n",
            "Iteration 139, loss = 1532545545.25808501\n",
            "Iteration 140, loss = 1532494802.75713181\n",
            "Iteration 141, loss = 1532443862.66728640\n",
            "Iteration 142, loss = 1532393143.44330883\n",
            "Iteration 143, loss = 1532342032.64649081\n",
            "Iteration 144, loss = 1532291534.10957789\n",
            "Iteration 145, loss = 1532240849.30602860\n",
            "Iteration 146, loss = 1532190293.85724807\n",
            "Iteration 147, loss = 1532139750.10623550\n",
            "Iteration 148, loss = 1532089311.53403616\n",
            "Iteration 149, loss = 1532039056.27566338\n",
            "Iteration 150, loss = 1531988561.52759218\n",
            "Iteration 151, loss = 1531937952.00886297\n",
            "Iteration 152, loss = 1531886240.24389100\n",
            "Iteration 153, loss = 1531830545.38431215\n",
            "Iteration 154, loss = 1531776660.03023505\n",
            "Iteration 155, loss = 1531723310.98544002\n",
            "Iteration 156, loss = 1531669748.54486561\n",
            "Iteration 157, loss = 1531616161.40313411\n",
            "Iteration 158, loss = 1531562688.37926722\n",
            "Iteration 159, loss = 1531509455.52028990\n",
            "Iteration 160, loss = 1531456002.74210167\n",
            "Iteration 161, loss = 1531402932.24437690\n",
            "Iteration 162, loss = 1531349843.31991935\n",
            "Iteration 163, loss = 1531296829.12444162\n",
            "Iteration 164, loss = 1531244157.65112567\n",
            "Iteration 165, loss = 1531191416.54568148\n",
            "Iteration 166, loss = 1531138617.99920678\n",
            "Iteration 167, loss = 1531086508.07241249\n",
            "Iteration 168, loss = 1531033964.02755547\n",
            "Iteration 169, loss = 1530982005.87895989\n",
            "Iteration 170, loss = 1530930155.74750113\n",
            "Iteration 171, loss = 1530878476.90533280\n",
            "Iteration 172, loss = 1530826639.41915202\n",
            "Iteration 173, loss = 1530775538.80523372\n",
            "Iteration 174, loss = 1530724005.42781425\n",
            "Iteration 175, loss = 1530672495.41557932\n",
            "Iteration 176, loss = 1530621560.59791946\n",
            "Iteration 177, loss = 1530570192.21918297\n",
            "Iteration 178, loss = 1530519293.11246586\n",
            "Iteration 179, loss = 1530467890.64809537\n",
            "Iteration 180, loss = 1530417422.61903858\n",
            "Iteration 181, loss = 1530366448.68568873\n",
            "Iteration 182, loss = 1530315555.83820033\n",
            "Iteration 183, loss = 1530264944.92326951\n",
            "Iteration 184, loss = 1530214295.41256690\n",
            "Iteration 185, loss = 1530163719.29094076\n",
            "Iteration 186, loss = 1530113161.65615773\n",
            "Iteration 187, loss = 1530062081.51143026\n",
            "Iteration 188, loss = 1530011695.29563093\n",
            "Iteration 189, loss = 1529959162.84693384\n",
            "Iteration 190, loss = 1529903350.91245532\n",
            "Iteration 191, loss = 1529848766.79094124\n",
            "Iteration 192, loss = 1529795259.58444285\n",
            "Iteration 193, loss = 1529741007.74939537\n",
            "Iteration 194, loss = 1529686745.71598744\n",
            "Iteration 195, loss = 1529632476.61271405\n",
            "Iteration 196, loss = 1529578395.09364772\n",
            "Iteration 197, loss = 1529524712.82965636\n",
            "Iteration 198, loss = 1529470222.70211959\n",
            "Iteration 199, loss = 1529416713.50496006\n",
            "Iteration 200, loss = 1529362834.73915768\n",
            "Iteration 201, loss = 1529309241.72605205\n",
            "Iteration 202, loss = 1529255826.38736391\n",
            "Iteration 203, loss = 1529202589.57425475\n",
            "Iteration 204, loss = 1529148872.46859407\n",
            "Iteration 205, loss = 1529095938.91588235\n",
            "Iteration 206, loss = 1529042759.82138276\n",
            "Iteration 207, loss = 1528989658.82842541\n",
            "Iteration 208, loss = 1528936702.21111965\n",
            "Iteration 209, loss = 1528883739.36512947\n",
            "Iteration 210, loss = 1528830949.06006289\n",
            "Iteration 211, loss = 1528778143.65740275\n",
            "Iteration 212, loss = 1528725436.46398139\n",
            "Iteration 213, loss = 1528672964.10337210\n",
            "Iteration 214, loss = 1528620195.30704570\n",
            "Iteration 215, loss = 1528566339.43609619\n",
            "Iteration 216, loss = 1528509176.07293630\n",
            "Iteration 217, loss = 1528452498.83990097\n",
            "Iteration 218, loss = 1528396433.11788106\n",
            "Iteration 219, loss = 1528340410.82838511\n",
            "Iteration 220, loss = 1528284364.01618838\n",
            "Iteration 221, loss = 1528228640.96483588\n",
            "Iteration 222, loss = 1528172440.89077640\n",
            "Iteration 223, loss = 1528116872.98471928\n",
            "Iteration 224, loss = 1528060703.57345462\n",
            "Iteration 225, loss = 1528005500.35188007\n",
            "Iteration 226, loss = 1527949708.01055169\n",
            "Iteration 227, loss = 1527894288.87352014\n",
            "Iteration 228, loss = 1527838727.00561428\n",
            "Iteration 229, loss = 1527783798.64391279\n",
            "Iteration 230, loss = 1527728437.65984893\n",
            "Iteration 231, loss = 1527673451.25201726\n",
            "Iteration 232, loss = 1527618562.23870587\n",
            "Iteration 233, loss = 1527563661.77610755\n",
            "Iteration 234, loss = 1527509209.41086602\n",
            "Iteration 235, loss = 1527454600.93001032\n",
            "Iteration 236, loss = 1527399998.42869663\n",
            "Iteration 237, loss = 1527345790.48960495\n",
            "Iteration 238, loss = 1527291669.37410259\n",
            "Iteration 239, loss = 1527237947.98698997\n",
            "Iteration 240, loss = 1527184091.36632562\n",
            "Iteration 241, loss = 1527130650.84197497\n",
            "Iteration 242, loss = 1527076831.19117594\n",
            "Iteration 243, loss = 1527023768.93533373\n",
            "Iteration 244, loss = 1526970279.16482353\n",
            "Iteration 245, loss = 1526916935.06865382\n",
            "Iteration 246, loss = 1526863618.04284859\n",
            "Iteration 247, loss = 1526809801.33829808\n",
            "Iteration 248, loss = 1526756787.14735746\n",
            "Iteration 249, loss = 1526703420.07826066\n",
            "Iteration 250, loss = 1526649636.88839960\n",
            "Iteration 251, loss = 1526596747.18078279\n",
            "Iteration 252, loss = 1526543165.97843003\n",
            "Iteration 253, loss = 1526490063.00891519\n",
            "Iteration 254, loss = 1526437440.08629870\n",
            "Iteration 255, loss = 1526384106.54320168\n",
            "Iteration 256, loss = 1526331190.12922502\n",
            "Iteration 257, loss = 1526278201.35899448\n",
            "Iteration 258, loss = 1526226029.48131275\n",
            "Iteration 259, loss = 1526172669.08262014\n",
            "Iteration 260, loss = 1526120530.87151623\n",
            "Iteration 261, loss = 1526067820.53843760\n",
            "Iteration 262, loss = 1526015158.40604639\n",
            "Iteration 263, loss = 1525962961.71754527\n",
            "Iteration 264, loss = 1525910538.95699024\n",
            "Iteration 265, loss = 1525858147.89684892\n",
            "Iteration 266, loss = 1525805891.63183284\n",
            "Iteration 267, loss = 1525753737.20675921\n",
            "Iteration 268, loss = 1525701469.78287387\n",
            "Iteration 269, loss = 1525649271.06679034\n",
            "Iteration 270, loss = 1525597163.34555554\n",
            "Iteration 271, loss = 1525545436.67315197\n",
            "Iteration 272, loss = 1525493300.66576576\n",
            "Iteration 273, loss = 1525441503.81859136\n",
            "Iteration 274, loss = 1525389779.37025690\n",
            "Iteration 275, loss = 1525337821.11324143\n",
            "Iteration 276, loss = 1525286305.93257737\n",
            "Iteration 277, loss = 1525234456.17167163\n",
            "Iteration 278, loss = 1525182941.49020123\n",
            "Iteration 279, loss = 1525131176.64789414\n",
            "Iteration 280, loss = 1525079638.61891603\n",
            "Iteration 281, loss = 1525027767.94169426\n",
            "Iteration 282, loss = 1524976262.54620218\n",
            "Iteration 283, loss = 1524924424.96258140\n",
            "Iteration 284, loss = 1524873113.61240220\n",
            "Iteration 285, loss = 1524821231.86890578\n",
            "Iteration 286, loss = 1524769893.61542988\n",
            "Iteration 287, loss = 1524718269.59214163\n",
            "Iteration 288, loss = 1524666885.69872046\n",
            "Iteration 289, loss = 1524615307.29490495\n",
            "Iteration 290, loss = 1524563813.12870693\n",
            "Iteration 291, loss = 1524512887.30884814\n",
            "Iteration 292, loss = 1524461110.94602108\n",
            "Iteration 293, loss = 1524410340.32141495\n",
            "Iteration 294, loss = 1524358969.12929583\n",
            "Iteration 295, loss = 1524307787.81491899\n",
            "Iteration 296, loss = 1524256453.51772666\n",
            "Iteration 297, loss = 1524205761.18473887\n",
            "Iteration 298, loss = 1524154268.47884488\n",
            "Iteration 299, loss = 1524103202.86916590\n",
            "Iteration 300, loss = 1524051999.60341859\n",
            "Iteration 301, loss = 1524000870.85995436\n",
            "Iteration 302, loss = 1523949635.24730754\n",
            "Iteration 303, loss = 1523898687.44615436\n",
            "Iteration 304, loss = 1523847640.92249870\n",
            "Iteration 305, loss = 1523796392.32039118\n",
            "Iteration 306, loss = 1523745282.52045012\n",
            "Iteration 307, loss = 1523694039.40352988\n",
            "Iteration 308, loss = 1523643142.82457614\n",
            "Iteration 309, loss = 1523591940.51921558\n",
            "Iteration 310, loss = 1523541035.35546136\n",
            "Iteration 311, loss = 1523489972.71681142\n",
            "Iteration 312, loss = 1523439148.23968148\n",
            "Iteration 313, loss = 1523388412.45199680\n",
            "Iteration 314, loss = 1523337589.49525213\n",
            "Iteration 315, loss = 1523286659.33754539\n",
            "Iteration 316, loss = 1523235898.51696086\n",
            "Iteration 317, loss = 1523185104.01512647\n",
            "Iteration 318, loss = 1523134045.09858489\n",
            "Iteration 319, loss = 1523082919.36915922\n",
            "Iteration 320, loss = 1523031650.70241213\n",
            "Iteration 321, loss = 1522978046.69299269\n",
            "Iteration 322, loss = 1522920579.65123868\n",
            "Iteration 323, loss = 1522865617.90289044\n",
            "Iteration 324, loss = 1522810412.47118783\n",
            "Iteration 325, loss = 1522754587.61465764\n",
            "Iteration 326, loss = 1522699169.22584534\n",
            "Iteration 327, loss = 1522643166.84624004\n",
            "Iteration 328, loss = 1522587275.73122072\n",
            "Iteration 329, loss = 1522531492.61342478\n",
            "Iteration 330, loss = 1522475835.59489536\n",
            "Iteration 331, loss = 1522420368.70475030\n",
            "Iteration 332, loss = 1522364720.14071059\n",
            "Iteration 333, loss = 1522309428.20650721\n",
            "Iteration 334, loss = 1522254356.80379009\n",
            "Iteration 335, loss = 1522199641.18950820\n",
            "Iteration 336, loss = 1522144735.46338224\n",
            "Iteration 337, loss = 1522090127.86454892\n",
            "Iteration 338, loss = 1522035620.23452234\n",
            "Iteration 339, loss = 1521981361.95607400\n",
            "Iteration 340, loss = 1521926900.59759569\n",
            "Iteration 341, loss = 1521872734.59348893\n",
            "Iteration 342, loss = 1521817982.45784235\n",
            "Iteration 343, loss = 1521763038.10829687\n",
            "Iteration 344, loss = 1521703179.18278217\n",
            "Iteration 345, loss = 1521640169.64877868\n",
            "Iteration 346, loss = 1521575191.62857294\n",
            "Iteration 347, loss = 1521512004.24608564\n",
            "Iteration 348, loss = 1521449183.03454256\n",
            "Iteration 349, loss = 1521385487.33117366\n",
            "Iteration 350, loss = 1521321472.71071100\n",
            "Iteration 351, loss = 1521258381.98586798\n",
            "Iteration 352, loss = 1521194965.97527862\n",
            "Iteration 353, loss = 1521131545.01961040\n",
            "Iteration 354, loss = 1521068594.73372579\n",
            "Iteration 355, loss = 1521006134.80667138\n",
            "Iteration 356, loss = 1520943562.57860804\n",
            "Iteration 357, loss = 1520881453.11676240\n",
            "Iteration 358, loss = 1520819605.27137423\n",
            "Iteration 359, loss = 1520757681.30592394\n",
            "Iteration 360, loss = 1520696526.56300139\n",
            "Iteration 361, loss = 1520635349.94165611\n",
            "Iteration 362, loss = 1520574320.34270883\n",
            "Iteration 363, loss = 1520513746.09035873\n",
            "Iteration 364, loss = 1520453360.61093903\n",
            "Iteration 365, loss = 1520393290.07506108\n",
            "Iteration 366, loss = 1520333283.83339500\n",
            "Iteration 367, loss = 1520272997.44166756\n",
            "Iteration 368, loss = 1520213782.37389851\n",
            "Iteration 369, loss = 1520154214.55726528\n",
            "Iteration 370, loss = 1520094468.95481944\n",
            "Iteration 371, loss = 1520035501.87348318\n",
            "Iteration 372, loss = 1519976253.24334741\n",
            "Iteration 373, loss = 1519917329.29240179\n",
            "Iteration 374, loss = 1519858387.14690185\n",
            "Iteration 375, loss = 1519799727.24714994\n",
            "Iteration 376, loss = 1519741143.83412218\n",
            "Iteration 377, loss = 1519682302.08855963\n",
            "Iteration 378, loss = 1519624270.62753773\n",
            "Iteration 379, loss = 1519565619.98702288\n",
            "Iteration 380, loss = 1519507561.72878003\n",
            "Iteration 381, loss = 1519449462.35579014\n",
            "Iteration 382, loss = 1519391324.37262487\n",
            "Iteration 383, loss = 1519333922.98699403\n",
            "Iteration 384, loss = 1519276347.24819279\n",
            "Iteration 385, loss = 1519218709.98707294\n",
            "Iteration 386, loss = 1519161479.42820501\n",
            "Iteration 387, loss = 1519104189.99296808\n",
            "Iteration 388, loss = 1519046632.89438891\n",
            "Iteration 389, loss = 1518989596.93953919\n",
            "Iteration 390, loss = 1518932458.64669776\n",
            "Iteration 391, loss = 1518874972.69704199\n",
            "Iteration 392, loss = 1518817755.89130163\n",
            "Iteration 393, loss = 1518760070.97682118\n",
            "Iteration 394, loss = 1518703896.41415238\n",
            "Iteration 395, loss = 1518646103.52098227\n",
            "Iteration 396, loss = 1518589052.52652955\n",
            "Iteration 397, loss = 1518532108.95165229\n",
            "Iteration 398, loss = 1518475388.42368364\n",
            "Iteration 399, loss = 1518418531.32610798\n",
            "Iteration 400, loss = 1518361745.74085355\n",
            "Iteration 401, loss = 1518305190.06689548\n",
            "Iteration 402, loss = 1518248512.48918056\n",
            "Iteration 403, loss = 1518192060.64771032\n",
            "Iteration 404, loss = 1518135919.96827340\n",
            "Iteration 405, loss = 1518079349.12925506\n",
            "Iteration 406, loss = 1518022748.50403261\n",
            "Iteration 407, loss = 1517966968.80678344\n",
            "Iteration 408, loss = 1517910428.63328218\n",
            "Iteration 409, loss = 1517853947.78261042\n",
            "Iteration 410, loss = 1517797816.10653949\n",
            "Iteration 411, loss = 1517741309.53289795\n",
            "Iteration 412, loss = 1517685082.84182549\n",
            "Iteration 413, loss = 1517629365.69231486\n",
            "Iteration 414, loss = 1517572661.59116554\n",
            "Iteration 415, loss = 1517516774.11016345\n",
            "Iteration 416, loss = 1517460544.14332652\n",
            "Iteration 417, loss = 1517404635.26234436\n",
            "Iteration 418, loss = 1517348629.91234827\n",
            "Iteration 419, loss = 1517292457.78593683\n",
            "Iteration 420, loss = 1517236543.24969459\n",
            "Iteration 421, loss = 1517180990.20492125\n",
            "Iteration 422, loss = 1517124745.97061038\n",
            "Iteration 423, loss = 1517068847.22513032\n",
            "Iteration 424, loss = 1517013397.52994704\n",
            "Iteration 425, loss = 1516957550.59636760\n",
            "Iteration 426, loss = 1516902021.99835801\n",
            "Iteration 427, loss = 1516846490.63101625\n",
            "Iteration 428, loss = 1516790748.40224218\n",
            "Iteration 429, loss = 1516735672.57530785\n",
            "Iteration 430, loss = 1516679885.47748518\n",
            "Iteration 431, loss = 1516624743.28777885\n",
            "Iteration 432, loss = 1516569375.96620393\n",
            "Iteration 433, loss = 1516513784.04879951\n",
            "Iteration 434, loss = 1516458907.74678731\n",
            "Iteration 435, loss = 1516403565.14333892\n",
            "Iteration 436, loss = 1516348231.81828451\n",
            "Iteration 437, loss = 1516293122.17281938\n",
            "Iteration 438, loss = 1516238243.52334356\n",
            "Iteration 439, loss = 1516182854.71101761\n",
            "Iteration 440, loss = 1516128132.75705695\n",
            "Iteration 441, loss = 1516072507.96382594\n",
            "Iteration 442, loss = 1516017990.91736960\n",
            "Iteration 443, loss = 1515962918.17752171\n",
            "Iteration 444, loss = 1515908109.82328296\n",
            "Iteration 445, loss = 1515853239.25755692\n",
            "Iteration 446, loss = 1515798517.71421432\n",
            "Iteration 447, loss = 1515743642.76338649\n",
            "Iteration 448, loss = 1515689059.71536136\n",
            "Iteration 449, loss = 1515634323.92591929\n",
            "Iteration 450, loss = 1515579653.72166157\n",
            "Iteration 451, loss = 1515524823.48393345\n",
            "Iteration 452, loss = 1515470176.42800713\n",
            "Iteration 453, loss = 1515415688.96900392\n",
            "Iteration 454, loss = 1515361113.63145399\n",
            "Iteration 455, loss = 1515306577.64319873\n",
            "Iteration 456, loss = 1515252184.42419052\n",
            "Iteration 457, loss = 1515197774.82954526\n",
            "Iteration 458, loss = 1515143081.64607477\n",
            "Iteration 459, loss = 1515088754.55804586\n",
            "Iteration 460, loss = 1515034289.52768707\n",
            "Iteration 461, loss = 1514979620.48023653\n",
            "Iteration 462, loss = 1514925225.98308563\n",
            "Iteration 463, loss = 1514870714.98664308\n",
            "Iteration 464, loss = 1514816345.81487703\n",
            "Iteration 465, loss = 1514761697.03776574\n",
            "Iteration 466, loss = 1514707843.59782624\n",
            "Iteration 467, loss = 1514652932.92023897\n",
            "Iteration 468, loss = 1514598877.08899760\n",
            "Iteration 469, loss = 1514544482.21036172\n",
            "Iteration 470, loss = 1514489886.20257759\n",
            "Iteration 471, loss = 1514435907.55392218\n",
            "Iteration 472, loss = 1514381395.13121915\n",
            "Iteration 473, loss = 1514327372.47610521\n",
            "Iteration 474, loss = 1514273195.08137918\n",
            "Iteration 475, loss = 1514219048.60281968\n",
            "Iteration 476, loss = 1514165190.12475014\n",
            "Iteration 477, loss = 1514111241.82423544\n",
            "Iteration 478, loss = 1514057173.80704665\n",
            "Iteration 479, loss = 1514003355.10794115\n",
            "Iteration 480, loss = 1513949350.11157274\n",
            "Iteration 481, loss = 1513895516.23553038\n",
            "Iteration 482, loss = 1513841833.55204654\n",
            "Iteration 483, loss = 1513787872.15450454\n",
            "Iteration 484, loss = 1513734324.35470462\n",
            "Iteration 485, loss = 1513680508.00021291\n",
            "Iteration 486, loss = 1513626639.36228681\n",
            "Iteration 487, loss = 1513572966.70499372\n",
            "Iteration 488, loss = 1513519282.81204510\n",
            "Iteration 489, loss = 1513465570.01663280\n",
            "Iteration 490, loss = 1513412071.58739972\n",
            "Iteration 491, loss = 1513358001.54432273\n",
            "Iteration 492, loss = 1513304351.14144182\n",
            "Iteration 493, loss = 1513250682.75803185\n",
            "Iteration 494, loss = 1513196762.90909314\n",
            "Iteration 495, loss = 1513142980.60822988\n",
            "Iteration 496, loss = 1513088884.53036594\n",
            "Iteration 497, loss = 1513035366.23118329\n",
            "Iteration 498, loss = 1512981309.14546466\n",
            "Iteration 499, loss = 1512927756.67293668\n",
            "Iteration 500, loss = 1512874168.32952404\n",
            "Iteration 501, loss = 1512820857.08543754\n",
            "Iteration 502, loss = 1512767312.58131933\n",
            "Iteration 503, loss = 1512713909.41315150\n",
            "Iteration 504, loss = 1512660722.59713674\n",
            "Iteration 505, loss = 1512607273.64010406\n",
            "Iteration 506, loss = 1512553872.54918742\n",
            "Iteration 507, loss = 1512500289.22339797\n",
            "Iteration 508, loss = 1512446636.24984431\n",
            "Iteration 509, loss = 1512393017.09129834\n",
            "Iteration 510, loss = 1512339202.22698879\n",
            "Iteration 511, loss = 1512285669.23674560\n",
            "Iteration 512, loss = 1512231656.41450691\n",
            "Iteration 513, loss = 1512178342.11414766\n",
            "Iteration 514, loss = 1512124216.59242368\n",
            "Iteration 515, loss = 1512070865.60215688\n",
            "Iteration 516, loss = 1512017019.30855584\n",
            "Iteration 517, loss = 1511963101.73317146\n",
            "Iteration 518, loss = 1511909864.99835849\n",
            "Iteration 519, loss = 1511855947.40829659\n",
            "Iteration 520, loss = 1511802223.02389646\n",
            "Iteration 521, loss = 1511749031.84666538\n",
            "Iteration 522, loss = 1511695269.77916837\n",
            "Iteration 523, loss = 1511642316.09280014\n",
            "Iteration 524, loss = 1511588581.71545863\n",
            "Iteration 525, loss = 1511535432.06925607\n",
            "Iteration 526, loss = 1511481939.07363462\n",
            "Iteration 527, loss = 1511428867.71745801\n",
            "Iteration 528, loss = 1511375141.06552792\n",
            "Iteration 529, loss = 1511322021.19734383\n",
            "Iteration 530, loss = 1511268175.11746025\n",
            "Iteration 531, loss = 1511214736.63451958\n",
            "Iteration 532, loss = 1511161341.77209592\n",
            "Iteration 533, loss = 1511107790.04125905\n",
            "Iteration 534, loss = 1511054513.51357341\n",
            "Iteration 535, loss = 1511000933.70147157\n",
            "Iteration 536, loss = 1510947716.05624890\n",
            "Iteration 537, loss = 1510894462.14773989\n",
            "Iteration 538, loss = 1510841463.37168717\n",
            "Iteration 539, loss = 1510787983.52064919\n",
            "Iteration 540, loss = 1510735046.05681038\n",
            "Iteration 541, loss = 1510681865.07978010\n",
            "Iteration 542, loss = 1510628911.83799696\n",
            "Iteration 543, loss = 1510575521.08055806\n",
            "Iteration 544, loss = 1510522512.95629978\n",
            "Iteration 545, loss = 1510469359.12031269\n",
            "Iteration 546, loss = 1510416404.27738905\n",
            "Iteration 547, loss = 1510362959.87604523\n",
            "Iteration 548, loss = 1510309658.09226727\n",
            "Iteration 549, loss = 1510256744.76178193\n",
            "Iteration 550, loss = 1510203426.86725950\n",
            "Iteration 551, loss = 1510150115.08644438\n",
            "Iteration 552, loss = 1510096829.08079839\n",
            "Iteration 553, loss = 1510043710.40556812\n",
            "Iteration 554, loss = 1509990556.27460837\n",
            "Iteration 555, loss = 1509937132.98508739\n",
            "Iteration 556, loss = 1509884498.98917198\n",
            "Iteration 557, loss = 1509830910.51905322\n",
            "Iteration 558, loss = 1509777902.17059326\n",
            "Iteration 559, loss = 1509724721.53566766\n",
            "Iteration 560, loss = 1509668468.56703281\n",
            "Iteration 561, loss = 1509608147.71617746\n",
            "Iteration 562, loss = 1509550405.20398974\n",
            "Iteration 563, loss = 1509491907.94032884\n",
            "Iteration 564, loss = 1509433983.49119663\n",
            "Iteration 565, loss = 1509375059.67742014\n",
            "Iteration 566, loss = 1509316585.21693301\n",
            "Iteration 567, loss = 1509258145.23782611\n",
            "Iteration 568, loss = 1509199415.20860004\n",
            "Iteration 569, loss = 1509141429.54911256\n",
            "Iteration 570, loss = 1509082959.77175117\n",
            "Iteration 571, loss = 1509024567.26123047\n",
            "Iteration 572, loss = 1508966467.52386856\n",
            "Iteration 573, loss = 1508908529.38135576\n",
            "Iteration 574, loss = 1508850494.70338273\n",
            "Iteration 575, loss = 1508792615.45142365\n",
            "Iteration 576, loss = 1508734981.40759349\n",
            "Iteration 577, loss = 1508677517.35648203\n",
            "Iteration 578, loss = 1508620130.44667888\n",
            "Iteration 579, loss = 1508562861.62332201\n",
            "Iteration 580, loss = 1508505709.98503947\n",
            "Iteration 581, loss = 1508448576.31308460\n",
            "Iteration 582, loss = 1508391525.51649547\n",
            "Iteration 583, loss = 1508334505.54101348\n",
            "Iteration 584, loss = 1508277473.91305399\n",
            "Iteration 585, loss = 1508220639.40169096\n",
            "Iteration 586, loss = 1508163766.59200191\n",
            "Iteration 587, loss = 1508106890.49590158\n",
            "Iteration 588, loss = 1508050424.55573726\n",
            "Iteration 589, loss = 1507993878.53538966\n",
            "Iteration 590, loss = 1507937502.51479483\n",
            "Iteration 591, loss = 1507881152.46600938\n",
            "Iteration 592, loss = 1507825453.59265137\n",
            "Iteration 593, loss = 1507769446.55465770\n",
            "Iteration 594, loss = 1507712890.46705890\n",
            "Iteration 595, loss = 1507657156.33273196\n",
            "Iteration 596, loss = 1507601369.39389277\n",
            "Iteration 597, loss = 1507545474.40279269\n",
            "Iteration 598, loss = 1507489057.57044482\n",
            "Iteration 599, loss = 1507433612.79752159\n",
            "Iteration 600, loss = 1507377484.29182315\n",
            "Iteration 601, loss = 1507321484.58226418\n",
            "Iteration 602, loss = 1507265827.57607484\n",
            "Iteration 603, loss = 1507209882.25383878\n",
            "Iteration 604, loss = 1507154342.71415973\n",
            "Iteration 605, loss = 1507098364.48890948\n",
            "Iteration 606, loss = 1507042809.71103907\n",
            "Iteration 607, loss = 1506987072.94145870\n",
            "Iteration 608, loss = 1506931252.92125010\n",
            "Iteration 609, loss = 1506875486.01407647\n",
            "Iteration 610, loss = 1506819986.48568034\n",
            "Iteration 611, loss = 1506764329.73067713\n",
            "Iteration 612, loss = 1506708687.56505775\n",
            "Iteration 613, loss = 1506652888.69853878\n",
            "Iteration 614, loss = 1506597274.51717830\n",
            "Iteration 615, loss = 1506542022.08849883\n",
            "Iteration 616, loss = 1506486351.70199728\n",
            "Iteration 617, loss = 1506430632.41924071\n",
            "Iteration 618, loss = 1506375152.10756779\n",
            "Iteration 619, loss = 1506319982.88137174\n",
            "Iteration 620, loss = 1506264449.88377452\n",
            "Iteration 621, loss = 1506208974.66183162\n",
            "Iteration 622, loss = 1506153850.71016502\n",
            "Iteration 623, loss = 1506098718.42339635\n",
            "Iteration 624, loss = 1506043223.52309728\n",
            "Iteration 625, loss = 1505988074.59797049\n",
            "Iteration 626, loss = 1505932954.06746149\n",
            "Iteration 627, loss = 1505877745.54753232\n",
            "Iteration 628, loss = 1505822690.83028412\n",
            "Iteration 629, loss = 1505767666.30942011\n",
            "Iteration 630, loss = 1505712576.12937975\n",
            "Iteration 631, loss = 1505657569.26905036\n",
            "Iteration 632, loss = 1505602758.34501052\n",
            "Iteration 633, loss = 1505547708.52505565\n",
            "Iteration 634, loss = 1505492875.44181490\n",
            "Iteration 635, loss = 1505438126.50284839\n",
            "Iteration 636, loss = 1505383198.58070755\n",
            "Iteration 637, loss = 1505328449.20520020\n",
            "Iteration 638, loss = 1505273539.37023687\n",
            "Iteration 639, loss = 1505219030.44676352\n",
            "Iteration 640, loss = 1505164702.78543115\n",
            "Iteration 641, loss = 1505109790.56326199\n",
            "Iteration 642, loss = 1505055475.14376235\n",
            "Iteration 643, loss = 1505001234.30604601\n",
            "Iteration 644, loss = 1504947154.54536843\n",
            "Iteration 645, loss = 1504892718.62319660\n",
            "Iteration 646, loss = 1504838672.15040612\n",
            "Iteration 647, loss = 1504784224.47355032\n",
            "Iteration 648, loss = 1504730268.53514314\n",
            "Iteration 649, loss = 1504675828.17852926\n",
            "Iteration 650, loss = 1504621418.23310447\n",
            "Iteration 651, loss = 1504567144.24723577\n",
            "Iteration 652, loss = 1504512354.44284749\n",
            "Iteration 653, loss = 1504458244.20159197\n",
            "Iteration 654, loss = 1504403069.25789237\n",
            "Iteration 655, loss = 1504348873.61184263\n",
            "Iteration 656, loss = 1504293922.73204827\n",
            "Iteration 657, loss = 1504239478.89536285\n",
            "Iteration 658, loss = 1504184530.04903483\n",
            "Iteration 659, loss = 1504129918.45027423\n",
            "Iteration 660, loss = 1504075096.14745569\n",
            "Iteration 661, loss = 1504020538.72389197\n",
            "Iteration 662, loss = 1503965813.05651188\n",
            "Iteration 663, loss = 1503911131.06080270\n",
            "Iteration 664, loss = 1503856661.96232367\n",
            "Iteration 665, loss = 1503801949.25114989\n",
            "Iteration 666, loss = 1503747415.75550914\n",
            "Iteration 667, loss = 1503692890.04558134\n",
            "Iteration 668, loss = 1503638834.66388249\n",
            "Iteration 669, loss = 1503584375.53450704\n",
            "Iteration 670, loss = 1503530162.02599788\n",
            "Iteration 671, loss = 1503475799.53540087\n",
            "Iteration 672, loss = 1503421719.73336196\n",
            "Iteration 673, loss = 1503367607.78319168\n",
            "Iteration 674, loss = 1503313124.61115313\n",
            "Iteration 675, loss = 1503259015.08049297\n",
            "Iteration 676, loss = 1503204691.42498326\n",
            "Iteration 677, loss = 1503150589.42356944\n",
            "Iteration 678, loss = 1503096254.04270864\n",
            "Iteration 679, loss = 1503042306.17006874\n",
            "Iteration 680, loss = 1502988373.59883022\n",
            "Iteration 681, loss = 1502934317.12316656\n",
            "Iteration 682, loss = 1502880778.92769551\n",
            "Iteration 683, loss = 1502826749.95306063\n",
            "Iteration 684, loss = 1502773358.79832816\n",
            "Iteration 685, loss = 1502719228.09148073\n",
            "Iteration 686, loss = 1502665590.52433777\n",
            "Iteration 687, loss = 1502612204.67317152\n",
            "Iteration 688, loss = 1502558188.25266910\n",
            "Iteration 689, loss = 1502504466.10824776\n",
            "Iteration 690, loss = 1502450618.58066940\n",
            "Iteration 691, loss = 1502397120.02118874\n",
            "Iteration 692, loss = 1502343476.37413526\n",
            "Iteration 693, loss = 1502289670.99309421\n",
            "Iteration 694, loss = 1502235935.45960951\n",
            "Iteration 695, loss = 1502182276.41287470\n",
            "Iteration 696, loss = 1502128327.17489552\n",
            "Iteration 697, loss = 1502075002.46466637\n",
            "Iteration 698, loss = 1502020867.85323215\n",
            "Iteration 699, loss = 1501967133.82239461\n",
            "Iteration 700, loss = 1501913263.48271441\n",
            "Iteration 701, loss = 1501859146.24388385\n",
            "Iteration 702, loss = 1501799684.29935718\n",
            "Iteration 703, loss = 1501739340.86078334\n",
            "Iteration 704, loss = 1501680724.01724052\n",
            "Iteration 705, loss = 1501621249.22313094\n",
            "Iteration 706, loss = 1501561428.01853204\n",
            "Iteration 707, loss = 1501501918.90006089\n",
            "Iteration 708, loss = 1501441689.26246333\n",
            "Iteration 709, loss = 1501382004.98065114\n",
            "Iteration 710, loss = 1501322506.60443854\n",
            "Iteration 711, loss = 1501262423.62589693\n",
            "Iteration 712, loss = 1501203295.64678216\n",
            "Iteration 713, loss = 1501143457.56574440\n",
            "Iteration 714, loss = 1501084522.19678164\n",
            "Iteration 715, loss = 1501025467.82946420\n",
            "Iteration 716, loss = 1500966348.43393111\n",
            "Iteration 717, loss = 1500907746.17696357\n",
            "Iteration 718, loss = 1500848825.06573939\n",
            "Iteration 719, loss = 1500790197.77278709\n",
            "Iteration 720, loss = 1500731753.78953862\n",
            "Iteration 721, loss = 1500673360.17906046\n",
            "Iteration 722, loss = 1500615118.53829503\n",
            "Iteration 723, loss = 1500557029.70665574\n",
            "Iteration 724, loss = 1500499081.42565680\n",
            "Iteration 725, loss = 1500441255.60358548\n",
            "Iteration 726, loss = 1500383587.65868187\n",
            "Iteration 727, loss = 1500325450.35368299\n",
            "Iteration 728, loss = 1500268635.61836171\n",
            "Iteration 729, loss = 1500210499.58574581\n",
            "Iteration 730, loss = 1500153438.48284245\n",
            "Iteration 731, loss = 1500095587.66608047\n",
            "Iteration 732, loss = 1500038500.02727175\n",
            "Iteration 733, loss = 1499981232.89012742\n",
            "Iteration 734, loss = 1499924212.33582520\n",
            "Iteration 735, loss = 1499867116.90387654\n",
            "Iteration 736, loss = 1499810268.30663490\n",
            "Iteration 737, loss = 1499753159.05405068\n",
            "Iteration 738, loss = 1499696372.83341765\n",
            "Iteration 739, loss = 1499640265.32995462\n",
            "Iteration 740, loss = 1499583017.55428004\n",
            "Iteration 741, loss = 1499526468.19643378\n",
            "Iteration 742, loss = 1499470082.93831944\n",
            "Iteration 743, loss = 1499413398.78188753\n",
            "Iteration 744, loss = 1499356959.03197813\n",
            "Iteration 745, loss = 1499300624.46181679\n",
            "Iteration 746, loss = 1499244267.61171865\n",
            "Iteration 747, loss = 1499187789.47662187\n",
            "Iteration 748, loss = 1499131506.50101829\n",
            "Iteration 749, loss = 1499075185.49038601\n",
            "Iteration 750, loss = 1499019082.37688923\n",
            "Iteration 751, loss = 1498962795.01082850\n",
            "Iteration 752, loss = 1498906767.47593999\n",
            "Iteration 753, loss = 1498850317.15971446\n",
            "Iteration 754, loss = 1498794246.13410139\n",
            "Iteration 755, loss = 1498738251.07627654\n",
            "Iteration 756, loss = 1498682046.39906693\n",
            "Iteration 757, loss = 1498625670.17024922\n",
            "Iteration 758, loss = 1498569834.27685642\n",
            "Iteration 759, loss = 1498513596.15258932\n",
            "Iteration 760, loss = 1498457519.56195140\n",
            "Iteration 761, loss = 1498401634.07797527\n",
            "Iteration 762, loss = 1498345467.96381068\n",
            "Iteration 763, loss = 1498289585.13577437\n",
            "Iteration 764, loss = 1498233604.21348405\n",
            "Iteration 765, loss = 1498177849.23444414\n",
            "Iteration 766, loss = 1498121631.95235133\n",
            "Iteration 767, loss = 1498065717.43887448\n",
            "Iteration 768, loss = 1498009481.46451521\n",
            "Iteration 769, loss = 1497953850.65315747\n",
            "Iteration 770, loss = 1497897628.98895383\n",
            "Iteration 771, loss = 1497841580.59306860\n",
            "Iteration 772, loss = 1497785633.85650849\n",
            "Iteration 773, loss = 1497729787.18614125\n",
            "Iteration 774, loss = 1497673470.91744971\n",
            "Iteration 775, loss = 1497617679.29645085\n",
            "Iteration 776, loss = 1497561649.44880009\n",
            "Iteration 777, loss = 1497506024.45686460\n",
            "Iteration 778, loss = 1497449705.45508385\n",
            "Iteration 779, loss = 1497394052.34188986\n",
            "Iteration 780, loss = 1497338072.04032826\n",
            "Iteration 781, loss = 1497282368.05303240\n",
            "Iteration 782, loss = 1497226550.98274255\n",
            "Iteration 783, loss = 1497171027.88699603\n",
            "Iteration 784, loss = 1497115609.74198198\n",
            "Iteration 785, loss = 1497059957.57901073\n",
            "Iteration 786, loss = 1497004611.99204493\n",
            "Iteration 787, loss = 1496948948.31426597\n",
            "Iteration 788, loss = 1496894044.14878106\n",
            "Iteration 789, loss = 1496838103.44659042\n",
            "Iteration 790, loss = 1496782821.71248317\n",
            "Iteration 791, loss = 1496727116.27236581\n",
            "Iteration 792, loss = 1496671420.68060088\n",
            "Iteration 793, loss = 1496615614.96607471\n",
            "Iteration 794, loss = 1496559956.33216715\n",
            "Iteration 795, loss = 1496504366.39801264\n",
            "Iteration 796, loss = 1496448781.86569047\n",
            "Iteration 797, loss = 1496393025.59297776\n",
            "Iteration 798, loss = 1496337838.22761416\n",
            "Iteration 799, loss = 1496282411.95678163\n",
            "Iteration 800, loss = 1496227048.40862584\n",
            "Iteration 801, loss = 1496172022.35599589\n",
            "Iteration 802, loss = 1496116833.05661774\n",
            "Iteration 803, loss = 1496061479.73929167\n",
            "Iteration 804, loss = 1496006681.75677562\n",
            "Iteration 805, loss = 1495951291.74463439\n",
            "Iteration 806, loss = 1495896577.29814386\n",
            "Iteration 807, loss = 1495841295.28482175\n",
            "Iteration 808, loss = 1495786168.57723355\n",
            "Iteration 809, loss = 1495731162.18937445\n",
            "Iteration 810, loss = 1495676272.33716941\n",
            "Iteration 811, loss = 1495621312.45933938\n",
            "Iteration 812, loss = 1495566325.76829600\n",
            "Iteration 813, loss = 1495511285.21757364\n",
            "Iteration 814, loss = 1495456272.24324274\n",
            "Iteration 815, loss = 1495401679.30527878\n",
            "Iteration 816, loss = 1495346249.02711082\n",
            "Iteration 817, loss = 1495291401.69207025\n",
            "Iteration 818, loss = 1495236083.62265301\n",
            "Iteration 819, loss = 1495180883.03353930\n",
            "Iteration 820, loss = 1495125757.07481122\n",
            "Iteration 821, loss = 1495070531.47707677\n",
            "Iteration 822, loss = 1495015674.23301744\n",
            "Iteration 823, loss = 1494960226.10632229\n",
            "Iteration 824, loss = 1494905216.92125320\n",
            "Iteration 825, loss = 1494850310.21756506\n",
            "Iteration 826, loss = 1494794981.58150458\n",
            "Iteration 827, loss = 1494739791.87643123\n",
            "Iteration 828, loss = 1494684393.06136537\n",
            "Iteration 829, loss = 1494629435.01079226\n",
            "Iteration 830, loss = 1494573744.45511460\n",
            "Iteration 831, loss = 1494518711.24786401\n",
            "Iteration 832, loss = 1494463408.82220006\n",
            "Iteration 833, loss = 1494408228.41950226\n",
            "Iteration 834, loss = 1494353089.04530501\n",
            "Iteration 835, loss = 1494298311.58754182\n",
            "Iteration 836, loss = 1494243062.20343375\n",
            "Iteration 837, loss = 1494187996.58798647\n",
            "Iteration 838, loss = 1494132946.71740055\n",
            "Iteration 839, loss = 1494078184.41214919\n",
            "Iteration 840, loss = 1494023105.44717383\n",
            "Iteration 841, loss = 1493968061.71079040\n",
            "Iteration 842, loss = 1493913165.89472318\n",
            "Iteration 843, loss = 1493858272.04762292\n",
            "Iteration 844, loss = 1493803604.00232983\n",
            "Iteration 845, loss = 1493748779.33703947\n",
            "Iteration 846, loss = 1493694131.56736827\n",
            "Iteration 847, loss = 1493639627.12738848\n",
            "Iteration 848, loss = 1493585092.74258041\n",
            "Iteration 849, loss = 1493530622.41338968\n",
            "Iteration 850, loss = 1493475939.27946687\n",
            "Iteration 851, loss = 1493421632.74655247\n",
            "Iteration 852, loss = 1493367125.71949959\n",
            "Iteration 853, loss = 1493312473.12662172\n",
            "Iteration 854, loss = 1493258164.94817924\n",
            "Iteration 855, loss = 1493203715.37729263\n",
            "Iteration 856, loss = 1493148848.37801576\n",
            "Iteration 857, loss = 1493094693.22812748\n",
            "Iteration 858, loss = 1493039871.34431362\n",
            "Iteration 859, loss = 1492985245.48653412\n",
            "Iteration 860, loss = 1492930915.41353250\n",
            "Iteration 861, loss = 1492876320.70638299\n",
            "Iteration 862, loss = 1492821428.46609354\n",
            "Iteration 863, loss = 1492767170.82769203\n",
            "Iteration 864, loss = 1492712590.95893002\n",
            "Iteration 865, loss = 1492657746.85115790\n",
            "Iteration 866, loss = 1492603163.30124378\n",
            "Iteration 867, loss = 1492548376.68751240\n",
            "Iteration 868, loss = 1492493359.36065936\n",
            "Iteration 869, loss = 1492438545.09455132\n",
            "Iteration 870, loss = 1492383752.18374848\n",
            "Iteration 871, loss = 1492329045.37795544\n",
            "Iteration 872, loss = 1492273834.39898467\n",
            "Iteration 873, loss = 1492219098.31144834\n",
            "Iteration 874, loss = 1492164368.49169517\n",
            "Iteration 875, loss = 1492109595.55375624\n",
            "Iteration 876, loss = 1492054929.64207053\n",
            "Iteration 877, loss = 1492000135.97759104\n",
            "Iteration 878, loss = 1491945970.76159143\n",
            "Iteration 879, loss = 1491891491.20943642\n",
            "Iteration 880, loss = 1491837149.49285960\n",
            "Iteration 881, loss = 1491782965.34061503\n",
            "Iteration 882, loss = 1491728818.38184881\n",
            "Iteration 883, loss = 1491674270.68075943\n",
            "Iteration 884, loss = 1491620218.23589635\n",
            "Iteration 885, loss = 1491565979.31520152\n",
            "Iteration 886, loss = 1491511971.28872800\n",
            "Iteration 887, loss = 1491457607.33585382\n",
            "Iteration 888, loss = 1491403615.37675428\n",
            "Iteration 889, loss = 1491349749.86016250\n",
            "Iteration 890, loss = 1491295640.28441501\n",
            "Iteration 891, loss = 1491242208.27253366\n",
            "Iteration 892, loss = 1491188010.36351180\n",
            "Iteration 893, loss = 1491134592.46544957\n",
            "Iteration 894, loss = 1491080794.73435354\n",
            "Iteration 895, loss = 1491026835.88384938\n",
            "Iteration 896, loss = 1490972827.06368113\n",
            "Iteration 897, loss = 1490919338.92803884\n",
            "Iteration 898, loss = 1490864960.05043244\n",
            "Iteration 899, loss = 1490811053.40041423\n",
            "Iteration 900, loss = 1490756645.11711144\n",
            "Iteration 901, loss = 1490702357.63055873\n",
            "Iteration 902, loss = 1490647983.51821518\n",
            "Iteration 903, loss = 1490594065.69540811\n",
            "Iteration 904, loss = 1490539538.08094358\n",
            "Iteration 905, loss = 1490485593.25423384\n",
            "Iteration 906, loss = 1490431106.29897237\n",
            "Iteration 907, loss = 1490377403.75760150\n",
            "Iteration 908, loss = 1490323251.04383373\n",
            "Iteration 909, loss = 1490269020.45748830\n",
            "Iteration 910, loss = 1490214875.35152888\n",
            "Iteration 911, loss = 1490160932.66095853\n",
            "Iteration 912, loss = 1490106380.34321308\n",
            "Iteration 913, loss = 1490052615.97098970\n",
            "Iteration 914, loss = 1489998352.48306870\n",
            "Iteration 915, loss = 1489944452.05131483\n",
            "Iteration 916, loss = 1489890145.87036848\n",
            "Iteration 917, loss = 1489836161.00984693\n",
            "Iteration 918, loss = 1489782251.77361202\n",
            "Iteration 919, loss = 1489728180.12090945\n",
            "Iteration 920, loss = 1489673938.73971391\n",
            "Iteration 921, loss = 1489620206.06937194\n",
            "Iteration 922, loss = 1489566366.65341902\n",
            "Iteration 923, loss = 1489511958.66189647\n",
            "Iteration 924, loss = 1489458320.67283702\n",
            "Iteration 925, loss = 1489404195.63027477\n",
            "Iteration 926, loss = 1489350764.06113243\n",
            "Iteration 927, loss = 1489296095.82193565\n",
            "Iteration 928, loss = 1489242553.21213245\n",
            "Iteration 929, loss = 1489188439.40532255\n",
            "Iteration 930, loss = 1489134546.58513498\n",
            "Iteration 931, loss = 1489080454.95730495\n",
            "Iteration 932, loss = 1489026875.46755862\n",
            "Iteration 933, loss = 1488972990.21356750\n",
            "Iteration 934, loss = 1488919133.91434503\n",
            "Iteration 935, loss = 1488865257.53117752\n",
            "Iteration 936, loss = 1488811540.78333807\n",
            "Iteration 937, loss = 1488757599.35483217\n",
            "Iteration 938, loss = 1488703551.94872022\n",
            "Iteration 939, loss = 1488649841.20248270\n",
            "Iteration 940, loss = 1488595583.82831454\n",
            "Iteration 941, loss = 1488542007.30159879\n",
            "Iteration 942, loss = 1488487700.86859918\n",
            "Iteration 943, loss = 1488434155.26232171\n",
            "Iteration 944, loss = 1488379831.48524618\n",
            "Iteration 945, loss = 1488325947.10961747\n",
            "Iteration 946, loss = 1488272143.52519512\n",
            "Iteration 947, loss = 1488218138.33427405\n",
            "Iteration 948, loss = 1488164162.48617196\n",
            "Iteration 949, loss = 1488110362.19757533\n",
            "Iteration 950, loss = 1488056656.31229329\n",
            "Iteration 951, loss = 1488003055.50640893\n",
            "Iteration 952, loss = 1487948981.02350950\n",
            "Iteration 953, loss = 1487895531.75337195\n",
            "Iteration 954, loss = 1487842166.57412839\n",
            "Iteration 955, loss = 1487788366.63578749\n",
            "Iteration 956, loss = 1487734850.02735901\n",
            "Iteration 957, loss = 1487680962.63679767\n",
            "Iteration 958, loss = 1487627438.22897267\n",
            "Iteration 959, loss = 1487573992.93635464\n",
            "Iteration 960, loss = 1487520176.97604966\n",
            "Iteration 961, loss = 1487466795.52698350\n",
            "Iteration 962, loss = 1487412966.17380810\n",
            "Iteration 963, loss = 1487359305.45102692\n",
            "Iteration 964, loss = 1487305934.62926340\n",
            "Iteration 965, loss = 1487252248.76776242\n",
            "Iteration 966, loss = 1487198687.62793374\n",
            "Iteration 967, loss = 1487145078.27978897\n",
            "Iteration 968, loss = 1487091360.35887885\n",
            "Iteration 969, loss = 1487037813.37566066\n",
            "Iteration 970, loss = 1486984050.88723087\n",
            "Iteration 971, loss = 1486930596.56702685\n",
            "Iteration 972, loss = 1486876682.86230969\n",
            "Iteration 973, loss = 1486822843.43633509\n",
            "Iteration 974, loss = 1486769642.55860686\n",
            "Iteration 975, loss = 1486715425.09084654\n",
            "Iteration 976, loss = 1486661987.07623887\n",
            "Iteration 977, loss = 1486608592.95522666\n",
            "Iteration 978, loss = 1486554749.96412921\n",
            "Iteration 979, loss = 1486501004.83367634\n",
            "Iteration 980, loss = 1486447591.85828137\n",
            "Iteration 981, loss = 1486393976.39564466\n",
            "Iteration 982, loss = 1486340301.64260530\n",
            "Iteration 983, loss = 1486286556.36424828\n",
            "Iteration 984, loss = 1486232879.36191225\n",
            "Iteration 985, loss = 1486179126.30422211\n",
            "Iteration 986, loss = 1486125221.03449392\n",
            "Iteration 987, loss = 1486071693.64852619\n",
            "Iteration 988, loss = 1486017471.87440753\n",
            "Iteration 989, loss = 1485963959.11738825\n",
            "Iteration 990, loss = 1485910374.17497921\n",
            "Iteration 991, loss = 1485856452.83414006\n",
            "Iteration 992, loss = 1485802341.14130139\n",
            "Iteration 993, loss = 1485748987.67042279\n",
            "Iteration 994, loss = 1485695317.37108803\n",
            "Iteration 995, loss = 1485641394.32961726\n",
            "Iteration 996, loss = 1485587816.38443756\n",
            "Iteration 997, loss = 1485534281.87749314\n",
            "Iteration 998, loss = 1485480658.39820194\n",
            "Iteration 999, loss = 1485426888.02588010\n",
            "Iteration 1000, loss = 1485373193.92988706\n",
            "Iteration 1, loss = 1428317518.17661238\n",
            "Iteration 2, loss = 252277274.82464558\n",
            "Iteration 3, loss = 231218532.35305667\n",
            "Iteration 4, loss = 279380362.38739145\n",
            "Iteration 5, loss = 122889959.44187294\n",
            "Iteration 6, loss = 105217615.54128471\n",
            "Iteration 7, loss = 118965366.96982624\n",
            "Iteration 8, loss = 102671639.71342915\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 9, loss = 95788340.75340870\n",
            "Iteration 10, loss = 97746105.35617726\n",
            "Iteration 11, loss = 98350358.51713441\n",
            "Iteration 12, loss = 96455342.06720369\n",
            "Iteration 13, loss = 95764295.50904326\n",
            "Iteration 14, loss = 95985541.97436871\n",
            "Iteration 15, loss = 95652715.98133002\n",
            "Iteration 16, loss = 95920571.75453475\n",
            "Iteration 17, loss = 95923137.74452503\n",
            "Iteration 18, loss = 97319827.68902707\n",
            "Iteration 19, loss = 96597155.68147972\n",
            "Iteration 20, loss = 95785303.23189591\n",
            "Iteration 21, loss = 95736469.16238166\n",
            "Iteration 22, loss = 95642633.28559610\n",
            "Iteration 23, loss = 95864200.23900673\n",
            "Iteration 24, loss = 96255246.28716983\n",
            "Iteration 25, loss = 96108510.43750626\n",
            "Iteration 26, loss = 95749353.03216201\n",
            "Iteration 27, loss = 96001216.83691557\n",
            "Iteration 28, loss = 96029871.47569774\n",
            "Iteration 29, loss = 96095393.12560104\n",
            "Iteration 30, loss = 95630328.57735561\n",
            "Iteration 31, loss = 96176693.03510021\n",
            "Iteration 32, loss = 95891188.45917220\n",
            "Iteration 33, loss = 95617930.39062081\n",
            "Iteration 34, loss = 96152169.29506347\n",
            "Iteration 35, loss = 96302537.42027235\n",
            "Iteration 36, loss = 96162512.85212347\n",
            "Iteration 37, loss = 96330391.74217990\n",
            "Iteration 38, loss = 96531437.41617560\n",
            "Iteration 39, loss = 96101794.20091662\n",
            "Iteration 40, loss = 96030201.03140578\n",
            "Iteration 41, loss = 95850348.01946381\n",
            "Iteration 42, loss = 95681933.80090900\n",
            "Iteration 43, loss = 95666851.81708983\n",
            "Iteration 44, loss = 95681973.76236418\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538787478.27960277\n",
            "Iteration 2, loss = 1538702586.50669289\n",
            "Iteration 3, loss = 1538631736.30065346\n",
            "Iteration 4, loss = 1538578134.05662894\n",
            "Iteration 5, loss = 1538532818.13865829\n",
            "Iteration 6, loss = 1538490228.44322228\n",
            "Iteration 7, loss = 1538448980.64471769\n",
            "Iteration 8, loss = 1538408252.84915018\n",
            "Iteration 9, loss = 1538366405.46634054\n",
            "Iteration 10, loss = 1538323037.20640087\n",
            "Iteration 11, loss = 1538278024.37933087\n",
            "Iteration 12, loss = 1538232184.28359127\n",
            "Iteration 13, loss = 1538186585.30846572\n",
            "Iteration 14, loss = 1538141018.96490502\n",
            "Iteration 15, loss = 1538094690.29489946\n",
            "Iteration 16, loss = 1538047725.22398210\n",
            "Iteration 17, loss = 1538000669.35931110\n",
            "Iteration 18, loss = 1537954078.63981581\n",
            "Iteration 19, loss = 1537907789.67736959\n",
            "Iteration 20, loss = 1537861649.15033221\n",
            "Iteration 21, loss = 1537815878.56886482\n",
            "Iteration 22, loss = 1537769849.31454325\n",
            "Iteration 23, loss = 1537723696.12166929\n",
            "Iteration 24, loss = 1537677790.43869543\n",
            "Iteration 25, loss = 1537631667.50894499\n",
            "Iteration 26, loss = 1537585336.94273710\n",
            "Iteration 27, loss = 1537538554.16610980\n",
            "Iteration 28, loss = 1537489886.41055870\n",
            "Iteration 29, loss = 1537441530.37467599\n",
            "Iteration 30, loss = 1537393633.36114478\n",
            "Iteration 31, loss = 1537346677.80653906\n",
            "Iteration 32, loss = 1537299434.90348315\n",
            "Iteration 33, loss = 1537252221.61332703\n",
            "Iteration 34, loss = 1537205352.96544981\n",
            "Iteration 35, loss = 1537158113.91830420\n",
            "Iteration 36, loss = 1537110801.27333641\n",
            "Iteration 37, loss = 1537062007.82164788\n",
            "Iteration 38, loss = 1537012327.36270404\n",
            "Iteration 39, loss = 1536963685.61277747\n",
            "Iteration 40, loss = 1536915137.75752401\n",
            "Iteration 41, loss = 1536866935.93898702\n",
            "Iteration 42, loss = 1536818659.35773492\n",
            "Iteration 43, loss = 1536770107.75505185\n",
            "Iteration 44, loss = 1536721156.36269569\n",
            "Iteration 45, loss = 1536671270.51560855\n",
            "Iteration 46, loss = 1536619628.25342631\n",
            "Iteration 47, loss = 1536568521.38179088\n",
            "Iteration 48, loss = 1536518583.17130804\n",
            "Iteration 49, loss = 1536468477.74009252\n",
            "Iteration 50, loss = 1536418832.78762650\n",
            "Iteration 51, loss = 1536368772.36627960\n",
            "Iteration 52, loss = 1536319026.36362863\n",
            "Iteration 53, loss = 1536269500.68698454\n",
            "Iteration 54, loss = 1536220007.35199833\n",
            "Iteration 55, loss = 1536170620.10411477\n",
            "Iteration 56, loss = 1536120964.67062259\n",
            "Iteration 57, loss = 1536071675.88814735\n",
            "Iteration 58, loss = 1536021791.74481416\n",
            "Iteration 59, loss = 1535970423.59012270\n",
            "Iteration 60, loss = 1535917391.78256416\n",
            "Iteration 61, loss = 1535865379.65835762\n",
            "Iteration 62, loss = 1535814382.87789583\n",
            "Iteration 63, loss = 1535762950.23749638\n",
            "Iteration 64, loss = 1535711675.85531282\n",
            "Iteration 65, loss = 1535660431.82667756\n",
            "Iteration 66, loss = 1535609346.40028286\n",
            "Iteration 67, loss = 1535558263.27188635\n",
            "Iteration 68, loss = 1535507233.31824493\n",
            "Iteration 69, loss = 1535456392.26196003\n",
            "Iteration 70, loss = 1535405527.96362686\n",
            "Iteration 71, loss = 1535354823.33120012\n",
            "Iteration 72, loss = 1535304199.62731504\n",
            "Iteration 73, loss = 1535253623.11250043\n",
            "Iteration 74, loss = 1535203096.69267988\n",
            "Iteration 75, loss = 1535152435.31788182\n",
            "Iteration 76, loss = 1535102614.28377414\n",
            "Iteration 77, loss = 1535052101.58862638\n",
            "Iteration 78, loss = 1535002046.18848419\n",
            "Iteration 79, loss = 1534952346.11168909\n",
            "Iteration 80, loss = 1534902351.41197896\n",
            "Iteration 81, loss = 1534852865.82007861\n",
            "Iteration 82, loss = 1534803083.82096314\n",
            "Iteration 83, loss = 1534753509.17704654\n",
            "Iteration 84, loss = 1534703862.83861446\n",
            "Iteration 85, loss = 1534654283.11220407\n",
            "Iteration 86, loss = 1534604809.25971508\n",
            "Iteration 87, loss = 1534555051.94567442\n",
            "Iteration 88, loss = 1534505573.66075802\n",
            "Iteration 89, loss = 1534456109.60700607\n",
            "Iteration 90, loss = 1534406525.82942271\n",
            "Iteration 91, loss = 1534357139.83964086\n",
            "Iteration 92, loss = 1534307684.22000408\n",
            "Iteration 93, loss = 1534258431.36422276\n",
            "Iteration 94, loss = 1534209204.96873903\n",
            "Iteration 95, loss = 1534160082.62202597\n",
            "Iteration 96, loss = 1534110858.95863867\n",
            "Iteration 97, loss = 1534061707.84865594\n",
            "Iteration 98, loss = 1534012666.57842660\n",
            "Iteration 99, loss = 1533963597.18158960\n",
            "Iteration 100, loss = 1533914101.99855208\n",
            "Iteration 101, loss = 1533865228.07236958\n",
            "Iteration 102, loss = 1533816158.33865118\n",
            "Iteration 103, loss = 1533766750.78878617\n",
            "Iteration 104, loss = 1533717893.78538132\n",
            "Iteration 105, loss = 1533668891.31871557\n",
            "Iteration 106, loss = 1533619780.75540805\n",
            "Iteration 107, loss = 1533571198.44916177\n",
            "Iteration 108, loss = 1533521916.42982054\n",
            "Iteration 109, loss = 1533473624.12784028\n",
            "Iteration 110, loss = 1533424505.37238359\n",
            "Iteration 111, loss = 1533375793.06611323\n",
            "Iteration 112, loss = 1533327315.07416558\n",
            "Iteration 113, loss = 1533278711.39962435\n",
            "Iteration 114, loss = 1533229969.35852242\n",
            "Iteration 115, loss = 1533181337.79762650\n",
            "Iteration 116, loss = 1533132898.04149961\n",
            "Iteration 117, loss = 1533084231.51319098\n",
            "Iteration 118, loss = 1533035858.89792323\n",
            "Iteration 119, loss = 1532986939.53667212\n",
            "Iteration 120, loss = 1532938408.33082676\n",
            "Iteration 121, loss = 1532889888.73332596\n",
            "Iteration 122, loss = 1532841256.31624389\n",
            "Iteration 123, loss = 1532792487.18533707\n",
            "Iteration 124, loss = 1532744162.74061060\n",
            "Iteration 125, loss = 1532695759.44917798\n",
            "Iteration 126, loss = 1532647089.69459510\n",
            "Iteration 127, loss = 1532599223.12994862\n",
            "Iteration 128, loss = 1532550959.70135474\n",
            "Iteration 129, loss = 1532502708.40706944\n",
            "Iteration 130, loss = 1532454450.21161389\n",
            "Iteration 131, loss = 1532406564.94022322\n",
            "Iteration 132, loss = 1532358150.94889617\n",
            "Iteration 133, loss = 1532309855.83912396\n",
            "Iteration 134, loss = 1532262036.93406510\n",
            "Iteration 135, loss = 1532213652.10604477\n",
            "Iteration 136, loss = 1532165325.66155148\n",
            "Iteration 137, loss = 1532117277.57767701\n",
            "Iteration 138, loss = 1532069046.06678700\n",
            "Iteration 139, loss = 1532020782.79561043\n",
            "Iteration 140, loss = 1531972626.59619641\n",
            "Iteration 141, loss = 1531924193.31419230\n",
            "Iteration 142, loss = 1531876222.36523199\n",
            "Iteration 143, loss = 1531827562.91964960\n",
            "Iteration 144, loss = 1531779305.11394358\n",
            "Iteration 145, loss = 1531730844.30706978\n",
            "Iteration 146, loss = 1531682483.27503896\n",
            "Iteration 147, loss = 1531633928.47960138\n",
            "Iteration 148, loss = 1531585623.47353411\n",
            "Iteration 149, loss = 1531537182.55722523\n",
            "Iteration 150, loss = 1531488540.43868947\n",
            "Iteration 151, loss = 1531440507.14635539\n",
            "Iteration 152, loss = 1531392068.76724553\n",
            "Iteration 153, loss = 1531343781.88973927\n",
            "Iteration 154, loss = 1531295806.05982232\n",
            "Iteration 155, loss = 1531247430.02802515\n",
            "Iteration 156, loss = 1531199530.58887410\n",
            "Iteration 157, loss = 1531151101.70468068\n",
            "Iteration 158, loss = 1531103416.99933076\n",
            "Iteration 159, loss = 1531055051.13726354\n",
            "Iteration 160, loss = 1531007114.57295918\n",
            "Iteration 161, loss = 1530959044.45971298\n",
            "Iteration 162, loss = 1530911130.34075189\n",
            "Iteration 163, loss = 1530863079.40411401\n",
            "Iteration 164, loss = 1530815006.24080491\n",
            "Iteration 165, loss = 1530766929.06163478\n",
            "Iteration 166, loss = 1530719212.75192595\n",
            "Iteration 167, loss = 1530671150.53510976\n",
            "Iteration 168, loss = 1530622942.88064432\n",
            "Iteration 169, loss = 1530575072.69329023\n",
            "Iteration 170, loss = 1530527207.97399545\n",
            "Iteration 171, loss = 1530479198.33770823\n",
            "Iteration 172, loss = 1530431292.57436872\n",
            "Iteration 173, loss = 1530383284.75879455\n",
            "Iteration 174, loss = 1530335601.93298006\n",
            "Iteration 175, loss = 1530287610.70708370\n",
            "Iteration 176, loss = 1530239578.51761770\n",
            "Iteration 177, loss = 1530191746.94838524\n",
            "Iteration 178, loss = 1530143683.91646671\n",
            "Iteration 179, loss = 1530096085.86152792\n",
            "Iteration 180, loss = 1530047959.88798428\n",
            "Iteration 181, loss = 1530000260.08521700\n",
            "Iteration 182, loss = 1529952169.95835137\n",
            "Iteration 183, loss = 1529904393.84116387\n",
            "Iteration 184, loss = 1529856634.01126146\n",
            "Iteration 185, loss = 1529808679.18511319\n",
            "Iteration 186, loss = 1529761053.99657559\n",
            "Iteration 187, loss = 1529713141.86521029\n",
            "Iteration 188, loss = 1529665635.43366861\n",
            "Iteration 189, loss = 1529617679.10970521\n",
            "Iteration 190, loss = 1529569982.28936744\n",
            "Iteration 191, loss = 1529522329.04755545\n",
            "Iteration 192, loss = 1529474447.53384209\n",
            "Iteration 193, loss = 1529426812.44013691\n",
            "Iteration 194, loss = 1529378933.30693483\n",
            "Iteration 195, loss = 1529331397.49920559\n",
            "Iteration 196, loss = 1529283523.38541293\n",
            "Iteration 197, loss = 1529236050.31410408\n",
            "Iteration 198, loss = 1529188424.39319491\n",
            "Iteration 199, loss = 1529140746.82510662\n",
            "Iteration 200, loss = 1529092966.12769890\n",
            "Iteration 201, loss = 1529045617.43976140\n",
            "Iteration 202, loss = 1528997815.95934105\n",
            "Iteration 203, loss = 1528949872.20052695\n",
            "Iteration 204, loss = 1528902253.13492179\n",
            "Iteration 205, loss = 1528854217.23731709\n",
            "Iteration 206, loss = 1528806513.32555032\n",
            "Iteration 207, loss = 1528758245.76118660\n",
            "Iteration 208, loss = 1528710558.56007361\n",
            "Iteration 209, loss = 1528662721.54763460\n",
            "Iteration 210, loss = 1528614809.38923430\n",
            "Iteration 211, loss = 1528567062.70091915\n",
            "Iteration 212, loss = 1528519219.14958167\n",
            "Iteration 213, loss = 1528471704.16280556\n",
            "Iteration 214, loss = 1528423694.17778182\n",
            "Iteration 215, loss = 1528376481.51812482\n",
            "Iteration 216, loss = 1528328500.99970436\n",
            "Iteration 217, loss = 1528280973.45492220\n",
            "Iteration 218, loss = 1528233119.74179697\n",
            "Iteration 219, loss = 1528185460.54786658\n",
            "Iteration 220, loss = 1528137558.06654882\n",
            "Iteration 221, loss = 1528089758.79520893\n",
            "Iteration 222, loss = 1528042020.03803611\n",
            "Iteration 223, loss = 1527994400.12586331\n",
            "Iteration 224, loss = 1527946316.63569808\n",
            "Iteration 225, loss = 1527898780.95207644\n",
            "Iteration 226, loss = 1527851116.70010233\n",
            "Iteration 227, loss = 1527803382.40288854\n",
            "Iteration 228, loss = 1527755684.76227689\n",
            "Iteration 229, loss = 1527707762.57623315\n",
            "Iteration 230, loss = 1527660125.49400401\n",
            "Iteration 231, loss = 1527612062.21771908\n",
            "Iteration 232, loss = 1527564238.92610264\n",
            "Iteration 233, loss = 1527516513.34134722\n",
            "Iteration 234, loss = 1527468777.43275785\n",
            "Iteration 235, loss = 1527420891.40486932\n",
            "Iteration 236, loss = 1527373293.18821955\n",
            "Iteration 237, loss = 1527325669.44401765\n",
            "Iteration 238, loss = 1527278003.89150763\n",
            "Iteration 239, loss = 1527230588.19667959\n",
            "Iteration 240, loss = 1527182705.31082439\n",
            "Iteration 241, loss = 1527134919.72720146\n",
            "Iteration 242, loss = 1527087440.97454667\n",
            "Iteration 243, loss = 1527039566.89489794\n",
            "Iteration 244, loss = 1526991836.14903045\n",
            "Iteration 245, loss = 1526944071.36795354\n",
            "Iteration 246, loss = 1526896432.55099106\n",
            "Iteration 247, loss = 1526848820.29325676\n",
            "Iteration 248, loss = 1526800984.52734184\n",
            "Iteration 249, loss = 1526753734.15141797\n",
            "Iteration 250, loss = 1526705998.55894351\n",
            "Iteration 251, loss = 1526658903.16898131\n",
            "Iteration 252, loss = 1526611065.52480030\n",
            "Iteration 253, loss = 1526563439.50451994\n",
            "Iteration 254, loss = 1526516226.03645968\n",
            "Iteration 255, loss = 1526468137.92112207\n",
            "Iteration 256, loss = 1526420673.00473833\n",
            "Iteration 257, loss = 1526372918.17233491\n",
            "Iteration 258, loss = 1526325142.92313766\n",
            "Iteration 259, loss = 1526277492.25019693\n",
            "Iteration 260, loss = 1526230029.20577264\n",
            "Iteration 261, loss = 1526182215.36916971\n",
            "Iteration 262, loss = 1526134641.30468559\n",
            "Iteration 263, loss = 1526087345.03340697\n",
            "Iteration 264, loss = 1526039721.56538081\n",
            "Iteration 265, loss = 1525992074.91932464\n",
            "Iteration 266, loss = 1525944591.21253991\n",
            "Iteration 267, loss = 1525896869.11447430\n",
            "Iteration 268, loss = 1525849369.34221578\n",
            "Iteration 269, loss = 1525801920.03707719\n",
            "Iteration 270, loss = 1525754407.09404469\n",
            "Iteration 271, loss = 1525707055.76308775\n",
            "Iteration 272, loss = 1525659508.54989457\n",
            "Iteration 273, loss = 1525612301.78996778\n",
            "Iteration 274, loss = 1525564978.95811343\n",
            "Iteration 275, loss = 1525517483.89534187\n",
            "Iteration 276, loss = 1525469942.30338955\n",
            "Iteration 277, loss = 1525422880.22196460\n",
            "Iteration 278, loss = 1525375114.97581458\n",
            "Iteration 279, loss = 1525327826.11639190\n",
            "Iteration 280, loss = 1525280395.19685125\n",
            "Iteration 281, loss = 1525233100.77193809\n",
            "Iteration 282, loss = 1525185282.38166094\n",
            "Iteration 283, loss = 1525138239.57909465\n",
            "Iteration 284, loss = 1525090758.72437239\n",
            "Iteration 285, loss = 1525043472.77451038\n",
            "Iteration 286, loss = 1524995665.56907129\n",
            "Iteration 287, loss = 1524948698.61201644\n",
            "Iteration 288, loss = 1524901191.37155032\n",
            "Iteration 289, loss = 1524853908.00900483\n",
            "Iteration 290, loss = 1524806431.33295894\n",
            "Iteration 291, loss = 1524759531.72064710\n",
            "Iteration 292, loss = 1524711683.01832223\n",
            "Iteration 293, loss = 1524664619.63534713\n",
            "Iteration 294, loss = 1524617231.80074263\n",
            "Iteration 295, loss = 1524570176.13497329\n",
            "Iteration 296, loss = 1524522769.61989808\n",
            "Iteration 297, loss = 1524475452.96028233\n",
            "Iteration 298, loss = 1524428233.96200871\n",
            "Iteration 299, loss = 1524380894.64318991\n",
            "Iteration 300, loss = 1524333544.27128315\n",
            "Iteration 301, loss = 1524286547.02328849\n",
            "Iteration 302, loss = 1524239217.14734983\n",
            "Iteration 303, loss = 1524191932.64173508\n",
            "Iteration 304, loss = 1524145054.52976084\n",
            "Iteration 305, loss = 1524097937.53548217\n",
            "Iteration 306, loss = 1524050764.06364298\n",
            "Iteration 307, loss = 1524003473.19332576\n",
            "Iteration 308, loss = 1523956652.90764928\n",
            "Iteration 309, loss = 1523909282.17400742\n",
            "Iteration 310, loss = 1523862469.48681617\n",
            "Iteration 311, loss = 1523815100.01471305\n",
            "Iteration 312, loss = 1523767737.09195733\n",
            "Iteration 313, loss = 1523720985.71573329\n",
            "Iteration 314, loss = 1523673709.51313043\n",
            "Iteration 315, loss = 1523626319.85030389\n",
            "Iteration 316, loss = 1523579304.13724399\n",
            "Iteration 317, loss = 1523532011.87553668\n",
            "Iteration 318, loss = 1523484844.55888605\n",
            "Iteration 319, loss = 1523437565.93193984\n",
            "Iteration 320, loss = 1523390233.41575122\n",
            "Iteration 321, loss = 1523342812.25771618\n",
            "Iteration 322, loss = 1523295762.76877117\n",
            "Iteration 323, loss = 1523248343.62878776\n",
            "Iteration 324, loss = 1523201213.02392936\n",
            "Iteration 325, loss = 1523153676.49120378\n",
            "Iteration 326, loss = 1523106557.74258184\n",
            "Iteration 327, loss = 1523059376.94536257\n",
            "Iteration 328, loss = 1523011858.77806425\n",
            "Iteration 329, loss = 1522964342.88111567\n",
            "Iteration 330, loss = 1522917192.31964183\n",
            "Iteration 331, loss = 1522870105.38563514\n",
            "Iteration 332, loss = 1522822514.45814013\n",
            "Iteration 333, loss = 1522775097.52045941\n",
            "Iteration 334, loss = 1522727922.14540005\n",
            "Iteration 335, loss = 1522680654.73822331\n",
            "Iteration 336, loss = 1522633413.63076115\n",
            "Iteration 337, loss = 1522586060.40239286\n",
            "Iteration 338, loss = 1522539059.82050896\n",
            "Iteration 339, loss = 1522491866.83701873\n",
            "Iteration 340, loss = 1522444839.07946944\n",
            "Iteration 341, loss = 1522397442.31805825\n",
            "Iteration 342, loss = 1522350856.75946903\n",
            "Iteration 343, loss = 1522303314.66254067\n",
            "Iteration 344, loss = 1522256138.59337854\n",
            "Iteration 345, loss = 1522208131.73994422\n",
            "Iteration 346, loss = 1522156116.03507996\n",
            "Iteration 347, loss = 1522104021.66216350\n",
            "Iteration 348, loss = 1522052363.41846204\n",
            "Iteration 349, loss = 1522000850.55444670\n",
            "Iteration 350, loss = 1521948735.60649347\n",
            "Iteration 351, loss = 1521896644.04062128\n",
            "Iteration 352, loss = 1521844703.21892190\n",
            "Iteration 353, loss = 1521792223.14654851\n",
            "Iteration 354, loss = 1521740405.01406693\n",
            "Iteration 355, loss = 1521688364.98643351\n",
            "Iteration 356, loss = 1521636356.49733734\n",
            "Iteration 357, loss = 1521584289.46015763\n",
            "Iteration 358, loss = 1521532834.57944655\n",
            "Iteration 359, loss = 1521480909.04301548\n",
            "Iteration 360, loss = 1521429285.76068783\n",
            "Iteration 361, loss = 1521377863.35456896\n",
            "Iteration 362, loss = 1521326428.60009098\n",
            "Iteration 363, loss = 1521275154.49911237\n",
            "Iteration 364, loss = 1521223882.94363928\n",
            "Iteration 365, loss = 1521172330.12990451\n",
            "Iteration 366, loss = 1521121390.53293991\n",
            "Iteration 367, loss = 1521069747.55569506\n",
            "Iteration 368, loss = 1521019286.55606842\n",
            "Iteration 369, loss = 1520967933.28830957\n",
            "Iteration 370, loss = 1520917236.37633204\n",
            "Iteration 371, loss = 1520866277.30664396\n",
            "Iteration 372, loss = 1520815853.60420752\n",
            "Iteration 373, loss = 1520765098.50064731\n",
            "Iteration 374, loss = 1520714923.83718300\n",
            "Iteration 375, loss = 1520664303.12608528\n",
            "Iteration 376, loss = 1520614238.88819933\n",
            "Iteration 377, loss = 1520563882.69402933\n",
            "Iteration 378, loss = 1520513488.68056202\n",
            "Iteration 379, loss = 1520463722.22682381\n",
            "Iteration 380, loss = 1520413276.54568434\n",
            "Iteration 381, loss = 1520363197.34566092\n",
            "Iteration 382, loss = 1520312963.99278569\n",
            "Iteration 383, loss = 1520262835.65312195\n",
            "Iteration 384, loss = 1520212746.16090226\n",
            "Iteration 385, loss = 1520162610.85421777\n",
            "Iteration 386, loss = 1520112424.29149604\n",
            "Iteration 387, loss = 1520062664.59632850\n",
            "Iteration 388, loss = 1520012421.83498478\n",
            "Iteration 389, loss = 1519962511.22136545\n",
            "Iteration 390, loss = 1519912015.93128228\n",
            "Iteration 391, loss = 1519859654.18795085\n",
            "Iteration 392, loss = 1519803190.94678020\n",
            "Iteration 393, loss = 1519749064.41140366\n",
            "Iteration 394, loss = 1519694618.80595016\n",
            "Iteration 395, loss = 1519639679.98972559\n",
            "Iteration 396, loss = 1519584960.52220225\n",
            "Iteration 397, loss = 1519530075.03784466\n",
            "Iteration 398, loss = 1519475278.57368636\n",
            "Iteration 399, loss = 1519420366.60483050\n",
            "Iteration 400, loss = 1519365752.10637999\n",
            "Iteration 401, loss = 1519311625.88349152\n",
            "Iteration 402, loss = 1519257077.62477088\n",
            "Iteration 403, loss = 1519203102.48218966\n",
            "Iteration 404, loss = 1519148937.67827582\n",
            "Iteration 405, loss = 1519094967.56035781\n",
            "Iteration 406, loss = 1519041104.27224779\n",
            "Iteration 407, loss = 1518987448.76893663\n",
            "Iteration 408, loss = 1518933936.45703936\n",
            "Iteration 409, loss = 1518880268.58978271\n",
            "Iteration 410, loss = 1518827024.44338560\n",
            "Iteration 411, loss = 1518773779.96698499\n",
            "Iteration 412, loss = 1518720433.20103192\n",
            "Iteration 413, loss = 1518667176.65865588\n",
            "Iteration 414, loss = 1518614475.86875248\n",
            "Iteration 415, loss = 1518561249.73828030\n",
            "Iteration 416, loss = 1518508033.43688035\n",
            "Iteration 417, loss = 1518455006.54121757\n",
            "Iteration 418, loss = 1518401796.95669460\n",
            "Iteration 419, loss = 1518345549.55169702\n",
            "Iteration 420, loss = 1518285938.76368523\n",
            "Iteration 421, loss = 1518228632.23738694\n",
            "Iteration 422, loss = 1518171101.30402470\n",
            "Iteration 423, loss = 1518113306.40052891\n",
            "Iteration 424, loss = 1518055570.74471307\n",
            "Iteration 425, loss = 1517997864.89658666\n",
            "Iteration 426, loss = 1517940167.86801958\n",
            "Iteration 427, loss = 1517883030.87920499\n",
            "Iteration 428, loss = 1517825538.16080523\n",
            "Iteration 429, loss = 1517768532.96387386\n",
            "Iteration 430, loss = 1517711463.93719029\n",
            "Iteration 431, loss = 1517654960.55222631\n",
            "Iteration 432, loss = 1517598519.50996256\n",
            "Iteration 433, loss = 1517542326.50957847\n",
            "Iteration 434, loss = 1517486047.38386440\n",
            "Iteration 435, loss = 1517430511.16396260\n",
            "Iteration 436, loss = 1517374916.22802377\n",
            "Iteration 437, loss = 1517319478.00736356\n",
            "Iteration 438, loss = 1517263935.57028031\n",
            "Iteration 439, loss = 1517208884.58755660\n",
            "Iteration 440, loss = 1517153656.06590390\n",
            "Iteration 441, loss = 1517098676.94689679\n",
            "Iteration 442, loss = 1517043144.78663325\n",
            "Iteration 443, loss = 1516988348.21434951\n",
            "Iteration 444, loss = 1516933161.40878654\n",
            "Iteration 445, loss = 1516878286.87347817\n",
            "Iteration 446, loss = 1516823399.82306457\n",
            "Iteration 447, loss = 1516768583.17387772\n",
            "Iteration 448, loss = 1516713346.57811952\n",
            "Iteration 449, loss = 1516659165.09891820\n",
            "Iteration 450, loss = 1516604257.52906728\n",
            "Iteration 451, loss = 1516549351.40656304\n",
            "Iteration 452, loss = 1516494934.55191684\n",
            "Iteration 453, loss = 1516440759.15755415\n",
            "Iteration 454, loss = 1516386141.39945102\n",
            "Iteration 455, loss = 1516331799.45644903\n",
            "Iteration 456, loss = 1516277714.80018234\n",
            "Iteration 457, loss = 1516223545.89348698\n",
            "Iteration 458, loss = 1516169355.89422584\n",
            "Iteration 459, loss = 1516115129.10100889\n",
            "Iteration 460, loss = 1516061257.13367128\n",
            "Iteration 461, loss = 1516007269.55540204\n",
            "Iteration 462, loss = 1515953034.31204581\n",
            "Iteration 463, loss = 1515899168.17407203\n",
            "Iteration 464, loss = 1515845461.81852603\n",
            "Iteration 465, loss = 1515791236.57697248\n",
            "Iteration 466, loss = 1515737590.74729037\n",
            "Iteration 467, loss = 1515683828.09977674\n",
            "Iteration 468, loss = 1515629695.22612643\n",
            "Iteration 469, loss = 1515576311.70215034\n",
            "Iteration 470, loss = 1515522075.16714644\n",
            "Iteration 471, loss = 1515468783.64748216\n",
            "Iteration 472, loss = 1515414843.16026545\n",
            "Iteration 473, loss = 1515361420.45071101\n",
            "Iteration 474, loss = 1515307761.73548198\n",
            "Iteration 475, loss = 1515254297.53957224\n",
            "Iteration 476, loss = 1515200511.42980433\n",
            "Iteration 477, loss = 1515147265.75574613\n",
            "Iteration 478, loss = 1515093925.25094342\n",
            "Iteration 479, loss = 1515040415.72654533\n",
            "Iteration 480, loss = 1514987004.23690319\n",
            "Iteration 481, loss = 1514934110.84551215\n",
            "Iteration 482, loss = 1514880642.33318615\n",
            "Iteration 483, loss = 1514827905.43966746\n",
            "Iteration 484, loss = 1514774459.94501472\n",
            "Iteration 485, loss = 1514721435.84315562\n",
            "Iteration 486, loss = 1514668927.04206395\n",
            "Iteration 487, loss = 1514615676.20346260\n",
            "Iteration 488, loss = 1514562960.45383430\n",
            "Iteration 489, loss = 1514510063.28293085\n",
            "Iteration 490, loss = 1514457500.43266392\n",
            "Iteration 491, loss = 1514404679.49258780\n",
            "Iteration 492, loss = 1514351993.40523410\n",
            "Iteration 493, loss = 1514299049.95003200\n",
            "Iteration 494, loss = 1514246421.40716195\n",
            "Iteration 495, loss = 1514193437.19389796\n",
            "Iteration 496, loss = 1514140596.77423525\n",
            "Iteration 497, loss = 1514087372.52382755\n",
            "Iteration 498, loss = 1514034804.17469931\n",
            "Iteration 499, loss = 1513981504.26511121\n",
            "Iteration 500, loss = 1513928618.92823291\n",
            "Iteration 501, loss = 1513875635.07403922\n",
            "Iteration 502, loss = 1513822728.39226007\n",
            "Iteration 503, loss = 1513769949.31038880\n",
            "Iteration 504, loss = 1513717427.83246017\n",
            "Iteration 505, loss = 1513664631.55779767\n",
            "Iteration 506, loss = 1513612159.26945686\n",
            "Iteration 507, loss = 1513559738.60290027\n",
            "Iteration 508, loss = 1513507447.74802971\n",
            "Iteration 509, loss = 1513454851.58613992\n",
            "Iteration 510, loss = 1513402403.05501819\n",
            "Iteration 511, loss = 1513350288.51683545\n",
            "Iteration 512, loss = 1513297952.56734371\n",
            "Iteration 513, loss = 1513245530.12562108\n",
            "Iteration 514, loss = 1513193230.07699823\n",
            "Iteration 515, loss = 1513141231.09898949\n",
            "Iteration 516, loss = 1513088541.98174739\n",
            "Iteration 517, loss = 1513036609.09488511\n",
            "Iteration 518, loss = 1512984419.57227206\n",
            "Iteration 519, loss = 1512932086.77315259\n",
            "Iteration 520, loss = 1512880024.58171248\n",
            "Iteration 521, loss = 1512828057.58620310\n",
            "Iteration 522, loss = 1512775791.46421218\n",
            "Iteration 523, loss = 1512724057.50844598\n",
            "Iteration 524, loss = 1512672074.00598145\n",
            "Iteration 525, loss = 1512620158.03219223\n",
            "Iteration 526, loss = 1512568033.87825346\n",
            "Iteration 527, loss = 1512516516.07301807\n",
            "Iteration 528, loss = 1512464504.97155213\n",
            "Iteration 529, loss = 1512412996.73254633\n",
            "Iteration 530, loss = 1512361404.64222479\n",
            "Iteration 531, loss = 1512309796.90174317\n",
            "Iteration 532, loss = 1512258144.81855726\n",
            "Iteration 533, loss = 1512206807.70799375\n",
            "Iteration 534, loss = 1512155105.92323780\n",
            "Iteration 535, loss = 1512103561.63863778\n",
            "Iteration 536, loss = 1512051694.29923081\n",
            "Iteration 537, loss = 1512000191.28156972\n",
            "Iteration 538, loss = 1511948057.02792835\n",
            "Iteration 539, loss = 1511896360.76728272\n",
            "Iteration 540, loss = 1511844124.35926223\n",
            "Iteration 541, loss = 1511792455.37936378\n",
            "Iteration 542, loss = 1511740407.35327959\n",
            "Iteration 543, loss = 1511688435.86209059\n",
            "Iteration 544, loss = 1511636515.09780407\n",
            "Iteration 545, loss = 1511584700.57880521\n",
            "Iteration 546, loss = 1511533224.95618629\n",
            "Iteration 547, loss = 1511481189.18066549\n",
            "Iteration 548, loss = 1511429402.13977480\n",
            "Iteration 549, loss = 1511377880.91701460\n",
            "Iteration 550, loss = 1511326427.38419676\n",
            "Iteration 551, loss = 1511274605.18701029\n",
            "Iteration 552, loss = 1511223190.06244659\n",
            "Iteration 553, loss = 1511171424.51002979\n",
            "Iteration 554, loss = 1511119846.02976990\n",
            "Iteration 555, loss = 1511068291.06105423\n",
            "Iteration 556, loss = 1511016553.64933038\n",
            "Iteration 557, loss = 1510965159.49784446\n",
            "Iteration 558, loss = 1510913321.67559767\n",
            "Iteration 559, loss = 1510861949.44375873\n",
            "Iteration 560, loss = 1510810490.28275323\n",
            "Iteration 561, loss = 1510759199.77346706\n",
            "Iteration 562, loss = 1510707458.02873921\n",
            "Iteration 563, loss = 1510656389.21485639\n",
            "Iteration 564, loss = 1510604702.17835546\n",
            "Iteration 565, loss = 1510553395.96318507\n",
            "Iteration 566, loss = 1510501433.11904764\n",
            "Iteration 567, loss = 1510450073.15342045\n",
            "Iteration 568, loss = 1510398586.72779417\n",
            "Iteration 569, loss = 1510346602.34866190\n",
            "Iteration 570, loss = 1510295212.02859664\n",
            "Iteration 571, loss = 1510243689.52120471\n",
            "Iteration 572, loss = 1510191766.79243565\n",
            "Iteration 573, loss = 1510139995.54425573\n",
            "Iteration 574, loss = 1510088197.28845358\n",
            "Iteration 575, loss = 1510036565.16930580\n",
            "Iteration 576, loss = 1509984905.04416013\n",
            "Iteration 577, loss = 1509932969.61301517\n",
            "Iteration 578, loss = 1509881144.65716076\n",
            "Iteration 579, loss = 1509829466.64767838\n",
            "Iteration 580, loss = 1509777530.49132633\n",
            "Iteration 581, loss = 1509725884.85046506\n",
            "Iteration 582, loss = 1509673867.60989690\n",
            "Iteration 583, loss = 1509621400.57401991\n",
            "Iteration 584, loss = 1509563515.50018334\n",
            "Iteration 585, loss = 1509505744.10892844\n",
            "Iteration 586, loss = 1509449118.87986708\n",
            "Iteration 587, loss = 1509391894.40222311\n",
            "Iteration 588, loss = 1509335080.68110585\n",
            "Iteration 589, loss = 1509277196.19604421\n",
            "Iteration 590, loss = 1509220243.21778512\n",
            "Iteration 591, loss = 1509162918.49456239\n",
            "Iteration 592, loss = 1509105877.90639257\n",
            "Iteration 593, loss = 1509048758.09325194\n",
            "Iteration 594, loss = 1508992280.07670450\n",
            "Iteration 595, loss = 1508935107.17029214\n",
            "Iteration 596, loss = 1508878875.59180927\n",
            "Iteration 597, loss = 1508822439.29406738\n",
            "Iteration 598, loss = 1508766169.44770384\n",
            "Iteration 599, loss = 1508710139.46713924\n",
            "Iteration 600, loss = 1508654014.83662510\n",
            "Iteration 601, loss = 1508598355.14658213\n",
            "Iteration 602, loss = 1508543004.86397386\n",
            "Iteration 603, loss = 1508487132.62859964\n",
            "Iteration 604, loss = 1508432025.23884773\n",
            "Iteration 605, loss = 1508376658.15009260\n",
            "Iteration 606, loss = 1508321730.83418775\n",
            "Iteration 607, loss = 1508266394.79038787\n",
            "Iteration 608, loss = 1508211792.27388597\n",
            "Iteration 609, loss = 1508156760.13037109\n",
            "Iteration 610, loss = 1508102059.05073929\n",
            "Iteration 611, loss = 1508046454.04221225\n",
            "Iteration 612, loss = 1507985876.86773682\n",
            "Iteration 613, loss = 1507924972.45469594\n",
            "Iteration 614, loss = 1507865558.74653983\n",
            "Iteration 615, loss = 1507805485.27226353\n",
            "Iteration 616, loss = 1507744780.88152766\n",
            "Iteration 617, loss = 1507684522.60250044\n",
            "Iteration 618, loss = 1507624204.40664434\n",
            "Iteration 619, loss = 1507563209.13835096\n",
            "Iteration 620, loss = 1507503101.65893126\n",
            "Iteration 621, loss = 1507442889.59621429\n",
            "Iteration 622, loss = 1507382930.14896274\n",
            "Iteration 623, loss = 1507322591.39911771\n",
            "Iteration 624, loss = 1507263183.95226097\n",
            "Iteration 625, loss = 1507203578.45338488\n",
            "Iteration 626, loss = 1507144103.93929267\n",
            "Iteration 627, loss = 1507085213.67554498\n",
            "Iteration 628, loss = 1507026016.81287885\n",
            "Iteration 629, loss = 1506967373.04287100\n",
            "Iteration 630, loss = 1506908697.27503014\n",
            "Iteration 631, loss = 1506850463.34709525\n",
            "Iteration 632, loss = 1506791990.05813646\n",
            "Iteration 633, loss = 1506733686.71980572\n",
            "Iteration 634, loss = 1506675777.76425004\n",
            "Iteration 635, loss = 1506617696.25913906\n",
            "Iteration 636, loss = 1506559373.76752162\n",
            "Iteration 637, loss = 1506501713.17568827\n",
            "Iteration 638, loss = 1506443721.71472692\n",
            "Iteration 639, loss = 1506385837.21020198\n",
            "Iteration 640, loss = 1506328346.71335721\n",
            "Iteration 641, loss = 1506270536.45971179\n",
            "Iteration 642, loss = 1506213043.79232359\n",
            "Iteration 643, loss = 1506155646.14389944\n",
            "Iteration 644, loss = 1506098436.34239173\n",
            "Iteration 645, loss = 1506040895.88234353\n",
            "Iteration 646, loss = 1505983754.06788325\n",
            "Iteration 647, loss = 1505926583.59705234\n",
            "Iteration 648, loss = 1505869717.02210617\n",
            "Iteration 649, loss = 1505812290.90492415\n",
            "Iteration 650, loss = 1505755633.79755545\n",
            "Iteration 651, loss = 1505698911.87951016\n",
            "Iteration 652, loss = 1505641936.20644569\n",
            "Iteration 653, loss = 1505585158.71612763\n",
            "Iteration 654, loss = 1505528784.59476376\n",
            "Iteration 655, loss = 1505472273.72535729\n",
            "Iteration 656, loss = 1505415595.67477942\n",
            "Iteration 657, loss = 1505359418.22398543\n",
            "Iteration 658, loss = 1505302736.93686438\n",
            "Iteration 659, loss = 1505246468.57287049\n",
            "Iteration 660, loss = 1505190129.47044253\n",
            "Iteration 661, loss = 1505133856.69359088\n",
            "Iteration 662, loss = 1505077270.44341874\n",
            "Iteration 663, loss = 1505021157.38646531\n",
            "Iteration 664, loss = 1504964963.23781872\n",
            "Iteration 665, loss = 1504908442.70055914\n",
            "Iteration 666, loss = 1504852517.63391662\n",
            "Iteration 667, loss = 1504796056.16245008\n",
            "Iteration 668, loss = 1504739984.58304524\n",
            "Iteration 669, loss = 1504683946.08657193\n",
            "Iteration 670, loss = 1504628099.76329613\n",
            "Iteration 671, loss = 1504571995.84652662\n",
            "Iteration 672, loss = 1504516481.27722287\n",
            "Iteration 673, loss = 1504460500.97536135\n",
            "Iteration 674, loss = 1504405274.03895760\n",
            "Iteration 675, loss = 1504349556.74480605\n",
            "Iteration 676, loss = 1504293902.85275102\n",
            "Iteration 677, loss = 1504238247.08692765\n",
            "Iteration 678, loss = 1504182710.42724752\n",
            "Iteration 679, loss = 1504127234.62943316\n",
            "Iteration 680, loss = 1504071451.80122209\n",
            "Iteration 681, loss = 1504015941.56872368\n",
            "Iteration 682, loss = 1503960895.80883431\n",
            "Iteration 683, loss = 1503905105.82074928\n",
            "Iteration 684, loss = 1503849688.19881892\n",
            "Iteration 685, loss = 1503794882.03168583\n",
            "Iteration 686, loss = 1503739208.12957406\n",
            "Iteration 687, loss = 1503683946.06248856\n",
            "Iteration 688, loss = 1503628557.22706699\n",
            "Iteration 689, loss = 1503573116.76379848\n",
            "Iteration 690, loss = 1503518066.62647820\n",
            "Iteration 691, loss = 1503462401.27344894\n",
            "Iteration 692, loss = 1503407126.79333711\n",
            "Iteration 693, loss = 1503351286.32269955\n",
            "Iteration 694, loss = 1503296018.13188910\n",
            "Iteration 695, loss = 1503240519.30595660\n",
            "Iteration 696, loss = 1503185239.69105268\n",
            "Iteration 697, loss = 1503129443.04038095\n",
            "Iteration 698, loss = 1503074031.00280643\n",
            "Iteration 699, loss = 1503019076.87671542\n",
            "Iteration 700, loss = 1502963376.86218476\n",
            "Iteration 701, loss = 1502908713.65655136\n",
            "Iteration 702, loss = 1502853304.68676090\n",
            "Iteration 703, loss = 1502798376.92145848\n",
            "Iteration 704, loss = 1502743540.59583616\n",
            "Iteration 705, loss = 1502688876.69037962\n",
            "Iteration 706, loss = 1502634370.78656340\n",
            "Iteration 707, loss = 1502579312.57438064\n",
            "Iteration 708, loss = 1502524604.58933496\n",
            "Iteration 709, loss = 1502469968.62545991\n",
            "Iteration 710, loss = 1502414940.48580265\n",
            "Iteration 711, loss = 1502360326.20505619\n",
            "Iteration 712, loss = 1502304972.94592333\n",
            "Iteration 713, loss = 1502250316.67497253\n",
            "Iteration 714, loss = 1502195040.00919223\n",
            "Iteration 715, loss = 1502140059.22830796\n",
            "Iteration 716, loss = 1502085578.36552024\n",
            "Iteration 717, loss = 1502030574.93140244\n",
            "Iteration 718, loss = 1501975844.92695904\n",
            "Iteration 719, loss = 1501921325.98526263\n",
            "Iteration 720, loss = 1501867188.75277424\n",
            "Iteration 721, loss = 1501812612.21740580\n",
            "Iteration 722, loss = 1501758654.44915056\n",
            "Iteration 723, loss = 1501704459.10950685\n",
            "Iteration 724, loss = 1501650196.46919656\n",
            "Iteration 725, loss = 1501596024.22298074\n",
            "Iteration 726, loss = 1501541768.70332098\n",
            "Iteration 727, loss = 1501487752.51846552\n",
            "Iteration 728, loss = 1501433348.66517234\n",
            "Iteration 729, loss = 1501379243.34327173\n",
            "Iteration 730, loss = 1501324785.01459765\n",
            "Iteration 731, loss = 1501270713.71164298\n",
            "Iteration 732, loss = 1501216705.82987142\n",
            "Iteration 733, loss = 1501162451.11842370\n",
            "Iteration 734, loss = 1501108442.26669598\n",
            "Iteration 735, loss = 1501054336.42464638\n",
            "Iteration 736, loss = 1501000316.50216317\n",
            "Iteration 737, loss = 1500945649.66081357\n",
            "Iteration 738, loss = 1500892038.72527027\n",
            "Iteration 739, loss = 1500837599.46740699\n",
            "Iteration 740, loss = 1500783424.09355497\n",
            "Iteration 741, loss = 1500729133.19780493\n",
            "Iteration 742, loss = 1500675115.88118601\n",
            "Iteration 743, loss = 1500620812.29254055\n",
            "Iteration 744, loss = 1500566896.37833786\n",
            "Iteration 745, loss = 1500512602.63237333\n",
            "Iteration 746, loss = 1500458501.65484357\n",
            "Iteration 747, loss = 1500404571.40813208\n",
            "Iteration 748, loss = 1500350479.90054536\n",
            "Iteration 749, loss = 1500296851.55011773\n",
            "Iteration 750, loss = 1500242653.90543628\n",
            "Iteration 751, loss = 1500189231.22636747\n",
            "Iteration 752, loss = 1500135388.86175370\n",
            "Iteration 753, loss = 1500081635.15811110\n",
            "Iteration 754, loss = 1500027939.79736352\n",
            "Iteration 755, loss = 1499974354.40149665\n",
            "Iteration 756, loss = 1499920519.19536138\n",
            "Iteration 757, loss = 1499866871.49176979\n",
            "Iteration 758, loss = 1499813170.34053087\n",
            "Iteration 759, loss = 1499759274.40675974\n",
            "Iteration 760, loss = 1499705670.93618488\n",
            "Iteration 761, loss = 1499651716.15793347\n",
            "Iteration 762, loss = 1499597898.25174022\n",
            "Iteration 763, loss = 1499543898.34027815\n",
            "Iteration 764, loss = 1499489877.87128901\n",
            "Iteration 765, loss = 1499436122.31923437\n",
            "Iteration 766, loss = 1499382019.99706173\n",
            "Iteration 767, loss = 1499327613.45790696\n",
            "Iteration 768, loss = 1499273654.98803425\n",
            "Iteration 769, loss = 1499219379.32597184\n",
            "Iteration 770, loss = 1499165568.15322495\n",
            "Iteration 771, loss = 1499111289.86928701\n",
            "Iteration 772, loss = 1499057218.54174685\n",
            "Iteration 773, loss = 1499003413.82177496\n",
            "Iteration 774, loss = 1498949303.63235569\n",
            "Iteration 775, loss = 1498895463.05339313\n",
            "Iteration 776, loss = 1498841640.33970523\n",
            "Iteration 777, loss = 1498787614.36949110\n",
            "Iteration 778, loss = 1498734242.29063702\n",
            "Iteration 779, loss = 1498680007.84952617\n",
            "Iteration 780, loss = 1498626765.87758040\n",
            "Iteration 781, loss = 1498572758.92696357\n",
            "Iteration 782, loss = 1498518859.65725756\n",
            "Iteration 783, loss = 1498465650.04953933\n",
            "Iteration 784, loss = 1498411877.51308918\n",
            "Iteration 785, loss = 1498358189.92801785\n",
            "Iteration 786, loss = 1498304768.60989785\n",
            "Iteration 787, loss = 1498251429.78911996\n",
            "Iteration 788, loss = 1498197970.73225570\n",
            "Iteration 789, loss = 1498144705.47256303\n",
            "Iteration 790, loss = 1498091324.01129389\n",
            "Iteration 791, loss = 1498038315.43250489\n",
            "Iteration 792, loss = 1497984713.68961477\n",
            "Iteration 793, loss = 1497931609.66599941\n",
            "Iteration 794, loss = 1497878232.02293873\n",
            "Iteration 795, loss = 1497824985.55866838\n",
            "Iteration 796, loss = 1497771571.37156034\n",
            "Iteration 797, loss = 1497717688.78306842\n",
            "Iteration 798, loss = 1497664402.42703438\n",
            "Iteration 799, loss = 1497610355.49433446\n",
            "Iteration 800, loss = 1497556819.30708170\n",
            "Iteration 801, loss = 1497502938.98397541\n",
            "Iteration 802, loss = 1497449242.14404035\n",
            "Iteration 803, loss = 1497395581.87352085\n",
            "Iteration 804, loss = 1497341709.52798915\n",
            "Iteration 805, loss = 1497288131.96251893\n",
            "Iteration 806, loss = 1497234669.24694133\n",
            "Iteration 807, loss = 1497181316.39328218\n",
            "Iteration 808, loss = 1497127772.12337899\n",
            "Iteration 809, loss = 1497074633.30431938\n",
            "Iteration 810, loss = 1497021218.98092055\n",
            "Iteration 811, loss = 1496967928.73344588\n",
            "Iteration 812, loss = 1496915127.10914946\n",
            "Iteration 813, loss = 1496861816.43701768\n",
            "Iteration 814, loss = 1496808859.15512943\n",
            "Iteration 815, loss = 1496755797.21499920\n",
            "Iteration 816, loss = 1496702813.51413035\n",
            "Iteration 817, loss = 1496649705.48269820\n",
            "Iteration 818, loss = 1496596854.29283237\n",
            "Iteration 819, loss = 1496543720.37201786\n",
            "Iteration 820, loss = 1496490657.54082155\n",
            "Iteration 821, loss = 1496437582.17262197\n",
            "Iteration 822, loss = 1496384943.98769808\n",
            "Iteration 823, loss = 1496331513.58188152\n",
            "Iteration 824, loss = 1496278697.47229004\n",
            "Iteration 825, loss = 1496225167.04697299\n",
            "Iteration 826, loss = 1496171958.36378717\n",
            "Iteration 827, loss = 1496118880.93805647\n",
            "Iteration 828, loss = 1496065235.03158021\n",
            "Iteration 829, loss = 1496011986.71355605\n",
            "Iteration 830, loss = 1495958575.75355506\n",
            "Iteration 831, loss = 1495905362.51941729\n",
            "Iteration 832, loss = 1495852131.33281231\n",
            "Iteration 833, loss = 1495798878.18015528\n",
            "Iteration 834, loss = 1495746198.21593523\n",
            "Iteration 835, loss = 1495692425.09311914\n",
            "Iteration 836, loss = 1495639965.81973529\n",
            "Iteration 837, loss = 1495586274.81170750\n",
            "Iteration 838, loss = 1495533362.38156223\n",
            "Iteration 839, loss = 1495480284.85478950\n",
            "Iteration 840, loss = 1495426910.79281950\n",
            "Iteration 841, loss = 1495373635.96149540\n",
            "Iteration 842, loss = 1495320396.17876649\n",
            "Iteration 843, loss = 1495266975.03817296\n",
            "Iteration 844, loss = 1495213864.62435746\n",
            "Iteration 845, loss = 1495161040.33990693\n",
            "Iteration 846, loss = 1495106906.77241373\n",
            "Iteration 847, loss = 1495053793.33347225\n",
            "Iteration 848, loss = 1495000931.06216598\n",
            "Iteration 849, loss = 1494947195.87175107\n",
            "Iteration 850, loss = 1494893746.39226151\n",
            "Iteration 851, loss = 1494840591.91488194\n",
            "Iteration 852, loss = 1494787304.29475260\n",
            "Iteration 853, loss = 1494734271.39134288\n",
            "Iteration 854, loss = 1494680958.44827604\n",
            "Iteration 855, loss = 1494627778.97892904\n",
            "Iteration 856, loss = 1494575143.58454394\n",
            "Iteration 857, loss = 1494522157.06517863\n",
            "Iteration 858, loss = 1494469214.62267613\n",
            "Iteration 859, loss = 1494416297.93294787\n",
            "Iteration 860, loss = 1494363311.29537797\n",
            "Iteration 861, loss = 1494310900.11550713\n",
            "Iteration 862, loss = 1494257727.13847494\n",
            "Iteration 863, loss = 1494205187.98992872\n",
            "Iteration 864, loss = 1494152290.52434134\n",
            "Iteration 865, loss = 1494099340.34479809\n",
            "Iteration 866, loss = 1494046443.98129559\n",
            "Iteration 867, loss = 1493993737.58971477\n",
            "Iteration 868, loss = 1493940494.06051326\n",
            "Iteration 869, loss = 1493887412.46239400\n",
            "Iteration 870, loss = 1493834725.10097933\n",
            "Iteration 871, loss = 1493781373.79720759\n",
            "Iteration 872, loss = 1493728357.15288639\n",
            "Iteration 873, loss = 1493675154.75920272\n",
            "Iteration 874, loss = 1493622319.15555978\n",
            "Iteration 875, loss = 1493569395.00223374\n",
            "Iteration 876, loss = 1493516189.88805771\n",
            "Iteration 877, loss = 1493462885.13589239\n",
            "Iteration 878, loss = 1493410144.18293142\n",
            "Iteration 879, loss = 1493356904.02054453\n",
            "Iteration 880, loss = 1493303883.09722400\n",
            "Iteration 881, loss = 1493250745.76489973\n",
            "Iteration 882, loss = 1493197665.80928421\n",
            "Iteration 883, loss = 1493144462.42941689\n",
            "Iteration 884, loss = 1493091524.89113474\n",
            "Iteration 885, loss = 1493038775.98656869\n",
            "Iteration 886, loss = 1492985588.41570926\n",
            "Iteration 887, loss = 1492932204.75055957\n",
            "Iteration 888, loss = 1492879470.10946202\n",
            "Iteration 889, loss = 1492826273.70973969\n",
            "Iteration 890, loss = 1492772857.56473827\n",
            "Iteration 891, loss = 1492719917.37565660\n",
            "Iteration 892, loss = 1492666844.99302506\n",
            "Iteration 893, loss = 1492613356.67191887\n",
            "Iteration 894, loss = 1492560877.40074611\n",
            "Iteration 895, loss = 1492507405.46694469\n",
            "Iteration 896, loss = 1492454843.44750738\n",
            "Iteration 897, loss = 1492402347.33882475\n",
            "Iteration 898, loss = 1492349462.41995597\n",
            "Iteration 899, loss = 1492296445.91457105\n",
            "Iteration 900, loss = 1492244101.48477268\n",
            "Iteration 901, loss = 1492191048.16643143\n",
            "Iteration 902, loss = 1492138324.87183046\n",
            "Iteration 903, loss = 1492085767.50458193\n",
            "Iteration 904, loss = 1492032609.96542740\n",
            "Iteration 905, loss = 1491980049.15466952\n",
            "Iteration 906, loss = 1491927705.58322525\n",
            "Iteration 907, loss = 1491874710.51369190\n",
            "Iteration 908, loss = 1491822493.69023633\n",
            "Iteration 909, loss = 1491769786.62219882\n",
            "Iteration 910, loss = 1491717267.50536013\n",
            "Iteration 911, loss = 1491664731.69284344\n",
            "Iteration 912, loss = 1491612467.44254303\n",
            "Iteration 913, loss = 1491560000.75027537\n",
            "Iteration 914, loss = 1491507230.73953652\n",
            "Iteration 915, loss = 1491454729.32749438\n",
            "Iteration 916, loss = 1491402015.45742297\n",
            "Iteration 917, loss = 1491347831.02680492\n",
            "Iteration 918, loss = 1491286459.16197944\n",
            "Iteration 919, loss = 1491228874.39891696\n",
            "Iteration 920, loss = 1491170097.91187072\n",
            "Iteration 921, loss = 1491111768.69952345\n",
            "Iteration 922, loss = 1491052795.61706614\n",
            "Iteration 923, loss = 1490993952.09537578\n",
            "Iteration 924, loss = 1490935150.54343963\n",
            "Iteration 925, loss = 1490876213.25545907\n",
            "Iteration 926, loss = 1490817528.86092496\n",
            "Iteration 927, loss = 1490759055.42054224\n",
            "Iteration 928, loss = 1490700469.07597303\n",
            "Iteration 929, loss = 1490641867.42611980\n",
            "Iteration 930, loss = 1490583522.65282202\n",
            "Iteration 931, loss = 1490525231.64876771\n",
            "Iteration 932, loss = 1490467071.22090697\n",
            "Iteration 933, loss = 1490408664.84131265\n",
            "Iteration 934, loss = 1490351127.25313759\n",
            "Iteration 935, loss = 1490292848.11661267\n",
            "Iteration 936, loss = 1490235377.28405714\n",
            "Iteration 937, loss = 1490177805.94406343\n",
            "Iteration 938, loss = 1490120756.54102516\n",
            "Iteration 939, loss = 1490063406.41814661\n",
            "Iteration 940, loss = 1490006524.78731012\n",
            "Iteration 941, loss = 1489949400.20443463\n",
            "Iteration 942, loss = 1489892867.27050829\n",
            "Iteration 943, loss = 1489836110.29435086\n",
            "Iteration 944, loss = 1489779125.11376548\n",
            "Iteration 945, loss = 1489722257.45486999\n",
            "Iteration 946, loss = 1489665843.20935583\n",
            "Iteration 947, loss = 1489608693.60548520\n",
            "Iteration 948, loss = 1489552340.65749216\n",
            "Iteration 949, loss = 1489495451.32085681\n",
            "Iteration 950, loss = 1489438645.92145610\n",
            "Iteration 951, loss = 1489382265.20832539\n",
            "Iteration 952, loss = 1489325642.59313178\n",
            "Iteration 953, loss = 1489268837.21235657\n",
            "Iteration 954, loss = 1489212909.87047744\n",
            "Iteration 955, loss = 1489156139.93346095\n",
            "Iteration 956, loss = 1489099633.66489434\n",
            "Iteration 957, loss = 1489043268.08337307\n",
            "Iteration 958, loss = 1488986932.28360248\n",
            "Iteration 959, loss = 1488930454.93566251\n",
            "Iteration 960, loss = 1488874269.00999260\n",
            "Iteration 961, loss = 1488818353.09562612\n",
            "Iteration 962, loss = 1488762098.70403314\n",
            "Iteration 963, loss = 1488705889.75952983\n",
            "Iteration 964, loss = 1488650137.28471136\n",
            "Iteration 965, loss = 1488593861.10959411\n",
            "Iteration 966, loss = 1488538453.37852001\n",
            "Iteration 967, loss = 1488482339.87133145\n",
            "Iteration 968, loss = 1488426677.03806305\n",
            "Iteration 969, loss = 1488370952.57792902\n",
            "Iteration 970, loss = 1488315310.35648394\n",
            "Iteration 971, loss = 1488259668.61036563\n",
            "Iteration 972, loss = 1488204282.24263287\n",
            "Iteration 973, loss = 1488148601.14203167\n",
            "Iteration 974, loss = 1488093279.07960033\n",
            "Iteration 975, loss = 1488037553.56067801\n",
            "Iteration 976, loss = 1487982272.23105001\n",
            "Iteration 977, loss = 1487926883.27311611\n",
            "Iteration 978, loss = 1487871329.77614403\n",
            "Iteration 979, loss = 1487815893.44651723\n",
            "Iteration 980, loss = 1487760587.34456754\n",
            "Iteration 981, loss = 1487705278.31929564\n",
            "Iteration 982, loss = 1487650010.04607320\n",
            "Iteration 983, loss = 1487594451.07824445\n",
            "Iteration 984, loss = 1487539186.00635242\n",
            "Iteration 985, loss = 1487484101.34387016\n",
            "Iteration 986, loss = 1487428820.47096133\n",
            "Iteration 987, loss = 1487373136.05197668\n",
            "Iteration 988, loss = 1487318305.16905642\n",
            "Iteration 989, loss = 1487263180.38481283\n",
            "Iteration 990, loss = 1487207758.24997354\n",
            "Iteration 991, loss = 1487152581.47811794\n",
            "Iteration 992, loss = 1487097818.11229444\n",
            "Iteration 993, loss = 1487042695.41505051\n",
            "Iteration 994, loss = 1486987904.17854190\n",
            "Iteration 995, loss = 1486932927.00461435\n",
            "Iteration 996, loss = 1486878616.07918572\n",
            "Iteration 997, loss = 1486823479.28491640\n",
            "Iteration 998, loss = 1486769038.83065081\n",
            "Iteration 999, loss = 1486714252.71138382\n",
            "Iteration 1000, loss = 1486659584.47615337\n",
            "Iteration 1, loss = 1416006345.95502424\n",
            "Iteration 2, loss = 186063289.01333910\n",
            "Iteration 3, loss = 286013091.24880117\n",
            "Iteration 4, loss = 264207057.61871460\n",
            "Iteration 5, loss = 102611006.47988541\n",
            "Iteration 6, loss = 117298016.94210579\n",
            "Iteration 7, loss = 111421650.37537970\n",
            "Iteration 8, loss = 96037036.25887407\n",
            "Iteration 9, loss = 98513315.26211360\n",
            "Iteration 10, loss = 97314593.27981523\n",
            "Iteration 11, loss = 96346176.60295506\n",
            "Iteration 12, loss = 95861458.52226673\n",
            "Iteration 13, loss = 96180079.01784600\n",
            "Iteration 14, loss = 96625994.87197523\n",
            "Iteration 15, loss = 96047507.58831486\n",
            "Iteration 16, loss = 96161339.55160816\n",
            "Iteration 17, loss = 96125335.11556238\n",
            "Iteration 18, loss = 97378089.55992252\n",
            "Iteration 19, loss = 96417873.81765507\n",
            "Iteration 20, loss = 96391787.11827038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 21, loss = 96408109.29800357\n",
            "Iteration 22, loss = 96767132.66944009\n",
            "Iteration 23, loss = 95608447.10997409\n",
            "Iteration 24, loss = 96473150.45630503\n",
            "Iteration 25, loss = 96090290.65016688\n",
            "Iteration 26, loss = 95891764.44837718\n",
            "Iteration 27, loss = 95756649.81515795\n",
            "Iteration 28, loss = 95670693.13560511\n",
            "Iteration 29, loss = 95681704.28864507\n",
            "Iteration 30, loss = 95710111.18450482\n",
            "Iteration 31, loss = 95975769.55634503\n",
            "Iteration 32, loss = 96393341.37644248\n",
            "Iteration 33, loss = 96055356.27085583\n",
            "Iteration 34, loss = 95870907.08837129\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538814923.38565397\n",
            "Iteration 2, loss = 1538730109.52210617\n",
            "Iteration 3, loss = 1538665284.46735620\n",
            "Iteration 4, loss = 1538618338.21174192\n",
            "Iteration 5, loss = 1538579459.82160735\n",
            "Iteration 6, loss = 1538542937.15504837\n",
            "Iteration 7, loss = 1538506779.77238441\n",
            "Iteration 8, loss = 1538470455.72050977\n",
            "Iteration 9, loss = 1538433374.46838665\n",
            "Iteration 10, loss = 1538396212.41210103\n",
            "Iteration 11, loss = 1538358642.61753798\n",
            "Iteration 12, loss = 1538320874.29902887\n",
            "Iteration 13, loss = 1538281988.10070848\n",
            "Iteration 14, loss = 1538242022.73403597\n",
            "Iteration 15, loss = 1538200452.52140093\n",
            "Iteration 16, loss = 1538159259.38086224\n",
            "Iteration 17, loss = 1538118764.76955605\n",
            "Iteration 18, loss = 1538077196.75930738\n",
            "Iteration 19, loss = 1538035331.69876122\n",
            "Iteration 20, loss = 1537993645.60385847\n",
            "Iteration 21, loss = 1537952602.42832327\n",
            "Iteration 22, loss = 1537912058.76821923\n",
            "Iteration 23, loss = 1537871156.25066328\n",
            "Iteration 24, loss = 1537830499.09683871\n",
            "Iteration 25, loss = 1537789940.90644288\n",
            "Iteration 26, loss = 1537749187.57981062\n",
            "Iteration 27, loss = 1537708957.51351166\n",
            "Iteration 28, loss = 1537668471.74515200\n",
            "Iteration 29, loss = 1537628306.82887697\n",
            "Iteration 30, loss = 1537588142.80530262\n",
            "Iteration 31, loss = 1537547804.64105368\n",
            "Iteration 32, loss = 1537508025.04955769\n",
            "Iteration 33, loss = 1537468059.08484006\n",
            "Iteration 34, loss = 1537428222.23285508\n",
            "Iteration 35, loss = 1537388530.27908587\n",
            "Iteration 36, loss = 1537348585.53310537\n",
            "Iteration 37, loss = 1537309006.30684948\n",
            "Iteration 38, loss = 1537269487.18032312\n",
            "Iteration 39, loss = 1537230076.31944036\n",
            "Iteration 40, loss = 1537190475.18717933\n",
            "Iteration 41, loss = 1537151171.91820312\n",
            "Iteration 42, loss = 1537111808.51929259\n",
            "Iteration 43, loss = 1537072654.66587806\n",
            "Iteration 44, loss = 1537033076.88790536\n",
            "Iteration 45, loss = 1536994036.86817789\n",
            "Iteration 46, loss = 1536955016.63401151\n",
            "Iteration 47, loss = 1536915491.89848757\n",
            "Iteration 48, loss = 1536876591.52109766\n",
            "Iteration 49, loss = 1536837504.85628295\n",
            "Iteration 50, loss = 1536798469.04780054\n",
            "Iteration 51, loss = 1536759534.02895689\n",
            "Iteration 52, loss = 1536720318.68946266\n",
            "Iteration 53, loss = 1536681569.67851734\n",
            "Iteration 54, loss = 1536642645.75663710\n",
            "Iteration 55, loss = 1536603595.42735171\n",
            "Iteration 56, loss = 1536564925.18893218\n",
            "Iteration 57, loss = 1536525877.00974822\n",
            "Iteration 58, loss = 1536487134.34247875\n",
            "Iteration 59, loss = 1536448505.00727868\n",
            "Iteration 60, loss = 1536409705.78532076\n",
            "Iteration 61, loss = 1536371142.22246408\n",
            "Iteration 62, loss = 1536332535.61096644\n",
            "Iteration 63, loss = 1536294063.34842896\n",
            "Iteration 64, loss = 1536255554.53635192\n",
            "Iteration 65, loss = 1536216916.25976038\n",
            "Iteration 66, loss = 1536178580.85303736\n",
            "Iteration 67, loss = 1536139827.64242053\n",
            "Iteration 68, loss = 1536101421.27085972\n",
            "Iteration 69, loss = 1536062761.28069091\n",
            "Iteration 70, loss = 1536024321.98816681\n",
            "Iteration 71, loss = 1535985795.26447129\n",
            "Iteration 72, loss = 1535947169.00920749\n",
            "Iteration 73, loss = 1535908887.83963513\n",
            "Iteration 74, loss = 1535870236.78504920\n",
            "Iteration 75, loss = 1535830995.43663716\n",
            "Iteration 76, loss = 1535789093.07549953\n",
            "Iteration 77, loss = 1535747050.17718577\n",
            "Iteration 78, loss = 1535706553.41985011\n",
            "Iteration 79, loss = 1535665409.36174989\n",
            "Iteration 80, loss = 1535624483.02338552\n",
            "Iteration 81, loss = 1535583546.25771666\n",
            "Iteration 82, loss = 1535542379.67392325\n",
            "Iteration 83, loss = 1535501437.58632517\n",
            "Iteration 84, loss = 1535460388.26323938\n",
            "Iteration 85, loss = 1535419184.16294575\n",
            "Iteration 86, loss = 1535378356.55465031\n",
            "Iteration 87, loss = 1535337290.31105089\n",
            "Iteration 88, loss = 1535296379.28083825\n",
            "Iteration 89, loss = 1535255644.06547689\n",
            "Iteration 90, loss = 1535214922.80368876\n",
            "Iteration 91, loss = 1535174301.40338326\n",
            "Iteration 92, loss = 1535133792.22994661\n",
            "Iteration 93, loss = 1535093255.71365309\n",
            "Iteration 94, loss = 1535053068.61881518\n",
            "Iteration 95, loss = 1535012808.07963109\n",
            "Iteration 96, loss = 1534972370.05296087\n",
            "Iteration 97, loss = 1534932314.29993677\n",
            "Iteration 98, loss = 1534892301.94418120\n",
            "Iteration 99, loss = 1534852319.98751855\n",
            "Iteration 100, loss = 1534811841.23552394\n",
            "Iteration 101, loss = 1534772054.60384393\n",
            "Iteration 102, loss = 1534732103.36343789\n",
            "Iteration 103, loss = 1534692151.46918869\n",
            "Iteration 104, loss = 1534651874.12826490\n",
            "Iteration 105, loss = 1534611941.24903154\n",
            "Iteration 106, loss = 1534572206.21383643\n",
            "Iteration 107, loss = 1534532179.09473920\n",
            "Iteration 108, loss = 1534492477.69006705\n",
            "Iteration 109, loss = 1534452330.55344987\n",
            "Iteration 110, loss = 1534412810.94059849\n",
            "Iteration 111, loss = 1534373051.65250134\n",
            "Iteration 112, loss = 1534333375.00836277\n",
            "Iteration 113, loss = 1534293603.33864093\n",
            "Iteration 114, loss = 1534253946.64401364\n",
            "Iteration 115, loss = 1534214271.52796626\n",
            "Iteration 116, loss = 1534174493.11689234\n",
            "Iteration 117, loss = 1534135038.94582701\n",
            "Iteration 118, loss = 1534095378.54502916\n",
            "Iteration 119, loss = 1534055740.16561151\n",
            "Iteration 120, loss = 1534016071.38397264\n",
            "Iteration 121, loss = 1533976346.37213826\n",
            "Iteration 122, loss = 1533936659.23116660\n",
            "Iteration 123, loss = 1533897193.50912428\n",
            "Iteration 124, loss = 1533857403.40011501\n",
            "Iteration 125, loss = 1533817513.65527630\n",
            "Iteration 126, loss = 1533778083.27895069\n",
            "Iteration 127, loss = 1533738349.93234825\n",
            "Iteration 128, loss = 1533698275.75111008\n",
            "Iteration 129, loss = 1533656710.06268573\n",
            "Iteration 130, loss = 1533612022.46785569\n",
            "Iteration 131, loss = 1533569044.00726104\n",
            "Iteration 132, loss = 1533526172.79492235\n",
            "Iteration 133, loss = 1533483249.32683372\n",
            "Iteration 134, loss = 1533440138.41269922\n",
            "Iteration 135, loss = 1533397063.37704515\n",
            "Iteration 136, loss = 1533353954.69484067\n",
            "Iteration 137, loss = 1533311122.85987115\n",
            "Iteration 138, loss = 1533267678.49784565\n",
            "Iteration 139, loss = 1533223686.28030133\n",
            "Iteration 140, loss = 1533176609.49078012\n",
            "Iteration 141, loss = 1533130268.70563841\n",
            "Iteration 142, loss = 1533084225.43607736\n",
            "Iteration 143, loss = 1533038191.60816789\n",
            "Iteration 144, loss = 1532990817.59042454\n",
            "Iteration 145, loss = 1532940815.85632992\n",
            "Iteration 146, loss = 1532890751.16798186\n",
            "Iteration 147, loss = 1532841463.41070533\n",
            "Iteration 148, loss = 1532792547.93447566\n",
            "Iteration 149, loss = 1532743375.67458391\n",
            "Iteration 150, loss = 1532693958.69786716\n",
            "Iteration 151, loss = 1532645225.05056620\n",
            "Iteration 152, loss = 1532596237.72026658\n",
            "Iteration 153, loss = 1532547403.28941560\n",
            "Iteration 154, loss = 1532499165.17660832\n",
            "Iteration 155, loss = 1532450525.21992445\n",
            "Iteration 156, loss = 1532402617.64956141\n",
            "Iteration 157, loss = 1532354607.31791186\n",
            "Iteration 158, loss = 1532306876.98032355\n",
            "Iteration 159, loss = 1532259060.34842324\n",
            "Iteration 160, loss = 1532211642.30971146\n",
            "Iteration 161, loss = 1532163934.07135701\n",
            "Iteration 162, loss = 1532114782.67991233\n",
            "Iteration 163, loss = 1532061914.74175501\n",
            "Iteration 164, loss = 1532010934.84300947\n",
            "Iteration 165, loss = 1531960431.21504164\n",
            "Iteration 166, loss = 1531909650.63239074\n",
            "Iteration 167, loss = 1531858868.61957693\n",
            "Iteration 168, loss = 1531808284.62403131\n",
            "Iteration 169, loss = 1531756918.99892735\n",
            "Iteration 170, loss = 1531701675.78556800\n",
            "Iteration 171, loss = 1531641344.06187367\n",
            "Iteration 172, loss = 1531583642.64429283\n",
            "Iteration 173, loss = 1531526555.79859447\n",
            "Iteration 174, loss = 1531469710.05133367\n",
            "Iteration 175, loss = 1531412807.86764359\n",
            "Iteration 176, loss = 1531355925.21791792\n",
            "Iteration 177, loss = 1531299039.11225200\n",
            "Iteration 178, loss = 1531242602.28288484\n",
            "Iteration 179, loss = 1531186320.94639254\n",
            "Iteration 180, loss = 1531130177.47203565\n",
            "Iteration 181, loss = 1531074664.81684971\n",
            "Iteration 182, loss = 1531018982.92375231\n",
            "Iteration 183, loss = 1530963778.01660156\n",
            "Iteration 184, loss = 1530908580.56883907\n",
            "Iteration 185, loss = 1530853924.34783983\n",
            "Iteration 186, loss = 1530799535.57197928\n",
            "Iteration 187, loss = 1530745003.05541229\n",
            "Iteration 188, loss = 1530691526.92150640\n",
            "Iteration 189, loss = 1530637486.11712217\n",
            "Iteration 190, loss = 1530584348.70403337\n",
            "Iteration 191, loss = 1530530842.85221028\n",
            "Iteration 192, loss = 1530478111.82898641\n",
            "Iteration 193, loss = 1530424961.43181181\n",
            "Iteration 194, loss = 1530372497.33308697\n",
            "Iteration 195, loss = 1530319864.84659028\n",
            "Iteration 196, loss = 1530267625.07325411\n",
            "Iteration 197, loss = 1530215008.58570743\n",
            "Iteration 198, loss = 1530163325.70171165\n",
            "Iteration 199, loss = 1530110785.81119800\n",
            "Iteration 200, loss = 1530058922.38785672\n",
            "Iteration 201, loss = 1530007432.21551132\n",
            "Iteration 202, loss = 1529955302.87092614\n",
            "Iteration 203, loss = 1529903608.11973548\n",
            "Iteration 204, loss = 1529851920.82501650\n",
            "Iteration 205, loss = 1529800631.12003589\n",
            "Iteration 206, loss = 1529749329.75392079\n",
            "Iteration 207, loss = 1529698025.37010646\n",
            "Iteration 208, loss = 1529647111.48229551\n",
            "Iteration 209, loss = 1529595703.26917577\n",
            "Iteration 210, loss = 1529545568.10956025\n",
            "Iteration 211, loss = 1529494677.93487835\n",
            "Iteration 212, loss = 1529443963.18464279\n",
            "Iteration 213, loss = 1529393591.40697694\n",
            "Iteration 214, loss = 1529342748.43943787\n",
            "Iteration 215, loss = 1529292130.29496408\n",
            "Iteration 216, loss = 1529238895.64164615\n",
            "Iteration 217, loss = 1529177214.59165287\n",
            "Iteration 218, loss = 1529119255.38581681\n",
            "Iteration 219, loss = 1529061498.01370358\n",
            "Iteration 220, loss = 1529004133.63663149\n",
            "Iteration 221, loss = 1528946000.03293395\n",
            "Iteration 222, loss = 1528888178.93011022\n",
            "Iteration 223, loss = 1528829955.79273820\n",
            "Iteration 224, loss = 1528772350.10895157\n",
            "Iteration 225, loss = 1528714443.55152416\n",
            "Iteration 226, loss = 1528656740.72495174\n",
            "Iteration 227, loss = 1528598823.71556568\n",
            "Iteration 228, loss = 1528541712.56808853\n",
            "Iteration 229, loss = 1528484423.89750314\n",
            "Iteration 230, loss = 1528427265.55111337\n",
            "Iteration 231, loss = 1528370341.23919249\n",
            "Iteration 232, loss = 1528314204.66399050\n",
            "Iteration 233, loss = 1528257664.69715810\n",
            "Iteration 234, loss = 1528201780.17877579\n",
            "Iteration 235, loss = 1528146126.63646507\n",
            "Iteration 236, loss = 1528090480.73154259\n",
            "Iteration 237, loss = 1528035312.87487507\n",
            "Iteration 238, loss = 1527980041.47401071\n",
            "Iteration 239, loss = 1527925408.04085565\n",
            "Iteration 240, loss = 1527870460.22179866\n",
            "Iteration 241, loss = 1527815621.95994616\n",
            "Iteration 242, loss = 1527760983.89609122\n",
            "Iteration 243, loss = 1527707072.93737268\n",
            "Iteration 244, loss = 1527652432.23194861\n",
            "Iteration 245, loss = 1527598414.25046563\n",
            "Iteration 246, loss = 1527544124.83003640\n",
            "Iteration 247, loss = 1527490370.46345878\n",
            "Iteration 248, loss = 1527436498.01810050\n",
            "Iteration 249, loss = 1527383008.05999541\n",
            "Iteration 250, loss = 1527329318.64603209\n",
            "Iteration 251, loss = 1527275802.00449586\n",
            "Iteration 252, loss = 1527222243.81755424\n",
            "Iteration 253, loss = 1527169267.52023411\n",
            "Iteration 254, loss = 1527115647.37381029\n",
            "Iteration 255, loss = 1527062790.59272170\n",
            "Iteration 256, loss = 1527009436.52764034\n",
            "Iteration 257, loss = 1526956428.87066603\n",
            "Iteration 258, loss = 1526903435.69377494\n",
            "Iteration 259, loss = 1526850168.10618496\n",
            "Iteration 260, loss = 1526797392.52318788\n",
            "Iteration 261, loss = 1526744484.49839568\n",
            "Iteration 262, loss = 1526691641.83217907\n",
            "Iteration 263, loss = 1526638942.51186728\n",
            "Iteration 264, loss = 1526586496.81473160\n",
            "Iteration 265, loss = 1526533831.37104607\n",
            "Iteration 266, loss = 1526481564.23126769\n",
            "Iteration 267, loss = 1526429004.38822889\n",
            "Iteration 268, loss = 1526376811.61741614\n",
            "Iteration 269, loss = 1526324400.62521791\n",
            "Iteration 270, loss = 1526272166.21261692\n",
            "Iteration 271, loss = 1526219802.38807178\n",
            "Iteration 272, loss = 1526167695.12770939\n",
            "Iteration 273, loss = 1526115496.67809105\n",
            "Iteration 274, loss = 1526063628.63651228\n",
            "Iteration 275, loss = 1526011416.18170810\n",
            "Iteration 276, loss = 1525959734.18672943\n",
            "Iteration 277, loss = 1525907890.53252387\n",
            "Iteration 278, loss = 1525856128.87313962\n",
            "Iteration 279, loss = 1525804318.17741990\n",
            "Iteration 280, loss = 1525752471.73257017\n",
            "Iteration 281, loss = 1525700745.01712990\n",
            "Iteration 282, loss = 1525649108.28986883\n",
            "Iteration 283, loss = 1525597224.03843617\n",
            "Iteration 284, loss = 1525545436.01711059\n",
            "Iteration 285, loss = 1525493798.84589553\n",
            "Iteration 286, loss = 1525441891.86524558\n",
            "Iteration 287, loss = 1525390832.70993924\n",
            "Iteration 288, loss = 1525338792.82690024\n",
            "Iteration 289, loss = 1525287498.25203371\n",
            "Iteration 290, loss = 1525236090.16025066\n",
            "Iteration 291, loss = 1525184945.01866102\n",
            "Iteration 292, loss = 1525133286.12984395\n",
            "Iteration 293, loss = 1525082130.69335032\n",
            "Iteration 294, loss = 1525030854.79285383\n",
            "Iteration 295, loss = 1524979422.91825175\n",
            "Iteration 296, loss = 1524928239.46414757\n",
            "Iteration 297, loss = 1524876809.60596085\n",
            "Iteration 298, loss = 1524825972.40681720\n",
            "Iteration 299, loss = 1524774645.95285392\n",
            "Iteration 300, loss = 1524723540.23222446\n",
            "Iteration 301, loss = 1524672355.82430029\n",
            "Iteration 302, loss = 1524621581.95599771\n",
            "Iteration 303, loss = 1524570720.89860034\n",
            "Iteration 304, loss = 1524519856.04231167\n",
            "Iteration 305, loss = 1524469419.92879558\n",
            "Iteration 306, loss = 1524418443.06640172\n",
            "Iteration 307, loss = 1524367782.37654209\n",
            "Iteration 308, loss = 1524317664.74377108\n",
            "Iteration 309, loss = 1524266845.30103111\n",
            "Iteration 310, loss = 1524216242.47616768\n",
            "Iteration 311, loss = 1524165728.14656878\n",
            "Iteration 312, loss = 1524115151.55333805\n",
            "Iteration 313, loss = 1524064766.95920825\n",
            "Iteration 314, loss = 1524014301.60849333\n",
            "Iteration 315, loss = 1523963357.53298974\n",
            "Iteration 316, loss = 1523913008.54860902\n",
            "Iteration 317, loss = 1523862561.14096332\n",
            "Iteration 318, loss = 1523812089.11768460\n",
            "Iteration 319, loss = 1523761183.41509318\n",
            "Iteration 320, loss = 1523710959.96338034\n",
            "Iteration 321, loss = 1523660350.14841485\n",
            "Iteration 322, loss = 1523609824.75919747\n",
            "Iteration 323, loss = 1523559407.31034708\n",
            "Iteration 324, loss = 1523509107.12971997\n",
            "Iteration 325, loss = 1523458727.33509326\n",
            "Iteration 326, loss = 1523408784.54154253\n",
            "Iteration 327, loss = 1523358327.08365488\n",
            "Iteration 328, loss = 1523308500.14972854\n",
            "Iteration 329, loss = 1523257954.55105400\n",
            "Iteration 330, loss = 1523207979.06848574\n",
            "Iteration 331, loss = 1523157946.31334782\n",
            "Iteration 332, loss = 1523107844.21380353\n",
            "Iteration 333, loss = 1523057892.28278613\n",
            "Iteration 334, loss = 1523007796.07268786\n",
            "Iteration 335, loss = 1522957938.60649419\n",
            "Iteration 336, loss = 1522908373.50839806\n",
            "Iteration 337, loss = 1522858372.27394986\n",
            "Iteration 338, loss = 1522808686.62299442\n",
            "Iteration 339, loss = 1522758834.03046155\n",
            "Iteration 340, loss = 1522709200.34986472\n",
            "Iteration 341, loss = 1522659010.53787637\n",
            "Iteration 342, loss = 1522609509.18594050\n",
            "Iteration 343, loss = 1522559845.88469744\n",
            "Iteration 344, loss = 1522509690.06113434\n",
            "Iteration 345, loss = 1522460126.88784742\n",
            "Iteration 346, loss = 1522410273.55096173\n",
            "Iteration 347, loss = 1522360797.05589581\n",
            "Iteration 348, loss = 1522311009.98729897\n",
            "Iteration 349, loss = 1522261356.49774027\n",
            "Iteration 350, loss = 1522211693.51016402\n",
            "Iteration 351, loss = 1522162127.07064390\n",
            "Iteration 352, loss = 1522111947.44599724\n",
            "Iteration 353, loss = 1522057601.56480503\n",
            "Iteration 354, loss = 1522002694.88946724\n",
            "Iteration 355, loss = 1521948958.10245752\n",
            "Iteration 356, loss = 1521895057.09006834\n",
            "Iteration 357, loss = 1521840339.98327756\n",
            "Iteration 358, loss = 1521785999.17251682\n",
            "Iteration 359, loss = 1521731516.92583823\n",
            "Iteration 360, loss = 1521676878.31029320\n",
            "Iteration 361, loss = 1521622369.73995900\n",
            "Iteration 362, loss = 1521568142.20457268\n",
            "Iteration 363, loss = 1521513239.96455669\n",
            "Iteration 364, loss = 1521459651.64612341\n",
            "Iteration 365, loss = 1521405230.71842289\n",
            "Iteration 366, loss = 1521351207.68607473\n",
            "Iteration 367, loss = 1521297237.36314845\n",
            "Iteration 368, loss = 1521243668.82837558\n",
            "Iteration 369, loss = 1521189913.13934088\n",
            "Iteration 370, loss = 1521136192.79313588\n",
            "Iteration 371, loss = 1521082587.25122356\n",
            "Iteration 372, loss = 1521029334.38215327\n",
            "Iteration 373, loss = 1520976194.21003699\n",
            "Iteration 374, loss = 1520922535.58652544\n",
            "Iteration 375, loss = 1520869545.36506295\n",
            "Iteration 376, loss = 1520816628.82319260\n",
            "Iteration 377, loss = 1520763757.92076015\n",
            "Iteration 378, loss = 1520710967.81009960\n",
            "Iteration 379, loss = 1520658153.25207472\n",
            "Iteration 380, loss = 1520605713.30392122\n",
            "Iteration 381, loss = 1520553035.53350520\n",
            "Iteration 382, loss = 1520500897.58666658\n",
            "Iteration 383, loss = 1520448314.00619984\n",
            "Iteration 384, loss = 1520395905.09635687\n",
            "Iteration 385, loss = 1520343707.45727396\n",
            "Iteration 386, loss = 1520291908.02431965\n",
            "Iteration 387, loss = 1520239236.97516131\n",
            "Iteration 388, loss = 1520187262.52532411\n",
            "Iteration 389, loss = 1520135054.40685439\n",
            "Iteration 390, loss = 1520083079.98238611\n",
            "Iteration 391, loss = 1520031196.43618631\n",
            "Iteration 392, loss = 1519979061.88250184\n",
            "Iteration 393, loss = 1519927094.65271878\n",
            "Iteration 394, loss = 1519875531.90720892\n",
            "Iteration 395, loss = 1519823498.38505411\n",
            "Iteration 396, loss = 1519771969.96498680\n",
            "Iteration 397, loss = 1519720585.17413449\n",
            "Iteration 398, loss = 1519668451.74245548\n",
            "Iteration 399, loss = 1519617328.86630869\n",
            "Iteration 400, loss = 1519565515.69210601\n",
            "Iteration 401, loss = 1519513825.59038615\n",
            "Iteration 402, loss = 1519462454.86001897\n",
            "Iteration 403, loss = 1519410976.22194386\n",
            "Iteration 404, loss = 1519359464.96291637\n",
            "Iteration 405, loss = 1519307873.12895656\n",
            "Iteration 406, loss = 1519256497.87996817\n",
            "Iteration 407, loss = 1519205524.05469537\n",
            "Iteration 408, loss = 1519154027.13587594\n",
            "Iteration 409, loss = 1519102624.95552754\n",
            "Iteration 410, loss = 1519051410.77078342\n",
            "Iteration 411, loss = 1519000163.73728752\n",
            "Iteration 412, loss = 1518948813.94410300\n",
            "Iteration 413, loss = 1518897384.58835268\n",
            "Iteration 414, loss = 1518846316.04513526\n",
            "Iteration 415, loss = 1518794820.23720741\n",
            "Iteration 416, loss = 1518743660.28008819\n",
            "Iteration 417, loss = 1518692121.71263814\n",
            "Iteration 418, loss = 1518640990.57354188\n",
            "Iteration 419, loss = 1518589800.98432946\n",
            "Iteration 420, loss = 1518538509.61128712\n",
            "Iteration 421, loss = 1518487233.53708196\n",
            "Iteration 422, loss = 1518436147.64536500\n",
            "Iteration 423, loss = 1518384839.07510304\n",
            "Iteration 424, loss = 1518333885.07905149\n",
            "Iteration 425, loss = 1518282919.47378373\n",
            "Iteration 426, loss = 1518231747.14880323\n",
            "Iteration 427, loss = 1518181150.81297517\n",
            "Iteration 428, loss = 1518129829.56268549\n",
            "Iteration 429, loss = 1518079108.40588427\n",
            "Iteration 430, loss = 1518028420.13207650\n",
            "Iteration 431, loss = 1517977210.37033510\n",
            "Iteration 432, loss = 1517926563.02653241\n",
            "Iteration 433, loss = 1517875507.80559444\n",
            "Iteration 434, loss = 1517824534.53280401\n",
            "Iteration 435, loss = 1517773936.27345705\n",
            "Iteration 436, loss = 1517722988.13150525\n",
            "Iteration 437, loss = 1517670733.65810323\n",
            "Iteration 438, loss = 1517614121.82800651\n",
            "Iteration 439, loss = 1517558351.82494092\n",
            "Iteration 440, loss = 1517502725.04657125\n",
            "Iteration 441, loss = 1517447010.68552732\n",
            "Iteration 442, loss = 1517390916.15876460\n",
            "Iteration 443, loss = 1517334480.11035633\n",
            "Iteration 444, loss = 1517278589.09363151\n",
            "Iteration 445, loss = 1517222327.99787259\n",
            "Iteration 446, loss = 1517166580.43874979\n",
            "Iteration 447, loss = 1517110495.24650836\n",
            "Iteration 448, loss = 1517054514.58957338\n",
            "Iteration 449, loss = 1516999220.30270362\n",
            "Iteration 450, loss = 1516943654.62305212\n",
            "Iteration 451, loss = 1516888251.77306652\n",
            "Iteration 452, loss = 1516833278.35105085\n",
            "Iteration 453, loss = 1516778157.38679790\n",
            "Iteration 454, loss = 1516723852.71938348\n",
            "Iteration 455, loss = 1516669083.27946186\n",
            "Iteration 456, loss = 1516614706.13101101\n",
            "Iteration 457, loss = 1516560437.07851410\n",
            "Iteration 458, loss = 1516506363.05887508\n",
            "Iteration 459, loss = 1516452164.05403543\n",
            "Iteration 460, loss = 1516398027.63069248\n",
            "Iteration 461, loss = 1516344092.57845354\n",
            "Iteration 462, loss = 1516290233.01313210\n",
            "Iteration 463, loss = 1516236113.07988691\n",
            "Iteration 464, loss = 1516182561.36839771\n",
            "Iteration 465, loss = 1516128672.22065282\n",
            "Iteration 466, loss = 1516074905.73983121\n",
            "Iteration 467, loss = 1516019713.79125404\n",
            "Iteration 468, loss = 1515958509.75818586\n",
            "Iteration 469, loss = 1515900188.93310308\n",
            "Iteration 470, loss = 1515842021.79622483\n",
            "Iteration 471, loss = 1515783582.63471055\n",
            "Iteration 472, loss = 1515724760.68387794\n",
            "Iteration 473, loss = 1515666601.16907144\n",
            "Iteration 474, loss = 1515608241.80541110\n",
            "Iteration 475, loss = 1515549634.02767634\n",
            "Iteration 476, loss = 1515491586.06485152\n",
            "Iteration 477, loss = 1515433493.71010399\n",
            "Iteration 478, loss = 1515375732.70083880\n",
            "Iteration 479, loss = 1515317951.77473593\n",
            "Iteration 480, loss = 1515260364.14853215\n",
            "Iteration 481, loss = 1515202799.00301027\n",
            "Iteration 482, loss = 1515144985.74869323\n",
            "Iteration 483, loss = 1515087953.93780398\n",
            "Iteration 484, loss = 1515030350.90160322\n",
            "Iteration 485, loss = 1514973147.71028137\n",
            "Iteration 486, loss = 1514916274.27071500\n",
            "Iteration 487, loss = 1514858811.21628451\n",
            "Iteration 488, loss = 1514801992.77592683\n",
            "Iteration 489, loss = 1514745148.95232439\n",
            "Iteration 490, loss = 1514688307.88758326\n",
            "Iteration 491, loss = 1514631609.41686535\n",
            "Iteration 492, loss = 1514575004.46503973\n",
            "Iteration 493, loss = 1514518289.47712517\n",
            "Iteration 494, loss = 1514462206.89736271\n",
            "Iteration 495, loss = 1514406013.88684130\n",
            "Iteration 496, loss = 1514349627.16430545\n",
            "Iteration 497, loss = 1514293723.16119933\n",
            "Iteration 498, loss = 1514237805.64910126\n",
            "Iteration 499, loss = 1514182232.13725567\n",
            "Iteration 500, loss = 1514126367.21603489\n",
            "Iteration 501, loss = 1514070673.08274961\n",
            "Iteration 502, loss = 1514015377.98920512\n",
            "Iteration 503, loss = 1513960063.37790513\n",
            "Iteration 504, loss = 1513904644.00828862\n",
            "Iteration 505, loss = 1513849523.98000956\n",
            "Iteration 506, loss = 1513794193.73967671\n",
            "Iteration 507, loss = 1513739237.81838036\n",
            "Iteration 508, loss = 1513684143.22587180\n",
            "Iteration 509, loss = 1513629241.45603299\n",
            "Iteration 510, loss = 1513574087.64349818\n",
            "Iteration 511, loss = 1513519288.26227331\n",
            "Iteration 512, loss = 1513464207.70946574\n",
            "Iteration 513, loss = 1513409718.11036634\n",
            "Iteration 514, loss = 1513354685.72913647\n",
            "Iteration 515, loss = 1513300260.41485810\n",
            "Iteration 516, loss = 1513245546.68034029\n",
            "Iteration 517, loss = 1513191137.12235117\n",
            "Iteration 518, loss = 1513136915.27699828\n",
            "Iteration 519, loss = 1513082012.93922877\n",
            "Iteration 520, loss = 1513027774.66903162\n",
            "Iteration 521, loss = 1512973382.45805526\n",
            "Iteration 522, loss = 1512919135.21065354\n",
            "Iteration 523, loss = 1512864797.98633575\n",
            "Iteration 524, loss = 1512810343.01676059\n",
            "Iteration 525, loss = 1512756414.52669215\n",
            "Iteration 526, loss = 1512702146.10555577\n",
            "Iteration 527, loss = 1512648223.41126013\n",
            "Iteration 528, loss = 1512594710.56443715\n",
            "Iteration 529, loss = 1512540417.11275411\n",
            "Iteration 530, loss = 1512486948.15150571\n",
            "Iteration 531, loss = 1512433336.24610710\n",
            "Iteration 532, loss = 1512379248.74846220\n",
            "Iteration 533, loss = 1512325757.84783864\n",
            "Iteration 534, loss = 1512272217.96830916\n",
            "Iteration 535, loss = 1512218299.42990303\n",
            "Iteration 536, loss = 1512164652.92682171\n",
            "Iteration 537, loss = 1512111024.46530104\n",
            "Iteration 538, loss = 1512057408.33679056\n",
            "Iteration 539, loss = 1512003934.82392430\n",
            "Iteration 540, loss = 1511950421.86292386\n",
            "Iteration 541, loss = 1511896837.50143456\n",
            "Iteration 542, loss = 1511843431.20845485\n",
            "Iteration 543, loss = 1511790171.32332540\n",
            "Iteration 544, loss = 1511737094.48292041\n",
            "Iteration 545, loss = 1511683477.93707967\n",
            "Iteration 546, loss = 1511629947.03248119\n",
            "Iteration 547, loss = 1511576622.51022124\n",
            "Iteration 548, loss = 1511523537.87722397\n",
            "Iteration 549, loss = 1511469886.74060106\n",
            "Iteration 550, loss = 1511416952.24736238\n",
            "Iteration 551, loss = 1511363687.22742105\n",
            "Iteration 552, loss = 1511310257.78312731\n",
            "Iteration 553, loss = 1511257638.93406153\n",
            "Iteration 554, loss = 1511204398.71104479\n",
            "Iteration 555, loss = 1511151207.96228456\n",
            "Iteration 556, loss = 1511098242.65549874\n",
            "Iteration 557, loss = 1511045194.71392989\n",
            "Iteration 558, loss = 1510992020.17425871\n",
            "Iteration 559, loss = 1510938690.43397164\n",
            "Iteration 560, loss = 1510885784.33126760\n",
            "Iteration 561, loss = 1510832517.05003524\n",
            "Iteration 562, loss = 1510779322.09467602\n",
            "Iteration 563, loss = 1510726250.27870655\n",
            "Iteration 564, loss = 1510672736.25614309\n",
            "Iteration 565, loss = 1510615716.23826671\n",
            "Iteration 566, loss = 1510554300.17215228\n",
            "Iteration 567, loss = 1510496404.68985343\n",
            "Iteration 568, loss = 1510438049.97076106\n",
            "Iteration 569, loss = 1510378993.88184381\n",
            "Iteration 570, loss = 1510320480.17622232\n",
            "Iteration 571, loss = 1510261026.95265961\n",
            "Iteration 572, loss = 1510202660.84079552\n",
            "Iteration 573, loss = 1510142446.95649052\n",
            "Iteration 574, loss = 1510076142.30402207\n",
            "Iteration 575, loss = 1510011722.51654005\n",
            "Iteration 576, loss = 1509948886.46710610\n",
            "Iteration 577, loss = 1509885312.35962486\n",
            "Iteration 578, loss = 1509821592.46429396\n",
            "Iteration 579, loss = 1509758088.28351259\n",
            "Iteration 580, loss = 1509694070.93565154\n",
            "Iteration 581, loss = 1509631334.95188832\n",
            "Iteration 582, loss = 1509568069.75461030\n",
            "Iteration 583, loss = 1509505297.42069507\n",
            "Iteration 584, loss = 1509442393.92945647\n",
            "Iteration 585, loss = 1509380018.63624287\n",
            "Iteration 586, loss = 1509317483.44621110\n",
            "Iteration 587, loss = 1509255701.09009981\n",
            "Iteration 588, loss = 1509193324.84459782\n",
            "Iteration 589, loss = 1509129489.80236578\n",
            "Iteration 590, loss = 1509061340.93639994\n",
            "Iteration 591, loss = 1508995267.01505852\n",
            "Iteration 592, loss = 1508928724.27723765\n",
            "Iteration 593, loss = 1508862462.84163094\n",
            "Iteration 594, loss = 1508795209.01378989\n",
            "Iteration 595, loss = 1508729057.21656203\n",
            "Iteration 596, loss = 1508662516.21823764\n",
            "Iteration 597, loss = 1508596051.45476866\n",
            "Iteration 598, loss = 1508530476.39088917\n",
            "Iteration 599, loss = 1508464122.36671114\n",
            "Iteration 600, loss = 1508399105.27538037\n",
            "Iteration 601, loss = 1508334189.04789519\n",
            "Iteration 602, loss = 1508269074.70884585\n",
            "Iteration 603, loss = 1508204456.09503031\n",
            "Iteration 604, loss = 1508140488.96144700\n",
            "Iteration 605, loss = 1508076709.54426217\n",
            "Iteration 606, loss = 1508012708.22606945\n",
            "Iteration 607, loss = 1507949627.16545987\n",
            "Iteration 608, loss = 1507886079.20406199\n",
            "Iteration 609, loss = 1507823346.82296681\n",
            "Iteration 610, loss = 1507760292.09444118\n",
            "Iteration 611, loss = 1507698057.15658593\n",
            "Iteration 612, loss = 1507634815.51273918\n",
            "Iteration 613, loss = 1507572486.32993746\n",
            "Iteration 614, loss = 1507510330.02853799\n",
            "Iteration 615, loss = 1507448033.67221689\n",
            "Iteration 616, loss = 1507386163.78841519\n",
            "Iteration 617, loss = 1507324067.93999577\n",
            "Iteration 618, loss = 1507262759.11383271\n",
            "Iteration 619, loss = 1507200867.72194886\n",
            "Iteration 620, loss = 1507139639.26022387\n",
            "Iteration 621, loss = 1507078041.62620282\n",
            "Iteration 622, loss = 1507016927.80653286\n",
            "Iteration 623, loss = 1506955886.96435261\n",
            "Iteration 624, loss = 1506894931.94543982\n",
            "Iteration 625, loss = 1506833722.36468244\n",
            "Iteration 626, loss = 1506773275.54089475\n",
            "Iteration 627, loss = 1506712700.92467833\n",
            "Iteration 628, loss = 1506652461.10538602\n",
            "Iteration 629, loss = 1506591574.17416167\n",
            "Iteration 630, loss = 1506531271.82895565\n",
            "Iteration 631, loss = 1506470651.48056293\n",
            "Iteration 632, loss = 1506410590.28357100\n",
            "Iteration 633, loss = 1506350326.83249927\n",
            "Iteration 634, loss = 1506289690.52875614\n",
            "Iteration 635, loss = 1506229796.92689490\n",
            "Iteration 636, loss = 1506169410.94407272\n",
            "Iteration 637, loss = 1506109499.15739369\n",
            "Iteration 638, loss = 1506049732.38433409\n",
            "Iteration 639, loss = 1505989901.25903130\n",
            "Iteration 640, loss = 1505929937.65666246\n",
            "Iteration 641, loss = 1505870129.47091627\n",
            "Iteration 642, loss = 1505810642.39376760\n",
            "Iteration 643, loss = 1505750906.17333317\n",
            "Iteration 644, loss = 1505691383.00787449\n",
            "Iteration 645, loss = 1505631673.66463041\n",
            "Iteration 646, loss = 1505571979.80860591\n",
            "Iteration 647, loss = 1505512948.64177608\n",
            "Iteration 648, loss = 1505453168.07601523\n",
            "Iteration 649, loss = 1505393829.20450091\n",
            "Iteration 650, loss = 1505334578.38893509\n",
            "Iteration 651, loss = 1505275093.10171556\n",
            "Iteration 652, loss = 1505215923.50133252\n",
            "Iteration 653, loss = 1505156874.04818702\n",
            "Iteration 654, loss = 1505097446.96950889\n",
            "Iteration 655, loss = 1505038368.32284188\n",
            "Iteration 656, loss = 1504979685.24448991\n",
            "Iteration 657, loss = 1504920418.67925763\n",
            "Iteration 658, loss = 1504861386.07202911\n",
            "Iteration 659, loss = 1504802560.81993270\n",
            "Iteration 660, loss = 1504743770.31606722\n",
            "Iteration 661, loss = 1504684869.13518429\n",
            "Iteration 662, loss = 1504626170.42090750\n",
            "Iteration 663, loss = 1504567133.21551275\n",
            "Iteration 664, loss = 1504508318.31976438\n",
            "Iteration 665, loss = 1504449539.38466835\n",
            "Iteration 666, loss = 1504390705.99365664\n",
            "Iteration 667, loss = 1504331730.72433567\n",
            "Iteration 668, loss = 1504273181.22667146\n",
            "Iteration 669, loss = 1504214285.72410774\n",
            "Iteration 670, loss = 1504156017.50496650\n",
            "Iteration 671, loss = 1504097451.72148180\n",
            "Iteration 672, loss = 1504039191.00056887\n",
            "Iteration 673, loss = 1503981115.50470519\n",
            "Iteration 674, loss = 1503923135.35546541\n",
            "Iteration 675, loss = 1503864646.59006858\n",
            "Iteration 676, loss = 1503806844.46541309\n",
            "Iteration 677, loss = 1503748671.60538983\n",
            "Iteration 678, loss = 1503690564.45377445\n",
            "Iteration 679, loss = 1503632824.10860777\n",
            "Iteration 680, loss = 1503574938.88685894\n",
            "Iteration 681, loss = 1503516946.55619192\n",
            "Iteration 682, loss = 1503459834.30501962\n",
            "Iteration 683, loss = 1503401639.95673299\n",
            "Iteration 684, loss = 1503344122.44861412\n",
            "Iteration 685, loss = 1503286435.25020742\n",
            "Iteration 686, loss = 1503228837.06459665\n",
            "Iteration 687, loss = 1503171105.26475620\n",
            "Iteration 688, loss = 1503113216.91123700\n",
            "Iteration 689, loss = 1503055691.29063392\n",
            "Iteration 690, loss = 1502997842.79632902\n",
            "Iteration 691, loss = 1502940740.99289942\n",
            "Iteration 692, loss = 1502882997.18384147\n",
            "Iteration 693, loss = 1502825641.11303043\n",
            "Iteration 694, loss = 1502768337.95137835\n",
            "Iteration 695, loss = 1502710762.35205722\n",
            "Iteration 696, loss = 1502653563.87470293\n",
            "Iteration 697, loss = 1502596082.02891541\n",
            "Iteration 698, loss = 1502539171.92935538\n",
            "Iteration 699, loss = 1502481461.83510971\n",
            "Iteration 700, loss = 1502424374.75194192\n",
            "Iteration 701, loss = 1502367319.41528463\n",
            "Iteration 702, loss = 1502310050.18314290\n",
            "Iteration 703, loss = 1502252866.33269715\n",
            "Iteration 704, loss = 1502195473.67720699\n",
            "Iteration 705, loss = 1502138584.00907350\n",
            "Iteration 706, loss = 1502081470.47174191\n",
            "Iteration 707, loss = 1502024411.11027026\n",
            "Iteration 708, loss = 1501967654.32810402\n",
            "Iteration 709, loss = 1501910564.07959723\n",
            "Iteration 710, loss = 1501853580.62098527\n",
            "Iteration 711, loss = 1501797127.39953279\n",
            "Iteration 712, loss = 1501740224.75071287\n",
            "Iteration 713, loss = 1501683452.99846697\n",
            "Iteration 714, loss = 1501626157.69339681\n",
            "Iteration 715, loss = 1501569883.61129451\n",
            "Iteration 716, loss = 1501513029.89790559\n",
            "Iteration 717, loss = 1501455989.17947030\n",
            "Iteration 718, loss = 1501399606.97586513\n",
            "Iteration 719, loss = 1501342792.99539089\n",
            "Iteration 720, loss = 1501286379.60740471\n",
            "Iteration 721, loss = 1501230062.46033478\n",
            "Iteration 722, loss = 1501173443.07850170\n",
            "Iteration 723, loss = 1501117077.71595168\n",
            "Iteration 724, loss = 1501060449.46574450\n",
            "Iteration 725, loss = 1501004054.14570618\n",
            "Iteration 726, loss = 1500947615.49714041\n",
            "Iteration 727, loss = 1500891154.74630857\n",
            "Iteration 728, loss = 1500834305.58450341\n",
            "Iteration 729, loss = 1500777942.23990202\n",
            "Iteration 730, loss = 1500721467.08756614\n",
            "Iteration 731, loss = 1500665095.11989594\n",
            "Iteration 732, loss = 1500608375.02702975\n",
            "Iteration 733, loss = 1500551825.26746082\n",
            "Iteration 734, loss = 1500495299.64079332\n",
            "Iteration 735, loss = 1500438661.55321002\n",
            "Iteration 736, loss = 1500382449.57059336\n",
            "Iteration 737, loss = 1500325739.33810186\n",
            "Iteration 738, loss = 1500269206.53374577\n",
            "Iteration 739, loss = 1500212816.09523344\n",
            "Iteration 740, loss = 1500156000.39609957\n",
            "Iteration 741, loss = 1500099411.81461859\n",
            "Iteration 742, loss = 1500043070.05780673\n",
            "Iteration 743, loss = 1499986032.70105267\n",
            "Iteration 744, loss = 1499929479.59371829\n",
            "Iteration 745, loss = 1499872874.28759909\n",
            "Iteration 746, loss = 1499816327.68169332\n",
            "Iteration 747, loss = 1499759984.03460836\n",
            "Iteration 748, loss = 1499703404.88106894\n",
            "Iteration 749, loss = 1499647454.70980954\n",
            "Iteration 750, loss = 1499591113.20104885\n",
            "Iteration 751, loss = 1499534937.08175087\n",
            "Iteration 752, loss = 1499478748.16059303\n",
            "Iteration 753, loss = 1499422753.65974879\n",
            "Iteration 754, loss = 1499366245.21629763\n",
            "Iteration 755, loss = 1499310018.94713616\n",
            "Iteration 756, loss = 1499254238.49112582\n",
            "Iteration 757, loss = 1499197853.41076517\n",
            "Iteration 758, loss = 1499141757.92423511\n",
            "Iteration 759, loss = 1499085388.39477968\n",
            "Iteration 760, loss = 1499029762.31415248\n",
            "Iteration 761, loss = 1498973723.28784609\n",
            "Iteration 762, loss = 1498917965.81585836\n",
            "Iteration 763, loss = 1498862315.67523909\n",
            "Iteration 764, loss = 1498806379.90198326\n",
            "Iteration 765, loss = 1498750568.30133581\n",
            "Iteration 766, loss = 1498695575.41579199\n",
            "Iteration 767, loss = 1498639432.35192442\n",
            "Iteration 768, loss = 1498583816.48788023\n",
            "Iteration 769, loss = 1498528349.99455643\n",
            "Iteration 770, loss = 1498472536.95325041\n",
            "Iteration 771, loss = 1498417143.75919056\n",
            "Iteration 772, loss = 1498361118.38503885\n",
            "Iteration 773, loss = 1498305479.87808895\n",
            "Iteration 774, loss = 1498249371.38042116\n",
            "Iteration 775, loss = 1498193809.62449884\n",
            "Iteration 776, loss = 1498137477.80829906\n",
            "Iteration 777, loss = 1498081536.39188004\n",
            "Iteration 778, loss = 1498025701.73365355\n",
            "Iteration 779, loss = 1497970160.37023592\n",
            "Iteration 780, loss = 1497913952.32303190\n",
            "Iteration 781, loss = 1497857771.21099496\n",
            "Iteration 782, loss = 1497795243.55815697\n",
            "Iteration 783, loss = 1497733476.53904796\n",
            "Iteration 784, loss = 1497672441.23740077\n",
            "Iteration 785, loss = 1497611083.56284189\n",
            "Iteration 786, loss = 1497549292.17552829\n",
            "Iteration 787, loss = 1497487542.30987549\n",
            "Iteration 788, loss = 1497425457.88479424\n",
            "Iteration 789, loss = 1497363913.84114027\n",
            "Iteration 790, loss = 1497301760.14208913\n",
            "Iteration 791, loss = 1497240606.14155197\n",
            "Iteration 792, loss = 1497178549.81301713\n",
            "Iteration 793, loss = 1497117750.37223721\n",
            "Iteration 794, loss = 1497056357.79892612\n",
            "Iteration 795, loss = 1496995047.04200768\n",
            "Iteration 796, loss = 1496934589.51063156\n",
            "Iteration 797, loss = 1496873452.62490153\n",
            "Iteration 798, loss = 1496813056.51053381\n",
            "Iteration 799, loss = 1496752654.56382561\n",
            "Iteration 800, loss = 1496691923.10758972\n",
            "Iteration 801, loss = 1496632057.98551655\n",
            "Iteration 802, loss = 1496571711.62970829\n",
            "Iteration 803, loss = 1496511811.54984069\n",
            "Iteration 804, loss = 1496451706.00108266\n",
            "Iteration 805, loss = 1496391940.69750953\n",
            "Iteration 806, loss = 1496331626.56411362\n",
            "Iteration 807, loss = 1496271882.49159408\n",
            "Iteration 808, loss = 1496212306.37848449\n",
            "Iteration 809, loss = 1496152724.97890615\n",
            "Iteration 810, loss = 1496092725.17360568\n",
            "Iteration 811, loss = 1496033562.57214069\n",
            "Iteration 812, loss = 1495974050.95895886\n",
            "Iteration 813, loss = 1495914911.96410108\n",
            "Iteration 814, loss = 1495855267.52311373\n",
            "Iteration 815, loss = 1495796564.15291023\n",
            "Iteration 816, loss = 1495737661.26416802\n",
            "Iteration 817, loss = 1495678785.77801108\n",
            "Iteration 818, loss = 1495619922.12656307\n",
            "Iteration 819, loss = 1495561331.15734506\n",
            "Iteration 820, loss = 1495502893.86348915\n",
            "Iteration 821, loss = 1495444235.67206573\n",
            "Iteration 822, loss = 1495385773.47977877\n",
            "Iteration 823, loss = 1495327428.49965334\n",
            "Iteration 824, loss = 1495268850.82935071\n",
            "Iteration 825, loss = 1495210325.08662534\n",
            "Iteration 826, loss = 1495152155.91249323\n",
            "Iteration 827, loss = 1495093609.66699171\n",
            "Iteration 828, loss = 1495035377.07178664\n",
            "Iteration 829, loss = 1494977213.28689814\n",
            "Iteration 830, loss = 1494918783.44371796\n",
            "Iteration 831, loss = 1494860864.85207057\n",
            "Iteration 832, loss = 1494802880.61720729\n",
            "Iteration 833, loss = 1494744453.69520140\n",
            "Iteration 834, loss = 1494687240.68715453\n",
            "Iteration 835, loss = 1494628615.96249962\n",
            "Iteration 836, loss = 1494571136.49734640\n",
            "Iteration 837, loss = 1494513073.90134239\n",
            "Iteration 838, loss = 1494455911.46848059\n",
            "Iteration 839, loss = 1494397649.32685947\n",
            "Iteration 840, loss = 1494340512.44775581\n",
            "Iteration 841, loss = 1494282816.53657675\n",
            "Iteration 842, loss = 1494225347.26842976\n",
            "Iteration 843, loss = 1494167847.19882107\n",
            "Iteration 844, loss = 1494110310.74827528\n",
            "Iteration 845, loss = 1494052940.46227837\n",
            "Iteration 846, loss = 1493995621.30831695\n",
            "Iteration 847, loss = 1493937724.02911472\n",
            "Iteration 848, loss = 1493880559.54323864\n",
            "Iteration 849, loss = 1493823208.85763764\n",
            "Iteration 850, loss = 1493765466.46538925\n",
            "Iteration 851, loss = 1493707868.60286450\n",
            "Iteration 852, loss = 1493650721.09653878\n",
            "Iteration 853, loss = 1493592960.57964897\n",
            "Iteration 854, loss = 1493535654.30578327\n",
            "Iteration 855, loss = 1493478121.98048043\n",
            "Iteration 856, loss = 1493420447.61754227\n",
            "Iteration 857, loss = 1493363227.00265837\n",
            "Iteration 858, loss = 1493305799.53218579\n",
            "Iteration 859, loss = 1493248398.71275353\n",
            "Iteration 860, loss = 1493191332.91608071\n",
            "Iteration 861, loss = 1493134326.51403928\n",
            "Iteration 862, loss = 1493077104.69242191\n",
            "Iteration 863, loss = 1493019794.09640670\n",
            "Iteration 864, loss = 1492963415.90821910\n",
            "Iteration 865, loss = 1492905906.31970501\n",
            "Iteration 866, loss = 1492848994.16377497\n",
            "Iteration 867, loss = 1492792244.15537333\n",
            "Iteration 868, loss = 1492734966.91038132\n",
            "Iteration 869, loss = 1492677740.81508541\n",
            "Iteration 870, loss = 1492620683.95498466\n",
            "Iteration 871, loss = 1492564158.05626512\n",
            "Iteration 872, loss = 1492506845.30860996\n",
            "Iteration 873, loss = 1492449989.99497461\n",
            "Iteration 874, loss = 1492393365.43140173\n",
            "Iteration 875, loss = 1492336105.80173397\n",
            "Iteration 876, loss = 1492279634.52756047\n",
            "Iteration 877, loss = 1492222909.13653994\n",
            "Iteration 878, loss = 1492166191.97605896\n",
            "Iteration 879, loss = 1492109282.45046115\n",
            "Iteration 880, loss = 1492052734.87388730\n",
            "Iteration 881, loss = 1491995771.87998223\n",
            "Iteration 882, loss = 1491939242.40520096\n",
            "Iteration 883, loss = 1491882363.30474758\n",
            "Iteration 884, loss = 1491825781.89385867\n",
            "Iteration 885, loss = 1491769121.23332548\n",
            "Iteration 886, loss = 1491712272.22541666\n",
            "Iteration 887, loss = 1491655535.92175102\n",
            "Iteration 888, loss = 1491598852.84401035\n",
            "Iteration 889, loss = 1491542242.84230065\n",
            "Iteration 890, loss = 1491485857.83353496\n",
            "Iteration 891, loss = 1491428926.43240213\n",
            "Iteration 892, loss = 1491371994.98224282\n",
            "Iteration 893, loss = 1491316017.33523512\n",
            "Iteration 894, loss = 1491258927.07313561\n",
            "Iteration 895, loss = 1491202537.08158231\n",
            "Iteration 896, loss = 1491146192.48572707\n",
            "Iteration 897, loss = 1491089567.22285748\n",
            "Iteration 898, loss = 1491033101.00361443\n",
            "Iteration 899, loss = 1490976708.23423696\n",
            "Iteration 900, loss = 1490919951.68847942\n",
            "Iteration 901, loss = 1490863779.27137733\n",
            "Iteration 902, loss = 1490807193.60571814\n",
            "Iteration 903, loss = 1490750657.53440619\n",
            "Iteration 904, loss = 1490694371.21955824\n",
            "Iteration 905, loss = 1490637509.56113291\n",
            "Iteration 906, loss = 1490581238.03413606\n",
            "Iteration 907, loss = 1490524434.13615203\n",
            "Iteration 908, loss = 1490468293.94647741\n",
            "Iteration 909, loss = 1490411427.66511035\n",
            "Iteration 910, loss = 1490355077.25114942\n",
            "Iteration 911, loss = 1490298715.88300920\n",
            "Iteration 912, loss = 1490242531.24169421\n",
            "Iteration 913, loss = 1490186013.97070980\n",
            "Iteration 914, loss = 1490129979.86377716\n",
            "Iteration 915, loss = 1490074027.75886083\n",
            "Iteration 916, loss = 1490017951.92858076\n",
            "Iteration 917, loss = 1489961925.32988381\n",
            "Iteration 918, loss = 1489905813.36398387\n",
            "Iteration 919, loss = 1489849785.51622629\n",
            "Iteration 920, loss = 1489793734.89474726\n",
            "Iteration 921, loss = 1489737679.06958747\n",
            "Iteration 922, loss = 1489681660.02016354\n",
            "Iteration 923, loss = 1489625720.62646484\n",
            "Iteration 924, loss = 1489569216.38075495\n",
            "Iteration 925, loss = 1489513884.23255944\n",
            "Iteration 926, loss = 1489457332.54893970\n",
            "Iteration 927, loss = 1489401427.75486422\n",
            "Iteration 928, loss = 1489345482.44024777\n",
            "Iteration 929, loss = 1489288810.73334241\n",
            "Iteration 930, loss = 1489233129.58435798\n",
            "Iteration 931, loss = 1489176768.92058134\n",
            "Iteration 932, loss = 1489121047.28688884\n",
            "Iteration 933, loss = 1489064552.34779716\n",
            "Iteration 934, loss = 1489008927.25106788\n",
            "Iteration 935, loss = 1488952814.44789743\n",
            "Iteration 936, loss = 1488896929.75610209\n",
            "Iteration 937, loss = 1488840844.99908400\n",
            "Iteration 938, loss = 1488784937.85936284\n",
            "Iteration 939, loss = 1488729140.40955448\n",
            "Iteration 940, loss = 1488673041.88482332\n",
            "Iteration 941, loss = 1488617073.31038857\n",
            "Iteration 942, loss = 1488561349.66370273\n",
            "Iteration 943, loss = 1488505234.77607918\n",
            "Iteration 944, loss = 1488449513.86801171\n",
            "Iteration 945, loss = 1488393794.79950809\n",
            "Iteration 946, loss = 1488337872.44461942\n",
            "Iteration 947, loss = 1488282344.03660107\n",
            "Iteration 948, loss = 1488226135.21514440\n",
            "Iteration 949, loss = 1488170764.34187031\n",
            "Iteration 950, loss = 1488114927.75710726\n",
            "Iteration 951, loss = 1488058768.43815756\n",
            "Iteration 952, loss = 1488003223.93826056\n",
            "Iteration 953, loss = 1487946832.61184788\n",
            "Iteration 954, loss = 1487890727.78303289\n",
            "Iteration 955, loss = 1487834792.23937654\n",
            "Iteration 956, loss = 1487778720.92766380\n",
            "Iteration 957, loss = 1487722521.08159661\n",
            "Iteration 958, loss = 1487666292.87915874\n",
            "Iteration 959, loss = 1487610604.36763835\n",
            "Iteration 960, loss = 1487554572.35840869\n",
            "Iteration 961, loss = 1487498876.04647303\n",
            "Iteration 962, loss = 1487443130.82738900\n",
            "Iteration 963, loss = 1487387281.77919674\n",
            "Iteration 964, loss = 1487331792.26898456\n",
            "Iteration 965, loss = 1487276354.84535789\n",
            "Iteration 966, loss = 1487220771.49735188\n",
            "Iteration 967, loss = 1487165088.28198075\n",
            "Iteration 968, loss = 1487109837.63615847\n",
            "Iteration 969, loss = 1487054179.67617321\n",
            "Iteration 970, loss = 1486998538.82154059\n",
            "Iteration 971, loss = 1486942910.03709817\n",
            "Iteration 972, loss = 1486887306.25534320\n",
            "Iteration 973, loss = 1486831166.44438362\n",
            "Iteration 974, loss = 1486775460.64510584\n",
            "Iteration 975, loss = 1486719407.06005859\n",
            "Iteration 976, loss = 1486663823.84318614\n",
            "Iteration 977, loss = 1486607580.32936072\n",
            "Iteration 978, loss = 1486551858.23253512\n",
            "Iteration 979, loss = 1486495909.23989844\n",
            "Iteration 980, loss = 1486439710.45800281\n",
            "Iteration 981, loss = 1486384233.44511890\n",
            "Iteration 982, loss = 1486328225.61680460\n",
            "Iteration 983, loss = 1486272295.59569621\n",
            "Iteration 984, loss = 1486216548.53893709\n",
            "Iteration 985, loss = 1486160689.93278909\n",
            "Iteration 986, loss = 1486105102.97404695\n",
            "Iteration 987, loss = 1486049458.72270489\n",
            "Iteration 988, loss = 1485993756.10397696\n",
            "Iteration 989, loss = 1485938487.66578245\n",
            "Iteration 990, loss = 1485883104.22202253\n",
            "Iteration 991, loss = 1485827480.98517394\n",
            "Iteration 992, loss = 1485772351.11438584\n",
            "Iteration 993, loss = 1485716655.95158529\n",
            "Iteration 994, loss = 1485661576.67406678\n",
            "Iteration 995, loss = 1485606466.45852876\n",
            "Iteration 996, loss = 1485550651.85784936\n",
            "Iteration 997, loss = 1485495165.21910715\n",
            "Iteration 998, loss = 1485439833.02537060\n",
            "Iteration 999, loss = 1485384121.07373977\n",
            "Iteration 1000, loss = 1485328548.83107424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 35018507511477848.00000000\n",
            "Iteration 2, loss = 275778608730177790680167326126386143664045055171213676971656078360041066185897945263883447444911585512870592601591826809491628228835933997803591861010330146361176688300159111453218450357447658946192848953016885927255030413831211002154036928521894363136.00000000\n",
            "Iteration 3, loss = inf\n",
            "Iteration 4, loss = inf\n",
            "Iteration 5, loss = inf\n",
            "Iteration 6, loss = inf\n",
            "Iteration 7, loss = inf\n",
            "Iteration 8, loss = inf\n",
            "Iteration 9, loss = inf\n",
            "Iteration 10, loss = inf\n",
            "Iteration 11, loss = inf\n",
            "Iteration 12, loss = inf\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538812673.86645746\n",
            "Iteration 2, loss = 1538704815.73570037\n",
            "Iteration 3, loss = 1538569666.48729753\n",
            "Iteration 4, loss = 1538369446.58401322\n",
            "Iteration 5, loss = 1538080992.48662686\n",
            "Iteration 6, loss = 1537685636.66786480\n",
            "Iteration 7, loss = 1537151188.99719882\n",
            "Iteration 8, loss = 1536443845.32225490\n",
            "Iteration 9, loss = 1535560072.99683261\n",
            "Iteration 10, loss = 1534417741.79934645\n",
            "Iteration 11, loss = 1533011628.17505050\n",
            "Iteration 12, loss = 1531285830.02889705\n",
            "Iteration 13, loss = 1529186142.27770114\n",
            "Iteration 14, loss = 1526658727.46674037\n",
            "Iteration 15, loss = 1523619926.19010782\n",
            "Iteration 16, loss = 1520034428.55982995\n",
            "Iteration 17, loss = 1515816132.96453476\n",
            "Iteration 18, loss = 1511002889.78760314\n",
            "Iteration 19, loss = 1505300288.82728457\n",
            "Iteration 20, loss = 1498791168.40288353\n",
            "Iteration 21, loss = 1491267075.32511449\n",
            "Iteration 22, loss = 1482784474.88001275\n",
            "Iteration 23, loss = 1472961670.32034469\n",
            "Iteration 24, loss = 1462067449.04307652\n",
            "Iteration 25, loss = 1449728104.25544834\n",
            "Iteration 26, loss = 1435854650.54163766\n",
            "Iteration 27, loss = 1420383589.30145812\n",
            "Iteration 28, loss = 1403151307.94853067\n",
            "Iteration 29, loss = 1384533839.64626455\n",
            "Iteration 30, loss = 1363751820.05209637\n",
            "Iteration 31, loss = 1340893966.61241698\n",
            "Iteration 32, loss = 1316269337.05756450\n",
            "Iteration 33, loss = 1289134868.42839074\n",
            "Iteration 34, loss = 1260673306.98106742\n",
            "Iteration 35, loss = 1229364460.20529723\n",
            "Iteration 36, loss = 1196085625.53565907\n",
            "Iteration 37, loss = 1160913000.18762183\n",
            "Iteration 38, loss = 1124035572.76447630\n",
            "Iteration 39, loss = 1084099200.85459685\n",
            "Iteration 40, loss = 1043263433.89947248\n",
            "Iteration 41, loss = 1001074072.75441873\n",
            "Iteration 42, loss = 956319479.63235402\n",
            "Iteration 43, loss = 910944412.09660769\n",
            "Iteration 44, loss = 864242554.31764352\n",
            "Iteration 45, loss = 816739594.71888149\n",
            "Iteration 46, loss = 768837077.84196007\n",
            "Iteration 47, loss = 719839568.41109669\n",
            "Iteration 48, loss = 671694288.94387197\n",
            "Iteration 49, loss = 623937637.33673751\n",
            "Iteration 50, loss = 576473600.90737283\n",
            "Iteration 51, loss = 530883348.83929443\n",
            "Iteration 52, loss = 486399728.68557155\n",
            "Iteration 53, loss = 443756245.45231831\n",
            "Iteration 54, loss = 403323127.67613912\n",
            "Iteration 55, loss = 366510449.13562316\n",
            "Iteration 56, loss = 330769992.58316672\n",
            "Iteration 57, loss = 299253544.04206103\n",
            "Iteration 58, loss = 269619109.87060100\n",
            "Iteration 59, loss = 243299289.72085220\n",
            "Iteration 60, loss = 219885284.77771404\n",
            "Iteration 61, loss = 199377419.36683908\n",
            "Iteration 62, loss = 180261504.26610509\n",
            "Iteration 63, loss = 164277795.32565442\n",
            "Iteration 64, loss = 150717023.37916315\n",
            "Iteration 65, loss = 138707503.42137396\n",
            "Iteration 66, loss = 129629321.69727416\n",
            "Iteration 67, loss = 121922490.25827275\n",
            "Iteration 68, loss = 116113769.61059076\n",
            "Iteration 69, loss = 111515081.77870668\n",
            "Iteration 70, loss = 108402461.77546850\n",
            "Iteration 71, loss = 106281469.19430004\n",
            "Iteration 72, loss = 104405514.85822339\n",
            "Iteration 73, loss = 103361376.73780526\n",
            "Iteration 74, loss = 102253565.76945487\n",
            "Iteration 75, loss = 101388086.10363162\n",
            "Iteration 76, loss = 100372852.18796840\n",
            "Iteration 77, loss = 99393239.55743581\n",
            "Iteration 78, loss = 98330358.82340221\n",
            "Iteration 79, loss = 97091536.84313029\n",
            "Iteration 80, loss = 95759502.85732786\n",
            "Iteration 81, loss = 94363598.59328324\n",
            "Iteration 82, loss = 92915770.58922531\n",
            "Iteration 83, loss = 91386735.81459558\n",
            "Iteration 84, loss = 89940098.47536163\n",
            "Iteration 85, loss = 88415002.45741303\n",
            "Iteration 86, loss = 86972384.56864168\n",
            "Iteration 87, loss = 85504244.50038408\n",
            "Iteration 88, loss = 84010357.50793093\n",
            "Iteration 89, loss = 82533414.51449817\n",
            "Iteration 90, loss = 81024552.76992242\n",
            "Iteration 91, loss = 79519133.27744584\n",
            "Iteration 92, loss = 78010699.91493553\n",
            "Iteration 93, loss = 76412623.42621462\n",
            "Iteration 94, loss = 74905671.36591353\n",
            "Iteration 95, loss = 73387568.92100929\n",
            "Iteration 96, loss = 71848133.94200942\n",
            "Iteration 97, loss = 70370376.27230869\n",
            "Iteration 98, loss = 68900269.01811554\n",
            "Iteration 99, loss = 67520587.32372859\n",
            "Iteration 100, loss = 66115583.40409366\n",
            "Iteration 101, loss = 64839414.74105672\n",
            "Iteration 102, loss = 63612582.30472287\n",
            "Iteration 103, loss = 62482517.57076616\n",
            "Iteration 104, loss = 61357772.41924240\n",
            "Iteration 105, loss = 60368019.38020140\n",
            "Iteration 106, loss = 59439003.89554126\n",
            "Iteration 107, loss = 58519267.55163659\n",
            "Iteration 108, loss = 57691109.75279818\n",
            "Iteration 109, loss = 56897153.73097290\n",
            "Iteration 110, loss = 56053953.17462006\n",
            "Iteration 111, loss = 55311362.25709729\n",
            "Iteration 112, loss = 54590538.61598986\n",
            "Iteration 113, loss = 53922658.20747993\n",
            "Iteration 114, loss = 53304947.72034624\n",
            "Iteration 115, loss = 52724522.49822910\n",
            "Iteration 116, loss = 52183457.42419045\n",
            "Iteration 117, loss = 51717895.94893178\n",
            "Iteration 118, loss = 51222756.99677353\n",
            "Iteration 119, loss = 50750947.13307950\n",
            "Iteration 120, loss = 50296849.15699681\n",
            "Iteration 121, loss = 49864104.78770074\n",
            "Iteration 122, loss = 49435118.54747391\n",
            "Iteration 123, loss = 49029726.70519972\n",
            "Iteration 124, loss = 48693466.55994302\n",
            "Iteration 125, loss = 48349408.88795243\n",
            "Iteration 126, loss = 48001575.58939438\n",
            "Iteration 127, loss = 47632308.39888804\n",
            "Iteration 128, loss = 47254999.50268243\n",
            "Iteration 129, loss = 46861183.39547005\n",
            "Iteration 130, loss = 46459604.32677010\n",
            "Iteration 131, loss = 46070354.58897072\n",
            "Iteration 132, loss = 45687941.17333162\n",
            "Iteration 133, loss = 45321401.80675240\n",
            "Iteration 134, loss = 44965039.55602045\n",
            "Iteration 135, loss = 44597743.60737545\n",
            "Iteration 136, loss = 44286170.34970359\n",
            "Iteration 137, loss = 43947600.16474918\n",
            "Iteration 138, loss = 43616049.74192955\n",
            "Iteration 139, loss = 43273934.90905011\n",
            "Iteration 140, loss = 42964948.50288794\n",
            "Iteration 141, loss = 42630573.76997985\n",
            "Iteration 142, loss = 42350673.46607574\n",
            "Iteration 143, loss = 42028352.59084806\n",
            "Iteration 144, loss = 41687041.69292607\n",
            "Iteration 145, loss = 41324074.87279715\n",
            "Iteration 146, loss = 40967719.46693509\n",
            "Iteration 147, loss = 40644585.04036553\n",
            "Iteration 148, loss = 40308566.16893527\n",
            "Iteration 149, loss = 39994007.44662942\n",
            "Iteration 150, loss = 39660275.50403590\n",
            "Iteration 151, loss = 39348675.07174803\n",
            "Iteration 152, loss = 39031249.63177031\n",
            "Iteration 153, loss = 38718100.38086333\n",
            "Iteration 154, loss = 38396188.45118780\n",
            "Iteration 155, loss = 38083598.21462381\n",
            "Iteration 156, loss = 37766316.33930441\n",
            "Iteration 157, loss = 37452271.62847660\n",
            "Iteration 158, loss = 37153893.61943957\n",
            "Iteration 159, loss = 36845051.24295805\n",
            "Iteration 160, loss = 36519802.80445983\n",
            "Iteration 161, loss = 36254433.39210297\n",
            "Iteration 162, loss = 35956464.89854303\n",
            "Iteration 163, loss = 35655677.61586830\n",
            "Iteration 164, loss = 35344681.86031606\n",
            "Iteration 165, loss = 35059390.85239545\n",
            "Iteration 166, loss = 34757853.76325113\n",
            "Iteration 167, loss = 34456142.41986313\n",
            "Iteration 168, loss = 34166541.11484668\n",
            "Iteration 169, loss = 33872659.84692606\n",
            "Iteration 170, loss = 33578488.39318478\n",
            "Iteration 171, loss = 33279163.80464748\n",
            "Iteration 172, loss = 32982744.36976250\n",
            "Iteration 173, loss = 32679194.74579915\n",
            "Iteration 174, loss = 32384147.57453793\n",
            "Iteration 175, loss = 32083442.07804795\n",
            "Iteration 176, loss = 31821094.40122343\n",
            "Iteration 177, loss = 31519587.53867437\n",
            "Iteration 178, loss = 31253316.05340061\n",
            "Iteration 179, loss = 30969596.00205290\n",
            "Iteration 180, loss = 30687609.10294798\n",
            "Iteration 181, loss = 30411546.81959724\n",
            "Iteration 182, loss = 30142203.42911754\n",
            "Iteration 183, loss = 29869959.02619220\n",
            "Iteration 184, loss = 29602288.90106222\n",
            "Iteration 185, loss = 29316170.05126617\n",
            "Iteration 186, loss = 29039617.70070900\n",
            "Iteration 187, loss = 28782763.01400190\n",
            "Iteration 188, loss = 28531773.57306833\n",
            "Iteration 189, loss = 28269827.49640088\n",
            "Iteration 190, loss = 28042579.08712817\n",
            "Iteration 191, loss = 27788825.00620173\n",
            "Iteration 192, loss = 27541611.06318600\n",
            "Iteration 193, loss = 27301458.64081704\n",
            "Iteration 194, loss = 27046635.44797029\n",
            "Iteration 195, loss = 26793144.28001042\n",
            "Iteration 196, loss = 26531105.21054356\n",
            "Iteration 197, loss = 26299526.68701137\n",
            "Iteration 198, loss = 26038929.20564613\n",
            "Iteration 199, loss = 25821766.81979932\n",
            "Iteration 200, loss = 25561943.40099683\n",
            "Iteration 201, loss = 25309429.99592316\n",
            "Iteration 202, loss = 25079834.00468314\n",
            "Iteration 203, loss = 24829079.79355323\n",
            "Iteration 204, loss = 24610008.50765675\n",
            "Iteration 205, loss = 24364981.24692556\n",
            "Iteration 206, loss = 24141670.29875623\n",
            "Iteration 207, loss = 23902835.79225783\n",
            "Iteration 208, loss = 23669761.43637246\n",
            "Iteration 209, loss = 23444691.89912662\n",
            "Iteration 210, loss = 23215320.51672367\n",
            "Iteration 211, loss = 22990443.01740189\n",
            "Iteration 212, loss = 22768935.01231261\n",
            "Iteration 213, loss = 22563792.54455234\n",
            "Iteration 214, loss = 22352037.98353440\n",
            "Iteration 215, loss = 22123320.18136821\n",
            "Iteration 216, loss = 21907416.83892435\n",
            "Iteration 217, loss = 21663744.73177430\n",
            "Iteration 218, loss = 21432115.95819809\n",
            "Iteration 219, loss = 21213540.56357218\n",
            "Iteration 220, loss = 20984895.15410646\n",
            "Iteration 221, loss = 20770626.82025654\n",
            "Iteration 222, loss = 20541477.91797097\n",
            "Iteration 223, loss = 20317733.51680921\n",
            "Iteration 224, loss = 20102362.74858459\n",
            "Iteration 225, loss = 19886418.53915915\n",
            "Iteration 226, loss = 19672419.21516766\n",
            "Iteration 227, loss = 19443871.89731300\n",
            "Iteration 228, loss = 19214751.98905973\n",
            "Iteration 229, loss = 18979265.54287584\n",
            "Iteration 230, loss = 18742238.64451097\n",
            "Iteration 231, loss = 18528167.05646104\n",
            "Iteration 232, loss = 18302948.02546220\n",
            "Iteration 233, loss = 18061955.36252049\n",
            "Iteration 234, loss = 17831149.16764675\n",
            "Iteration 235, loss = 17585530.85332693\n",
            "Iteration 236, loss = 17352613.77706774\n",
            "Iteration 237, loss = 17109600.60962753\n",
            "Iteration 238, loss = 16874513.34525575\n",
            "Iteration 239, loss = 16633494.15687082\n",
            "Iteration 240, loss = 16387411.12678128\n",
            "Iteration 241, loss = 16150285.46038611\n",
            "Iteration 242, loss = 15913040.70367844\n",
            "Iteration 243, loss = 15665030.24599407\n",
            "Iteration 244, loss = 15436550.92112067\n",
            "Iteration 245, loss = 15198458.26892330\n",
            "Iteration 246, loss = 14980013.28503984\n",
            "Iteration 247, loss = 14761267.92030322\n",
            "Iteration 248, loss = 14528473.80167681\n",
            "Iteration 249, loss = 14268589.32845044\n",
            "Iteration 250, loss = 14029322.86870201\n",
            "Iteration 251, loss = 13783254.15920689\n",
            "Iteration 252, loss = 13542853.15857974\n",
            "Iteration 253, loss = 13305700.59988734\n",
            "Iteration 254, loss = 13088593.50859832\n",
            "Iteration 255, loss = 12856291.64963770\n",
            "Iteration 256, loss = 12650105.91854485\n",
            "Iteration 257, loss = 12406409.21680547\n",
            "Iteration 258, loss = 12187426.25047745\n",
            "Iteration 259, loss = 11963063.69274674\n",
            "Iteration 260, loss = 11744020.32452955\n",
            "Iteration 261, loss = 11524378.80889835\n",
            "Iteration 262, loss = 11302089.55258314\n",
            "Iteration 263, loss = 11097850.36935205\n",
            "Iteration 264, loss = 10889401.84717617\n",
            "Iteration 265, loss = 10678092.79643030\n",
            "Iteration 266, loss = 10469597.12185124\n",
            "Iteration 267, loss = 10266734.70726574\n",
            "Iteration 268, loss = 10049062.60093145\n",
            "Iteration 269, loss = 9854823.10831793\n",
            "Iteration 270, loss = 9656519.18398363\n",
            "Iteration 271, loss = 9453888.33584279\n",
            "Iteration 272, loss = 9270372.04241989\n",
            "Iteration 273, loss = 9068345.50367698\n",
            "Iteration 274, loss = 8895368.10644455\n",
            "Iteration 275, loss = 8697752.31207273\n",
            "Iteration 276, loss = 8510004.01553954\n",
            "Iteration 277, loss = 8331310.84801515\n",
            "Iteration 278, loss = 8153505.57207607\n",
            "Iteration 279, loss = 7968689.60484317\n",
            "Iteration 280, loss = 7794495.70841244\n",
            "Iteration 281, loss = 7631078.37159614\n",
            "Iteration 282, loss = 7463544.77800763\n",
            "Iteration 283, loss = 7303971.66233489\n",
            "Iteration 284, loss = 7152292.46016170\n",
            "Iteration 285, loss = 7005764.15851650\n",
            "Iteration 286, loss = 6869761.06780131\n",
            "Iteration 287, loss = 6729428.38016157\n",
            "Iteration 288, loss = 6598219.33941695\n",
            "Iteration 289, loss = 6454352.14220261\n",
            "Iteration 290, loss = 6316353.02039392\n",
            "Iteration 291, loss = 6172210.07352744\n",
            "Iteration 292, loss = 6052799.51030283\n",
            "Iteration 293, loss = 5925907.92361071\n",
            "Iteration 294, loss = 5803627.71535477\n",
            "Iteration 295, loss = 5676952.46676720\n",
            "Iteration 296, loss = 5569977.76631137\n",
            "Iteration 297, loss = 5447684.48374837\n",
            "Iteration 298, loss = 5341342.82775640\n",
            "Iteration 299, loss = 5226253.34053254\n",
            "Iteration 300, loss = 5125274.97269176\n",
            "Iteration 301, loss = 5027702.97439229\n",
            "Iteration 302, loss = 4935335.57896061\n",
            "Iteration 303, loss = 4841833.70791261\n",
            "Iteration 304, loss = 4752617.94435498\n",
            "Iteration 305, loss = 4666902.15763791\n",
            "Iteration 306, loss = 4581328.11921519\n",
            "Iteration 307, loss = 4497341.59670246\n",
            "Iteration 308, loss = 4417586.50331353\n",
            "Iteration 309, loss = 4330821.53490916\n",
            "Iteration 310, loss = 4258285.56126706\n",
            "Iteration 311, loss = 4181105.87010813\n",
            "Iteration 312, loss = 4108539.82464439\n",
            "Iteration 313, loss = 4040502.93771473\n",
            "Iteration 314, loss = 3967437.46521204\n",
            "Iteration 315, loss = 3899708.30957116\n",
            "Iteration 316, loss = 3832395.40818488\n",
            "Iteration 317, loss = 3769525.86819137\n",
            "Iteration 318, loss = 3704772.44133025\n",
            "Iteration 319, loss = 3641872.63205564\n",
            "Iteration 320, loss = 3583471.98180169\n",
            "Iteration 321, loss = 3535692.90036901\n",
            "Iteration 322, loss = 3476495.89805977\n",
            "Iteration 323, loss = 3417990.77583206\n",
            "Iteration 324, loss = 3356553.34789318\n",
            "Iteration 325, loss = 3299612.94632784\n",
            "Iteration 326, loss = 3250308.43938982\n",
            "Iteration 327, loss = 3199983.48906003\n",
            "Iteration 328, loss = 3152765.92321696\n",
            "Iteration 329, loss = 3105494.96187720\n",
            "Iteration 330, loss = 3059016.42595752\n",
            "Iteration 331, loss = 3014958.10929337\n",
            "Iteration 332, loss = 2971136.92390777\n",
            "Iteration 333, loss = 2924330.01705202\n",
            "Iteration 334, loss = 2882223.91326474\n",
            "Iteration 335, loss = 2840327.52272706\n",
            "Iteration 336, loss = 2801653.29687585\n",
            "Iteration 337, loss = 2762678.76108452\n",
            "Iteration 338, loss = 2725427.11693363\n",
            "Iteration 339, loss = 2690678.87196448\n",
            "Iteration 340, loss = 2653372.09084303\n",
            "Iteration 341, loss = 2617344.85948682\n",
            "Iteration 342, loss = 2582578.37910847\n",
            "Iteration 343, loss = 2545803.80926720\n",
            "Iteration 344, loss = 2511828.94408587\n",
            "Iteration 345, loss = 2478439.58180279\n",
            "Iteration 346, loss = 2445500.74464331\n",
            "Iteration 347, loss = 2420512.16910989\n",
            "Iteration 348, loss = 2391693.91428650\n",
            "Iteration 349, loss = 2368121.43777455\n",
            "Iteration 350, loss = 2339394.81324458\n",
            "Iteration 351, loss = 2307463.03528211\n",
            "Iteration 352, loss = 2272945.07941069\n",
            "Iteration 353, loss = 2248468.63347379\n",
            "Iteration 354, loss = 2219486.78691341\n",
            "Iteration 355, loss = 2194455.34412732\n",
            "Iteration 356, loss = 2171569.72094713\n",
            "Iteration 357, loss = 2150919.18572811\n",
            "Iteration 358, loss = 2130133.09540175\n",
            "Iteration 359, loss = 2112091.67339338\n",
            "Iteration 360, loss = 2088104.16946635\n",
            "Iteration 361, loss = 2064971.82061352\n",
            "Iteration 362, loss = 2038512.71978942\n",
            "Iteration 363, loss = 2018051.24749576\n",
            "Iteration 364, loss = 2001206.72918831\n",
            "Iteration 365, loss = 1984035.53482788\n",
            "Iteration 366, loss = 1966945.62837542\n",
            "Iteration 367, loss = 1944777.12400922\n",
            "Iteration 368, loss = 1922334.91838219\n",
            "Iteration 369, loss = 1903703.27997028\n",
            "Iteration 370, loss = 1887427.25333364\n",
            "Iteration 371, loss = 1874358.65429777\n",
            "Iteration 372, loss = 1859088.13994633\n",
            "Iteration 373, loss = 1845537.46220510\n",
            "Iteration 374, loss = 1827207.49541680\n",
            "Iteration 375, loss = 1811297.09506518\n",
            "Iteration 376, loss = 1795801.61611086\n",
            "Iteration 377, loss = 1780020.04937271\n",
            "Iteration 378, loss = 1764203.35165857\n",
            "Iteration 379, loss = 1754719.65247657\n",
            "Iteration 380, loss = 1745182.43258273\n",
            "Iteration 381, loss = 1732902.16098719\n",
            "Iteration 382, loss = 1718039.86474003\n",
            "Iteration 383, loss = 1703534.61025682\n",
            "Iteration 384, loss = 1689181.60889940\n",
            "Iteration 385, loss = 1674838.81537013\n",
            "Iteration 386, loss = 1660798.85734399\n",
            "Iteration 387, loss = 1647004.01478152\n",
            "Iteration 388, loss = 1635927.69823178\n",
            "Iteration 389, loss = 1622744.16934690\n",
            "Iteration 390, loss = 1613101.52636607\n",
            "Iteration 391, loss = 1601428.50636119\n",
            "Iteration 392, loss = 1589670.34413573\n",
            "Iteration 393, loss = 1579608.31308377\n",
            "Iteration 394, loss = 1571880.19595037\n",
            "Iteration 395, loss = 1562093.82898965\n",
            "Iteration 396, loss = 1551502.29058429\n",
            "Iteration 397, loss = 1542627.30908922\n",
            "Iteration 398, loss = 1533115.94863371\n",
            "Iteration 399, loss = 1524232.88993751\n",
            "Iteration 400, loss = 1516295.14259533\n",
            "Iteration 401, loss = 1507308.31067324\n",
            "Iteration 402, loss = 1499029.27775677\n",
            "Iteration 403, loss = 1489951.86073918\n",
            "Iteration 404, loss = 1483443.79302504\n",
            "Iteration 405, loss = 1477048.31358361\n",
            "Iteration 406, loss = 1472867.97276202\n",
            "Iteration 407, loss = 1465669.34539589\n",
            "Iteration 408, loss = 1458262.67783699\n",
            "Iteration 409, loss = 1448215.87837814\n",
            "Iteration 410, loss = 1440151.73571097\n",
            "Iteration 411, loss = 1432611.22556394\n",
            "Iteration 412, loss = 1424411.69354264\n",
            "Iteration 413, loss = 1419439.06654541\n",
            "Iteration 414, loss = 1412991.72236578\n",
            "Iteration 415, loss = 1407161.20267160\n",
            "Iteration 416, loss = 1401477.41021007\n",
            "Iteration 417, loss = 1396059.53143407\n",
            "Iteration 418, loss = 1389080.33815501\n",
            "Iteration 419, loss = 1382021.81853115\n",
            "Iteration 420, loss = 1375386.64474673\n",
            "Iteration 421, loss = 1368972.43295444\n",
            "Iteration 422, loss = 1363396.21191353\n",
            "Iteration 423, loss = 1358103.10454316\n",
            "Iteration 424, loss = 1355192.85744418\n",
            "Iteration 425, loss = 1349235.97613321\n",
            "Iteration 426, loss = 1344459.80947626\n",
            "Iteration 427, loss = 1340483.46640294\n",
            "Iteration 428, loss = 1335007.39736234\n",
            "Iteration 429, loss = 1328968.48328589\n",
            "Iteration 430, loss = 1326109.25301793\n",
            "Iteration 431, loss = 1321635.87606947\n",
            "Iteration 432, loss = 1319111.95657717\n",
            "Iteration 433, loss = 1314148.34772119\n",
            "Iteration 434, loss = 1307838.52298950\n",
            "Iteration 435, loss = 1304042.65903529\n",
            "Iteration 436, loss = 1298884.45966638\n",
            "Iteration 437, loss = 1294468.32100861\n",
            "Iteration 438, loss = 1290955.90494343\n",
            "Iteration 439, loss = 1286321.64216311\n",
            "Iteration 440, loss = 1282169.25228304\n",
            "Iteration 441, loss = 1277719.48919604\n",
            "Iteration 442, loss = 1273768.62773693\n",
            "Iteration 443, loss = 1270570.29171762\n",
            "Iteration 444, loss = 1268028.81823935\n",
            "Iteration 445, loss = 1263401.15852526\n",
            "Iteration 446, loss = 1258545.08316380\n",
            "Iteration 447, loss = 1254247.86350754\n",
            "Iteration 448, loss = 1252007.23840698\n",
            "Iteration 449, loss = 1250095.68212479\n",
            "Iteration 450, loss = 1246756.88854221\n",
            "Iteration 451, loss = 1244566.12598020\n",
            "Iteration 452, loss = 1240657.77661646\n",
            "Iteration 453, loss = 1236223.07345559\n",
            "Iteration 454, loss = 1231065.88977534\n",
            "Iteration 455, loss = 1227103.50403876\n",
            "Iteration 456, loss = 1224408.76585778\n",
            "Iteration 457, loss = 1222916.16787721\n",
            "Iteration 458, loss = 1219774.11129179\n",
            "Iteration 459, loss = 1216618.07971335\n",
            "Iteration 460, loss = 1213556.21912078\n",
            "Iteration 461, loss = 1210643.28642131\n",
            "Iteration 462, loss = 1207979.18134281\n",
            "Iteration 463, loss = 1205307.51611167\n",
            "Iteration 464, loss = 1203436.29475299\n",
            "Iteration 465, loss = 1200959.20508203\n",
            "Iteration 466, loss = 1198792.72094817\n",
            "Iteration 467, loss = 1196589.59416321\n",
            "Iteration 468, loss = 1194425.51476517\n",
            "Iteration 469, loss = 1192624.08155432\n",
            "Iteration 470, loss = 1189362.47151235\n",
            "Iteration 471, loss = 1187628.44019103\n",
            "Iteration 472, loss = 1185809.21954211\n",
            "Iteration 473, loss = 1183794.51209607\n",
            "Iteration 474, loss = 1182005.49548246\n",
            "Iteration 475, loss = 1180108.13395078\n",
            "Iteration 476, loss = 1178528.71276709\n",
            "Iteration 477, loss = 1176858.30226198\n",
            "Iteration 478, loss = 1174862.55244718\n",
            "Iteration 479, loss = 1172470.30950409\n",
            "Iteration 480, loss = 1170446.78145830\n",
            "Iteration 481, loss = 1168717.47592868\n",
            "Iteration 482, loss = 1167142.11098384\n",
            "Iteration 483, loss = 1165538.81502625\n",
            "Iteration 484, loss = 1164097.26153623\n",
            "Iteration 485, loss = 1163163.19607178\n",
            "Iteration 486, loss = 1162379.56420841\n",
            "Iteration 487, loss = 1161135.80136573\n",
            "Iteration 488, loss = 1161073.56291358\n",
            "Iteration 489, loss = 1158938.87622216\n",
            "Iteration 490, loss = 1157360.11974805\n",
            "Iteration 491, loss = 1155094.14456792\n",
            "Iteration 492, loss = 1153495.84356354\n",
            "Iteration 493, loss = 1151610.87022655\n",
            "Iteration 494, loss = 1150806.58086208\n",
            "Iteration 495, loss = 1150216.50305576\n",
            "Iteration 496, loss = 1150787.79954520\n",
            "Iteration 497, loss = 1150173.53810392\n",
            "Iteration 498, loss = 1148494.52903459\n",
            "Iteration 499, loss = 1146670.37000455\n",
            "Iteration 500, loss = 1144667.15388027\n",
            "Iteration 501, loss = 1145095.16743677\n",
            "Iteration 502, loss = 1145641.18244645\n",
            "Iteration 503, loss = 1143723.11139533\n",
            "Iteration 504, loss = 1141168.98440007\n",
            "Iteration 505, loss = 1140692.97714931\n",
            "Iteration 506, loss = 1138992.83992420\n",
            "Iteration 507, loss = 1137856.08485350\n",
            "Iteration 508, loss = 1136439.07733210\n",
            "Iteration 509, loss = 1135007.34744058\n",
            "Iteration 510, loss = 1138084.29858712\n",
            "Iteration 511, loss = 1135629.00775354\n",
            "Iteration 512, loss = 1134381.39284857\n",
            "Iteration 513, loss = 1134363.43468012\n",
            "Iteration 514, loss = 1133105.55659290\n",
            "Iteration 515, loss = 1131563.47085000\n",
            "Iteration 516, loss = 1130358.59552189\n",
            "Iteration 517, loss = 1129625.94476554\n",
            "Iteration 518, loss = 1128701.67689772\n",
            "Iteration 519, loss = 1127579.25311740\n",
            "Iteration 520, loss = 1126942.32128452\n",
            "Iteration 521, loss = 1127237.93030545\n",
            "Iteration 522, loss = 1126032.49597356\n",
            "Iteration 523, loss = 1125416.24776397\n",
            "Iteration 524, loss = 1125578.70769922\n",
            "Iteration 525, loss = 1124760.55828852\n",
            "Iteration 526, loss = 1121695.84638580\n",
            "Iteration 527, loss = 1119732.00413605\n",
            "Iteration 528, loss = 1120632.26204565\n",
            "Iteration 529, loss = 1120189.28744682\n",
            "Iteration 530, loss = 1120241.22476305\n",
            "Iteration 531, loss = 1117630.65586439\n",
            "Iteration 532, loss = 1116634.11604514\n",
            "Iteration 533, loss = 1115561.48033828\n",
            "Iteration 534, loss = 1116055.45490743\n",
            "Iteration 535, loss = 1113244.22759674\n",
            "Iteration 536, loss = 1111436.94273201\n",
            "Iteration 537, loss = 1112561.63409523\n",
            "Iteration 538, loss = 1112125.74595587\n",
            "Iteration 539, loss = 1110187.60195375\n",
            "Iteration 540, loss = 1108700.49214822\n",
            "Iteration 541, loss = 1107706.04141973\n",
            "Iteration 542, loss = 1107828.95282460\n",
            "Iteration 543, loss = 1107938.56729396\n",
            "Iteration 544, loss = 1107264.85618731\n",
            "Iteration 545, loss = 1105846.86612522\n",
            "Iteration 546, loss = 1103502.22243164\n",
            "Iteration 547, loss = 1102110.84077184\n",
            "Iteration 548, loss = 1101282.12239902\n",
            "Iteration 549, loss = 1104619.53715507\n",
            "Iteration 550, loss = 1106142.23390587\n",
            "Iteration 551, loss = 1104357.93554707\n",
            "Iteration 552, loss = 1101743.17634582\n",
            "Iteration 553, loss = 1097775.28342270\n",
            "Iteration 554, loss = 1097692.93531541\n",
            "Iteration 555, loss = 1097747.52295900\n",
            "Iteration 556, loss = 1099171.65932382\n",
            "Iteration 557, loss = 1100458.90504074\n",
            "Iteration 558, loss = 1100393.80370993\n",
            "Iteration 559, loss = 1098067.02701909\n",
            "Iteration 560, loss = 1096816.37782186\n",
            "Iteration 561, loss = 1093067.23428843\n",
            "Iteration 562, loss = 1092827.71734349\n",
            "Iteration 563, loss = 1092444.84012104\n",
            "Iteration 564, loss = 1091782.47328345\n",
            "Iteration 565, loss = 1091676.05100209\n",
            "Iteration 566, loss = 1091872.36680076\n",
            "Iteration 567, loss = 1090360.26005322\n",
            "Iteration 568, loss = 1088939.95037538\n",
            "Iteration 569, loss = 1087970.40392221\n",
            "Iteration 570, loss = 1087128.12790040\n",
            "Iteration 571, loss = 1089473.71837633\n",
            "Iteration 572, loss = 1089020.13488555\n",
            "Iteration 573, loss = 1088047.87749784\n",
            "Iteration 574, loss = 1086566.76277064\n",
            "Iteration 575, loss = 1084585.14306720\n",
            "Iteration 576, loss = 1085025.97404770\n",
            "Iteration 577, loss = 1085498.46398396\n",
            "Iteration 578, loss = 1086450.30122323\n",
            "Iteration 579, loss = 1086220.86444672\n",
            "Iteration 580, loss = 1085651.18558561\n",
            "Iteration 581, loss = 1085042.20332362\n",
            "Iteration 582, loss = 1083526.08569420\n",
            "Iteration 583, loss = 1082965.24978319\n",
            "Iteration 584, loss = 1080751.42098128\n",
            "Iteration 585, loss = 1080044.49383861\n",
            "Iteration 586, loss = 1079398.34923241\n",
            "Iteration 587, loss = 1079849.15116321\n",
            "Iteration 588, loss = 1081382.73158079\n",
            "Iteration 589, loss = 1082259.06273215\n",
            "Iteration 590, loss = 1081204.72417023\n",
            "Iteration 591, loss = 1078970.38790637\n",
            "Iteration 592, loss = 1077056.30868551\n",
            "Iteration 593, loss = 1082143.56999306\n",
            "Iteration 594, loss = 1088573.47500546\n",
            "Iteration 595, loss = 1088717.06689733\n",
            "Iteration 596, loss = 1084850.48576822\n",
            "Iteration 597, loss = 1077716.84867176\n",
            "Iteration 598, loss = 1074319.00751743\n",
            "Iteration 599, loss = 1073489.46275129\n",
            "Iteration 600, loss = 1079664.37096201\n",
            "Iteration 601, loss = 1082480.52596398\n",
            "Iteration 602, loss = 1082471.87719588\n",
            "Iteration 603, loss = 1077301.83355282\n",
            "Iteration 604, loss = 1070710.56706808\n",
            "Iteration 605, loss = 1070649.51656045\n",
            "Iteration 606, loss = 1075762.67439996\n",
            "Iteration 607, loss = 1078436.48126661\n",
            "Iteration 608, loss = 1079734.14695633\n",
            "Iteration 609, loss = 1079347.84400537\n",
            "Iteration 610, loss = 1076150.61745993\n",
            "Iteration 611, loss = 1073103.89316791\n",
            "Iteration 612, loss = 1070383.29268257\n",
            "Iteration 613, loss = 1068716.00833793\n",
            "Iteration 614, loss = 1068649.55026085\n",
            "Iteration 615, loss = 1068290.31313883\n",
            "Iteration 616, loss = 1067950.20385416\n",
            "Iteration 617, loss = 1066921.84942733\n",
            "Iteration 618, loss = 1065957.47289434\n",
            "Iteration 619, loss = 1065444.65713939\n",
            "Iteration 620, loss = 1065179.16357693\n",
            "Iteration 621, loss = 1065263.39806600\n",
            "Iteration 622, loss = 1065031.46463535\n",
            "Iteration 623, loss = 1064245.02404354\n",
            "Iteration 624, loss = 1063367.62091599\n",
            "Iteration 625, loss = 1063062.47838340\n",
            "Iteration 626, loss = 1061989.71610015\n",
            "Iteration 627, loss = 1061886.49398131\n",
            "Iteration 628, loss = 1062618.62569258\n",
            "Iteration 629, loss = 1062854.53699613\n",
            "Iteration 630, loss = 1062472.85184348\n",
            "Iteration 631, loss = 1061443.57966576\n",
            "Iteration 632, loss = 1060386.05503275\n",
            "Iteration 633, loss = 1060221.94721956\n",
            "Iteration 634, loss = 1060017.07098607\n",
            "Iteration 635, loss = 1060612.30892846\n",
            "Iteration 636, loss = 1062670.45957959\n",
            "Iteration 637, loss = 1064268.84575946\n",
            "Iteration 638, loss = 1061923.14135246\n",
            "Iteration 639, loss = 1059058.40321379\n",
            "Iteration 640, loss = 1057417.02783236\n",
            "Iteration 641, loss = 1057653.51823976\n",
            "Iteration 642, loss = 1058240.76854300\n",
            "Iteration 643, loss = 1059439.09879177\n",
            "Iteration 644, loss = 1058290.68266004\n",
            "Iteration 645, loss = 1057875.85547876\n",
            "Iteration 646, loss = 1055755.51100325\n",
            "Iteration 647, loss = 1055625.08984222\n",
            "Iteration 648, loss = 1054893.81607587\n",
            "Iteration 649, loss = 1055266.51933618\n",
            "Iteration 650, loss = 1055501.96934519\n",
            "Iteration 651, loss = 1054391.20957690\n",
            "Iteration 652, loss = 1054368.30367390\n",
            "Iteration 653, loss = 1054442.32378528\n",
            "Iteration 654, loss = 1054289.66580256\n",
            "Iteration 655, loss = 1053723.30331097\n",
            "Iteration 656, loss = 1053440.49812837\n",
            "Iteration 657, loss = 1051781.42819541\n",
            "Iteration 658, loss = 1051374.38983862\n",
            "Iteration 659, loss = 1052250.25445010\n",
            "Iteration 660, loss = 1052927.59789230\n",
            "Iteration 661, loss = 1053261.67060923\n",
            "Iteration 662, loss = 1051880.66068807\n",
            "Iteration 663, loss = 1050877.16382868\n",
            "Iteration 664, loss = 1050305.26322600\n",
            "Iteration 665, loss = 1050588.05760289\n",
            "Iteration 666, loss = 1050897.61759534\n",
            "Iteration 667, loss = 1051808.99449741\n",
            "Iteration 668, loss = 1052493.50378796\n",
            "Iteration 669, loss = 1053288.16606292\n",
            "Iteration 670, loss = 1052876.27428007\n",
            "Iteration 671, loss = 1050683.86805487\n",
            "Iteration 672, loss = 1048695.49574796\n",
            "Iteration 673, loss = 1046722.33074041\n",
            "Iteration 674, loss = 1047126.67420575\n",
            "Iteration 675, loss = 1048723.26815506\n",
            "Iteration 676, loss = 1049217.87847055\n",
            "Iteration 677, loss = 1050747.93586821\n",
            "Iteration 678, loss = 1048149.91222207\n",
            "Iteration 679, loss = 1046312.44254797\n",
            "Iteration 680, loss = 1045244.81277254\n",
            "Iteration 681, loss = 1045256.41725895\n",
            "Iteration 682, loss = 1045111.73225259\n",
            "Iteration 683, loss = 1045591.33259644\n",
            "Iteration 684, loss = 1045339.29685098\n",
            "Iteration 685, loss = 1044182.32781841\n",
            "Iteration 686, loss = 1044885.93407048\n",
            "Iteration 687, loss = 1043840.81049694\n",
            "Iteration 688, loss = 1044408.11975633\n",
            "Iteration 689, loss = 1044547.52552101\n",
            "Iteration 690, loss = 1042504.03891331\n",
            "Iteration 691, loss = 1042891.45790150\n",
            "Iteration 692, loss = 1043798.35940246\n",
            "Iteration 693, loss = 1046303.98632130\n",
            "Iteration 694, loss = 1046544.35745427\n",
            "Iteration 695, loss = 1045232.63983885\n",
            "Iteration 696, loss = 1042284.53277772\n",
            "Iteration 697, loss = 1044276.76530434\n",
            "Iteration 698, loss = 1040804.92936592\n",
            "Iteration 699, loss = 1040539.33078009\n",
            "Iteration 700, loss = 1040074.07287646\n",
            "Iteration 701, loss = 1039873.80344426\n",
            "Iteration 702, loss = 1040135.65814037\n",
            "Iteration 703, loss = 1040410.68819077\n",
            "Iteration 704, loss = 1041235.58306439\n",
            "Iteration 705, loss = 1041614.61658431\n",
            "Iteration 706, loss = 1041507.73220674\n",
            "Iteration 707, loss = 1040201.42839398\n",
            "Iteration 708, loss = 1039059.22762942\n",
            "Iteration 709, loss = 1039023.26634412\n",
            "Iteration 710, loss = 1039832.46103892\n",
            "Iteration 711, loss = 1040240.37368227\n",
            "Iteration 712, loss = 1039486.86521317\n",
            "Iteration 713, loss = 1039881.54813228\n",
            "Iteration 714, loss = 1039372.08236582\n",
            "Iteration 715, loss = 1038786.29824271\n",
            "Iteration 716, loss = 1038813.66748201\n",
            "Iteration 717, loss = 1037424.02616559\n",
            "Iteration 718, loss = 1037610.32166230\n",
            "Iteration 719, loss = 1038435.03021577\n",
            "Iteration 720, loss = 1039195.93952843\n",
            "Iteration 721, loss = 1038286.51150122\n",
            "Iteration 722, loss = 1036611.03483017\n",
            "Iteration 723, loss = 1035836.74457169\n",
            "Iteration 724, loss = 1036330.89580093\n",
            "Iteration 725, loss = 1038031.42710983\n",
            "Iteration 726, loss = 1036836.34109645\n",
            "Iteration 727, loss = 1034924.11758080\n",
            "Iteration 728, loss = 1035789.32093339\n",
            "Iteration 729, loss = 1036369.79688665\n",
            "Iteration 730, loss = 1035835.53952515\n",
            "Iteration 731, loss = 1034690.98692159\n",
            "Iteration 732, loss = 1033994.65212135\n",
            "Iteration 733, loss = 1034856.62624168\n",
            "Iteration 734, loss = 1037876.21293801\n",
            "Iteration 735, loss = 1039305.37128420\n",
            "Iteration 736, loss = 1038836.43956257\n",
            "Iteration 737, loss = 1036559.29938007\n",
            "Iteration 738, loss = 1034221.46360196\n",
            "Iteration 739, loss = 1031860.45879251\n",
            "Iteration 740, loss = 1035832.75723597\n",
            "Iteration 741, loss = 1038771.58715895\n",
            "Iteration 742, loss = 1039406.94384681\n",
            "Iteration 743, loss = 1037744.93973676\n",
            "Iteration 744, loss = 1035987.59862584\n",
            "Iteration 745, loss = 1033833.95897634\n",
            "Iteration 746, loss = 1033540.62812070\n",
            "Iteration 747, loss = 1032883.02859249\n",
            "Iteration 748, loss = 1034856.60929144\n",
            "Iteration 749, loss = 1036445.49351593\n",
            "Iteration 750, loss = 1036370.36403253\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 6010010152147832.00000000\n",
            "Iteration 2, loss = 17329231271058777941506859052567121094910076547475967221163894013976617249871387597634944484687831880696176324811331875946723482626085924220628733949800668334054731623096157527745889886455209363527517397958261274621862404106421774687610676969472.00000000\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with parameters (100, 100), relu, 0.001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538819160.15149951\n",
            "Iteration 2, loss = 1538733858.15644932\n",
            "Iteration 3, loss = 1538629058.56911707\n",
            "Iteration 4, loss = 1538470048.15879655\n",
            "Iteration 5, loss = 1538226791.06021714\n",
            "Iteration 6, loss = 1537884752.76119065\n",
            "Iteration 7, loss = 1537406656.62506104\n",
            "Iteration 8, loss = 1536780379.29850125\n",
            "Iteration 9, loss = 1535958772.22767115\n",
            "Iteration 10, loss = 1534902605.15099788\n",
            "Iteration 11, loss = 1533568034.41589618\n",
            "Iteration 12, loss = 1531918449.04492211\n",
            "Iteration 13, loss = 1529859727.84214163\n",
            "Iteration 14, loss = 1527389870.00757813\n",
            "Iteration 15, loss = 1524375483.39544177\n",
            "Iteration 16, loss = 1520823139.27548409\n",
            "Iteration 17, loss = 1516605894.98541474\n",
            "Iteration 18, loss = 1511635095.06243753\n",
            "Iteration 19, loss = 1505878821.38056946\n",
            "Iteration 20, loss = 1499160266.46200609\n",
            "Iteration 21, loss = 1491458829.31113243\n",
            "Iteration 22, loss = 1482659795.54385448\n",
            "Iteration 23, loss = 1472781424.37141919\n",
            "Iteration 24, loss = 1461526818.55456829\n",
            "Iteration 25, loss = 1448968556.91907167\n",
            "Iteration 26, loss = 1434798969.55830050\n",
            "Iteration 27, loss = 1419243861.03244233\n",
            "Iteration 28, loss = 1402026561.85119700\n",
            "Iteration 29, loss = 1382850448.80147195\n",
            "Iteration 30, loss = 1362133106.37212873\n",
            "Iteration 31, loss = 1339456922.99676514\n",
            "Iteration 32, loss = 1314578225.78577852\n",
            "Iteration 33, loss = 1288062817.61408758\n",
            "Iteration 34, loss = 1259259468.17044187\n",
            "Iteration 35, loss = 1228470182.09045601\n",
            "Iteration 36, loss = 1195785223.81813002\n",
            "Iteration 37, loss = 1160973550.70190096\n",
            "Iteration 38, loss = 1124573467.91788316\n",
            "Iteration 39, loss = 1086007854.40555763\n",
            "Iteration 40, loss = 1045968283.15202856\n",
            "Iteration 41, loss = 1003489275.95330489\n",
            "Iteration 42, loss = 960411406.81652296\n",
            "Iteration 43, loss = 915859477.13289011\n",
            "Iteration 44, loss = 869339702.95816243\n",
            "Iteration 45, loss = 822333875.39001131\n",
            "Iteration 46, loss = 774927769.53770983\n",
            "Iteration 47, loss = 726662564.43495476\n",
            "Iteration 48, loss = 678586952.03883266\n",
            "Iteration 49, loss = 630073334.28298163\n",
            "Iteration 50, loss = 583595010.62369871\n",
            "Iteration 51, loss = 537867256.46507847\n",
            "Iteration 52, loss = 492638045.96672624\n",
            "Iteration 53, loss = 451008081.66529876\n",
            "Iteration 54, loss = 409971438.24509174\n",
            "Iteration 55, loss = 371643504.72858143\n",
            "Iteration 56, loss = 336282304.42044687\n",
            "Iteration 57, loss = 304183993.22743160\n",
            "Iteration 58, loss = 274074821.30383915\n",
            "Iteration 59, loss = 246905831.35485613\n",
            "Iteration 60, loss = 223308589.13258484\n",
            "Iteration 61, loss = 201820349.02979368\n",
            "Iteration 62, loss = 183236466.26448679\n",
            "Iteration 63, loss = 167358096.54921001\n",
            "Iteration 64, loss = 153559099.88198107\n",
            "Iteration 65, loss = 142388680.53088793\n",
            "Iteration 66, loss = 133139232.37899345\n",
            "Iteration 67, loss = 125629096.47604750\n",
            "Iteration 68, loss = 120058391.24524397\n",
            "Iteration 69, loss = 115555926.82075840\n",
            "Iteration 70, loss = 112254937.35668080\n",
            "Iteration 71, loss = 109664522.92120560\n",
            "Iteration 72, loss = 107906824.95346540\n",
            "Iteration 73, loss = 106421254.70428874\n",
            "Iteration 74, loss = 105246141.08953865\n",
            "Iteration 75, loss = 104185030.62485988\n",
            "Iteration 76, loss = 103214539.17029096\n",
            "Iteration 77, loss = 102253619.95764454\n",
            "Iteration 78, loss = 101245332.46129602\n",
            "Iteration 79, loss = 100150602.87831716\n",
            "Iteration 80, loss = 99008879.34361464\n",
            "Iteration 81, loss = 97819078.44876207\n",
            "Iteration 82, loss = 96649635.95352371\n",
            "Iteration 83, loss = 95312186.29680352\n",
            "Iteration 84, loss = 94076249.18455692\n",
            "Iteration 85, loss = 92747900.81078520\n",
            "Iteration 86, loss = 91438923.98262985\n",
            "Iteration 87, loss = 90049619.22332034\n",
            "Iteration 88, loss = 88777764.01608527\n",
            "Iteration 89, loss = 87426519.09839275\n",
            "Iteration 90, loss = 86102596.83802651\n",
            "Iteration 91, loss = 84772229.66082923\n",
            "Iteration 92, loss = 83410991.00861751\n",
            "Iteration 93, loss = 82059309.54175951\n",
            "Iteration 94, loss = 80732504.88624328\n",
            "Iteration 95, loss = 79299940.12766704\n",
            "Iteration 96, loss = 77912701.44056179\n",
            "Iteration 97, loss = 76496976.43096805\n",
            "Iteration 98, loss = 75070877.61394630\n",
            "Iteration 99, loss = 73659172.55715106\n",
            "Iteration 100, loss = 72196359.78722051\n",
            "Iteration 101, loss = 70805703.81412777\n",
            "Iteration 102, loss = 69420958.96610712\n",
            "Iteration 103, loss = 68022851.30703370\n",
            "Iteration 104, loss = 66698358.78093628\n",
            "Iteration 105, loss = 65400753.21059995\n",
            "Iteration 106, loss = 64174786.55186453\n",
            "Iteration 107, loss = 62973085.98150963\n",
            "Iteration 108, loss = 61859344.80611233\n",
            "Iteration 109, loss = 60797008.35457290\n",
            "Iteration 110, loss = 59776165.05349948\n",
            "Iteration 111, loss = 58854606.85045063\n",
            "Iteration 112, loss = 57929194.77060288\n",
            "Iteration 113, loss = 57076955.53925633\n",
            "Iteration 114, loss = 56263018.59409475\n",
            "Iteration 115, loss = 55500239.22488706\n",
            "Iteration 116, loss = 54766952.79450376\n",
            "Iteration 117, loss = 54081547.15233491\n",
            "Iteration 118, loss = 53451537.40227148\n",
            "Iteration 119, loss = 52819203.38137661\n",
            "Iteration 120, loss = 52227342.96682944\n",
            "Iteration 121, loss = 51679082.53802679\n",
            "Iteration 122, loss = 51164571.05266668\n",
            "Iteration 123, loss = 50697289.54993395\n",
            "Iteration 124, loss = 50222009.56188307\n",
            "Iteration 125, loss = 49795991.98067787\n",
            "Iteration 126, loss = 49380044.48295865\n",
            "Iteration 127, loss = 48988264.08120268\n",
            "Iteration 128, loss = 48627585.39284818\n",
            "Iteration 129, loss = 48248076.28000715\n",
            "Iteration 130, loss = 47936461.52754348\n",
            "Iteration 131, loss = 47577125.62235149\n",
            "Iteration 132, loss = 47202405.19105952\n",
            "Iteration 133, loss = 46857950.64519621\n",
            "Iteration 134, loss = 46496474.27883434\n",
            "Iteration 135, loss = 46148841.54839718\n",
            "Iteration 136, loss = 45802456.68003553\n",
            "Iteration 137, loss = 45505705.18001904\n",
            "Iteration 138, loss = 45157707.02948453\n",
            "Iteration 139, loss = 44827075.31993508\n",
            "Iteration 140, loss = 44513668.29234803\n",
            "Iteration 141, loss = 44152778.27070561\n",
            "Iteration 142, loss = 43821439.57032694\n",
            "Iteration 143, loss = 43511508.37920366\n",
            "Iteration 144, loss = 43149235.00164090\n",
            "Iteration 145, loss = 42832766.87668084\n",
            "Iteration 146, loss = 42501814.00543390\n",
            "Iteration 147, loss = 42163421.19430491\n",
            "Iteration 148, loss = 41849925.33167582\n",
            "Iteration 149, loss = 41521816.40565775\n",
            "Iteration 150, loss = 41206398.75200415\n",
            "Iteration 151, loss = 40887938.78580707\n",
            "Iteration 152, loss = 40572117.45685211\n",
            "Iteration 153, loss = 40255770.86075589\n",
            "Iteration 154, loss = 39953237.80632541\n",
            "Iteration 155, loss = 39635196.71675655\n",
            "Iteration 156, loss = 39309626.58996605\n",
            "Iteration 157, loss = 38997954.34603799\n",
            "Iteration 158, loss = 38688837.73831745\n",
            "Iteration 159, loss = 38374076.72596473\n",
            "Iteration 160, loss = 38054238.44547272\n",
            "Iteration 161, loss = 37741723.22880621\n",
            "Iteration 162, loss = 37434068.02976076\n",
            "Iteration 163, loss = 37112022.09380573\n",
            "Iteration 164, loss = 36779480.11359495\n",
            "Iteration 165, loss = 36490366.10974150\n",
            "Iteration 166, loss = 36172450.92190269\n",
            "Iteration 167, loss = 35887325.31603476\n",
            "Iteration 168, loss = 35578824.53379274\n",
            "Iteration 169, loss = 35278849.77573287\n",
            "Iteration 170, loss = 34976681.97189321\n",
            "Iteration 171, loss = 34682691.33011621\n",
            "Iteration 172, loss = 34373011.32143532\n",
            "Iteration 173, loss = 34064958.68797567\n",
            "Iteration 174, loss = 33768556.11252756\n",
            "Iteration 175, loss = 33486218.91861644\n",
            "Iteration 176, loss = 33202043.03362043\n",
            "Iteration 177, loss = 32902766.55226741\n",
            "Iteration 178, loss = 32619298.26422910\n",
            "Iteration 179, loss = 32343004.76872895\n",
            "Iteration 180, loss = 32057284.00086311\n",
            "Iteration 181, loss = 31779340.88264180\n",
            "Iteration 182, loss = 31499514.75617114\n",
            "Iteration 183, loss = 31226801.89120817\n",
            "Iteration 184, loss = 30962762.44079046\n",
            "Iteration 185, loss = 30722741.04609562\n",
            "Iteration 186, loss = 30449027.65351929\n",
            "Iteration 187, loss = 30189192.55173531\n",
            "Iteration 188, loss = 29927018.25600094\n",
            "Iteration 189, loss = 29672121.53162086\n",
            "Iteration 190, loss = 29417011.42451533\n",
            "Iteration 191, loss = 29132862.65832333\n",
            "Iteration 192, loss = 28863676.85291200\n",
            "Iteration 193, loss = 28612021.95965781\n",
            "Iteration 194, loss = 28349132.57847599\n",
            "Iteration 195, loss = 28084401.90346297\n",
            "Iteration 196, loss = 27818310.72051482\n",
            "Iteration 197, loss = 27567948.31294739\n",
            "Iteration 198, loss = 27306037.74370095\n",
            "Iteration 199, loss = 27051953.06193991\n",
            "Iteration 200, loss = 26805008.90561656\n",
            "Iteration 201, loss = 26552997.36909672\n",
            "Iteration 202, loss = 26310496.29196623\n",
            "Iteration 203, loss = 26063040.84688985\n",
            "Iteration 204, loss = 25830420.26482905\n",
            "Iteration 205, loss = 25581864.55203059\n",
            "Iteration 206, loss = 25352638.49189562\n",
            "Iteration 207, loss = 25126127.56337769\n",
            "Iteration 208, loss = 24894776.46923796\n",
            "Iteration 209, loss = 24624650.86423710\n",
            "Iteration 210, loss = 24389147.94011102\n",
            "Iteration 211, loss = 24099667.88160548\n",
            "Iteration 212, loss = 23847974.39123775\n",
            "Iteration 213, loss = 23606875.81989035\n",
            "Iteration 214, loss = 23348906.76986366\n",
            "Iteration 215, loss = 23110607.39848612\n",
            "Iteration 216, loss = 22861222.81460641\n",
            "Iteration 217, loss = 22608774.70224527\n",
            "Iteration 218, loss = 22375522.91822058\n",
            "Iteration 219, loss = 22120872.51605974\n",
            "Iteration 220, loss = 21873469.16167701\n",
            "Iteration 221, loss = 21621513.16060325\n",
            "Iteration 222, loss = 21371426.15912636\n",
            "Iteration 223, loss = 21123038.84826589\n",
            "Iteration 224, loss = 20868534.11677223\n",
            "Iteration 225, loss = 20603716.83575955\n",
            "Iteration 226, loss = 20346639.95083882\n",
            "Iteration 227, loss = 20075858.65109152\n",
            "Iteration 228, loss = 19812561.59075268\n",
            "Iteration 229, loss = 19567216.73446998\n",
            "Iteration 230, loss = 19291476.62542225\n",
            "Iteration 231, loss = 19026898.27355906\n",
            "Iteration 232, loss = 18763656.71184616\n",
            "Iteration 233, loss = 18494487.08136464\n",
            "Iteration 234, loss = 18224687.34927694\n",
            "Iteration 235, loss = 17977210.81097027\n",
            "Iteration 236, loss = 17710456.43952599\n",
            "Iteration 237, loss = 17446777.41030403\n",
            "Iteration 238, loss = 17174400.74836029\n",
            "Iteration 239, loss = 16910904.11602954\n",
            "Iteration 240, loss = 16629714.03262640\n",
            "Iteration 241, loss = 16361745.52372759\n",
            "Iteration 242, loss = 16081208.62200286\n",
            "Iteration 243, loss = 15795542.22272381\n",
            "Iteration 244, loss = 15528755.49233378\n",
            "Iteration 245, loss = 15247909.15294922\n",
            "Iteration 246, loss = 14965027.03834096\n",
            "Iteration 247, loss = 14692400.12629275\n",
            "Iteration 248, loss = 14408923.58528632\n",
            "Iteration 249, loss = 14136043.16059684\n",
            "Iteration 250, loss = 13867263.17811868\n",
            "Iteration 251, loss = 13589452.63174774\n",
            "Iteration 252, loss = 13314612.16999636\n",
            "Iteration 253, loss = 13054036.80812234\n",
            "Iteration 254, loss = 12788919.98159973\n",
            "Iteration 255, loss = 12519119.38161421\n",
            "Iteration 256, loss = 12260381.63572508\n",
            "Iteration 257, loss = 12002250.78232406\n",
            "Iteration 258, loss = 11741590.31819135\n",
            "Iteration 259, loss = 11503039.62669585\n",
            "Iteration 260, loss = 11235691.07701935\n",
            "Iteration 261, loss = 10993452.70487221\n",
            "Iteration 262, loss = 10767972.38267582\n",
            "Iteration 263, loss = 10532719.15781438\n",
            "Iteration 264, loss = 10308946.07841794\n",
            "Iteration 265, loss = 10083864.23655761\n",
            "Iteration 266, loss = 9856244.69785337\n",
            "Iteration 267, loss = 9632423.68702367\n",
            "Iteration 268, loss = 9409442.55624771\n",
            "Iteration 269, loss = 9198641.29884084\n",
            "Iteration 270, loss = 8981906.79848923\n",
            "Iteration 271, loss = 8781337.28510993\n",
            "Iteration 272, loss = 8582475.40776914\n",
            "Iteration 273, loss = 8382857.51029940\n",
            "Iteration 274, loss = 8188098.82672413\n",
            "Iteration 275, loss = 8008340.08079273\n",
            "Iteration 276, loss = 7824122.74488429\n",
            "Iteration 277, loss = 7641853.34271332\n",
            "Iteration 278, loss = 7472448.56048814\n",
            "Iteration 279, loss = 7301130.49095771\n",
            "Iteration 280, loss = 7149866.34059064\n",
            "Iteration 281, loss = 6985691.40549039\n",
            "Iteration 282, loss = 6834444.66091666\n",
            "Iteration 283, loss = 6684534.04959918\n",
            "Iteration 284, loss = 6530317.31491261\n",
            "Iteration 285, loss = 6401826.13502420\n",
            "Iteration 286, loss = 6253099.56619178\n",
            "Iteration 287, loss = 6110734.64565974\n",
            "Iteration 288, loss = 5971754.09823010\n",
            "Iteration 289, loss = 5841783.21262539\n",
            "Iteration 290, loss = 5718092.99793177\n",
            "Iteration 291, loss = 5597186.76952408\n",
            "Iteration 292, loss = 5485366.29614988\n",
            "Iteration 293, loss = 5369170.35739055\n",
            "Iteration 294, loss = 5266833.88100901\n",
            "Iteration 295, loss = 5153475.29767234\n",
            "Iteration 296, loss = 5050012.55498603\n",
            "Iteration 297, loss = 4950427.54664748\n",
            "Iteration 298, loss = 4848056.93589117\n",
            "Iteration 299, loss = 4747490.59949517\n",
            "Iteration 300, loss = 4655067.34249951\n",
            "Iteration 301, loss = 4559084.61508706\n",
            "Iteration 302, loss = 4468381.03692237\n",
            "Iteration 303, loss = 4377426.82805051\n",
            "Iteration 304, loss = 4291787.45051234\n",
            "Iteration 305, loss = 4201429.87947845\n",
            "Iteration 306, loss = 4122938.91587228\n",
            "Iteration 307, loss = 4038472.20286762\n",
            "Iteration 308, loss = 3961990.72407917\n",
            "Iteration 309, loss = 3885445.33124569\n",
            "Iteration 310, loss = 3813488.93401238\n",
            "Iteration 311, loss = 3744691.19543114\n",
            "Iteration 312, loss = 3675730.81245306\n",
            "Iteration 313, loss = 3618247.17212735\n",
            "Iteration 314, loss = 3551735.47240239\n",
            "Iteration 315, loss = 3490163.97029275\n",
            "Iteration 316, loss = 3432430.35653228\n",
            "Iteration 317, loss = 3378208.46432413\n",
            "Iteration 318, loss = 3322251.38783539\n",
            "Iteration 319, loss = 3268477.99431600\n",
            "Iteration 320, loss = 3220869.33155383\n",
            "Iteration 321, loss = 3167683.23402223\n",
            "Iteration 322, loss = 3117344.98697808\n",
            "Iteration 323, loss = 3066344.91007803\n",
            "Iteration 324, loss = 3017682.55200712\n",
            "Iteration 325, loss = 2969457.86295450\n",
            "Iteration 326, loss = 2921510.34213930\n",
            "Iteration 327, loss = 2880639.93485287\n",
            "Iteration 328, loss = 2836330.80539774\n",
            "Iteration 329, loss = 2799231.68152509\n",
            "Iteration 330, loss = 2755221.47050587\n",
            "Iteration 331, loss = 2713203.47335736\n",
            "Iteration 332, loss = 2677397.11601753\n",
            "Iteration 333, loss = 2638764.43064042\n",
            "Iteration 334, loss = 2603111.44846916\n",
            "Iteration 335, loss = 2569101.72656083\n",
            "Iteration 336, loss = 2535414.49773496\n",
            "Iteration 337, loss = 2500968.13716402\n",
            "Iteration 338, loss = 2468557.75067449\n",
            "Iteration 339, loss = 2437895.14608006\n",
            "Iteration 340, loss = 2409070.98988778\n",
            "Iteration 341, loss = 2381395.67963269\n",
            "Iteration 342, loss = 2354026.43349752\n",
            "Iteration 343, loss = 2323256.40214342\n",
            "Iteration 344, loss = 2292370.04481154\n",
            "Iteration 345, loss = 2268706.02675084\n",
            "Iteration 346, loss = 2244889.94929079\n",
            "Iteration 347, loss = 2219977.93231271\n",
            "Iteration 348, loss = 2201978.68057700\n",
            "Iteration 349, loss = 2177689.74049163\n",
            "Iteration 350, loss = 2152521.73205705\n",
            "Iteration 351, loss = 2126806.79968099\n",
            "Iteration 352, loss = 2101628.19085839\n",
            "Iteration 353, loss = 2074508.43022047\n",
            "Iteration 354, loss = 2051400.18038796\n",
            "Iteration 355, loss = 2025167.92060360\n",
            "Iteration 356, loss = 2005725.63297530\n",
            "Iteration 357, loss = 1983731.26777994\n",
            "Iteration 358, loss = 1963463.62338720\n",
            "Iteration 359, loss = 1944413.35001949\n",
            "Iteration 360, loss = 1928141.49482954\n",
            "Iteration 361, loss = 1910472.32431437\n",
            "Iteration 362, loss = 1893044.04402983\n",
            "Iteration 363, loss = 1875501.91491080\n",
            "Iteration 364, loss = 1863184.17835836\n",
            "Iteration 365, loss = 1848578.02341580\n",
            "Iteration 366, loss = 1836973.13319168\n",
            "Iteration 367, loss = 1824117.95832069\n",
            "Iteration 368, loss = 1810763.67892839\n",
            "Iteration 369, loss = 1797538.69294506\n",
            "Iteration 370, loss = 1781912.64555543\n",
            "Iteration 371, loss = 1766578.01180606\n",
            "Iteration 372, loss = 1752145.68100985\n",
            "Iteration 373, loss = 1740524.41378037\n",
            "Iteration 374, loss = 1729568.40738552\n",
            "Iteration 375, loss = 1718866.81593406\n",
            "Iteration 376, loss = 1709866.04963834\n",
            "Iteration 377, loss = 1697292.48357363\n",
            "Iteration 378, loss = 1683647.82053329\n",
            "Iteration 379, loss = 1670568.60412037\n",
            "Iteration 380, loss = 1661629.66628911\n",
            "Iteration 381, loss = 1654374.82146616\n",
            "Iteration 382, loss = 1647383.32994437\n",
            "Iteration 383, loss = 1640588.17357818\n",
            "Iteration 384, loss = 1630919.75957248\n",
            "Iteration 385, loss = 1620524.72142864\n",
            "Iteration 386, loss = 1607417.02505793\n",
            "Iteration 387, loss = 1597970.96594785\n",
            "Iteration 388, loss = 1587562.92774407\n",
            "Iteration 389, loss = 1579066.54463287\n",
            "Iteration 390, loss = 1571324.34468667\n",
            "Iteration 391, loss = 1562845.84509128\n",
            "Iteration 392, loss = 1555498.77716553\n",
            "Iteration 393, loss = 1547813.00160461\n",
            "Iteration 394, loss = 1539938.33579306\n",
            "Iteration 395, loss = 1531224.93636218\n",
            "Iteration 396, loss = 1525524.41697550\n",
            "Iteration 397, loss = 1517531.33169564\n",
            "Iteration 398, loss = 1509735.75878809\n",
            "Iteration 399, loss = 1502008.33717347\n",
            "Iteration 400, loss = 1497458.38962896\n",
            "Iteration 401, loss = 1490978.03083981\n",
            "Iteration 402, loss = 1482088.68453162\n",
            "Iteration 403, loss = 1474952.26628036\n",
            "Iteration 404, loss = 1469409.72578809\n",
            "Iteration 405, loss = 1462113.90047004\n",
            "Iteration 406, loss = 1456601.50180048\n",
            "Iteration 407, loss = 1449908.68261032\n",
            "Iteration 408, loss = 1442129.42435319\n",
            "Iteration 409, loss = 1436231.92875687\n",
            "Iteration 410, loss = 1430217.74221637\n",
            "Iteration 411, loss = 1422024.83578428\n",
            "Iteration 412, loss = 1415304.46531213\n",
            "Iteration 413, loss = 1409334.26330895\n",
            "Iteration 414, loss = 1404000.84380227\n",
            "Iteration 415, loss = 1398550.95247284\n",
            "Iteration 416, loss = 1393229.10752371\n",
            "Iteration 417, loss = 1387878.92072731\n",
            "Iteration 418, loss = 1382071.53143682\n",
            "Iteration 419, loss = 1375297.65920686\n",
            "Iteration 420, loss = 1369689.13726167\n",
            "Iteration 421, loss = 1365752.07274753\n",
            "Iteration 422, loss = 1360243.78987927\n",
            "Iteration 423, loss = 1354808.02950483\n",
            "Iteration 424, loss = 1350735.84513019\n",
            "Iteration 425, loss = 1347374.55419308\n",
            "Iteration 426, loss = 1343458.44749237\n",
            "Iteration 427, loss = 1338259.52163388\n",
            "Iteration 428, loss = 1332698.37705316\n",
            "Iteration 429, loss = 1326816.33753263\n",
            "Iteration 430, loss = 1320697.17096704\n",
            "Iteration 431, loss = 1315572.39217349\n",
            "Iteration 432, loss = 1311386.02928003\n",
            "Iteration 433, loss = 1308966.92262179\n",
            "Iteration 434, loss = 1304713.02325036\n",
            "Iteration 435, loss = 1300042.01477406\n",
            "Iteration 436, loss = 1295239.41390985\n",
            "Iteration 437, loss = 1290312.82713371\n",
            "Iteration 438, loss = 1286735.92899919\n",
            "Iteration 439, loss = 1283260.69978796\n",
            "Iteration 440, loss = 1279693.37695610\n",
            "Iteration 441, loss = 1275596.59453687\n",
            "Iteration 442, loss = 1273023.90728922\n",
            "Iteration 443, loss = 1270442.59077177\n",
            "Iteration 444, loss = 1268473.18494318\n",
            "Iteration 445, loss = 1265227.99136486\n",
            "Iteration 446, loss = 1260608.74123091\n",
            "Iteration 447, loss = 1256835.47399997\n",
            "Iteration 448, loss = 1253292.74112495\n",
            "Iteration 449, loss = 1248730.73710652\n",
            "Iteration 450, loss = 1244270.59133149\n",
            "Iteration 451, loss = 1238838.51499132\n",
            "Iteration 452, loss = 1237181.75223375\n",
            "Iteration 453, loss = 1233598.77747949\n",
            "Iteration 454, loss = 1230741.24623491\n",
            "Iteration 455, loss = 1228236.93000924\n",
            "Iteration 456, loss = 1227656.22996406\n",
            "Iteration 457, loss = 1225053.32171385\n",
            "Iteration 458, loss = 1220334.25383103\n",
            "Iteration 459, loss = 1215753.92280672\n",
            "Iteration 460, loss = 1213588.58266600\n",
            "Iteration 461, loss = 1208208.78975208\n",
            "Iteration 462, loss = 1206225.96363204\n",
            "Iteration 463, loss = 1203103.50034482\n",
            "Iteration 464, loss = 1199871.39992401\n",
            "Iteration 465, loss = 1197424.56555619\n",
            "Iteration 466, loss = 1194764.05235861\n",
            "Iteration 467, loss = 1191190.57807935\n",
            "Iteration 468, loss = 1188057.94867483\n",
            "Iteration 469, loss = 1187303.36886171\n",
            "Iteration 470, loss = 1184791.81411943\n",
            "Iteration 471, loss = 1182933.34599861\n",
            "Iteration 472, loss = 1181940.85527265\n",
            "Iteration 473, loss = 1178585.97727740\n",
            "Iteration 474, loss = 1175941.99047201\n",
            "Iteration 475, loss = 1173676.21019303\n",
            "Iteration 476, loss = 1170388.69559867\n",
            "Iteration 477, loss = 1167986.48263677\n",
            "Iteration 478, loss = 1166024.07628504\n",
            "Iteration 479, loss = 1165059.50647641\n",
            "Iteration 480, loss = 1164215.50797619\n",
            "Iteration 481, loss = 1161849.85835695\n",
            "Iteration 482, loss = 1159916.14206163\n",
            "Iteration 483, loss = 1155994.77683690\n",
            "Iteration 484, loss = 1153041.78893244\n",
            "Iteration 485, loss = 1155843.53056984\n",
            "Iteration 486, loss = 1156067.66930791\n",
            "Iteration 487, loss = 1155270.14239504\n",
            "Iteration 488, loss = 1153548.50257489\n",
            "Iteration 489, loss = 1150785.62145351\n",
            "Iteration 490, loss = 1147746.53160848\n",
            "Iteration 491, loss = 1144872.55505922\n",
            "Iteration 492, loss = 1141390.37303709\n",
            "Iteration 493, loss = 1138934.70956768\n",
            "Iteration 494, loss = 1139683.41814705\n",
            "Iteration 495, loss = 1142708.01115465\n",
            "Iteration 496, loss = 1143250.15895905\n",
            "Iteration 497, loss = 1141853.52206276\n",
            "Iteration 498, loss = 1138525.96537166\n",
            "Iteration 499, loss = 1134981.32907803\n",
            "Iteration 500, loss = 1130836.93512251\n",
            "Iteration 501, loss = 1128517.54625327\n",
            "Iteration 502, loss = 1127632.79940126\n",
            "Iteration 503, loss = 1128228.38638300\n",
            "Iteration 504, loss = 1129185.10996476\n",
            "Iteration 505, loss = 1130970.36950056\n",
            "Iteration 506, loss = 1131710.74212891\n",
            "Iteration 507, loss = 1130850.19752950\n",
            "Iteration 508, loss = 1126165.48622405\n",
            "Iteration 509, loss = 1119943.16729983\n",
            "Iteration 510, loss = 1119350.99853820\n",
            "Iteration 511, loss = 1119884.82580149\n",
            "Iteration 512, loss = 1124205.90074456\n",
            "Iteration 513, loss = 1121576.12413879\n",
            "Iteration 514, loss = 1119556.60443637\n",
            "Iteration 515, loss = 1112179.76809832\n",
            "Iteration 516, loss = 1111474.91713157\n",
            "Iteration 517, loss = 1111028.61084810\n",
            "Iteration 518, loss = 1111408.02530692\n",
            "Iteration 519, loss = 1110408.01716495\n",
            "Iteration 520, loss = 1108399.80940525\n",
            "Iteration 521, loss = 1107829.28450171\n",
            "Iteration 522, loss = 1105427.70893214\n",
            "Iteration 523, loss = 1102771.72975158\n",
            "Iteration 524, loss = 1101238.00914029\n",
            "Iteration 525, loss = 1100492.00283674\n",
            "Iteration 526, loss = 1102548.61596542\n",
            "Iteration 527, loss = 1101320.93452900\n",
            "Iteration 528, loss = 1099417.96118799\n",
            "Iteration 529, loss = 1097855.27530138\n",
            "Iteration 530, loss = 1097034.26825374\n",
            "Iteration 531, loss = 1094989.26602384\n",
            "Iteration 532, loss = 1093989.44525038\n",
            "Iteration 533, loss = 1094029.69310327\n",
            "Iteration 534, loss = 1094754.88760953\n",
            "Iteration 535, loss = 1096213.14011936\n",
            "Iteration 536, loss = 1095091.70548072\n",
            "Iteration 537, loss = 1093056.93069607\n",
            "Iteration 538, loss = 1092173.78903414\n",
            "Iteration 539, loss = 1091885.38578267\n",
            "Iteration 540, loss = 1091215.25912823\n",
            "Iteration 541, loss = 1090350.84040149\n",
            "Iteration 542, loss = 1087829.90607048\n",
            "Iteration 543, loss = 1085744.69372739\n",
            "Iteration 544, loss = 1084573.09984821\n",
            "Iteration 545, loss = 1084188.99586298\n",
            "Iteration 546, loss = 1084171.57271372\n",
            "Iteration 547, loss = 1083753.99244136\n",
            "Iteration 548, loss = 1084332.79938013\n",
            "Iteration 549, loss = 1084123.12038544\n",
            "Iteration 550, loss = 1083773.94533443\n",
            "Iteration 551, loss = 1083156.08572268\n",
            "Iteration 552, loss = 1081462.03976449\n",
            "Iteration 553, loss = 1079059.77578335\n",
            "Iteration 554, loss = 1078319.06081059\n",
            "Iteration 555, loss = 1077910.69056856\n",
            "Iteration 556, loss = 1077112.77689969\n",
            "Iteration 557, loss = 1078032.92039214\n",
            "Iteration 558, loss = 1075893.77804887\n",
            "Iteration 559, loss = 1075504.55439542\n",
            "Iteration 560, loss = 1074814.29659562\n",
            "Iteration 561, loss = 1073766.46154999\n",
            "Iteration 562, loss = 1073951.20399167\n",
            "Iteration 563, loss = 1073249.57306927\n",
            "Iteration 564, loss = 1072687.53808918\n",
            "Iteration 565, loss = 1072359.18801440\n",
            "Iteration 566, loss = 1072417.71239363\n",
            "Iteration 567, loss = 1071728.22918178\n",
            "Iteration 568, loss = 1070671.72053970\n",
            "Iteration 569, loss = 1070246.23543275\n",
            "Iteration 570, loss = 1069649.56563284\n",
            "Iteration 571, loss = 1069120.33670028\n",
            "Iteration 572, loss = 1068971.01996625\n",
            "Iteration 573, loss = 1068956.10018240\n",
            "Iteration 574, loss = 1068516.24661532\n",
            "Iteration 575, loss = 1067732.59472409\n",
            "Iteration 576, loss = 1066661.38100890\n",
            "Iteration 577, loss = 1066631.96583102\n",
            "Iteration 578, loss = 1066628.41014205\n",
            "Iteration 579, loss = 1067296.22019814\n",
            "Iteration 580, loss = 1067299.53504949\n",
            "Iteration 581, loss = 1067233.71343186\n",
            "Iteration 582, loss = 1067836.18958632\n",
            "Iteration 583, loss = 1066001.50372642\n",
            "Iteration 584, loss = 1064022.01393651\n",
            "Iteration 585, loss = 1063361.92402987\n",
            "Iteration 586, loss = 1064161.71445404\n",
            "Iteration 587, loss = 1063608.14648556\n",
            "Iteration 588, loss = 1063325.57588491\n",
            "Iteration 589, loss = 1063419.08799333\n",
            "Iteration 590, loss = 1063182.57073829\n",
            "Iteration 591, loss = 1062643.50992077\n",
            "Iteration 592, loss = 1062364.22440959\n",
            "Iteration 593, loss = 1063261.45081014\n",
            "Iteration 594, loss = 1062434.78215025\n",
            "Iteration 595, loss = 1061342.15889618\n",
            "Iteration 596, loss = 1059827.49974967\n",
            "Iteration 597, loss = 1058934.38785187\n",
            "Iteration 598, loss = 1059413.22136505\n",
            "Iteration 599, loss = 1057691.36971977\n",
            "Iteration 600, loss = 1057463.49999534\n",
            "Iteration 601, loss = 1057085.38133848\n",
            "Iteration 602, loss = 1057062.21950401\n",
            "Iteration 603, loss = 1057847.81270745\n",
            "Iteration 604, loss = 1057996.75482163\n",
            "Iteration 605, loss = 1057614.38768958\n",
            "Iteration 606, loss = 1056988.59080991\n",
            "Iteration 607, loss = 1055353.48691566\n",
            "Iteration 608, loss = 1054371.04931242\n",
            "Iteration 609, loss = 1054119.72620398\n",
            "Iteration 610, loss = 1054810.02892037\n",
            "Iteration 611, loss = 1056585.54477270\n",
            "Iteration 612, loss = 1056470.09861027\n",
            "Iteration 613, loss = 1055444.28808410\n",
            "Iteration 614, loss = 1053547.56276139\n",
            "Iteration 615, loss = 1052597.56538706\n",
            "Iteration 616, loss = 1052438.53273130\n",
            "Iteration 617, loss = 1051952.71841326\n",
            "Iteration 618, loss = 1052347.15518442\n",
            "Iteration 619, loss = 1051048.12089398\n",
            "Iteration 620, loss = 1050991.13438047\n",
            "Iteration 621, loss = 1050492.77708873\n",
            "Iteration 622, loss = 1050581.78626055\n",
            "Iteration 623, loss = 1050638.66213288\n",
            "Iteration 624, loss = 1052526.07750436\n",
            "Iteration 625, loss = 1051376.40134150\n",
            "Iteration 626, loss = 1049298.80412330\n",
            "Iteration 627, loss = 1048099.76799885\n",
            "Iteration 628, loss = 1049844.77231570\n",
            "Iteration 629, loss = 1053339.94045033\n",
            "Iteration 630, loss = 1056025.25283717\n",
            "Iteration 631, loss = 1057371.50521040\n",
            "Iteration 632, loss = 1055838.01181661\n",
            "Iteration 633, loss = 1051056.35755534\n",
            "Iteration 634, loss = 1048092.68206991\n",
            "Iteration 635, loss = 1048157.59811363\n",
            "Iteration 636, loss = 1049522.52204769\n",
            "Iteration 637, loss = 1048522.19943127\n",
            "Iteration 638, loss = 1046176.88397241\n",
            "Iteration 639, loss = 1045421.97653519\n",
            "Iteration 640, loss = 1046400.66051632\n",
            "Iteration 641, loss = 1046988.54719453\n",
            "Iteration 642, loss = 1047641.43528223\n",
            "Iteration 643, loss = 1047878.84473900\n",
            "Iteration 644, loss = 1046674.72910825\n",
            "Iteration 645, loss = 1045647.25680907\n",
            "Iteration 646, loss = 1044098.24850187\n",
            "Iteration 647, loss = 1043487.68288743\n",
            "Iteration 648, loss = 1044746.50761709\n",
            "Iteration 649, loss = 1042815.83343295\n",
            "Iteration 650, loss = 1043021.01763418\n",
            "Iteration 651, loss = 1044008.81130152\n",
            "Iteration 652, loss = 1043268.72438905\n",
            "Iteration 653, loss = 1043975.12261874\n",
            "Iteration 654, loss = 1042520.18909521\n",
            "Iteration 655, loss = 1043744.52525670\n",
            "Iteration 656, loss = 1043154.36862569\n",
            "Iteration 657, loss = 1042787.49654923\n",
            "Iteration 658, loss = 1043298.54904913\n",
            "Iteration 659, loss = 1042851.34611148\n",
            "Iteration 660, loss = 1041505.28370925\n",
            "Iteration 661, loss = 1039874.52403316\n",
            "Iteration 662, loss = 1040194.40496299\n",
            "Iteration 663, loss = 1042741.75693282\n",
            "Iteration 664, loss = 1043147.96810635\n",
            "Iteration 665, loss = 1043046.64413564\n",
            "Iteration 666, loss = 1040463.98557132\n",
            "Iteration 667, loss = 1040785.21350213\n",
            "Iteration 668, loss = 1039483.60697999\n",
            "Iteration 669, loss = 1039783.42200003\n",
            "Iteration 670, loss = 1041003.14093414\n",
            "Iteration 671, loss = 1041874.98612255\n",
            "Iteration 672, loss = 1039771.80787086\n",
            "Iteration 673, loss = 1038852.15199619\n",
            "Iteration 674, loss = 1037885.45579872\n",
            "Iteration 675, loss = 1038021.48831297\n",
            "Iteration 676, loss = 1038310.07844222\n",
            "Iteration 677, loss = 1039018.88965808\n",
            "Iteration 678, loss = 1039691.19138685\n",
            "Iteration 679, loss = 1038869.32174763\n",
            "Iteration 680, loss = 1038869.74319802\n",
            "Iteration 681, loss = 1037972.07641184\n",
            "Iteration 682, loss = 1036457.99049967\n",
            "Iteration 683, loss = 1036425.50405962\n",
            "Iteration 684, loss = 1036516.06922614\n",
            "Iteration 685, loss = 1038628.20347624\n",
            "Iteration 686, loss = 1038842.28490424\n",
            "Iteration 687, loss = 1038352.49898940\n",
            "Iteration 688, loss = 1038754.81543604\n",
            "Iteration 689, loss = 1038454.89344947\n",
            "Iteration 690, loss = 1036644.59773372\n",
            "Iteration 691, loss = 1036305.83724537\n",
            "Iteration 692, loss = 1034400.65027958\n",
            "Iteration 693, loss = 1035261.94484330\n",
            "Iteration 694, loss = 1035647.25005655\n",
            "Iteration 695, loss = 1035797.77672193\n",
            "Iteration 696, loss = 1034534.60211455\n",
            "Iteration 697, loss = 1034305.14730910\n",
            "Iteration 698, loss = 1034844.83562725\n",
            "Iteration 699, loss = 1033937.14606772\n",
            "Iteration 700, loss = 1032804.29977843\n",
            "Iteration 701, loss = 1032802.91138178\n",
            "Iteration 702, loss = 1032823.12860033\n",
            "Iteration 703, loss = 1032896.25629472\n",
            "Iteration 704, loss = 1033381.49103584\n",
            "Iteration 705, loss = 1033934.51483267\n",
            "Iteration 706, loss = 1032714.45669866\n",
            "Iteration 707, loss = 1035158.04010281\n",
            "Iteration 708, loss = 1034250.29293708\n",
            "Iteration 709, loss = 1032290.61571562\n",
            "Iteration 710, loss = 1032141.26949842\n",
            "Iteration 711, loss = 1031028.17693971\n",
            "Iteration 712, loss = 1031564.62892116\n",
            "Iteration 713, loss = 1031486.76767285\n",
            "Iteration 714, loss = 1031039.44753511\n",
            "Iteration 715, loss = 1030319.63035511\n",
            "Iteration 716, loss = 1029922.35767155\n",
            "Iteration 717, loss = 1029907.79015922\n",
            "Iteration 718, loss = 1032195.89935685\n",
            "Iteration 719, loss = 1036133.41119868\n",
            "Iteration 720, loss = 1037284.61939244\n",
            "Iteration 721, loss = 1034971.79950536\n",
            "Iteration 722, loss = 1034551.70286171\n",
            "Iteration 723, loss = 1031471.39263583\n",
            "Iteration 724, loss = 1029716.55012625\n",
            "Iteration 725, loss = 1029791.17457833\n",
            "Iteration 726, loss = 1029615.82129596\n",
            "Iteration 727, loss = 1029147.97035974\n",
            "Iteration 728, loss = 1029328.02176413\n",
            "Iteration 729, loss = 1029228.75314293\n",
            "Iteration 730, loss = 1028300.48787850\n",
            "Iteration 731, loss = 1028852.00049155\n",
            "Iteration 732, loss = 1029995.82389019\n",
            "Iteration 733, loss = 1033584.00444903\n",
            "Iteration 734, loss = 1032093.20159127\n",
            "Iteration 735, loss = 1030584.80279319\n",
            "Iteration 736, loss = 1027233.88288148\n",
            "Iteration 737, loss = 1029405.41595907\n",
            "Iteration 738, loss = 1030406.34817648\n",
            "Iteration 739, loss = 1031185.04169006\n",
            "Iteration 740, loss = 1029902.46370337\n",
            "Iteration 741, loss = 1027363.57178088\n",
            "Iteration 742, loss = 1027051.65074353\n",
            "Iteration 743, loss = 1029583.58305423\n",
            "Iteration 744, loss = 1031898.86464525\n",
            "Iteration 745, loss = 1033210.93423174\n",
            "Iteration 746, loss = 1031071.30990047\n",
            "Iteration 747, loss = 1030715.45860213\n",
            "Iteration 748, loss = 1029796.70838654\n",
            "Iteration 749, loss = 1028104.61128018\n",
            "Iteration 750, loss = 1027635.19860408\n",
            "Iteration 751, loss = 1027175.61571113\n",
            "Iteration 752, loss = 1027774.72084913\n",
            "Iteration 753, loss = 1027324.06691363\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 3206767266548775.50000000\n",
            "Iteration 2, loss = 12699052909380179294561543231762059933931003754248379184694334628554113548290250065869093739566603283979707768751643205615601717647853474940194727292124017063721476102599616305346430334741991048926995303508010970671350565239259136.00000000\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (100, 100), relu, 0.01, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538789614.97187376\n",
            "Iteration 2, loss = 1538696296.77476120\n",
            "Iteration 3, loss = 1538562577.82110286\n",
            "Iteration 4, loss = 1538357032.65114570\n",
            "Iteration 5, loss = 1538057295.18464160\n",
            "Iteration 6, loss = 1537625574.79140353\n",
            "Iteration 7, loss = 1537048021.59066987\n",
            "Iteration 8, loss = 1536281079.71256661\n",
            "Iteration 9, loss = 1535301584.88772750\n",
            "Iteration 10, loss = 1534055258.36184335\n",
            "Iteration 11, loss = 1532494369.38408256\n",
            "Iteration 12, loss = 1530533704.08541107\n",
            "Iteration 13, loss = 1528191208.90294051\n",
            "Iteration 14, loss = 1525310021.42622995\n",
            "Iteration 15, loss = 1521872580.99203968\n",
            "Iteration 16, loss = 1517772158.97089481\n",
            "Iteration 17, loss = 1512961720.51977515\n",
            "Iteration 18, loss = 1507230332.00706053\n",
            "Iteration 19, loss = 1500759945.96884131\n",
            "Iteration 20, loss = 1493253139.60584998\n",
            "Iteration 21, loss = 1484485858.08635664\n",
            "Iteration 22, loss = 1474787759.80036712\n",
            "Iteration 23, loss = 1463474351.67114210\n",
            "Iteration 24, loss = 1450920737.03177524\n",
            "Iteration 25, loss = 1436865245.84103036\n",
            "Iteration 26, loss = 1421029700.38022327\n",
            "Iteration 27, loss = 1403613238.70726037\n",
            "Iteration 28, loss = 1384262856.73452711\n",
            "Iteration 29, loss = 1362862069.91674066\n",
            "Iteration 30, loss = 1339798383.71387386\n",
            "Iteration 31, loss = 1314417327.64306951\n",
            "Iteration 32, loss = 1287050369.62944698\n",
            "Iteration 33, loss = 1257324532.68591332\n",
            "Iteration 34, loss = 1225842542.39569783\n",
            "Iteration 35, loss = 1191395698.89340591\n",
            "Iteration 36, loss = 1155563853.77296519\n",
            "Iteration 37, loss = 1117229865.85125184\n",
            "Iteration 38, loss = 1076640415.71434379\n",
            "Iteration 39, loss = 1034313759.42691493\n",
            "Iteration 40, loss = 989837682.99387813\n",
            "Iteration 41, loss = 944303292.53158998\n",
            "Iteration 42, loss = 896507159.78156006\n",
            "Iteration 43, loss = 847800526.51151788\n",
            "Iteration 44, loss = 798120835.00473082\n",
            "Iteration 45, loss = 747676920.15342414\n",
            "Iteration 46, loss = 697604034.29358280\n",
            "Iteration 47, loss = 646759769.35465860\n",
            "Iteration 48, loss = 596457145.79249680\n",
            "Iteration 49, loss = 547455390.72557878\n",
            "Iteration 50, loss = 500533636.27038795\n",
            "Iteration 51, loss = 454014783.65998989\n",
            "Iteration 52, loss = 410301377.07058322\n",
            "Iteration 53, loss = 369751401.58848131\n",
            "Iteration 54, loss = 331378547.76916260\n",
            "Iteration 55, loss = 296053133.04604584\n",
            "Iteration 56, loss = 264709755.93453291\n",
            "Iteration 57, loss = 236449866.81656802\n",
            "Iteration 58, loss = 211815343.97650754\n",
            "Iteration 59, loss = 190195964.11020043\n",
            "Iteration 60, loss = 172445019.46330753\n",
            "Iteration 61, loss = 157275974.42740706\n",
            "Iteration 62, loss = 145623413.95361385\n",
            "Iteration 63, loss = 135632438.19764620\n",
            "Iteration 64, loss = 128722680.09405178\n",
            "Iteration 65, loss = 123149659.59275207\n",
            "Iteration 66, loss = 119084518.33469349\n",
            "Iteration 67, loss = 116469716.00176461\n",
            "Iteration 68, loss = 114365449.06736560\n",
            "Iteration 69, loss = 112755449.49483350\n",
            "Iteration 70, loss = 111728017.85098369\n",
            "Iteration 71, loss = 110853679.27894951\n",
            "Iteration 72, loss = 109823959.41010354\n",
            "Iteration 73, loss = 108803582.19389567\n",
            "Iteration 74, loss = 107617087.97929814\n",
            "Iteration 75, loss = 106408279.43529467\n",
            "Iteration 76, loss = 105041611.13149130\n",
            "Iteration 77, loss = 103491649.49458125\n",
            "Iteration 78, loss = 102063235.82907519\n",
            "Iteration 79, loss = 100707850.52906683\n",
            "Iteration 80, loss = 99279435.34927708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 81, loss = 98049581.87911858\n",
            "Iteration 82, loss = 96775299.30333033\n",
            "Iteration 83, loss = 95519485.60180131\n",
            "Iteration 84, loss = 94246651.48018463\n",
            "Iteration 85, loss = 93019840.14396918\n",
            "Iteration 86, loss = 91783188.59602465\n",
            "Iteration 87, loss = 90522210.01775007\n",
            "Iteration 88, loss = 89233273.76785655\n",
            "Iteration 89, loss = 87969366.70841767\n",
            "Iteration 90, loss = 86594503.53550698\n",
            "Iteration 91, loss = 85253351.49349254\n",
            "Iteration 92, loss = 83811762.27458195\n",
            "Iteration 93, loss = 82381277.75921839\n",
            "Iteration 94, loss = 80964383.40721968\n",
            "Iteration 95, loss = 79461167.87032972\n",
            "Iteration 96, loss = 78020208.40516278\n",
            "Iteration 97, loss = 76540699.88897422\n",
            "Iteration 98, loss = 75080097.89808790\n",
            "Iteration 99, loss = 73616451.41348171\n",
            "Iteration 100, loss = 72197879.37309621\n",
            "Iteration 101, loss = 70752087.02674635\n",
            "Iteration 102, loss = 69369747.93459454\n",
            "Iteration 103, loss = 67993866.66303721\n",
            "Iteration 104, loss = 66681493.96033801\n",
            "Iteration 105, loss = 65412523.31147632\n",
            "Iteration 106, loss = 64164147.84110449\n",
            "Iteration 107, loss = 62967672.77563963\n",
            "Iteration 108, loss = 61821492.54783376\n",
            "Iteration 109, loss = 60752804.53196955\n",
            "Iteration 110, loss = 59738042.24939880\n",
            "Iteration 111, loss = 58699093.14826224\n",
            "Iteration 112, loss = 57743747.03377153\n",
            "Iteration 113, loss = 56839978.56242567\n",
            "Iteration 114, loss = 56000507.83518089\n",
            "Iteration 115, loss = 55135513.08124181\n",
            "Iteration 116, loss = 54374694.31302037\n",
            "Iteration 117, loss = 53708694.44230927\n",
            "Iteration 118, loss = 53048577.56673885\n",
            "Iteration 119, loss = 52435447.49554019\n",
            "Iteration 120, loss = 51889859.73696354\n",
            "Iteration 121, loss = 51296183.06393218\n",
            "Iteration 122, loss = 50787292.20521443\n",
            "Iteration 123, loss = 50331900.46002357\n",
            "Iteration 124, loss = 49888197.49353827\n",
            "Iteration 125, loss = 49488195.00723940\n",
            "Iteration 126, loss = 49112848.94884985\n",
            "Iteration 127, loss = 48710245.03841037\n",
            "Iteration 128, loss = 48300121.21659525\n",
            "Iteration 129, loss = 47908346.60551588\n",
            "Iteration 130, loss = 47546579.47007349\n",
            "Iteration 131, loss = 47137881.06078194\n",
            "Iteration 132, loss = 46763891.54922247\n",
            "Iteration 133, loss = 46409527.62809744\n",
            "Iteration 134, loss = 46053426.39766289\n",
            "Iteration 135, loss = 45685510.14464152\n",
            "Iteration 136, loss = 45326813.99339679\n",
            "Iteration 137, loss = 44947255.03772453\n",
            "Iteration 138, loss = 44593375.59505799\n",
            "Iteration 139, loss = 44246917.94526669\n",
            "Iteration 140, loss = 43919599.26294103\n",
            "Iteration 141, loss = 43562200.41017324\n",
            "Iteration 142, loss = 43212915.60860270\n",
            "Iteration 143, loss = 42848598.06322391\n",
            "Iteration 144, loss = 42523917.16720308\n",
            "Iteration 145, loss = 42159861.29467641\n",
            "Iteration 146, loss = 41839674.09032760\n",
            "Iteration 147, loss = 41492107.47969242\n",
            "Iteration 148, loss = 41161191.09162881\n",
            "Iteration 149, loss = 40844645.36261046\n",
            "Iteration 150, loss = 40500331.02634244\n",
            "Iteration 151, loss = 40171199.16752129\n",
            "Iteration 152, loss = 39838105.52978725\n",
            "Iteration 153, loss = 39521222.39503092\n",
            "Iteration 154, loss = 39210099.68021342\n",
            "Iteration 155, loss = 38897257.44876787\n",
            "Iteration 156, loss = 38580046.55478283\n",
            "Iteration 157, loss = 38262615.98868143\n",
            "Iteration 158, loss = 37961352.73370874\n",
            "Iteration 159, loss = 37653321.11586294\n",
            "Iteration 160, loss = 37343139.58566491\n",
            "Iteration 161, loss = 37036970.12545426\n",
            "Iteration 162, loss = 36728355.96424305\n",
            "Iteration 163, loss = 36420224.50284505\n",
            "Iteration 164, loss = 36139694.19429331\n",
            "Iteration 165, loss = 35842575.86472570\n",
            "Iteration 166, loss = 35561966.66587525\n",
            "Iteration 167, loss = 35246984.81301744\n",
            "Iteration 168, loss = 34946570.40544634\n",
            "Iteration 169, loss = 34611600.69978718\n",
            "Iteration 170, loss = 34330441.84427613\n",
            "Iteration 171, loss = 34009730.56575680\n",
            "Iteration 172, loss = 33694766.17458355\n",
            "Iteration 173, loss = 33415451.66449347\n",
            "Iteration 174, loss = 33134335.07351810\n",
            "Iteration 175, loss = 32828523.42867196\n",
            "Iteration 176, loss = 32544042.10630101\n",
            "Iteration 177, loss = 32280287.03494823\n",
            "Iteration 178, loss = 31989165.10555121\n",
            "Iteration 179, loss = 31706191.90536679\n",
            "Iteration 180, loss = 31410566.95214987\n",
            "Iteration 181, loss = 31137598.05607490\n",
            "Iteration 182, loss = 30847443.56777981\n",
            "Iteration 183, loss = 30551669.62514936\n",
            "Iteration 184, loss = 30271636.53872543\n",
            "Iteration 185, loss = 29998689.78365879\n",
            "Iteration 186, loss = 29729079.89713385\n",
            "Iteration 187, loss = 29441954.69962075\n",
            "Iteration 188, loss = 29180308.27461220\n",
            "Iteration 189, loss = 28923162.23612545\n",
            "Iteration 190, loss = 28654988.01195789\n",
            "Iteration 191, loss = 28390687.54351549\n",
            "Iteration 192, loss = 28113364.38111013\n",
            "Iteration 193, loss = 27856172.46787489\n",
            "Iteration 194, loss = 27578870.29056790\n",
            "Iteration 195, loss = 27313454.84857837\n",
            "Iteration 196, loss = 27050356.62226296\n",
            "Iteration 197, loss = 26771604.42466172\n",
            "Iteration 198, loss = 26507630.06798948\n",
            "Iteration 199, loss = 26250386.80400489\n",
            "Iteration 200, loss = 26019177.64324065\n",
            "Iteration 201, loss = 25747517.29836863\n",
            "Iteration 202, loss = 25476710.45950630\n",
            "Iteration 203, loss = 25184640.19163635\n",
            "Iteration 204, loss = 24910191.82965468\n",
            "Iteration 205, loss = 24612285.19317408\n",
            "Iteration 206, loss = 24338682.78731427\n",
            "Iteration 207, loss = 24053659.71184255\n",
            "Iteration 208, loss = 23786421.94113850\n",
            "Iteration 209, loss = 23502005.92952416\n",
            "Iteration 210, loss = 23235283.75413900\n",
            "Iteration 211, loss = 22951045.60084593\n",
            "Iteration 212, loss = 22696330.29390827\n",
            "Iteration 213, loss = 22409419.98858179\n",
            "Iteration 214, loss = 22128520.49073879\n",
            "Iteration 215, loss = 21841645.50023610\n",
            "Iteration 216, loss = 21563745.10906166\n",
            "Iteration 217, loss = 21274997.33207124\n",
            "Iteration 218, loss = 20989435.77234240\n",
            "Iteration 219, loss = 20715665.10684840\n",
            "Iteration 220, loss = 20416302.80289802\n",
            "Iteration 221, loss = 20134265.15131182\n",
            "Iteration 222, loss = 19841079.59993230\n",
            "Iteration 223, loss = 19546213.58763107\n",
            "Iteration 224, loss = 19261367.89660275\n",
            "Iteration 225, loss = 18975885.08867946\n",
            "Iteration 226, loss = 18698964.90447263\n",
            "Iteration 227, loss = 18423327.08245344\n",
            "Iteration 228, loss = 18146363.63213535\n",
            "Iteration 229, loss = 17851833.60118234\n",
            "Iteration 230, loss = 17513749.26383663\n",
            "Iteration 231, loss = 17216312.44102537\n",
            "Iteration 232, loss = 16909106.49825852\n",
            "Iteration 233, loss = 16584581.12562807\n",
            "Iteration 234, loss = 16291228.98363196\n",
            "Iteration 235, loss = 15998286.61487643\n",
            "Iteration 236, loss = 15692218.08500705\n",
            "Iteration 237, loss = 15425989.80232789\n",
            "Iteration 238, loss = 15153657.14357423\n",
            "Iteration 239, loss = 14872855.31952841\n",
            "Iteration 240, loss = 14610994.26920888\n",
            "Iteration 241, loss = 14338830.60202177\n",
            "Iteration 242, loss = 14046087.35076596\n",
            "Iteration 243, loss = 13746306.38152464\n",
            "Iteration 244, loss = 13439473.39031680\n",
            "Iteration 245, loss = 13125322.18481424\n",
            "Iteration 246, loss = 12834915.47362906\n",
            "Iteration 247, loss = 12545351.66131341\n",
            "Iteration 248, loss = 12248701.55657848\n",
            "Iteration 249, loss = 11955105.74520102\n",
            "Iteration 250, loss = 11672761.70686454\n",
            "Iteration 251, loss = 11392185.64127322\n",
            "Iteration 252, loss = 11122350.99430374\n",
            "Iteration 253, loss = 10862012.37714607\n",
            "Iteration 254, loss = 10601711.18419865\n",
            "Iteration 255, loss = 10347959.95378002\n",
            "Iteration 256, loss = 10101455.72083155\n",
            "Iteration 257, loss = 9854876.10102207\n",
            "Iteration 258, loss = 9609403.40513038\n",
            "Iteration 259, loss = 9371683.23199188\n",
            "Iteration 260, loss = 9157314.36135140\n",
            "Iteration 261, loss = 8958203.50770757\n",
            "Iteration 262, loss = 8738449.07513082\n",
            "Iteration 263, loss = 8523656.74095457\n",
            "Iteration 264, loss = 8321399.31463760\n",
            "Iteration 265, loss = 8115533.88037106\n",
            "Iteration 266, loss = 7904155.74302184\n",
            "Iteration 267, loss = 7714584.96591236\n",
            "Iteration 268, loss = 7531008.67499394\n",
            "Iteration 269, loss = 7344122.76549367\n",
            "Iteration 270, loss = 7159956.46430246\n",
            "Iteration 271, loss = 6986317.68483038\n",
            "Iteration 272, loss = 6813355.02817243\n",
            "Iteration 273, loss = 6647177.59634023\n",
            "Iteration 274, loss = 6486306.72019310\n",
            "Iteration 275, loss = 6332836.50990258\n",
            "Iteration 276, loss = 6175925.75102005\n",
            "Iteration 277, loss = 6033152.59573342\n",
            "Iteration 278, loss = 5892837.93360000\n",
            "Iteration 279, loss = 5755783.89127856\n",
            "Iteration 280, loss = 5629791.41995768\n",
            "Iteration 281, loss = 5500853.77118243\n",
            "Iteration 282, loss = 5376228.92787287\n",
            "Iteration 283, loss = 5252465.43742336\n",
            "Iteration 284, loss = 5145849.09053207\n",
            "Iteration 285, loss = 5027586.53198829\n",
            "Iteration 286, loss = 4925055.33493504\n",
            "Iteration 287, loss = 4818364.97244022\n",
            "Iteration 288, loss = 4714868.72677159\n",
            "Iteration 289, loss = 4613430.83481831\n",
            "Iteration 290, loss = 4521906.36677515\n",
            "Iteration 291, loss = 4422456.89470362\n",
            "Iteration 292, loss = 4329460.24920811\n",
            "Iteration 293, loss = 4236820.26953859\n",
            "Iteration 294, loss = 4144813.94150982\n",
            "Iteration 295, loss = 4058045.48262513\n",
            "Iteration 296, loss = 3977004.87034418\n",
            "Iteration 297, loss = 3896620.82549055\n",
            "Iteration 298, loss = 3821496.70876584\n",
            "Iteration 299, loss = 3747779.70309714\n",
            "Iteration 300, loss = 3677652.50875801\n",
            "Iteration 301, loss = 3612115.54730232\n",
            "Iteration 302, loss = 3555629.63690594\n",
            "Iteration 303, loss = 3495385.58363646\n",
            "Iteration 304, loss = 3436389.49420226\n",
            "Iteration 305, loss = 3379254.14849486\n",
            "Iteration 306, loss = 3322058.07668809\n",
            "Iteration 307, loss = 3262455.00522700\n",
            "Iteration 308, loss = 3209519.46486143\n",
            "Iteration 309, loss = 3147806.51067599\n",
            "Iteration 310, loss = 3090991.24783323\n",
            "Iteration 311, loss = 3038700.11439656\n",
            "Iteration 312, loss = 2987930.39896652\n",
            "Iteration 313, loss = 2944897.17028506\n",
            "Iteration 314, loss = 2896332.97134731\n",
            "Iteration 315, loss = 2855788.94363267\n",
            "Iteration 316, loss = 2809051.87348863\n",
            "Iteration 317, loss = 2765263.98313220\n",
            "Iteration 318, loss = 2722701.01651994\n",
            "Iteration 319, loss = 2680195.65056707\n",
            "Iteration 320, loss = 2636162.35687468\n",
            "Iteration 321, loss = 2596986.38927107\n",
            "Iteration 322, loss = 2558741.67164940\n",
            "Iteration 323, loss = 2521469.45273997\n",
            "Iteration 324, loss = 2485246.71949724\n",
            "Iteration 325, loss = 2450197.56226890\n",
            "Iteration 326, loss = 2416962.49514718\n",
            "Iteration 327, loss = 2384943.98672641\n",
            "Iteration 328, loss = 2349874.45609548\n",
            "Iteration 329, loss = 2316715.36953247\n",
            "Iteration 330, loss = 2286401.93422736\n",
            "Iteration 331, loss = 2255614.16422249\n",
            "Iteration 332, loss = 2228291.10078467\n",
            "Iteration 333, loss = 2200738.43561701\n",
            "Iteration 334, loss = 2177822.73887145\n",
            "Iteration 335, loss = 2151843.02473476\n",
            "Iteration 336, loss = 2127782.36455179\n",
            "Iteration 337, loss = 2104811.79443553\n",
            "Iteration 338, loss = 2082098.29182880\n",
            "Iteration 339, loss = 2060356.93935517\n",
            "Iteration 340, loss = 2040976.29334583\n",
            "Iteration 341, loss = 2019950.62783564\n",
            "Iteration 342, loss = 1999850.87139916\n",
            "Iteration 343, loss = 1979345.29783059\n",
            "Iteration 344, loss = 1960794.55330274\n",
            "Iteration 345, loss = 1942371.13267709\n",
            "Iteration 346, loss = 1922401.55978532\n",
            "Iteration 347, loss = 1903682.37477550\n",
            "Iteration 348, loss = 1887516.49193403\n",
            "Iteration 349, loss = 1870216.52995910\n",
            "Iteration 350, loss = 1852994.61391900\n",
            "Iteration 351, loss = 1837353.34013523\n",
            "Iteration 352, loss = 1820800.45736457\n",
            "Iteration 353, loss = 1805368.48546654\n",
            "Iteration 354, loss = 1789879.53841307\n",
            "Iteration 355, loss = 1775894.70684292\n",
            "Iteration 356, loss = 1760467.68748222\n",
            "Iteration 357, loss = 1747612.02737205\n",
            "Iteration 358, loss = 1734053.09975401\n",
            "Iteration 359, loss = 1720598.88986364\n",
            "Iteration 360, loss = 1707445.47001745\n",
            "Iteration 361, loss = 1695561.58226235\n",
            "Iteration 362, loss = 1684315.06485810\n",
            "Iteration 363, loss = 1674893.50102561\n",
            "Iteration 364, loss = 1665768.79809517\n",
            "Iteration 365, loss = 1654791.56176206\n",
            "Iteration 366, loss = 1642180.09148386\n",
            "Iteration 367, loss = 1630346.49717178\n",
            "Iteration 368, loss = 1616732.36944744\n",
            "Iteration 369, loss = 1605784.75198304\n",
            "Iteration 370, loss = 1594866.75624261\n",
            "Iteration 371, loss = 1585162.69950334\n",
            "Iteration 372, loss = 1574756.75309384\n",
            "Iteration 373, loss = 1566217.29948585\n",
            "Iteration 374, loss = 1557428.54945098\n",
            "Iteration 375, loss = 1549379.10034760\n",
            "Iteration 376, loss = 1541176.05680056\n",
            "Iteration 377, loss = 1533096.12694074\n",
            "Iteration 378, loss = 1524204.79044269\n",
            "Iteration 379, loss = 1516305.90601918\n",
            "Iteration 380, loss = 1508603.40327739\n",
            "Iteration 381, loss = 1500369.99638336\n",
            "Iteration 382, loss = 1492626.48061603\n",
            "Iteration 383, loss = 1485576.83247323\n",
            "Iteration 384, loss = 1476721.48821999\n",
            "Iteration 385, loss = 1469035.56094712\n",
            "Iteration 386, loss = 1461819.77705635\n",
            "Iteration 387, loss = 1456882.36542694\n",
            "Iteration 388, loss = 1451771.03986332\n",
            "Iteration 389, loss = 1444719.30139488\n",
            "Iteration 390, loss = 1436689.79306607\n",
            "Iteration 391, loss = 1428880.19519406\n",
            "Iteration 392, loss = 1422907.11536380\n",
            "Iteration 393, loss = 1419194.39046626\n",
            "Iteration 394, loss = 1412839.17960812\n",
            "Iteration 395, loss = 1406555.57475358\n",
            "Iteration 396, loss = 1400903.96662526\n",
            "Iteration 397, loss = 1395075.20520815\n",
            "Iteration 398, loss = 1390775.63380953\n",
            "Iteration 399, loss = 1383690.67448886\n",
            "Iteration 400, loss = 1377558.72828958\n",
            "Iteration 401, loss = 1372026.61645696\n",
            "Iteration 402, loss = 1366502.35544224\n",
            "Iteration 403, loss = 1361831.59287559\n",
            "Iteration 404, loss = 1357383.77856731\n",
            "Iteration 405, loss = 1351798.04617460\n",
            "Iteration 406, loss = 1348732.06364014\n",
            "Iteration 407, loss = 1344526.23704108\n",
            "Iteration 408, loss = 1338557.56154481\n",
            "Iteration 409, loss = 1332772.83771730\n",
            "Iteration 410, loss = 1327534.83399336\n",
            "Iteration 411, loss = 1323145.93325473\n",
            "Iteration 412, loss = 1318861.90743594\n",
            "Iteration 413, loss = 1314968.50564232\n",
            "Iteration 414, loss = 1312104.15617356\n",
            "Iteration 415, loss = 1307809.09615275\n",
            "Iteration 416, loss = 1302703.23446259\n",
            "Iteration 417, loss = 1297893.11996884\n",
            "Iteration 418, loss = 1294791.61142280\n",
            "Iteration 419, loss = 1294804.70935465\n",
            "Iteration 420, loss = 1289810.23820090\n",
            "Iteration 421, loss = 1282154.36998581\n",
            "Iteration 422, loss = 1277111.99998364\n",
            "Iteration 423, loss = 1272387.62871105\n",
            "Iteration 424, loss = 1268173.05274120\n",
            "Iteration 425, loss = 1264862.51954592\n",
            "Iteration 426, loss = 1261629.76577455\n",
            "Iteration 427, loss = 1257610.60423626\n",
            "Iteration 428, loss = 1253636.14540878\n",
            "Iteration 429, loss = 1251162.52696143\n",
            "Iteration 430, loss = 1248208.93912889\n",
            "Iteration 431, loss = 1244880.32485281\n",
            "Iteration 432, loss = 1242123.68741686\n",
            "Iteration 433, loss = 1241039.65724329\n",
            "Iteration 434, loss = 1239645.64947949\n",
            "Iteration 435, loss = 1237489.47355353\n",
            "Iteration 436, loss = 1232578.11855887\n",
            "Iteration 437, loss = 1226493.90681717\n",
            "Iteration 438, loss = 1223899.12208954\n",
            "Iteration 439, loss = 1224297.47965900\n",
            "Iteration 440, loss = 1227718.80326232\n",
            "Iteration 441, loss = 1228863.25492480\n",
            "Iteration 442, loss = 1226838.55581376\n",
            "Iteration 443, loss = 1220960.70452322\n",
            "Iteration 444, loss = 1214202.92252567\n",
            "Iteration 445, loss = 1210268.63843687\n",
            "Iteration 446, loss = 1207072.03796047\n",
            "Iteration 447, loss = 1204192.74299449\n",
            "Iteration 448, loss = 1200577.79118578\n",
            "Iteration 449, loss = 1200415.33389752\n",
            "Iteration 450, loss = 1197217.10065681\n",
            "Iteration 451, loss = 1195883.89014082\n",
            "Iteration 452, loss = 1193924.78374500\n",
            "Iteration 453, loss = 1191727.35926130\n",
            "Iteration 454, loss = 1188843.78003436\n",
            "Iteration 455, loss = 1186409.88652459\n",
            "Iteration 456, loss = 1183499.49735415\n",
            "Iteration 457, loss = 1183080.68847803\n",
            "Iteration 458, loss = 1180489.14746401\n",
            "Iteration 459, loss = 1178232.70332586\n",
            "Iteration 460, loss = 1175528.82736206\n",
            "Iteration 461, loss = 1175006.88472935\n",
            "Iteration 462, loss = 1173429.39393459\n",
            "Iteration 463, loss = 1172185.82100705\n",
            "Iteration 464, loss = 1170365.72377730\n",
            "Iteration 465, loss = 1167308.41548279\n",
            "Iteration 466, loss = 1165121.72652638\n",
            "Iteration 467, loss = 1164190.29137341\n",
            "Iteration 468, loss = 1165103.54396931\n",
            "Iteration 469, loss = 1164478.10193059\n",
            "Iteration 470, loss = 1163019.10504626\n",
            "Iteration 471, loss = 1161975.91982421\n",
            "Iteration 472, loss = 1158946.92180618\n",
            "Iteration 473, loss = 1156470.96465738\n",
            "Iteration 474, loss = 1154232.87780167\n",
            "Iteration 475, loss = 1150870.50124274\n",
            "Iteration 476, loss = 1149469.03841348\n",
            "Iteration 477, loss = 1148934.59955656\n",
            "Iteration 478, loss = 1147929.11872128\n",
            "Iteration 479, loss = 1147276.66274252\n",
            "Iteration 480, loss = 1144256.05361775\n",
            "Iteration 481, loss = 1142858.90417209\n",
            "Iteration 482, loss = 1140625.52974173\n",
            "Iteration 483, loss = 1139109.56622649\n",
            "Iteration 484, loss = 1137793.03292041\n",
            "Iteration 485, loss = 1136634.69323858\n",
            "Iteration 486, loss = 1136257.17465856\n",
            "Iteration 487, loss = 1136210.67159668\n",
            "Iteration 488, loss = 1135697.45590474\n",
            "Iteration 489, loss = 1134856.42429982\n",
            "Iteration 490, loss = 1133662.92875029\n",
            "Iteration 491, loss = 1131463.77020598\n",
            "Iteration 492, loss = 1130139.59201608\n",
            "Iteration 493, loss = 1128384.88990472\n",
            "Iteration 494, loss = 1130793.11045320\n",
            "Iteration 495, loss = 1128663.85838916\n",
            "Iteration 496, loss = 1127077.84727253\n",
            "Iteration 497, loss = 1125091.56520377\n",
            "Iteration 498, loss = 1124023.50307239\n",
            "Iteration 499, loss = 1122583.07364215\n",
            "Iteration 500, loss = 1121383.71679445\n",
            "Iteration 501, loss = 1121061.13791987\n",
            "Iteration 502, loss = 1120490.53406031\n",
            "Iteration 503, loss = 1120109.38908030\n",
            "Iteration 504, loss = 1119239.52450893\n",
            "Iteration 505, loss = 1117255.55624198\n",
            "Iteration 506, loss = 1115120.25446371\n",
            "Iteration 507, loss = 1114803.94538395\n",
            "Iteration 508, loss = 1116242.30156267\n",
            "Iteration 509, loss = 1121176.03681463\n",
            "Iteration 510, loss = 1118864.60151717\n",
            "Iteration 511, loss = 1113864.63212803\n",
            "Iteration 512, loss = 1109812.81355512\n",
            "Iteration 513, loss = 1110449.61720831\n",
            "Iteration 514, loss = 1112360.36010535\n",
            "Iteration 515, loss = 1112160.75232084\n",
            "Iteration 516, loss = 1110240.37633693\n",
            "Iteration 517, loss = 1107506.83229298\n",
            "Iteration 518, loss = 1104924.72450026\n",
            "Iteration 519, loss = 1104034.71305266\n",
            "Iteration 520, loss = 1106135.86886565\n",
            "Iteration 521, loss = 1104919.28933256\n",
            "Iteration 522, loss = 1103743.88554342\n",
            "Iteration 523, loss = 1102714.98545742\n",
            "Iteration 524, loss = 1101238.47235259\n",
            "Iteration 525, loss = 1101841.73483835\n",
            "Iteration 526, loss = 1099052.68710311\n",
            "Iteration 527, loss = 1098405.96457525\n",
            "Iteration 528, loss = 1098550.41844240\n",
            "Iteration 529, loss = 1097270.91586258\n",
            "Iteration 530, loss = 1096108.57905870\n",
            "Iteration 531, loss = 1095670.15556277\n",
            "Iteration 532, loss = 1095048.00341703\n",
            "Iteration 533, loss = 1094366.07208386\n",
            "Iteration 534, loss = 1093663.41138459\n",
            "Iteration 535, loss = 1093221.38641403\n",
            "Iteration 536, loss = 1096707.58014399\n",
            "Iteration 537, loss = 1105976.74299356\n",
            "Iteration 538, loss = 1110432.77920135\n",
            "Iteration 539, loss = 1104953.59090131\n",
            "Iteration 540, loss = 1092680.93312839\n",
            "Iteration 541, loss = 1086882.83914555\n",
            "Iteration 542, loss = 1088837.64390898\n",
            "Iteration 543, loss = 1092423.12061889\n",
            "Iteration 544, loss = 1090193.97271925\n",
            "Iteration 545, loss = 1085670.72868996\n",
            "Iteration 546, loss = 1085462.44008824\n",
            "Iteration 547, loss = 1083458.77486688\n",
            "Iteration 548, loss = 1084726.45978660\n",
            "Iteration 549, loss = 1083807.23647983\n",
            "Iteration 550, loss = 1082290.32988272\n",
            "Iteration 551, loss = 1080794.03339185\n",
            "Iteration 552, loss = 1079013.61314365\n",
            "Iteration 553, loss = 1078311.83701689\n",
            "Iteration 554, loss = 1077912.37051481\n",
            "Iteration 555, loss = 1077723.81312634\n",
            "Iteration 556, loss = 1076617.73965458\n",
            "Iteration 557, loss = 1076071.72296479\n",
            "Iteration 558, loss = 1075044.19787978\n",
            "Iteration 559, loss = 1074503.85268326\n",
            "Iteration 560, loss = 1073971.45475067\n",
            "Iteration 561, loss = 1077135.09713315\n",
            "Iteration 562, loss = 1075919.62844633\n",
            "Iteration 563, loss = 1074359.86923487\n",
            "Iteration 564, loss = 1072278.10492829\n",
            "Iteration 565, loss = 1070771.15099618\n",
            "Iteration 566, loss = 1070473.96104112\n",
            "Iteration 567, loss = 1070611.93254635\n",
            "Iteration 568, loss = 1069538.25771575\n",
            "Iteration 569, loss = 1069725.74099860\n",
            "Iteration 570, loss = 1068691.16970676\n",
            "Iteration 571, loss = 1068132.28323853\n",
            "Iteration 572, loss = 1067989.61000250\n",
            "Iteration 573, loss = 1067711.25723229\n",
            "Iteration 574, loss = 1067380.07913179\n",
            "Iteration 575, loss = 1066745.58889550\n",
            "Iteration 576, loss = 1066277.33360354\n",
            "Iteration 577, loss = 1065649.34152245\n",
            "Iteration 578, loss = 1064968.80194032\n",
            "Iteration 579, loss = 1065097.99165616\n",
            "Iteration 580, loss = 1063792.20676712\n",
            "Iteration 581, loss = 1063425.61748173\n",
            "Iteration 582, loss = 1063116.70471745\n",
            "Iteration 583, loss = 1063034.76185769\n",
            "Iteration 584, loss = 1063964.85285665\n",
            "Iteration 585, loss = 1063051.68596698\n",
            "Iteration 586, loss = 1061853.95277503\n",
            "Iteration 587, loss = 1062007.05857087\n",
            "Iteration 588, loss = 1060943.14871693\n",
            "Iteration 589, loss = 1061758.58925257\n",
            "Iteration 590, loss = 1064470.55527978\n",
            "Iteration 591, loss = 1066358.57982913\n",
            "Iteration 592, loss = 1066927.04484684\n",
            "Iteration 593, loss = 1065707.78023525\n",
            "Iteration 594, loss = 1061989.46919505\n",
            "Iteration 595, loss = 1060668.54597444\n",
            "Iteration 596, loss = 1058038.10185639\n",
            "Iteration 597, loss = 1057011.08094087\n",
            "Iteration 598, loss = 1056803.30259152\n",
            "Iteration 599, loss = 1056558.44994828\n",
            "Iteration 600, loss = 1056383.23255692\n",
            "Iteration 601, loss = 1057576.63431657\n",
            "Iteration 602, loss = 1056616.07406655\n",
            "Iteration 603, loss = 1055491.86424144\n",
            "Iteration 604, loss = 1054291.41999846\n",
            "Iteration 605, loss = 1054843.65799185\n",
            "Iteration 606, loss = 1057132.67908749\n",
            "Iteration 607, loss = 1056502.68039102\n",
            "Iteration 608, loss = 1055652.10603875\n",
            "Iteration 609, loss = 1054463.37401157\n",
            "Iteration 610, loss = 1054235.47042707\n",
            "Iteration 611, loss = 1053440.55059538\n",
            "Iteration 612, loss = 1052821.07031125\n",
            "Iteration 613, loss = 1052195.34733415\n",
            "Iteration 614, loss = 1051505.70833906\n",
            "Iteration 615, loss = 1050824.80301128\n",
            "Iteration 616, loss = 1051370.70733019\n",
            "Iteration 617, loss = 1053955.33771113\n",
            "Iteration 618, loss = 1055304.88280365\n",
            "Iteration 619, loss = 1055868.57134563\n",
            "Iteration 620, loss = 1055067.00434801\n",
            "Iteration 621, loss = 1051899.63204370\n",
            "Iteration 622, loss = 1049919.91986309\n",
            "Iteration 623, loss = 1049967.54419682\n",
            "Iteration 624, loss = 1050315.92242497\n",
            "Iteration 625, loss = 1050556.88769082\n",
            "Iteration 626, loss = 1050674.58116461\n",
            "Iteration 627, loss = 1050115.68636941\n",
            "Iteration 628, loss = 1051000.20209445\n",
            "Iteration 629, loss = 1049607.86399117\n",
            "Iteration 630, loss = 1051064.76371528\n",
            "Iteration 631, loss = 1050366.89002542\n",
            "Iteration 632, loss = 1046467.92693232\n",
            "Iteration 633, loss = 1046522.74817960\n",
            "Iteration 634, loss = 1046747.24284291\n",
            "Iteration 635, loss = 1046713.12780993\n",
            "Iteration 636, loss = 1050572.47833647\n",
            "Iteration 637, loss = 1050387.75718726\n",
            "Iteration 638, loss = 1047842.45890766\n",
            "Iteration 639, loss = 1046347.72478967\n",
            "Iteration 640, loss = 1045876.56473136\n",
            "Iteration 641, loss = 1046426.85412354\n",
            "Iteration 642, loss = 1045542.33691478\n",
            "Iteration 643, loss = 1043457.23887795\n",
            "Iteration 644, loss = 1042785.67063759\n",
            "Iteration 645, loss = 1047787.36745005\n",
            "Iteration 646, loss = 1051852.42724506\n",
            "Iteration 647, loss = 1051736.88030163\n",
            "Iteration 648, loss = 1048095.40371284\n",
            "Iteration 649, loss = 1045670.67941697\n",
            "Iteration 650, loss = 1044828.85252879\n",
            "Iteration 651, loss = 1042678.40276447\n",
            "Iteration 652, loss = 1042384.96225035\n",
            "Iteration 653, loss = 1041867.79038173\n",
            "Iteration 654, loss = 1041869.30754895\n",
            "Iteration 655, loss = 1042575.02746907\n",
            "Iteration 656, loss = 1040564.76269112\n",
            "Iteration 657, loss = 1040808.67330376\n",
            "Iteration 658, loss = 1042611.26893364\n",
            "Iteration 659, loss = 1043121.31861678\n",
            "Iteration 660, loss = 1042907.43211848\n",
            "Iteration 661, loss = 1041815.45290885\n",
            "Iteration 662, loss = 1041035.52226383\n",
            "Iteration 663, loss = 1039691.04821499\n",
            "Iteration 664, loss = 1038647.19365145\n",
            "Iteration 665, loss = 1041752.57430140\n",
            "Iteration 666, loss = 1041318.09748938\n",
            "Iteration 667, loss = 1039952.30699448\n",
            "Iteration 668, loss = 1039379.83762776\n",
            "Iteration 669, loss = 1038451.58758640\n",
            "Iteration 670, loss = 1038331.59394790\n",
            "Iteration 671, loss = 1039333.03593122\n",
            "Iteration 672, loss = 1038970.75993340\n",
            "Iteration 673, loss = 1038122.72795800\n",
            "Iteration 674, loss = 1038414.11429926\n",
            "Iteration 675, loss = 1038949.84840695\n",
            "Iteration 676, loss = 1036559.97508088\n",
            "Iteration 677, loss = 1039021.59748806\n",
            "Iteration 678, loss = 1038619.13445839\n",
            "Iteration 679, loss = 1039008.20370221\n",
            "Iteration 680, loss = 1038656.61487439\n",
            "Iteration 681, loss = 1039207.21653783\n",
            "Iteration 682, loss = 1038552.03187699\n",
            "Iteration 683, loss = 1037928.38832081\n",
            "Iteration 684, loss = 1036789.56568866\n",
            "Iteration 685, loss = 1035869.87475723\n",
            "Iteration 686, loss = 1034632.41251980\n",
            "Iteration 687, loss = 1036207.30264716\n",
            "Iteration 688, loss = 1038135.66286442\n",
            "Iteration 689, loss = 1041457.68851543\n",
            "Iteration 690, loss = 1041662.32819956\n",
            "Iteration 691, loss = 1036545.16402754\n",
            "Iteration 692, loss = 1032527.39837219\n",
            "Iteration 693, loss = 1040465.97243428\n",
            "Iteration 694, loss = 1042318.84217520\n",
            "Iteration 695, loss = 1040837.17038072\n",
            "Iteration 696, loss = 1038302.43427314\n",
            "Iteration 697, loss = 1033997.34161254\n",
            "Iteration 698, loss = 1034200.42966378\n",
            "Iteration 699, loss = 1034243.56474149\n",
            "Iteration 700, loss = 1035292.58118978\n",
            "Iteration 701, loss = 1035513.01957066\n",
            "Iteration 702, loss = 1035183.38110403\n",
            "Iteration 703, loss = 1035869.81581856\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1528802043.06166244\n",
            "Iteration 2, loss = 1150798400.03542066\n",
            "Iteration 3, loss = 295396643.74928737\n",
            "Iteration 4, loss = 75111714.07069978\n",
            "Iteration 5, loss = 65481400.27828716\n",
            "Iteration 6, loss = 66041029.18942811\n",
            "Iteration 7, loss = 66183836.24003462\n",
            "Iteration 8, loss = 61057863.73991988\n",
            "Iteration 9, loss = 43966024.00268710\n",
            "Iteration 10, loss = 33442402.03174761\n",
            "Iteration 11, loss = 32462483.78553127\n",
            "Iteration 12, loss = 34570821.94599127\n",
            "Iteration 13, loss = 38043399.34674913\n",
            "Iteration 14, loss = 30218948.86061209\n",
            "Iteration 15, loss = 35135314.44241063\n",
            "Iteration 16, loss = 46690585.47120342\n",
            "Iteration 17, loss = 20790687.24715522\n",
            "Iteration 18, loss = 23770107.19485704\n",
            "Iteration 19, loss = 21639315.20287293\n",
            "Iteration 20, loss = 19370385.81603564\n",
            "Iteration 21, loss = 19265034.76863003\n",
            "Iteration 22, loss = 18960234.66309737\n",
            "Iteration 23, loss = 18631686.99415227\n",
            "Iteration 24, loss = 19069063.39998639\n",
            "Iteration 25, loss = 17892608.23259608\n",
            "Iteration 26, loss = 17843508.63534743\n",
            "Iteration 27, loss = 17622306.36591081\n",
            "Iteration 28, loss = 16361118.33850467\n",
            "Iteration 29, loss = 16469672.63143541\n",
            "Iteration 30, loss = 16031705.25257686\n",
            "Iteration 31, loss = 17388600.52900061\n",
            "Iteration 32, loss = 16454173.80080425\n",
            "Iteration 33, loss = 15187375.68971290\n",
            "Iteration 34, loss = 15062237.53576653\n",
            "Iteration 35, loss = 14996690.65292905\n",
            "Iteration 36, loss = 14718824.13712421\n",
            "Iteration 37, loss = 14652757.92797567\n",
            "Iteration 38, loss = 14478805.04672163\n",
            "Iteration 39, loss = 14457262.40303347\n",
            "Iteration 40, loss = 14563049.20871264\n",
            "Iteration 41, loss = 14372575.98576329\n",
            "Iteration 42, loss = 14234277.38749899\n",
            "Iteration 43, loss = 14104844.53002799\n",
            "Iteration 44, loss = 14218731.66050569\n",
            "Iteration 45, loss = 13745646.07027691\n",
            "Iteration 46, loss = 13931876.75418142\n",
            "Iteration 47, loss = 13702115.27113382\n",
            "Iteration 48, loss = 13816020.61039557\n",
            "Iteration 49, loss = 13463417.63892198\n",
            "Iteration 50, loss = 13694545.09805434\n",
            "Iteration 51, loss = 13596272.33321435\n",
            "Iteration 52, loss = 13544757.40773468\n",
            "Iteration 53, loss = 13310618.95078232\n",
            "Iteration 54, loss = 13370360.40088560\n",
            "Iteration 55, loss = 13200227.14458545\n",
            "Iteration 56, loss = 13353682.24138988\n",
            "Iteration 57, loss = 13165063.68458100\n",
            "Iteration 58, loss = 13090617.37559996\n",
            "Iteration 59, loss = 13114603.82088595\n",
            "Iteration 60, loss = 13202999.03087696\n",
            "Iteration 61, loss = 13002168.18515156\n",
            "Iteration 62, loss = 13110507.95805891\n",
            "Iteration 63, loss = 13447423.63512819\n",
            "Iteration 64, loss = 13001290.92794046\n",
            "Iteration 65, loss = 13072124.37499290\n",
            "Iteration 66, loss = 12913359.68494736\n",
            "Iteration 67, loss = 13088157.99681189\n",
            "Iteration 68, loss = 12843713.48264074\n",
            "Iteration 69, loss = 12863615.07892997\n",
            "Iteration 70, loss = 12800736.31605700\n",
            "Iteration 71, loss = 12801578.95899213\n",
            "Iteration 72, loss = 12808705.34722698\n",
            "Iteration 73, loss = 13044148.34068682\n",
            "Iteration 74, loss = 12822879.62428428\n",
            "Iteration 75, loss = 12905873.63737346\n",
            "Iteration 76, loss = 13046152.46671671\n",
            "Iteration 77, loss = 12830438.76185569\n",
            "Iteration 78, loss = 12676961.75981600\n",
            "Iteration 79, loss = 12955101.87814659\n",
            "Iteration 80, loss = 12708311.86825585\n",
            "Iteration 81, loss = 13021534.56789346\n",
            "Iteration 82, loss = 12695981.25573004\n",
            "Iteration 83, loss = 12671128.24305254\n",
            "Iteration 84, loss = 12613709.84313652\n",
            "Iteration 85, loss = 12645465.69853607\n",
            "Iteration 86, loss = 12845224.59600002\n",
            "Iteration 87, loss = 12631593.59188668\n",
            "Iteration 88, loss = 12608436.10452564\n",
            "Iteration 89, loss = 12693404.99018437\n",
            "Iteration 90, loss = 12512065.21495422\n",
            "Iteration 91, loss = 12517606.98273795\n",
            "Iteration 92, loss = 12671001.91494094\n",
            "Iteration 93, loss = 12482760.77010969\n",
            "Iteration 94, loss = 12470345.35938214\n",
            "Iteration 95, loss = 12596432.04673856\n",
            "Iteration 96, loss = 12471533.18411150\n",
            "Iteration 97, loss = 12441125.43948002\n",
            "Iteration 98, loss = 12451848.40493693\n",
            "Iteration 99, loss = 12547250.73017588\n",
            "Iteration 100, loss = 12746427.18534816\n",
            "Iteration 101, loss = 12425917.24941148\n",
            "Iteration 102, loss = 12366073.00333104\n",
            "Iteration 103, loss = 12382289.01783975\n",
            "Iteration 104, loss = 12512562.43965254\n",
            "Iteration 105, loss = 12336814.46050444\n",
            "Iteration 106, loss = 12421291.37543510\n",
            "Iteration 107, loss = 12360731.49277796\n",
            "Iteration 108, loss = 12597794.99766966\n",
            "Iteration 109, loss = 12493972.39595979\n",
            "Iteration 110, loss = 12331393.04721510\n",
            "Iteration 111, loss = 12472507.96063501\n",
            "Iteration 112, loss = 12397649.00679688\n",
            "Iteration 113, loss = 12629392.37280061\n",
            "Iteration 114, loss = 12476257.35665723\n",
            "Iteration 115, loss = 12277535.31793113\n",
            "Iteration 116, loss = 12293741.13985227\n",
            "Iteration 117, loss = 12460775.31718913\n",
            "Iteration 118, loss = 12380626.70431634\n",
            "Iteration 119, loss = 12277439.92729796\n",
            "Iteration 120, loss = 12279170.42198234\n",
            "Iteration 121, loss = 12226590.64432064\n",
            "Iteration 122, loss = 12262521.73021021\n",
            "Iteration 123, loss = 12202544.36131394\n",
            "Iteration 124, loss = 12198704.32879235\n",
            "Iteration 125, loss = 12280905.42889627\n",
            "Iteration 126, loss = 12293169.94557567\n",
            "Iteration 127, loss = 12226610.03936882\n",
            "Iteration 128, loss = 12191518.36878465\n",
            "Iteration 129, loss = 12187680.27165894\n",
            "Iteration 130, loss = 12224996.13343352\n",
            "Iteration 131, loss = 12488106.78979747\n",
            "Iteration 132, loss = 12168635.49532570\n",
            "Iteration 133, loss = 12159373.45634501\n",
            "Iteration 134, loss = 12156176.07970675\n",
            "Iteration 135, loss = 12272941.75317137\n",
            "Iteration 136, loss = 12137966.99737786\n",
            "Iteration 137, loss = 12145931.40599137\n",
            "Iteration 138, loss = 12169749.40412467\n",
            "Iteration 139, loss = 12211115.91961464\n",
            "Iteration 140, loss = 12914084.16579051\n",
            "Iteration 141, loss = 12184029.60955419\n",
            "Iteration 142, loss = 12890257.04726462\n",
            "Iteration 143, loss = 12081621.66182765\n",
            "Iteration 144, loss = 12163391.98499599\n",
            "Iteration 145, loss = 12128772.98412166\n",
            "Iteration 146, loss = 12217031.83363603\n",
            "Iteration 147, loss = 12190764.78255670\n",
            "Iteration 148, loss = 12201376.76687223\n",
            "Iteration 149, loss = 12164177.94280287\n",
            "Iteration 150, loss = 12181119.61750478\n",
            "Iteration 151, loss = 12156336.11380079\n",
            "Iteration 152, loss = 12120383.31119771\n",
            "Iteration 153, loss = 12227591.73448100\n",
            "Iteration 154, loss = 12208820.68046376\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538789027.17312789\n",
            "Iteration 2, loss = 1538581956.43585873\n",
            "Iteration 3, loss = 1538374155.79276037\n",
            "Iteration 4, loss = 1538171069.97610569\n",
            "Iteration 5, loss = 1537954320.85589075\n",
            "Iteration 6, loss = 1537777373.90171647\n",
            "Iteration 7, loss = 1537635207.61030126\n",
            "Iteration 8, loss = 1537501876.71127844\n",
            "Iteration 9, loss = 1537375293.05866122\n",
            "Iteration 10, loss = 1537253201.70541620\n",
            "Iteration 11, loss = 1537132744.64382219\n",
            "Iteration 12, loss = 1537012399.97725844\n",
            "Iteration 13, loss = 1536893963.35608053\n",
            "Iteration 14, loss = 1536774412.21972275\n",
            "Iteration 15, loss = 1536654496.91125655\n",
            "Iteration 16, loss = 1536535876.95861959\n",
            "Iteration 17, loss = 1536416787.97001147\n",
            "Iteration 18, loss = 1536297622.08608317\n",
            "Iteration 19, loss = 1536179961.99508500\n",
            "Iteration 20, loss = 1536061926.38807416\n",
            "Iteration 21, loss = 1535943745.83471775\n",
            "Iteration 22, loss = 1535826419.75866961\n",
            "Iteration 23, loss = 1535709421.09792662\n",
            "Iteration 24, loss = 1535592826.37610555\n",
            "Iteration 25, loss = 1535475942.61107969\n",
            "Iteration 26, loss = 1535359789.43136096\n",
            "Iteration 27, loss = 1535243296.42172027\n",
            "Iteration 28, loss = 1535128515.25601554\n",
            "Iteration 29, loss = 1535013238.98303127\n",
            "Iteration 30, loss = 1534897771.47336531\n",
            "Iteration 31, loss = 1534783021.06840825\n",
            "Iteration 32, loss = 1534669480.98510575\n",
            "Iteration 33, loss = 1534554896.42628956\n",
            "Iteration 34, loss = 1534441415.02488899\n",
            "Iteration 35, loss = 1534327138.87334561\n",
            "Iteration 36, loss = 1534213712.74361682\n",
            "Iteration 37, loss = 1534099687.54720616\n",
            "Iteration 38, loss = 1533987104.55626845\n",
            "Iteration 39, loss = 1533872563.65325761\n",
            "Iteration 40, loss = 1533760022.06866407\n",
            "Iteration 41, loss = 1533646470.07573462\n",
            "Iteration 42, loss = 1533533544.01850319\n",
            "Iteration 43, loss = 1533420340.20834637\n",
            "Iteration 44, loss = 1533307640.59543490\n",
            "Iteration 45, loss = 1533195113.81782556\n",
            "Iteration 46, loss = 1533082258.22783923\n",
            "Iteration 47, loss = 1532969320.88379598\n",
            "Iteration 48, loss = 1532857142.33919597\n",
            "Iteration 49, loss = 1532744328.84014177\n",
            "Iteration 50, loss = 1532632690.27377152\n",
            "Iteration 51, loss = 1532520651.01173306\n",
            "Iteration 52, loss = 1532408063.07061887\n",
            "Iteration 53, loss = 1532296016.75113940\n",
            "Iteration 54, loss = 1532185108.51662612\n",
            "Iteration 55, loss = 1532072499.43635654\n",
            "Iteration 56, loss = 1531961390.47907162\n",
            "Iteration 57, loss = 1531849676.14592147\n",
            "Iteration 58, loss = 1531738355.93295264\n",
            "Iteration 59, loss = 1531626586.43537259\n",
            "Iteration 60, loss = 1531515338.95231915\n",
            "Iteration 61, loss = 1531404453.14819384\n",
            "Iteration 62, loss = 1531294309.98990035\n",
            "Iteration 63, loss = 1531183207.42375278\n",
            "Iteration 64, loss = 1531072887.67499614\n",
            "Iteration 65, loss = 1530963027.43355942\n",
            "Iteration 66, loss = 1530852611.11580849\n",
            "Iteration 67, loss = 1530742531.55499768\n",
            "Iteration 68, loss = 1530632119.73565388\n",
            "Iteration 69, loss = 1530522168.98991704\n",
            "Iteration 70, loss = 1530411471.88212609\n",
            "Iteration 71, loss = 1530300926.11933589\n",
            "Iteration 72, loss = 1530190705.68188548\n",
            "Iteration 73, loss = 1530080654.15971470\n",
            "Iteration 74, loss = 1529970080.47615862\n",
            "Iteration 75, loss = 1529860502.10806656\n",
            "Iteration 76, loss = 1529749925.37613416\n",
            "Iteration 77, loss = 1529640218.63323164\n",
            "Iteration 78, loss = 1529530381.64946842\n",
            "Iteration 79, loss = 1529420572.08242774\n",
            "Iteration 80, loss = 1529310573.54066992\n",
            "Iteration 81, loss = 1529200832.89502430\n",
            "Iteration 82, loss = 1529091151.02833080\n",
            "Iteration 83, loss = 1528980838.23286724\n",
            "Iteration 84, loss = 1528872531.95795178\n",
            "Iteration 85, loss = 1528762338.64024901\n",
            "Iteration 86, loss = 1528653319.71001458\n",
            "Iteration 87, loss = 1528543587.26379752\n",
            "Iteration 88, loss = 1528433950.56441617\n",
            "Iteration 89, loss = 1528325019.35109711\n",
            "Iteration 90, loss = 1528215043.31869531\n",
            "Iteration 91, loss = 1528105748.65449286\n",
            "Iteration 92, loss = 1527995604.34132934\n",
            "Iteration 93, loss = 1527886519.10814595\n",
            "Iteration 94, loss = 1527777762.17347598\n",
            "Iteration 95, loss = 1527668386.94110012\n",
            "Iteration 96, loss = 1527558795.35409689\n",
            "Iteration 97, loss = 1527450144.90599179\n",
            "Iteration 98, loss = 1527340963.90317798\n",
            "Iteration 99, loss = 1527232158.66536713\n",
            "Iteration 100, loss = 1527122735.60218406\n",
            "Iteration 101, loss = 1527013573.64523840\n",
            "Iteration 102, loss = 1526904343.12027550\n",
            "Iteration 103, loss = 1526795416.01023674\n",
            "Iteration 104, loss = 1526685861.64793277\n",
            "Iteration 105, loss = 1526576361.55597091\n",
            "Iteration 106, loss = 1526467511.41884732\n",
            "Iteration 107, loss = 1526357477.04978275\n",
            "Iteration 108, loss = 1526248646.94381499\n",
            "Iteration 109, loss = 1526138976.54873681\n",
            "Iteration 110, loss = 1526030046.51601887\n",
            "Iteration 111, loss = 1525919917.51118279\n",
            "Iteration 112, loss = 1525810740.28885436\n",
            "Iteration 113, loss = 1525701421.77883601\n",
            "Iteration 114, loss = 1525592064.84077716\n",
            "Iteration 115, loss = 1525482210.79180980\n",
            "Iteration 116, loss = 1525373010.96200347\n",
            "Iteration 117, loss = 1525263204.16328311\n",
            "Iteration 118, loss = 1525153643.76195240\n",
            "Iteration 119, loss = 1525044254.08036733\n",
            "Iteration 120, loss = 1524934489.08316827\n",
            "Iteration 121, loss = 1524825130.55414820\n",
            "Iteration 122, loss = 1524715639.12204480\n",
            "Iteration 123, loss = 1524606155.00721598\n",
            "Iteration 124, loss = 1524497132.60094976\n",
            "Iteration 125, loss = 1524388477.62390423\n",
            "Iteration 126, loss = 1524279606.81849146\n",
            "Iteration 127, loss = 1524170931.28867674\n",
            "Iteration 128, loss = 1524062740.16801572\n",
            "Iteration 129, loss = 1523954396.27438688\n",
            "Iteration 130, loss = 1523845235.84065628\n",
            "Iteration 131, loss = 1523736759.61604977\n",
            "Iteration 132, loss = 1523628674.04384923\n",
            "Iteration 133, loss = 1523520249.21058917\n",
            "Iteration 134, loss = 1523411129.18380642\n",
            "Iteration 135, loss = 1523302552.21949816\n",
            "Iteration 136, loss = 1523194342.41969967\n",
            "Iteration 137, loss = 1523085451.86644268\n",
            "Iteration 138, loss = 1522977197.95043945\n",
            "Iteration 139, loss = 1522868406.48307729\n",
            "Iteration 140, loss = 1522759463.09634924\n",
            "Iteration 141, loss = 1522650300.58224964\n",
            "Iteration 142, loss = 1522541713.14591312\n",
            "Iteration 143, loss = 1522432121.31183410\n",
            "Iteration 144, loss = 1522322629.23982644\n",
            "Iteration 145, loss = 1522214123.49671769\n",
            "Iteration 146, loss = 1522104066.39374876\n",
            "Iteration 147, loss = 1521994847.81146502\n",
            "Iteration 148, loss = 1521885870.74287057\n",
            "Iteration 149, loss = 1521777069.01096201\n",
            "Iteration 150, loss = 1521667419.06687164\n",
            "Iteration 151, loss = 1521559275.65723109\n",
            "Iteration 152, loss = 1521450099.40608859\n",
            "Iteration 153, loss = 1521341834.40219307\n",
            "Iteration 154, loss = 1521233101.69290709\n",
            "Iteration 155, loss = 1521124188.17222166\n",
            "Iteration 156, loss = 1521016315.27993989\n",
            "Iteration 157, loss = 1520908194.32152820\n",
            "Iteration 158, loss = 1520799303.51589203\n",
            "Iteration 159, loss = 1520690228.96264505\n",
            "Iteration 160, loss = 1520581516.18030906\n",
            "Iteration 161, loss = 1520472482.63423061\n",
            "Iteration 162, loss = 1520363893.72724843\n",
            "Iteration 163, loss = 1520254980.31838560\n",
            "Iteration 164, loss = 1520146280.09442449\n",
            "Iteration 165, loss = 1520037902.11727381\n",
            "Iteration 166, loss = 1519929621.68744230\n",
            "Iteration 167, loss = 1519821420.19622922\n",
            "Iteration 168, loss = 1519713229.21061444\n",
            "Iteration 169, loss = 1519604974.83142662\n",
            "Iteration 170, loss = 1519497243.61823773\n",
            "Iteration 171, loss = 1519388773.69179678\n",
            "Iteration 172, loss = 1519280266.18412423\n",
            "Iteration 173, loss = 1519172384.18162465\n",
            "Iteration 174, loss = 1519064814.90971994\n",
            "Iteration 175, loss = 1518956696.29299712\n",
            "Iteration 176, loss = 1518848654.25302529\n",
            "Iteration 177, loss = 1518741598.12256050\n",
            "Iteration 178, loss = 1518633715.24561620\n",
            "Iteration 179, loss = 1518526943.91334414\n",
            "Iteration 180, loss = 1518418211.00380874\n",
            "Iteration 181, loss = 1518310696.49533010\n",
            "Iteration 182, loss = 1518203222.41575742\n",
            "Iteration 183, loss = 1518095161.49033666\n",
            "Iteration 184, loss = 1517985724.69410372\n",
            "Iteration 185, loss = 1517877933.54920888\n",
            "Iteration 186, loss = 1517769417.17492819\n",
            "Iteration 187, loss = 1517660856.35214686\n",
            "Iteration 188, loss = 1517552021.55065060\n",
            "Iteration 189, loss = 1517444494.93052292\n",
            "Iteration 190, loss = 1517335975.82687545\n",
            "Iteration 191, loss = 1517227640.60880899\n",
            "Iteration 192, loss = 1517120254.24215794\n",
            "Iteration 193, loss = 1517011703.09432507\n",
            "Iteration 194, loss = 1516904041.01640224\n",
            "Iteration 195, loss = 1516796020.90135169\n",
            "Iteration 196, loss = 1516687740.27097297\n",
            "Iteration 197, loss = 1516579163.31856179\n",
            "Iteration 198, loss = 1516471189.15490913\n",
            "Iteration 199, loss = 1516363793.07836390\n",
            "Iteration 200, loss = 1516255219.72476792\n",
            "Iteration 201, loss = 1516146697.81482530\n",
            "Iteration 202, loss = 1516038969.15577078\n",
            "Iteration 203, loss = 1515930532.91068149\n",
            "Iteration 204, loss = 1515823040.72643042\n",
            "Iteration 205, loss = 1515714780.23541236\n",
            "Iteration 206, loss = 1515606537.95733070\n",
            "Iteration 207, loss = 1515498857.85651779\n",
            "Iteration 208, loss = 1515391204.86680222\n",
            "Iteration 209, loss = 1515283103.25225520\n",
            "Iteration 210, loss = 1515175112.91436434\n",
            "Iteration 211, loss = 1515067329.81158566\n",
            "Iteration 212, loss = 1514959861.55173564\n",
            "Iteration 213, loss = 1514851915.45097852\n",
            "Iteration 214, loss = 1514744137.69929934\n",
            "Iteration 215, loss = 1514636866.66102862\n",
            "Iteration 216, loss = 1514528170.51627660\n",
            "Iteration 217, loss = 1514422216.70035529\n",
            "Iteration 218, loss = 1514313463.86159730\n",
            "Iteration 219, loss = 1514206033.67395115\n",
            "Iteration 220, loss = 1514098281.49127865\n",
            "Iteration 221, loss = 1513990435.70460558\n",
            "Iteration 222, loss = 1513882067.78051353\n",
            "Iteration 223, loss = 1513774242.43754864\n",
            "Iteration 224, loss = 1513665632.03380227\n",
            "Iteration 225, loss = 1513557745.26136518\n",
            "Iteration 226, loss = 1513449561.02674270\n",
            "Iteration 227, loss = 1513341061.57558441\n",
            "Iteration 228, loss = 1513232502.51467586\n",
            "Iteration 229, loss = 1513123984.85413527\n",
            "Iteration 230, loss = 1513015964.10903192\n",
            "Iteration 231, loss = 1512907662.66143250\n",
            "Iteration 232, loss = 1512799045.57542157\n",
            "Iteration 233, loss = 1512690752.76763368\n",
            "Iteration 234, loss = 1512582227.74755120\n",
            "Iteration 235, loss = 1512474720.10986972\n",
            "Iteration 236, loss = 1512366429.67998600\n",
            "Iteration 237, loss = 1512257294.14971566\n",
            "Iteration 238, loss = 1512149923.86368299\n",
            "Iteration 239, loss = 1512042097.69369555\n",
            "Iteration 240, loss = 1511933397.60007715\n",
            "Iteration 241, loss = 1511825660.47734308\n",
            "Iteration 242, loss = 1511718147.45376086\n",
            "Iteration 243, loss = 1511610661.58010674\n",
            "Iteration 244, loss = 1511502944.60293221\n",
            "Iteration 245, loss = 1511395720.94182348\n",
            "Iteration 246, loss = 1511289342.87985492\n",
            "Iteration 247, loss = 1511181922.60357451\n",
            "Iteration 248, loss = 1511075317.23455811\n",
            "Iteration 249, loss = 1510968091.78648901\n",
            "Iteration 250, loss = 1510861166.76710033\n",
            "Iteration 251, loss = 1510754241.52119231\n",
            "Iteration 252, loss = 1510647773.49007344\n",
            "Iteration 253, loss = 1510539616.14221931\n",
            "Iteration 254, loss = 1510433443.34089851\n",
            "Iteration 255, loss = 1510324960.69430876\n",
            "Iteration 256, loss = 1510218135.14008856\n",
            "Iteration 257, loss = 1510110238.48670411\n",
            "Iteration 258, loss = 1510002475.70007110\n",
            "Iteration 259, loss = 1509894900.72741985\n",
            "Iteration 260, loss = 1509786977.41374326\n",
            "Iteration 261, loss = 1509678415.37759161\n",
            "Iteration 262, loss = 1509570560.10304618\n",
            "Iteration 263, loss = 1509462506.93650150\n",
            "Iteration 264, loss = 1509354476.54620218\n",
            "Iteration 265, loss = 1509246326.88627338\n",
            "Iteration 266, loss = 1509138344.63456440\n",
            "Iteration 267, loss = 1509029891.05881834\n",
            "Iteration 268, loss = 1508922578.53277540\n",
            "Iteration 269, loss = 1508814501.04557061\n",
            "Iteration 270, loss = 1508707997.74223042\n",
            "Iteration 271, loss = 1508599828.06522989\n",
            "Iteration 272, loss = 1508492623.58420849\n",
            "Iteration 273, loss = 1508385308.24526596\n",
            "Iteration 274, loss = 1508278473.30270815\n",
            "Iteration 275, loss = 1508171547.97765350\n",
            "Iteration 276, loss = 1508063721.77398992\n",
            "Iteration 277, loss = 1507957030.94221640\n",
            "Iteration 278, loss = 1507849925.34248114\n",
            "Iteration 279, loss = 1507742533.18823576\n",
            "Iteration 280, loss = 1507635826.01439857\n",
            "Iteration 281, loss = 1507528540.25210190\n",
            "Iteration 282, loss = 1507422129.26935577\n",
            "Iteration 283, loss = 1507314833.50105476\n",
            "Iteration 284, loss = 1507208004.66030025\n",
            "Iteration 285, loss = 1507101497.57597661\n",
            "Iteration 286, loss = 1506994469.65136862\n",
            "Iteration 287, loss = 1506887862.73063374\n",
            "Iteration 288, loss = 1506780451.00172067\n",
            "Iteration 289, loss = 1506673442.78916574\n",
            "Iteration 290, loss = 1506566579.25146699\n",
            "Iteration 291, loss = 1506458937.01086879\n",
            "Iteration 292, loss = 1506351365.34209895\n",
            "Iteration 293, loss = 1506244112.26870060\n",
            "Iteration 294, loss = 1506136656.98894548\n",
            "Iteration 295, loss = 1506028671.10626006\n",
            "Iteration 296, loss = 1505921077.75318742\n",
            "Iteration 297, loss = 1505814629.17376614\n",
            "Iteration 298, loss = 1505706912.01405358\n",
            "Iteration 299, loss = 1505599641.32142186\n",
            "Iteration 300, loss = 1505491809.25910759\n",
            "Iteration 301, loss = 1505386345.90278006\n",
            "Iteration 302, loss = 1505277709.49262023\n",
            "Iteration 303, loss = 1505171024.89672422\n",
            "Iteration 304, loss = 1505064157.51251769\n",
            "Iteration 305, loss = 1504957568.15494370\n",
            "Iteration 306, loss = 1504850495.69557166\n",
            "Iteration 307, loss = 1504743419.13575363\n",
            "Iteration 308, loss = 1504636580.18252015\n",
            "Iteration 309, loss = 1504529968.33878255\n",
            "Iteration 310, loss = 1504423291.75138712\n",
            "Iteration 311, loss = 1504317013.66476822\n",
            "Iteration 312, loss = 1504210256.56169772\n",
            "Iteration 313, loss = 1504103393.78785443\n",
            "Iteration 314, loss = 1503996466.73275471\n",
            "Iteration 315, loss = 1503890156.63901424\n",
            "Iteration 316, loss = 1503783414.53296733\n",
            "Iteration 317, loss = 1503676063.99882317\n",
            "Iteration 318, loss = 1503569084.76128936\n",
            "Iteration 319, loss = 1503462188.74602771\n",
            "Iteration 320, loss = 1503354387.27975345\n",
            "Iteration 321, loss = 1503248259.03406644\n",
            "Iteration 322, loss = 1503140324.22496033\n",
            "Iteration 323, loss = 1503033878.82337642\n",
            "Iteration 324, loss = 1502926606.68452454\n",
            "Iteration 325, loss = 1502819977.04815793\n",
            "Iteration 326, loss = 1502713383.80900431\n",
            "Iteration 327, loss = 1502606515.67765427\n",
            "Iteration 328, loss = 1502499624.82026815\n",
            "Iteration 329, loss = 1502393803.92022777\n",
            "Iteration 330, loss = 1502286919.58790040\n",
            "Iteration 331, loss = 1502179679.51279306\n",
            "Iteration 332, loss = 1502074613.52541804\n",
            "Iteration 333, loss = 1501967207.18068385\n",
            "Iteration 334, loss = 1501860396.99106503\n",
            "Iteration 335, loss = 1501754125.11926150\n",
            "Iteration 336, loss = 1501647065.68999648\n",
            "Iteration 337, loss = 1501539968.86306405\n",
            "Iteration 338, loss = 1501433097.35066009\n",
            "Iteration 339, loss = 1501325769.02102017\n",
            "Iteration 340, loss = 1501218930.91543722\n",
            "Iteration 341, loss = 1501112404.33064198\n",
            "Iteration 342, loss = 1501005588.48128152\n",
            "Iteration 343, loss = 1500899088.77501869\n",
            "Iteration 344, loss = 1500792630.57584023\n",
            "Iteration 345, loss = 1500686576.84585905\n",
            "Iteration 346, loss = 1500579642.03214097\n",
            "Iteration 347, loss = 1500472735.02073503\n",
            "Iteration 348, loss = 1500366473.67964077\n",
            "Iteration 349, loss = 1500259487.55648160\n",
            "Iteration 350, loss = 1500152651.28090262\n",
            "Iteration 351, loss = 1500046154.69395804\n",
            "Iteration 352, loss = 1499939537.07147670\n",
            "Iteration 353, loss = 1499833474.49436092\n",
            "Iteration 354, loss = 1499727700.02710223\n",
            "Iteration 355, loss = 1499620690.03290606\n",
            "Iteration 356, loss = 1499514886.39142704\n",
            "Iteration 357, loss = 1499409053.74015784\n",
            "Iteration 358, loss = 1499302069.95876026\n",
            "Iteration 359, loss = 1499196078.98283029\n",
            "Iteration 360, loss = 1499089204.36630630\n",
            "Iteration 361, loss = 1498983244.18133664\n",
            "Iteration 362, loss = 1498876220.55540061\n",
            "Iteration 363, loss = 1498769330.37731028\n",
            "Iteration 364, loss = 1498663614.93161559\n",
            "Iteration 365, loss = 1498556469.16826010\n",
            "Iteration 366, loss = 1498450864.57337260\n",
            "Iteration 367, loss = 1498343755.26311111\n",
            "Iteration 368, loss = 1498237476.53575873\n",
            "Iteration 369, loss = 1498130333.71048379\n",
            "Iteration 370, loss = 1498024656.20672870\n",
            "Iteration 371, loss = 1497916774.50486970\n",
            "Iteration 372, loss = 1497810628.38125038\n",
            "Iteration 373, loss = 1497703779.63292885\n",
            "Iteration 374, loss = 1497596437.59137225\n",
            "Iteration 375, loss = 1497489852.33010983\n",
            "Iteration 376, loss = 1497381893.25379682\n",
            "Iteration 377, loss = 1497275412.40745974\n",
            "Iteration 378, loss = 1497167871.05325818\n",
            "Iteration 379, loss = 1497060620.34103298\n",
            "Iteration 380, loss = 1496953133.77111912\n",
            "Iteration 381, loss = 1496845682.49671841\n",
            "Iteration 382, loss = 1496738636.72165680\n",
            "Iteration 383, loss = 1496631378.18719316\n",
            "Iteration 384, loss = 1496523849.49969888\n",
            "Iteration 385, loss = 1496416973.31809783\n",
            "Iteration 386, loss = 1496309381.18967414\n",
            "Iteration 387, loss = 1496202053.58655763\n",
            "Iteration 388, loss = 1496095499.98895860\n",
            "Iteration 389, loss = 1495988599.79916215\n",
            "Iteration 390, loss = 1495881110.13151622\n",
            "Iteration 391, loss = 1495774310.00416470\n",
            "Iteration 392, loss = 1495667472.29462314\n",
            "Iteration 393, loss = 1495560801.91975403\n",
            "Iteration 394, loss = 1495453775.78626752\n",
            "Iteration 395, loss = 1495346920.35813570\n",
            "Iteration 396, loss = 1495240099.01318264\n",
            "Iteration 397, loss = 1495132759.31383038\n",
            "Iteration 398, loss = 1495026148.22341990\n",
            "Iteration 399, loss = 1494918831.71912408\n",
            "Iteration 400, loss = 1494811582.60149050\n",
            "Iteration 401, loss = 1494704967.38594651\n",
            "Iteration 402, loss = 1494597110.94352531\n",
            "Iteration 403, loss = 1494489946.61063790\n",
            "Iteration 404, loss = 1494382532.95615339\n",
            "Iteration 405, loss = 1494276252.10410738\n",
            "Iteration 406, loss = 1494168750.51219130\n",
            "Iteration 407, loss = 1494062224.70974231\n",
            "Iteration 408, loss = 1493955200.33296180\n",
            "Iteration 409, loss = 1493848282.02589297\n",
            "Iteration 410, loss = 1493741092.09763026\n",
            "Iteration 411, loss = 1493634331.93366194\n",
            "Iteration 412, loss = 1493527931.37906289\n",
            "Iteration 413, loss = 1493420438.78194618\n",
            "Iteration 414, loss = 1493312974.09347630\n",
            "Iteration 415, loss = 1493206554.07092118\n",
            "Iteration 416, loss = 1493099724.86129355\n",
            "Iteration 417, loss = 1492991981.63615727\n",
            "Iteration 418, loss = 1492885892.31378913\n",
            "Iteration 419, loss = 1492778510.77974868\n",
            "Iteration 420, loss = 1492671436.68907714\n",
            "Iteration 421, loss = 1492565569.43931222\n",
            "Iteration 422, loss = 1492457890.74373412\n",
            "Iteration 423, loss = 1492350954.94568825\n",
            "Iteration 424, loss = 1492243835.47226286\n",
            "Iteration 425, loss = 1492137347.93455076\n",
            "Iteration 426, loss = 1492029987.29786968\n",
            "Iteration 427, loss = 1491923998.61523008\n",
            "Iteration 428, loss = 1491816513.51364851\n",
            "Iteration 429, loss = 1491710768.94046640\n",
            "Iteration 430, loss = 1491603579.74026155\n",
            "Iteration 431, loss = 1491498385.38792229\n",
            "Iteration 432, loss = 1491391962.21980095\n",
            "Iteration 433, loss = 1491285632.14865851\n",
            "Iteration 434, loss = 1491179937.54218745\n",
            "Iteration 435, loss = 1491073870.80978370\n",
            "Iteration 436, loss = 1490967980.42430449\n",
            "Iteration 437, loss = 1490861114.35340428\n",
            "Iteration 438, loss = 1490754922.12618351\n",
            "Iteration 439, loss = 1490649068.50858927\n",
            "Iteration 440, loss = 1490541650.40122366\n",
            "Iteration 441, loss = 1490435642.67224932\n",
            "Iteration 442, loss = 1490329331.53896952\n",
            "Iteration 443, loss = 1490222235.31861877\n",
            "Iteration 444, loss = 1490116718.54923224\n",
            "Iteration 445, loss = 1490009933.32882309\n",
            "Iteration 446, loss = 1489903463.79366016\n",
            "Iteration 447, loss = 1489797901.77876616\n",
            "Iteration 448, loss = 1489690828.10373735\n",
            "Iteration 449, loss = 1489584825.03035545\n",
            "Iteration 450, loss = 1489478103.33458900\n",
            "Iteration 451, loss = 1489372130.91949439\n",
            "Iteration 452, loss = 1489265301.16120863\n",
            "Iteration 453, loss = 1489159311.58438873\n",
            "Iteration 454, loss = 1489052340.43358159\n",
            "Iteration 455, loss = 1488945974.38853335\n",
            "Iteration 456, loss = 1488839047.85319376\n",
            "Iteration 457, loss = 1488732872.42476678\n",
            "Iteration 458, loss = 1488626766.82974052\n",
            "Iteration 459, loss = 1488520568.25226688\n",
            "Iteration 460, loss = 1488414731.27588010\n",
            "Iteration 461, loss = 1488308265.62354636\n",
            "Iteration 462, loss = 1488202390.46284938\n",
            "Iteration 463, loss = 1488096606.41921496\n",
            "Iteration 464, loss = 1487989605.75018215\n",
            "Iteration 465, loss = 1487884581.87645364\n",
            "Iteration 466, loss = 1487777529.47357774\n",
            "Iteration 467, loss = 1487671169.60241175\n",
            "Iteration 468, loss = 1487564479.37139463\n",
            "Iteration 469, loss = 1487458741.54095769\n",
            "Iteration 470, loss = 1487352032.23923540\n",
            "Iteration 471, loss = 1487246118.55139112\n",
            "Iteration 472, loss = 1487139403.64502668\n",
            "Iteration 473, loss = 1487033430.47099400\n",
            "Iteration 474, loss = 1486927411.13764977\n",
            "Iteration 475, loss = 1486821286.43182826\n",
            "Iteration 476, loss = 1486715371.19220972\n",
            "Iteration 477, loss = 1486608992.27275229\n",
            "Iteration 478, loss = 1486502738.18512344\n",
            "Iteration 479, loss = 1486397174.78391266\n",
            "Iteration 480, loss = 1486291021.38833976\n",
            "Iteration 481, loss = 1486184709.05027199\n",
            "Iteration 482, loss = 1486078921.56899810\n",
            "Iteration 483, loss = 1485973463.93488145\n",
            "Iteration 484, loss = 1485867475.59578514\n",
            "Iteration 485, loss = 1485761345.80567098\n",
            "Iteration 486, loss = 1485656169.68512154\n",
            "Iteration 487, loss = 1485550343.73076534\n",
            "Iteration 488, loss = 1485444997.03369975\n",
            "Iteration 489, loss = 1485339095.61508846\n",
            "Iteration 490, loss = 1485233492.07608557\n",
            "Iteration 491, loss = 1485128076.67464328\n",
            "Iteration 492, loss = 1485022117.85196185\n",
            "Iteration 493, loss = 1484916600.00959969\n",
            "Iteration 494, loss = 1484810990.57872152\n",
            "Iteration 495, loss = 1484705215.53491402\n",
            "Iteration 496, loss = 1484599820.70248604\n",
            "Iteration 497, loss = 1484494743.47788882\n",
            "Iteration 498, loss = 1484389706.21419096\n",
            "Iteration 499, loss = 1484283936.82463360\n",
            "Iteration 500, loss = 1484179577.81144738\n",
            "Iteration 501, loss = 1484074248.57842255\n",
            "Iteration 502, loss = 1483969059.52302146\n",
            "Iteration 503, loss = 1483863965.59563518\n",
            "Iteration 504, loss = 1483758923.79969931\n",
            "Iteration 505, loss = 1483653317.14213443\n",
            "Iteration 506, loss = 1483547450.60243559\n",
            "Iteration 507, loss = 1483441941.86315870\n",
            "Iteration 508, loss = 1483336304.78121901\n",
            "Iteration 509, loss = 1483230907.92967153\n",
            "Iteration 510, loss = 1483124154.71446109\n",
            "Iteration 511, loss = 1483019239.40962958\n",
            "Iteration 512, loss = 1482913530.43782806\n",
            "Iteration 513, loss = 1482807962.52710772\n",
            "Iteration 514, loss = 1482701862.64982104\n",
            "Iteration 515, loss = 1482596066.87615991\n",
            "Iteration 516, loss = 1482490658.68026328\n",
            "Iteration 517, loss = 1482384243.86167240\n",
            "Iteration 518, loss = 1482278798.82218599\n",
            "Iteration 519, loss = 1482172654.67785954\n",
            "Iteration 520, loss = 1482065989.07544374\n",
            "Iteration 521, loss = 1481960578.43816090\n",
            "Iteration 522, loss = 1481855225.71813321\n",
            "Iteration 523, loss = 1481748992.29977894\n",
            "Iteration 524, loss = 1481643034.22804928\n",
            "Iteration 525, loss = 1481537482.57639074\n",
            "Iteration 526, loss = 1481431863.69021559\n",
            "Iteration 527, loss = 1481326457.98017168\n",
            "Iteration 528, loss = 1481220455.73753214\n",
            "Iteration 529, loss = 1481115798.53559589\n",
            "Iteration 530, loss = 1481010076.61652994\n",
            "Iteration 531, loss = 1480905051.72358465\n",
            "Iteration 532, loss = 1480799899.64724684\n",
            "Iteration 533, loss = 1480694690.34805536\n",
            "Iteration 534, loss = 1480588887.17724586\n",
            "Iteration 535, loss = 1480484140.94120145\n",
            "Iteration 536, loss = 1480378406.16672802\n",
            "Iteration 537, loss = 1480273480.44077301\n",
            "Iteration 538, loss = 1480168115.34921503\n",
            "Iteration 539, loss = 1480063175.31692314\n",
            "Iteration 540, loss = 1479957836.16591811\n",
            "Iteration 541, loss = 1479852863.17284322\n",
            "Iteration 542, loss = 1479747803.49072719\n",
            "Iteration 543, loss = 1479642473.55486202\n",
            "Iteration 544, loss = 1479537257.80256200\n",
            "Iteration 545, loss = 1479432857.15887737\n",
            "Iteration 546, loss = 1479327853.94601250\n",
            "Iteration 547, loss = 1479223016.64253402\n",
            "Iteration 548, loss = 1479117012.26501846\n",
            "Iteration 549, loss = 1479013185.66296864\n",
            "Iteration 550, loss = 1478907582.15842390\n",
            "Iteration 551, loss = 1478802468.48021936\n",
            "Iteration 552, loss = 1478696764.98072934\n",
            "Iteration 553, loss = 1478592370.93741441\n",
            "Iteration 554, loss = 1478486473.95965075\n",
            "Iteration 555, loss = 1478381551.50818515\n",
            "Iteration 556, loss = 1478276570.83595538\n",
            "Iteration 557, loss = 1478171273.37060118\n",
            "Iteration 558, loss = 1478066539.28837919\n",
            "Iteration 559, loss = 1477961520.15218163\n",
            "Iteration 560, loss = 1477856546.13772178\n",
            "Iteration 561, loss = 1477751305.13956118\n",
            "Iteration 562, loss = 1477646146.28199339\n",
            "Iteration 563, loss = 1477540678.87498260\n",
            "Iteration 564, loss = 1477435262.73139000\n",
            "Iteration 565, loss = 1477330409.95032024\n",
            "Iteration 566, loss = 1477224035.88401318\n",
            "Iteration 567, loss = 1477118612.92791891\n",
            "Iteration 568, loss = 1477013420.11474586\n",
            "Iteration 569, loss = 1476907187.57732320\n",
            "Iteration 570, loss = 1476801664.44785047\n",
            "Iteration 571, loss = 1476695443.22582316\n",
            "Iteration 572, loss = 1476590153.39456892\n",
            "Iteration 573, loss = 1476484082.33891106\n",
            "Iteration 574, loss = 1476378325.10391283\n",
            "Iteration 575, loss = 1476272310.66799021\n",
            "Iteration 576, loss = 1476166995.18145323\n",
            "Iteration 577, loss = 1476060347.19449735\n",
            "Iteration 578, loss = 1475955071.67815018\n",
            "Iteration 579, loss = 1475848726.21747780\n",
            "Iteration 580, loss = 1475743301.81231403\n",
            "Iteration 581, loss = 1475637096.33580685\n",
            "Iteration 582, loss = 1475530939.30104113\n",
            "Iteration 583, loss = 1475425448.33332109\n",
            "Iteration 584, loss = 1475320284.88576984\n",
            "Iteration 585, loss = 1475214522.49626970\n",
            "Iteration 586, loss = 1475109057.95218134\n",
            "Iteration 587, loss = 1475003179.01511502\n",
            "Iteration 588, loss = 1474898376.01039743\n",
            "Iteration 589, loss = 1474792786.16774797\n",
            "Iteration 590, loss = 1474687150.77413869\n",
            "Iteration 591, loss = 1474582395.56229138\n",
            "Iteration 592, loss = 1474476896.28903341\n",
            "Iteration 593, loss = 1474371505.63215995\n",
            "Iteration 594, loss = 1474266440.20809007\n",
            "Iteration 595, loss = 1474161660.76996374\n",
            "Iteration 596, loss = 1474055805.75073552\n",
            "Iteration 597, loss = 1473950706.51133966\n",
            "Iteration 598, loss = 1473844940.49995637\n",
            "Iteration 599, loss = 1473740233.77385139\n",
            "Iteration 600, loss = 1473634266.43318319\n",
            "Iteration 601, loss = 1473529174.93784213\n",
            "Iteration 602, loss = 1473423313.95339990\n",
            "Iteration 603, loss = 1473318614.34289861\n",
            "Iteration 604, loss = 1473212522.34823108\n",
            "Iteration 605, loss = 1473107875.17004895\n",
            "Iteration 606, loss = 1473001886.27716398\n",
            "Iteration 607, loss = 1472896734.44359279\n",
            "Iteration 608, loss = 1472791064.21454334\n",
            "Iteration 609, loss = 1472685848.39012694\n",
            "Iteration 610, loss = 1472580483.46758652\n",
            "Iteration 611, loss = 1472474166.74535298\n",
            "Iteration 612, loss = 1472369181.56100106\n",
            "Iteration 613, loss = 1472263859.38855433\n",
            "Iteration 614, loss = 1472157277.15457368\n",
            "Iteration 615, loss = 1472052535.12909150\n",
            "Iteration 616, loss = 1471946340.70150828\n",
            "Iteration 617, loss = 1471841540.90254021\n",
            "Iteration 618, loss = 1471735975.93479156\n",
            "Iteration 619, loss = 1471630725.03280210\n",
            "Iteration 620, loss = 1471526227.05404902\n",
            "Iteration 621, loss = 1471421104.61013031\n",
            "Iteration 622, loss = 1471316873.45004368\n",
            "Iteration 623, loss = 1471212624.25226998\n",
            "Iteration 624, loss = 1471108439.26355386\n",
            "Iteration 625, loss = 1471004458.48963308\n",
            "Iteration 626, loss = 1470899796.17895794\n",
            "Iteration 627, loss = 1470795477.76069403\n",
            "Iteration 628, loss = 1470691033.03957319\n",
            "Iteration 629, loss = 1470586206.57463264\n",
            "Iteration 630, loss = 1470481164.52407312\n",
            "Iteration 631, loss = 1470376460.44837928\n",
            "Iteration 632, loss = 1470271216.30066466\n",
            "Iteration 633, loss = 1470165459.66215014\n",
            "Iteration 634, loss = 1470060782.31907845\n",
            "Iteration 635, loss = 1469955437.97454071\n",
            "Iteration 636, loss = 1469850128.95039272\n",
            "Iteration 637, loss = 1469744436.74028730\n",
            "Iteration 638, loss = 1469639123.47521377\n",
            "Iteration 639, loss = 1469533520.42159271\n",
            "Iteration 640, loss = 1469428575.81845069\n",
            "Iteration 641, loss = 1469322753.20830035\n",
            "Iteration 642, loss = 1469216876.19571948\n",
            "Iteration 643, loss = 1469111727.16533661\n",
            "Iteration 644, loss = 1469006661.69914865\n",
            "Iteration 645, loss = 1468900961.14020324\n",
            "Iteration 646, loss = 1468795249.59050035\n",
            "Iteration 647, loss = 1468690527.84538960\n",
            "Iteration 648, loss = 1468584834.56537938\n",
            "Iteration 649, loss = 1468480125.91209722\n",
            "Iteration 650, loss = 1468375093.96923590\n",
            "Iteration 651, loss = 1468270235.13081551\n",
            "Iteration 652, loss = 1468164885.72926307\n",
            "Iteration 653, loss = 1468060632.04889679\n",
            "Iteration 654, loss = 1467956003.05107856\n",
            "Iteration 655, loss = 1467850673.08437300\n",
            "Iteration 656, loss = 1467745962.22154355\n",
            "Iteration 657, loss = 1467641362.58200717\n",
            "Iteration 658, loss = 1467536832.98198462\n",
            "Iteration 659, loss = 1467431222.57145405\n",
            "Iteration 660, loss = 1467327175.14794159\n",
            "Iteration 661, loss = 1467222085.79959464\n",
            "Iteration 662, loss = 1467116963.89216304\n",
            "Iteration 663, loss = 1467012561.06884360\n",
            "Iteration 664, loss = 1466907500.13954997\n",
            "Iteration 665, loss = 1466802193.06792068\n",
            "Iteration 666, loss = 1466697004.60758305\n",
            "Iteration 667, loss = 1466592333.68087173\n",
            "Iteration 668, loss = 1466487593.08722329\n",
            "Iteration 669, loss = 1466381839.17786956\n",
            "Iteration 670, loss = 1466276923.75249958\n",
            "Iteration 671, loss = 1466172104.79362440\n",
            "Iteration 672, loss = 1466066758.72099328\n",
            "Iteration 673, loss = 1465962111.21192670\n",
            "Iteration 674, loss = 1465856180.54290891\n",
            "Iteration 675, loss = 1465752197.90272784\n",
            "Iteration 676, loss = 1465646893.26358175\n",
            "Iteration 677, loss = 1465542097.15938067\n",
            "Iteration 678, loss = 1465437084.88095760\n",
            "Iteration 679, loss = 1465332155.61163926\n",
            "Iteration 680, loss = 1465227573.88051653\n",
            "Iteration 681, loss = 1465122859.88599205\n",
            "Iteration 682, loss = 1465018193.32730126\n",
            "Iteration 683, loss = 1464913507.79470301\n",
            "Iteration 684, loss = 1464809404.40343046\n",
            "Iteration 685, loss = 1464704327.59876800\n",
            "Iteration 686, loss = 1464600036.29232001\n",
            "Iteration 687, loss = 1464495335.62268186\n",
            "Iteration 688, loss = 1464390854.71404576\n",
            "Iteration 689, loss = 1464286003.42276311\n",
            "Iteration 690, loss = 1464181578.48842072\n",
            "Iteration 691, loss = 1464076553.59703064\n",
            "Iteration 692, loss = 1463971809.94644046\n",
            "Iteration 693, loss = 1463867158.89534283\n",
            "Iteration 694, loss = 1463762050.27921033\n",
            "Iteration 695, loss = 1463658631.13516545\n",
            "Iteration 696, loss = 1463553381.37916207\n",
            "Iteration 697, loss = 1463449105.80621648\n",
            "Iteration 698, loss = 1463344923.70440340\n",
            "Iteration 699, loss = 1463240257.66197276\n",
            "Iteration 700, loss = 1463136586.52156758\n",
            "Iteration 701, loss = 1463031845.13942337\n",
            "Iteration 702, loss = 1462927715.96882915\n",
            "Iteration 703, loss = 1462822866.46741104\n",
            "Iteration 704, loss = 1462718232.63163567\n",
            "Iteration 705, loss = 1462615125.70400667\n",
            "Iteration 706, loss = 1462509716.44077897\n",
            "Iteration 707, loss = 1462405116.01988173\n",
            "Iteration 708, loss = 1462300754.46861291\n",
            "Iteration 709, loss = 1462195953.05987310\n",
            "Iteration 710, loss = 1462090914.52410245\n",
            "Iteration 711, loss = 1461985574.52165365\n",
            "Iteration 712, loss = 1461880858.95830083\n",
            "Iteration 713, loss = 1461775129.22744417\n",
            "Iteration 714, loss = 1461669855.78548861\n",
            "Iteration 715, loss = 1461564984.72811365\n",
            "Iteration 716, loss = 1461460946.67529798\n",
            "Iteration 717, loss = 1461355220.46088243\n",
            "Iteration 718, loss = 1461251706.52570152\n",
            "Iteration 719, loss = 1461146835.43822289\n",
            "Iteration 720, loss = 1461042851.85782075\n",
            "Iteration 721, loss = 1460938153.85011506\n",
            "Iteration 722, loss = 1460834480.58803701\n",
            "Iteration 723, loss = 1460729456.45624018\n",
            "Iteration 724, loss = 1460625604.10136080\n",
            "Iteration 725, loss = 1460520543.97872305\n",
            "Iteration 726, loss = 1460416714.96372867\n",
            "Iteration 727, loss = 1460312952.94163704\n",
            "Iteration 728, loss = 1460207907.78425074\n",
            "Iteration 729, loss = 1460103365.08681536\n",
            "Iteration 730, loss = 1459999571.24324036\n",
            "Iteration 731, loss = 1459895374.80410194\n",
            "Iteration 732, loss = 1459790672.99697614\n",
            "Iteration 733, loss = 1459685699.48271894\n",
            "Iteration 734, loss = 1459581633.66773438\n",
            "Iteration 735, loss = 1459478043.59618330\n",
            "Iteration 736, loss = 1459372479.09590793\n",
            "Iteration 737, loss = 1459268713.66396618\n",
            "Iteration 738, loss = 1459164227.98167586\n",
            "Iteration 739, loss = 1459059246.27958989\n",
            "Iteration 740, loss = 1458954396.43636298\n",
            "Iteration 741, loss = 1458849852.41816330\n",
            "Iteration 742, loss = 1458744936.49742103\n",
            "Iteration 743, loss = 1458640031.89816380\n",
            "Iteration 744, loss = 1458535154.79344773\n",
            "Iteration 745, loss = 1458430120.99288011\n",
            "Iteration 746, loss = 1458325520.87589908\n",
            "Iteration 747, loss = 1458221365.07569265\n",
            "Iteration 748, loss = 1458116748.21824503\n",
            "Iteration 749, loss = 1458012399.09756446\n",
            "Iteration 750, loss = 1457907924.76083040\n",
            "Iteration 751, loss = 1457803881.80709004\n",
            "Iteration 752, loss = 1457699493.46634984\n",
            "Iteration 753, loss = 1457595734.02686286\n",
            "Iteration 754, loss = 1457490932.92661858\n",
            "Iteration 755, loss = 1457387093.48039389\n",
            "Iteration 756, loss = 1457282617.03643799\n",
            "Iteration 757, loss = 1457179032.37369084\n",
            "Iteration 758, loss = 1457074443.59900641\n",
            "Iteration 759, loss = 1456970985.00044203\n",
            "Iteration 760, loss = 1456866579.62818408\n",
            "Iteration 761, loss = 1456762871.90742111\n",
            "Iteration 762, loss = 1456658784.46267867\n",
            "Iteration 763, loss = 1456554654.38608027\n",
            "Iteration 764, loss = 1456450580.87489128\n",
            "Iteration 765, loss = 1456346303.33485508\n",
            "Iteration 766, loss = 1456242941.79660678\n",
            "Iteration 767, loss = 1456137883.35396552\n",
            "Iteration 768, loss = 1456034971.87169266\n",
            "Iteration 769, loss = 1455931012.13957524\n",
            "Iteration 770, loss = 1455827545.06845355\n",
            "Iteration 771, loss = 1455723848.99542427\n",
            "Iteration 772, loss = 1455620577.07545805\n",
            "Iteration 773, loss = 1455517753.99771976\n",
            "Iteration 774, loss = 1455413636.41450524\n",
            "Iteration 775, loss = 1455309763.08167601\n",
            "Iteration 776, loss = 1455205537.86557698\n",
            "Iteration 777, loss = 1455101924.33396554\n",
            "Iteration 778, loss = 1454997780.94191098\n",
            "Iteration 779, loss = 1454893528.85362220\n",
            "Iteration 780, loss = 1454789265.18757391\n",
            "Iteration 781, loss = 1454685075.16050291\n",
            "Iteration 782, loss = 1454581354.21285081\n",
            "Iteration 783, loss = 1454477764.81127191\n",
            "Iteration 784, loss = 1454373501.69351768\n",
            "Iteration 785, loss = 1454269618.48603988\n",
            "Iteration 786, loss = 1454165941.50991893\n",
            "Iteration 787, loss = 1454061621.65958548\n",
            "Iteration 788, loss = 1453957479.22606301\n",
            "Iteration 789, loss = 1453853873.43792748\n",
            "Iteration 790, loss = 1453750053.06403351\n",
            "Iteration 791, loss = 1453645571.66238761\n",
            "Iteration 792, loss = 1453541679.86269736\n",
            "Iteration 793, loss = 1453438034.72083259\n",
            "Iteration 794, loss = 1453334201.83828759\n",
            "Iteration 795, loss = 1453230059.97263598\n",
            "Iteration 796, loss = 1453126487.63472748\n",
            "Iteration 797, loss = 1453022277.84676766\n",
            "Iteration 798, loss = 1452918637.19770050\n",
            "Iteration 799, loss = 1452815183.94025207\n",
            "Iteration 800, loss = 1452710630.65661144\n",
            "Iteration 801, loss = 1452607713.43472505\n",
            "Iteration 802, loss = 1452504030.37709618\n",
            "Iteration 803, loss = 1452400319.64248538\n",
            "Iteration 804, loss = 1452295988.18188095\n",
            "Iteration 805, loss = 1452193196.82808113\n",
            "Iteration 806, loss = 1452089427.28819990\n",
            "Iteration 807, loss = 1451985550.28387427\n",
            "Iteration 808, loss = 1451882182.57540846\n",
            "Iteration 809, loss = 1451778769.40447187\n",
            "Iteration 810, loss = 1451674964.05904889\n",
            "Iteration 811, loss = 1451571423.06061983\n",
            "Iteration 812, loss = 1451468555.83203578\n",
            "Iteration 813, loss = 1451364884.35230255\n",
            "Iteration 814, loss = 1451261577.45627189\n",
            "Iteration 815, loss = 1451157971.86924314\n",
            "Iteration 816, loss = 1451053951.44470096\n",
            "Iteration 817, loss = 1450950715.74976444\n",
            "Iteration 818, loss = 1450846761.14923835\n",
            "Iteration 819, loss = 1450742820.15895295\n",
            "Iteration 820, loss = 1450638971.81682348\n",
            "Iteration 821, loss = 1450535524.24251461\n",
            "Iteration 822, loss = 1450431013.52147889\n",
            "Iteration 823, loss = 1450327248.21137738\n",
            "Iteration 824, loss = 1450222942.09724784\n",
            "Iteration 825, loss = 1450119115.47840285\n",
            "Iteration 826, loss = 1450014895.32250237\n",
            "Iteration 827, loss = 1449909994.79711056\n",
            "Iteration 828, loss = 1449805936.09720993\n",
            "Iteration 829, loss = 1449701375.59288096\n",
            "Iteration 830, loss = 1449597275.04228497\n",
            "Iteration 831, loss = 1449492193.52169728\n",
            "Iteration 832, loss = 1449387375.00985289\n",
            "Iteration 833, loss = 1449283329.26104784\n",
            "Iteration 834, loss = 1449178827.33440852\n",
            "Iteration 835, loss = 1449074389.22720098\n",
            "Iteration 836, loss = 1448969757.54817939\n",
            "Iteration 837, loss = 1448865248.33975577\n",
            "Iteration 838, loss = 1448761624.66346645\n",
            "Iteration 839, loss = 1448657142.88479877\n",
            "Iteration 840, loss = 1448552960.89371800\n",
            "Iteration 841, loss = 1448448959.10867572\n",
            "Iteration 842, loss = 1448345438.78701234\n",
            "Iteration 843, loss = 1448240609.17377353\n",
            "Iteration 844, loss = 1448136674.43909526\n",
            "Iteration 845, loss = 1448032481.13894129\n",
            "Iteration 846, loss = 1447928040.16375661\n",
            "Iteration 847, loss = 1447823536.31764126\n",
            "Iteration 848, loss = 1447719001.14037013\n",
            "Iteration 849, loss = 1447615106.51756382\n",
            "Iteration 850, loss = 1447510754.80820203\n",
            "Iteration 851, loss = 1447406138.02953124\n",
            "Iteration 852, loss = 1447301982.16173577\n",
            "Iteration 853, loss = 1447198115.86306095\n",
            "Iteration 854, loss = 1447094000.25891781\n",
            "Iteration 855, loss = 1446989747.55647683\n",
            "Iteration 856, loss = 1446886417.91417718\n",
            "Iteration 857, loss = 1446782530.08987021\n",
            "Iteration 858, loss = 1446678808.90937114\n",
            "Iteration 859, loss = 1446575674.29702401\n",
            "Iteration 860, loss = 1446471766.07106948\n",
            "Iteration 861, loss = 1446369150.62788153\n",
            "Iteration 862, loss = 1446264817.37985253\n",
            "Iteration 863, loss = 1446161553.47234201\n",
            "Iteration 864, loss = 1446057343.00677395\n",
            "Iteration 865, loss = 1445953720.18383002\n",
            "Iteration 866, loss = 1445849600.54693651\n",
            "Iteration 867, loss = 1445745288.01672149\n",
            "Iteration 868, loss = 1445640538.67746687\n",
            "Iteration 869, loss = 1445536680.40488195\n",
            "Iteration 870, loss = 1445431780.84902596\n",
            "Iteration 871, loss = 1445327750.06565976\n",
            "Iteration 872, loss = 1445222822.88306618\n",
            "Iteration 873, loss = 1445117984.17282438\n",
            "Iteration 874, loss = 1445014662.59555125\n",
            "Iteration 875, loss = 1444909725.79081178\n",
            "Iteration 876, loss = 1444805289.47582221\n",
            "Iteration 877, loss = 1444701608.33523750\n",
            "Iteration 878, loss = 1444597212.83561683\n",
            "Iteration 879, loss = 1444492883.99099994\n",
            "Iteration 880, loss = 1444389462.32618165\n",
            "Iteration 881, loss = 1444284945.11883664\n",
            "Iteration 882, loss = 1444181333.04139519\n",
            "Iteration 883, loss = 1444077416.63679504\n",
            "Iteration 884, loss = 1443973090.37447143\n",
            "Iteration 885, loss = 1443868817.29377747\n",
            "Iteration 886, loss = 1443765077.15780067\n",
            "Iteration 887, loss = 1443660770.32835150\n",
            "Iteration 888, loss = 1443556834.00478888\n",
            "Iteration 889, loss = 1443452939.18647766\n",
            "Iteration 890, loss = 1443349084.08314466\n",
            "Iteration 891, loss = 1443245013.28236675\n",
            "Iteration 892, loss = 1443141422.76917863\n",
            "Iteration 893, loss = 1443038259.64995861\n",
            "Iteration 894, loss = 1442933863.71407056\n",
            "Iteration 895, loss = 1442830668.70215034\n",
            "Iteration 896, loss = 1442726850.70513058\n",
            "Iteration 897, loss = 1442623297.54817104\n",
            "Iteration 898, loss = 1442518567.93645382\n",
            "Iteration 899, loss = 1442415458.83935928\n",
            "Iteration 900, loss = 1442311071.93959689\n",
            "Iteration 901, loss = 1442208340.84849501\n",
            "Iteration 902, loss = 1442104130.24054956\n",
            "Iteration 903, loss = 1442001130.16989255\n",
            "Iteration 904, loss = 1441897628.29565334\n",
            "Iteration 905, loss = 1441794114.79752755\n",
            "Iteration 906, loss = 1441691067.62626791\n",
            "Iteration 907, loss = 1441587783.46306372\n",
            "Iteration 908, loss = 1441484242.67073345\n",
            "Iteration 909, loss = 1441381338.18428278\n",
            "Iteration 910, loss = 1441277765.36253333\n",
            "Iteration 911, loss = 1441174657.06503534\n",
            "Iteration 912, loss = 1441071233.39059615\n",
            "Iteration 913, loss = 1440968240.50825119\n",
            "Iteration 914, loss = 1440864471.46364737\n",
            "Iteration 915, loss = 1440762298.05932236\n",
            "Iteration 916, loss = 1440658538.75204873\n",
            "Iteration 917, loss = 1440555787.70342827\n",
            "Iteration 918, loss = 1440452002.24774361\n",
            "Iteration 919, loss = 1440348863.61116743\n",
            "Iteration 920, loss = 1440245664.93572760\n",
            "Iteration 921, loss = 1440142146.28452969\n",
            "Iteration 922, loss = 1440038793.91188073\n",
            "Iteration 923, loss = 1439935755.57659411\n",
            "Iteration 924, loss = 1439831413.16011286\n",
            "Iteration 925, loss = 1439728828.69237089\n",
            "Iteration 926, loss = 1439625344.72185707\n",
            "Iteration 927, loss = 1439521984.43809605\n",
            "Iteration 928, loss = 1439418183.45650434\n",
            "Iteration 929, loss = 1439315647.03986621\n",
            "Iteration 930, loss = 1439212129.88335037\n",
            "Iteration 931, loss = 1439109218.15974903\n",
            "Iteration 932, loss = 1439005812.89854646\n",
            "Iteration 933, loss = 1438902371.96697903\n",
            "Iteration 934, loss = 1438799353.23727560\n",
            "Iteration 935, loss = 1438696236.39147997\n",
            "Iteration 936, loss = 1438592835.28792453\n",
            "Iteration 937, loss = 1438488730.69616532\n",
            "Iteration 938, loss = 1438385864.87776518\n",
            "Iteration 939, loss = 1438281700.68103433\n",
            "Iteration 940, loss = 1438177967.51340628\n",
            "Iteration 941, loss = 1438074350.48122454\n",
            "Iteration 942, loss = 1437970268.85999727\n",
            "Iteration 943, loss = 1437867007.51005673\n",
            "Iteration 944, loss = 1437762358.42314553\n",
            "Iteration 945, loss = 1437659403.09404993\n",
            "Iteration 946, loss = 1437555483.32123232\n",
            "Iteration 947, loss = 1437451593.12334847\n",
            "Iteration 948, loss = 1437347884.27529716\n",
            "Iteration 949, loss = 1437244539.72820854\n",
            "Iteration 950, loss = 1437140542.02947569\n",
            "Iteration 951, loss = 1437037173.35481358\n",
            "Iteration 952, loss = 1436933301.23552108\n",
            "Iteration 953, loss = 1436830519.40619659\n",
            "Iteration 954, loss = 1436727051.06532645\n",
            "Iteration 955, loss = 1436624569.42836094\n",
            "Iteration 956, loss = 1436520830.39238310\n",
            "Iteration 957, loss = 1436418618.10340238\n",
            "Iteration 958, loss = 1436315313.82451391\n",
            "Iteration 959, loss = 1436212577.10017681\n",
            "Iteration 960, loss = 1436109863.73487926\n",
            "Iteration 961, loss = 1436007194.19756722\n",
            "Iteration 962, loss = 1435904488.56490612\n",
            "Iteration 963, loss = 1435801359.70696449\n",
            "Iteration 964, loss = 1435698714.05390692\n",
            "Iteration 965, loss = 1435596292.18952894\n",
            "Iteration 966, loss = 1435493752.10550189\n",
            "Iteration 967, loss = 1435391132.57387590\n",
            "Iteration 968, loss = 1435288818.87188387\n",
            "Iteration 969, loss = 1435186098.19709063\n",
            "Iteration 970, loss = 1435083171.18011832\n",
            "Iteration 971, loss = 1434981063.77666974\n",
            "Iteration 972, loss = 1434877419.06801224\n",
            "Iteration 973, loss = 1434775657.05200911\n",
            "Iteration 974, loss = 1434671873.06278133\n",
            "Iteration 975, loss = 1434569065.95858455\n",
            "Iteration 976, loss = 1434466801.60777235\n",
            "Iteration 977, loss = 1434363918.34329891\n",
            "Iteration 978, loss = 1434260202.10606217\n",
            "Iteration 979, loss = 1434157449.88238549\n",
            "Iteration 980, loss = 1434054149.50459456\n",
            "Iteration 981, loss = 1433950827.88239121\n",
            "Iteration 982, loss = 1433847230.69390655\n",
            "Iteration 983, loss = 1433743949.37728357\n",
            "Iteration 984, loss = 1433640991.65434837\n",
            "Iteration 985, loss = 1433537330.23154879\n",
            "Iteration 986, loss = 1433433925.91423607\n",
            "Iteration 987, loss = 1433331557.87230182\n",
            "Iteration 988, loss = 1433227569.81948328\n",
            "Iteration 989, loss = 1433124921.59694624\n",
            "Iteration 990, loss = 1433021651.05313301\n",
            "Iteration 991, loss = 1432918753.83230639\n",
            "Iteration 992, loss = 1432815761.27057099\n",
            "Iteration 993, loss = 1432712294.65372610\n",
            "Iteration 994, loss = 1432610539.55384517\n",
            "Iteration 995, loss = 1432506786.44919610\n",
            "Iteration 996, loss = 1432403694.92417455\n",
            "Iteration 997, loss = 1432301873.77979684\n",
            "Iteration 998, loss = 1432197865.39821553\n",
            "Iteration 999, loss = 1432095793.19972110\n",
            "Iteration 1000, loss = 1431992255.34920144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1545232097.96552014\n",
            "Iteration 2, loss = 2079463731.01199937\n",
            "Iteration 3, loss = 1101013287.44229555\n",
            "Iteration 4, loss = 603406813.57322884\n",
            "Iteration 5, loss = 819016182.10006166\n",
            "Iteration 6, loss = 849421104.59297037\n",
            "Iteration 7, loss = 929749100.31065607\n",
            "Iteration 8, loss = 1086641856.56095910\n",
            "Iteration 9, loss = 1220847832.88390613\n",
            "Iteration 10, loss = 1328018471.26654363\n",
            "Iteration 11, loss = 1421862577.05803514\n",
            "Iteration 12, loss = 1493665657.73215199\n",
            "Iteration 13, loss = 1548313267.24465275\n",
            "Iteration 14, loss = 1594539929.10092402\n",
            "Iteration 15, loss = 1635647024.95077920\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538804074.30398655\n",
            "Iteration 2, loss = 1538594929.39764905\n",
            "Iteration 3, loss = 1538402539.46326280\n",
            "Iteration 4, loss = 1538219848.42330718\n",
            "Iteration 5, loss = 1538021989.83762670\n",
            "Iteration 6, loss = 1537851475.58171654\n",
            "Iteration 7, loss = 1537715361.26272869\n",
            "Iteration 8, loss = 1537587477.10945582\n",
            "Iteration 9, loss = 1537463911.37110257\n",
            "Iteration 10, loss = 1537342454.24356437\n",
            "Iteration 11, loss = 1537222959.28464794\n",
            "Iteration 12, loss = 1537103970.89044595\n",
            "Iteration 13, loss = 1536985021.89671803\n",
            "Iteration 14, loss = 1536866465.89725375\n",
            "Iteration 15, loss = 1536747735.65109539\n",
            "Iteration 16, loss = 1536628953.20676684\n",
            "Iteration 17, loss = 1536510362.62016988\n",
            "Iteration 18, loss = 1536392669.49442434\n",
            "Iteration 19, loss = 1536274187.97616529\n",
            "Iteration 20, loss = 1536156836.72018623\n",
            "Iteration 21, loss = 1536039117.61765146\n",
            "Iteration 22, loss = 1535922396.05046892\n",
            "Iteration 23, loss = 1535804693.98632431\n",
            "Iteration 24, loss = 1535688362.00978780\n",
            "Iteration 25, loss = 1535572652.06297374\n",
            "Iteration 26, loss = 1535455998.42422915\n",
            "Iteration 27, loss = 1535339922.68220663\n",
            "Iteration 28, loss = 1535225084.80396175\n",
            "Iteration 29, loss = 1535109695.16463065\n",
            "Iteration 30, loss = 1534993741.70635128\n",
            "Iteration 31, loss = 1534879621.08901882\n",
            "Iteration 32, loss = 1534764982.72871852\n",
            "Iteration 33, loss = 1534650794.54528809\n",
            "Iteration 34, loss = 1534537186.43359518\n",
            "Iteration 35, loss = 1534422770.05381107\n",
            "Iteration 36, loss = 1534309863.79118991\n",
            "Iteration 37, loss = 1534196446.86424184\n",
            "Iteration 38, loss = 1534083969.96007061\n",
            "Iteration 39, loss = 1533971297.47231936\n",
            "Iteration 40, loss = 1533859451.94826460\n",
            "Iteration 41, loss = 1533747055.34073091\n",
            "Iteration 42, loss = 1533635008.11559749\n",
            "Iteration 43, loss = 1533523414.52156210\n",
            "Iteration 44, loss = 1533411075.19723058\n",
            "Iteration 45, loss = 1533299133.09504867\n",
            "Iteration 46, loss = 1533186818.39458132\n",
            "Iteration 47, loss = 1533074418.32423472\n",
            "Iteration 48, loss = 1532962287.27712631\n",
            "Iteration 49, loss = 1532849831.77120709\n",
            "Iteration 50, loss = 1532738324.33306623\n",
            "Iteration 51, loss = 1532625010.97548842\n",
            "Iteration 52, loss = 1532513772.86091399\n",
            "Iteration 53, loss = 1532402111.59482312\n",
            "Iteration 54, loss = 1532290037.41577196\n",
            "Iteration 55, loss = 1532178840.99311161\n",
            "Iteration 56, loss = 1532066888.61470866\n",
            "Iteration 57, loss = 1531955772.93945241\n",
            "Iteration 58, loss = 1531844182.31201839\n",
            "Iteration 59, loss = 1531732931.42653322\n",
            "Iteration 60, loss = 1531622103.70924020\n",
            "Iteration 61, loss = 1531511110.04722357\n",
            "Iteration 62, loss = 1531400019.76493692\n",
            "Iteration 63, loss = 1531288775.19293094\n",
            "Iteration 64, loss = 1531178154.01675367\n",
            "Iteration 65, loss = 1531067185.11316204\n",
            "Iteration 66, loss = 1530955956.23322248\n",
            "Iteration 67, loss = 1530844838.96787763\n",
            "Iteration 68, loss = 1530734115.66215825\n",
            "Iteration 69, loss = 1530622678.42891383\n",
            "Iteration 70, loss = 1530511958.76595140\n",
            "Iteration 71, loss = 1530399849.39200282\n",
            "Iteration 72, loss = 1530289786.59234691\n",
            "Iteration 73, loss = 1530178561.15702605\n",
            "Iteration 74, loss = 1530068064.91620088\n",
            "Iteration 75, loss = 1529957182.52876425\n",
            "Iteration 76, loss = 1529846879.38123226\n",
            "Iteration 77, loss = 1529736548.65979934\n",
            "Iteration 78, loss = 1529625971.00304389\n",
            "Iteration 79, loss = 1529516405.04097366\n",
            "Iteration 80, loss = 1529406099.32237792\n",
            "Iteration 81, loss = 1529296405.06941986\n",
            "Iteration 82, loss = 1529185579.21859264\n",
            "Iteration 83, loss = 1529076622.57151031\n",
            "Iteration 84, loss = 1528967193.52065802\n",
            "Iteration 85, loss = 1528857220.67562103\n",
            "Iteration 86, loss = 1528748542.21222973\n",
            "Iteration 87, loss = 1528638708.06930470\n",
            "Iteration 88, loss = 1528529503.41753411\n",
            "Iteration 89, loss = 1528420428.83206534\n",
            "Iteration 90, loss = 1528310504.64213896\n",
            "Iteration 91, loss = 1528201077.13056970\n",
            "Iteration 92, loss = 1528090924.11644530\n",
            "Iteration 93, loss = 1527981215.22653365\n",
            "Iteration 94, loss = 1527872136.58052659\n",
            "Iteration 95, loss = 1527761950.42692900\n",
            "Iteration 96, loss = 1527652076.98209643\n",
            "Iteration 97, loss = 1527542482.57025290\n",
            "Iteration 98, loss = 1527432879.78454018\n",
            "Iteration 99, loss = 1527323004.27174115\n",
            "Iteration 100, loss = 1527213486.54288363\n",
            "Iteration 101, loss = 1527103688.17164445\n",
            "Iteration 102, loss = 1526994194.58371782\n",
            "Iteration 103, loss = 1526883584.93281412\n",
            "Iteration 104, loss = 1526774643.39946842\n",
            "Iteration 105, loss = 1526664237.96325970\n",
            "Iteration 106, loss = 1526554419.24466348\n",
            "Iteration 107, loss = 1526444367.84422517\n",
            "Iteration 108, loss = 1526334372.37043214\n",
            "Iteration 109, loss = 1526225355.01808071\n",
            "Iteration 110, loss = 1526115115.86955118\n",
            "Iteration 111, loss = 1526005528.08946204\n",
            "Iteration 112, loss = 1525896007.03520727\n",
            "Iteration 113, loss = 1525787113.30018258\n",
            "Iteration 114, loss = 1525678101.84636450\n",
            "Iteration 115, loss = 1525568291.41116285\n",
            "Iteration 116, loss = 1525459296.16781259\n",
            "Iteration 117, loss = 1525349938.00487518\n",
            "Iteration 118, loss = 1525240657.25749588\n",
            "Iteration 119, loss = 1525131764.56283593\n",
            "Iteration 120, loss = 1525022225.83529735\n",
            "Iteration 121, loss = 1524913710.44737554\n",
            "Iteration 122, loss = 1524805031.37449861\n",
            "Iteration 123, loss = 1524696127.26243258\n",
            "Iteration 124, loss = 1524586619.97730231\n",
            "Iteration 125, loss = 1524478317.81652141\n",
            "Iteration 126, loss = 1524369040.13557005\n",
            "Iteration 127, loss = 1524260336.66225290\n",
            "Iteration 128, loss = 1524150466.11711955\n",
            "Iteration 129, loss = 1524041146.10412407\n",
            "Iteration 130, loss = 1523931186.86429262\n",
            "Iteration 131, loss = 1523822793.14115453\n",
            "Iteration 132, loss = 1523713160.26229429\n",
            "Iteration 133, loss = 1523603353.71615458\n",
            "Iteration 134, loss = 1523494401.76631999\n",
            "Iteration 135, loss = 1523385214.84834218\n",
            "Iteration 136, loss = 1523276236.78880954\n",
            "Iteration 137, loss = 1523166324.58030367\n",
            "Iteration 138, loss = 1523057474.36250877\n",
            "Iteration 139, loss = 1522947947.12343025\n",
            "Iteration 140, loss = 1522838711.05983138\n",
            "Iteration 141, loss = 1522729429.03591275\n",
            "Iteration 142, loss = 1522620352.28264976\n",
            "Iteration 143, loss = 1522510805.87542462\n",
            "Iteration 144, loss = 1522401867.13676929\n",
            "Iteration 145, loss = 1522292868.52843142\n",
            "Iteration 146, loss = 1522184270.90041733\n",
            "Iteration 147, loss = 1522074404.96102858\n",
            "Iteration 148, loss = 1521966299.57921410\n",
            "Iteration 149, loss = 1521857344.10430241\n",
            "Iteration 150, loss = 1521748507.49896502\n",
            "Iteration 151, loss = 1521640288.12349653\n",
            "Iteration 152, loss = 1521530750.98029470\n",
            "Iteration 153, loss = 1521422744.21482682\n",
            "Iteration 154, loss = 1521313571.17827868\n",
            "Iteration 155, loss = 1521204961.50559282\n",
            "Iteration 156, loss = 1521096645.80671620\n",
            "Iteration 157, loss = 1520987900.37503910\n",
            "Iteration 158, loss = 1520879009.43603325\n",
            "Iteration 159, loss = 1520770270.30560899\n",
            "Iteration 160, loss = 1520662434.28113723\n",
            "Iteration 161, loss = 1520553429.97504139\n",
            "Iteration 162, loss = 1520444494.86178565\n",
            "Iteration 163, loss = 1520336234.41288710\n",
            "Iteration 164, loss = 1520227800.76893401\n",
            "Iteration 165, loss = 1520118485.33074760\n",
            "Iteration 166, loss = 1520010854.39088511\n",
            "Iteration 167, loss = 1519902443.15121531\n",
            "Iteration 168, loss = 1519794541.61413336\n",
            "Iteration 169, loss = 1519685753.17665601\n",
            "Iteration 170, loss = 1519577740.66687441\n",
            "Iteration 171, loss = 1519469276.46122456\n",
            "Iteration 172, loss = 1519361490.40991735\n",
            "Iteration 173, loss = 1519252166.70191073\n",
            "Iteration 174, loss = 1519144215.79408669\n",
            "Iteration 175, loss = 1519035267.85320377\n",
            "Iteration 176, loss = 1518926188.60481215\n",
            "Iteration 177, loss = 1518818107.29081368\n",
            "Iteration 178, loss = 1518708847.14552474\n",
            "Iteration 179, loss = 1518600617.24378276\n",
            "Iteration 180, loss = 1518491606.75207090\n",
            "Iteration 181, loss = 1518383888.65510559\n",
            "Iteration 182, loss = 1518274788.35664654\n",
            "Iteration 183, loss = 1518166990.51961207\n",
            "Iteration 184, loss = 1518058753.81907988\n",
            "Iteration 185, loss = 1517950953.35852170\n",
            "Iteration 186, loss = 1517842547.98868561\n",
            "Iteration 187, loss = 1517734986.24810910\n",
            "Iteration 188, loss = 1517626556.34181333\n",
            "Iteration 189, loss = 1517518896.03566480\n",
            "Iteration 190, loss = 1517411183.11629748\n",
            "Iteration 191, loss = 1517303051.88498664\n",
            "Iteration 192, loss = 1517195256.52527928\n",
            "Iteration 193, loss = 1517087729.83736920\n",
            "Iteration 194, loss = 1516980227.62331629\n",
            "Iteration 195, loss = 1516872711.53236413\n",
            "Iteration 196, loss = 1516765213.35369205\n",
            "Iteration 197, loss = 1516657878.24565315\n",
            "Iteration 198, loss = 1516550880.58255601\n",
            "Iteration 199, loss = 1516442982.41745710\n",
            "Iteration 200, loss = 1516335177.69797754\n",
            "Iteration 201, loss = 1516226868.45845389\n",
            "Iteration 202, loss = 1516119448.26220202\n",
            "Iteration 203, loss = 1516010689.63491845\n",
            "Iteration 204, loss = 1515902170.07215619\n",
            "Iteration 205, loss = 1515793713.02456212\n",
            "Iteration 206, loss = 1515684848.57856011\n",
            "Iteration 207, loss = 1515576581.68206286\n",
            "Iteration 208, loss = 1515468774.79219842\n",
            "Iteration 209, loss = 1515360441.03771591\n",
            "Iteration 210, loss = 1515252458.52085376\n",
            "Iteration 211, loss = 1515144524.26174402\n",
            "Iteration 212, loss = 1515036973.52764416\n",
            "Iteration 213, loss = 1514929444.41718960\n",
            "Iteration 214, loss = 1514821761.71853113\n",
            "Iteration 215, loss = 1514714365.99550414\n",
            "Iteration 216, loss = 1514607040.96066618\n",
            "Iteration 217, loss = 1514499638.87308717\n",
            "Iteration 218, loss = 1514392555.48540378\n",
            "Iteration 219, loss = 1514285446.64963675\n",
            "Iteration 220, loss = 1514177846.64255762\n",
            "Iteration 221, loss = 1514071287.24816108\n",
            "Iteration 222, loss = 1513963711.13550282\n",
            "Iteration 223, loss = 1513857066.98974371\n",
            "Iteration 224, loss = 1513749571.42922139\n",
            "Iteration 225, loss = 1513642031.25209141\n",
            "Iteration 226, loss = 1513535176.08516049\n",
            "Iteration 227, loss = 1513428179.70486522\n",
            "Iteration 228, loss = 1513320250.90233636\n",
            "Iteration 229, loss = 1513212476.84761643\n",
            "Iteration 230, loss = 1513105033.43162203\n",
            "Iteration 231, loss = 1512997319.33418369\n",
            "Iteration 232, loss = 1512888862.92837286\n",
            "Iteration 233, loss = 1512780900.67927527\n",
            "Iteration 234, loss = 1512673251.81135535\n",
            "Iteration 235, loss = 1512564754.03847837\n",
            "Iteration 236, loss = 1512457598.19965506\n",
            "Iteration 237, loss = 1512349285.24457502\n",
            "Iteration 238, loss = 1512241346.46223855\n",
            "Iteration 239, loss = 1512134112.00743961\n",
            "Iteration 240, loss = 1512026122.83886290\n",
            "Iteration 241, loss = 1511918643.11139369\n",
            "Iteration 242, loss = 1511810878.75857878\n",
            "Iteration 243, loss = 1511703696.11265016\n",
            "Iteration 244, loss = 1511595942.44406867\n",
            "Iteration 245, loss = 1511488678.88814878\n",
            "Iteration 246, loss = 1511381230.65074563\n",
            "Iteration 247, loss = 1511274846.64824319\n",
            "Iteration 248, loss = 1511167587.11224270\n",
            "Iteration 249, loss = 1511060336.32097530\n",
            "Iteration 250, loss = 1510954120.67203712\n",
            "Iteration 251, loss = 1510847273.74611712\n",
            "Iteration 252, loss = 1510740457.27428412\n",
            "Iteration 253, loss = 1510632598.31340599\n",
            "Iteration 254, loss = 1510525843.52562141\n",
            "Iteration 255, loss = 1510418213.02482843\n",
            "Iteration 256, loss = 1510310422.80251360\n",
            "Iteration 257, loss = 1510201967.55515623\n",
            "Iteration 258, loss = 1510094148.94868016\n",
            "Iteration 259, loss = 1509985981.50408435\n",
            "Iteration 260, loss = 1509877249.70248699\n",
            "Iteration 261, loss = 1509769617.89434695\n",
            "Iteration 262, loss = 1509661441.26052284\n",
            "Iteration 263, loss = 1509553110.73992586\n",
            "Iteration 264, loss = 1509445397.35387683\n",
            "Iteration 265, loss = 1509337563.47169209\n",
            "Iteration 266, loss = 1509229712.20034337\n",
            "Iteration 267, loss = 1509121846.86491013\n",
            "Iteration 268, loss = 1509014219.40230393\n",
            "Iteration 269, loss = 1508905644.43746519\n",
            "Iteration 270, loss = 1508798799.23575521\n",
            "Iteration 271, loss = 1508690874.86684155\n",
            "Iteration 272, loss = 1508582836.13631415\n",
            "Iteration 273, loss = 1508475759.65818644\n",
            "Iteration 274, loss = 1508368472.51855302\n",
            "Iteration 275, loss = 1508260298.92509699\n",
            "Iteration 276, loss = 1508153160.12505841\n",
            "Iteration 277, loss = 1508044757.80050898\n",
            "Iteration 278, loss = 1507937669.72525525\n",
            "Iteration 279, loss = 1507829369.34307599\n",
            "Iteration 280, loss = 1507720760.74882483\n",
            "Iteration 281, loss = 1507613389.19069266\n",
            "Iteration 282, loss = 1507504605.27964878\n",
            "Iteration 283, loss = 1507396708.38437366\n",
            "Iteration 284, loss = 1507289411.83164215\n",
            "Iteration 285, loss = 1507180839.17619085\n",
            "Iteration 286, loss = 1507073242.43691444\n",
            "Iteration 287, loss = 1506965319.72774625\n",
            "Iteration 288, loss = 1506857844.69687915\n",
            "Iteration 289, loss = 1506750675.35736775\n",
            "Iteration 290, loss = 1506642308.34423828\n",
            "Iteration 291, loss = 1506535023.58020663\n",
            "Iteration 292, loss = 1506427853.79559875\n",
            "Iteration 293, loss = 1506320377.23113251\n",
            "Iteration 294, loss = 1506213138.37303591\n",
            "Iteration 295, loss = 1506105939.26064372\n",
            "Iteration 296, loss = 1505998952.72596717\n",
            "Iteration 297, loss = 1505891029.50413632\n",
            "Iteration 298, loss = 1505785115.99807858\n",
            "Iteration 299, loss = 1505677245.26145482\n",
            "Iteration 300, loss = 1505570633.18066955\n",
            "Iteration 301, loss = 1505463271.99884629\n",
            "Iteration 302, loss = 1505355839.06810784\n",
            "Iteration 303, loss = 1505248445.22755909\n",
            "Iteration 304, loss = 1505141336.04979706\n",
            "Iteration 305, loss = 1505033783.76166534\n",
            "Iteration 306, loss = 1504926047.75694013\n",
            "Iteration 307, loss = 1504819363.70177174\n",
            "Iteration 308, loss = 1504711362.14580750\n",
            "Iteration 309, loss = 1504604982.22912979\n",
            "Iteration 310, loss = 1504497331.03646064\n",
            "Iteration 311, loss = 1504391046.93790960\n",
            "Iteration 312, loss = 1504284142.59515905\n",
            "Iteration 313, loss = 1504177561.59958339\n",
            "Iteration 314, loss = 1504071089.27718520\n",
            "Iteration 315, loss = 1503964161.43177295\n",
            "Iteration 316, loss = 1503857743.42851210\n",
            "Iteration 317, loss = 1503750767.71621823\n",
            "Iteration 318, loss = 1503644506.43708825\n",
            "Iteration 319, loss = 1503537687.76282310\n",
            "Iteration 320, loss = 1503430432.46537900\n",
            "Iteration 321, loss = 1503324009.94292784\n",
            "Iteration 322, loss = 1503216828.41304064\n",
            "Iteration 323, loss = 1503110054.26627612\n",
            "Iteration 324, loss = 1503002886.91503477\n",
            "Iteration 325, loss = 1502895314.69349599\n",
            "Iteration 326, loss = 1502788736.72780561\n",
            "Iteration 327, loss = 1502681336.88258767\n",
            "Iteration 328, loss = 1502574052.53597808\n",
            "Iteration 329, loss = 1502466269.86282754\n",
            "Iteration 330, loss = 1502359504.27930713\n",
            "Iteration 331, loss = 1502252297.91980720\n",
            "Iteration 332, loss = 1502144821.84875131\n",
            "Iteration 333, loss = 1502037978.10651231\n",
            "Iteration 334, loss = 1501931417.47299361\n",
            "Iteration 335, loss = 1501824770.60038376\n",
            "Iteration 336, loss = 1501717560.54103041\n",
            "Iteration 337, loss = 1501611135.12449884\n",
            "Iteration 338, loss = 1501504282.82911873\n",
            "Iteration 339, loss = 1501397730.81183529\n",
            "Iteration 340, loss = 1501290708.59527183\n",
            "Iteration 341, loss = 1501183338.55015683\n",
            "Iteration 342, loss = 1501076727.53460050\n",
            "Iteration 343, loss = 1500969486.27278090\n",
            "Iteration 344, loss = 1500862830.49067235\n",
            "Iteration 345, loss = 1500755427.26265454\n",
            "Iteration 346, loss = 1500648697.03658366\n",
            "Iteration 347, loss = 1500542038.07143140\n",
            "Iteration 348, loss = 1500434589.39295769\n",
            "Iteration 349, loss = 1500327745.68074512\n",
            "Iteration 350, loss = 1500221127.91098714\n",
            "Iteration 351, loss = 1500114496.55098772\n",
            "Iteration 352, loss = 1500007468.33967495\n",
            "Iteration 353, loss = 1499900869.14387488\n",
            "Iteration 354, loss = 1499793565.98597932\n",
            "Iteration 355, loss = 1499687361.60261583\n",
            "Iteration 356, loss = 1499580463.09458351\n",
            "Iteration 357, loss = 1499473663.50798011\n",
            "Iteration 358, loss = 1499366827.50971222\n",
            "Iteration 359, loss = 1499260631.34687018\n",
            "Iteration 360, loss = 1499154151.92482424\n",
            "Iteration 361, loss = 1499047030.77916360\n",
            "Iteration 362, loss = 1498941135.59427571\n",
            "Iteration 363, loss = 1498834109.93617654\n",
            "Iteration 364, loss = 1498727907.48756647\n",
            "Iteration 365, loss = 1498620577.47601151\n",
            "Iteration 366, loss = 1498514005.13684869\n",
            "Iteration 367, loss = 1498406870.84892535\n",
            "Iteration 368, loss = 1498300489.15954828\n",
            "Iteration 369, loss = 1498193121.38442469\n",
            "Iteration 370, loss = 1498086507.59124804\n",
            "Iteration 371, loss = 1497979973.41085887\n",
            "Iteration 372, loss = 1497873324.84396648\n",
            "Iteration 373, loss = 1497766688.51404500\n",
            "Iteration 374, loss = 1497660446.02600622\n",
            "Iteration 375, loss = 1497553763.49572277\n",
            "Iteration 376, loss = 1497447237.37035012\n",
            "Iteration 377, loss = 1497339785.41089439\n",
            "Iteration 378, loss = 1497234211.75131273\n",
            "Iteration 379, loss = 1497127081.62150431\n",
            "Iteration 380, loss = 1497020446.28259921\n",
            "Iteration 381, loss = 1496913802.67376733\n",
            "Iteration 382, loss = 1496807498.48375392\n",
            "Iteration 383, loss = 1496700697.69503808\n",
            "Iteration 384, loss = 1496594923.42640018\n",
            "Iteration 385, loss = 1496488294.15034509\n",
            "Iteration 386, loss = 1496381898.48242044\n",
            "Iteration 387, loss = 1496275261.84852529\n",
            "Iteration 388, loss = 1496169075.05766344\n",
            "Iteration 389, loss = 1496062614.68888783\n",
            "Iteration 390, loss = 1495955539.12101960\n",
            "Iteration 391, loss = 1495848713.69707298\n",
            "Iteration 392, loss = 1495742139.11134052\n",
            "Iteration 393, loss = 1495635137.57487345\n",
            "Iteration 394, loss = 1495528348.67460752\n",
            "Iteration 395, loss = 1495421833.32942295\n",
            "Iteration 396, loss = 1495314702.58500671\n",
            "Iteration 397, loss = 1495208626.66248035\n",
            "Iteration 398, loss = 1495101331.77464461\n",
            "Iteration 399, loss = 1494995249.35445857\n",
            "Iteration 400, loss = 1494888683.32171988\n",
            "Iteration 401, loss = 1494781857.39140892\n",
            "Iteration 402, loss = 1494675761.34844518\n",
            "Iteration 403, loss = 1494569183.45687413\n",
            "Iteration 404, loss = 1494463168.55439973\n",
            "Iteration 405, loss = 1494356166.25866747\n",
            "Iteration 406, loss = 1494250214.48248124\n",
            "Iteration 407, loss = 1494144014.95554829\n",
            "Iteration 408, loss = 1494037972.87705326\n",
            "Iteration 409, loss = 1493930953.39770842\n",
            "Iteration 410, loss = 1493825128.23604012\n",
            "Iteration 411, loss = 1493719079.86711740\n",
            "Iteration 412, loss = 1493612390.07573986\n",
            "Iteration 413, loss = 1493506798.92070317\n",
            "Iteration 414, loss = 1493400020.06083608\n",
            "Iteration 415, loss = 1493293647.62365055\n",
            "Iteration 416, loss = 1493186899.18846226\n",
            "Iteration 417, loss = 1493080634.09266782\n",
            "Iteration 418, loss = 1492973499.40526915\n",
            "Iteration 419, loss = 1492867131.48091102\n",
            "Iteration 420, loss = 1492759822.49021959\n",
            "Iteration 421, loss = 1492653448.95474076\n",
            "Iteration 422, loss = 1492546326.65434599\n",
            "Iteration 423, loss = 1492439777.32663941\n",
            "Iteration 424, loss = 1492333003.08641672\n",
            "Iteration 425, loss = 1492226706.13378668\n",
            "Iteration 426, loss = 1492119821.34455800\n",
            "Iteration 427, loss = 1492013122.79396248\n",
            "Iteration 428, loss = 1491907444.62394619\n",
            "Iteration 429, loss = 1491800304.01818252\n",
            "Iteration 430, loss = 1491693782.04148793\n",
            "Iteration 431, loss = 1491587345.78830576\n",
            "Iteration 432, loss = 1491480768.75097251\n",
            "Iteration 433, loss = 1491373539.90592933\n",
            "Iteration 434, loss = 1491268102.92650771\n",
            "Iteration 435, loss = 1491161028.35790586\n",
            "Iteration 436, loss = 1491054846.20240569\n",
            "Iteration 437, loss = 1490949021.02268076\n",
            "Iteration 438, loss = 1490842537.96073055\n",
            "Iteration 439, loss = 1490736471.61212993\n",
            "Iteration 440, loss = 1490630344.27591968\n",
            "Iteration 441, loss = 1490524478.92056370\n",
            "Iteration 442, loss = 1490418473.12164140\n",
            "Iteration 443, loss = 1490312286.87056351\n",
            "Iteration 444, loss = 1490206866.28063679\n",
            "Iteration 445, loss = 1490100768.47113132\n",
            "Iteration 446, loss = 1489994777.52987075\n",
            "Iteration 447, loss = 1489889169.63258147\n",
            "Iteration 448, loss = 1489783243.85706019\n",
            "Iteration 449, loss = 1489677504.85951304\n",
            "Iteration 450, loss = 1489571160.48597288\n",
            "Iteration 451, loss = 1489466072.06823373\n",
            "Iteration 452, loss = 1489360497.42204499\n",
            "Iteration 453, loss = 1489254190.30994749\n",
            "Iteration 454, loss = 1489149962.94079685\n",
            "Iteration 455, loss = 1489043409.12105751\n",
            "Iteration 456, loss = 1488938815.84904909\n",
            "Iteration 457, loss = 1488833467.67748451\n",
            "Iteration 458, loss = 1488728583.35439849\n",
            "Iteration 459, loss = 1488622405.56972528\n",
            "Iteration 460, loss = 1488517953.38382387\n",
            "Iteration 461, loss = 1488412868.73730636\n",
            "Iteration 462, loss = 1488307166.12024283\n",
            "Iteration 463, loss = 1488202174.04650640\n",
            "Iteration 464, loss = 1488097035.02291203\n",
            "Iteration 465, loss = 1487991222.83985496\n",
            "Iteration 466, loss = 1487885656.20053530\n",
            "Iteration 467, loss = 1487780446.77034473\n",
            "Iteration 468, loss = 1487674174.96131897\n",
            "Iteration 469, loss = 1487568989.94894147\n",
            "Iteration 470, loss = 1487463138.86136508\n",
            "Iteration 471, loss = 1487357301.01471090\n",
            "Iteration 472, loss = 1487252166.56298709\n",
            "Iteration 473, loss = 1487145913.14630437\n",
            "Iteration 474, loss = 1487040308.98403645\n",
            "Iteration 475, loss = 1486934993.07561684\n",
            "Iteration 476, loss = 1486828992.48039675\n",
            "Iteration 477, loss = 1486723169.34130740\n",
            "Iteration 478, loss = 1486617231.08028626\n",
            "Iteration 479, loss = 1486511212.43076873\n",
            "Iteration 480, loss = 1486406240.35876632\n",
            "Iteration 481, loss = 1486299537.51322746\n",
            "Iteration 482, loss = 1486193729.07782149\n",
            "Iteration 483, loss = 1486087795.01622486\n",
            "Iteration 484, loss = 1485982371.93870020\n",
            "Iteration 485, loss = 1485876207.01474404\n",
            "Iteration 486, loss = 1485770369.45072341\n",
            "Iteration 487, loss = 1485664315.77756548\n",
            "Iteration 488, loss = 1485558258.46064019\n",
            "Iteration 489, loss = 1485453051.40901637\n",
            "Iteration 490, loss = 1485346375.24416542\n",
            "Iteration 491, loss = 1485241078.26497245\n",
            "Iteration 492, loss = 1485135712.07383299\n",
            "Iteration 493, loss = 1485029910.03520346\n",
            "Iteration 494, loss = 1484923904.15022779\n",
            "Iteration 495, loss = 1484818837.58598351\n",
            "Iteration 496, loss = 1484712400.01082778\n",
            "Iteration 497, loss = 1484606288.99872899\n",
            "Iteration 498, loss = 1484500503.09193635\n",
            "Iteration 499, loss = 1484394412.07305670\n",
            "Iteration 500, loss = 1484287940.26629138\n",
            "Iteration 501, loss = 1484181607.81395245\n",
            "Iteration 502, loss = 1484075488.13608599\n",
            "Iteration 503, loss = 1483970008.78794384\n",
            "Iteration 504, loss = 1483863471.11371017\n",
            "Iteration 505, loss = 1483757537.98599458\n",
            "Iteration 506, loss = 1483652351.76697040\n",
            "Iteration 507, loss = 1483545541.34726405\n",
            "Iteration 508, loss = 1483439844.32194495\n",
            "Iteration 509, loss = 1483335189.27693081\n",
            "Iteration 510, loss = 1483228556.45801306\n",
            "Iteration 511, loss = 1483122985.30680895\n",
            "Iteration 512, loss = 1483017326.83237243\n",
            "Iteration 513, loss = 1482911492.47046447\n",
            "Iteration 514, loss = 1482806444.59504890\n",
            "Iteration 515, loss = 1482699771.96241212\n",
            "Iteration 516, loss = 1482594695.10892129\n",
            "Iteration 517, loss = 1482488859.90568042\n",
            "Iteration 518, loss = 1482382334.60009122\n",
            "Iteration 519, loss = 1482278071.61038566\n",
            "Iteration 520, loss = 1482172586.54576039\n",
            "Iteration 521, loss = 1482066602.38293600\n",
            "Iteration 522, loss = 1481962006.68386936\n",
            "Iteration 523, loss = 1481857540.32572818\n",
            "Iteration 524, loss = 1481752067.11300302\n",
            "Iteration 525, loss = 1481647687.67994428\n",
            "Iteration 526, loss = 1481543017.40254402\n",
            "Iteration 527, loss = 1481438137.39143467\n",
            "Iteration 528, loss = 1481333657.06293774\n",
            "Iteration 529, loss = 1481228610.57070255\n",
            "Iteration 530, loss = 1481124280.65449667\n",
            "Iteration 531, loss = 1481019517.86708093\n",
            "Iteration 532, loss = 1480914375.99631071\n",
            "Iteration 533, loss = 1480809503.70847225\n",
            "Iteration 534, loss = 1480704146.98055291\n",
            "Iteration 535, loss = 1480598890.19942069\n",
            "Iteration 536, loss = 1480493901.65552235\n",
            "Iteration 537, loss = 1480388180.74857545\n",
            "Iteration 538, loss = 1480282178.30047584\n",
            "Iteration 539, loss = 1480177283.55656195\n",
            "Iteration 540, loss = 1480072384.32690549\n",
            "Iteration 541, loss = 1479965909.17139554\n",
            "Iteration 542, loss = 1479860799.87149477\n",
            "Iteration 543, loss = 1479755634.48411870\n",
            "Iteration 544, loss = 1479649646.99515414\n",
            "Iteration 545, loss = 1479544026.14412212\n",
            "Iteration 546, loss = 1479439321.46729827\n",
            "Iteration 547, loss = 1479333003.27587128\n",
            "Iteration 548, loss = 1479227335.63285446\n",
            "Iteration 549, loss = 1479121946.49569345\n",
            "Iteration 550, loss = 1479017091.90125728\n",
            "Iteration 551, loss = 1478911304.44806886\n",
            "Iteration 552, loss = 1478805467.17572737\n",
            "Iteration 553, loss = 1478701291.74714065\n",
            "Iteration 554, loss = 1478596065.36804986\n",
            "Iteration 555, loss = 1478490539.29102802\n",
            "Iteration 556, loss = 1478385826.73159027\n",
            "Iteration 557, loss = 1478280333.55290103\n",
            "Iteration 558, loss = 1478175653.44677162\n",
            "Iteration 559, loss = 1478070062.80902863\n",
            "Iteration 560, loss = 1477964570.27663970\n",
            "Iteration 561, loss = 1477859659.61749220\n",
            "Iteration 562, loss = 1477754497.49705243\n",
            "Iteration 563, loss = 1477648715.04696488\n",
            "Iteration 564, loss = 1477543892.29121637\n",
            "Iteration 565, loss = 1477438713.66068840\n",
            "Iteration 566, loss = 1477334107.72847176\n",
            "Iteration 567, loss = 1477228866.90029001\n",
            "Iteration 568, loss = 1477123161.84376431\n",
            "Iteration 569, loss = 1477018509.09115219\n",
            "Iteration 570, loss = 1476913512.61884856\n",
            "Iteration 571, loss = 1476808000.47600508\n",
            "Iteration 572, loss = 1476702806.79022765\n",
            "Iteration 573, loss = 1476597589.00966644\n",
            "Iteration 574, loss = 1476492238.26159477\n",
            "Iteration 575, loss = 1476386653.97576833\n",
            "Iteration 576, loss = 1476281628.09206009\n",
            "Iteration 577, loss = 1476176352.84212852\n",
            "Iteration 578, loss = 1476070815.38753629\n",
            "Iteration 579, loss = 1475965467.14431906\n",
            "Iteration 580, loss = 1475860331.64692116\n",
            "Iteration 581, loss = 1475754724.34458399\n",
            "Iteration 582, loss = 1475650251.27047133\n",
            "Iteration 583, loss = 1475544698.59531760\n",
            "Iteration 584, loss = 1475440009.65495872\n",
            "Iteration 585, loss = 1475334486.26680970\n",
            "Iteration 586, loss = 1475230117.06114888\n",
            "Iteration 587, loss = 1475125080.68809342\n",
            "Iteration 588, loss = 1475019399.28424382\n",
            "Iteration 589, loss = 1474914769.01247478\n",
            "Iteration 590, loss = 1474808885.44583392\n",
            "Iteration 591, loss = 1474703620.48922253\n",
            "Iteration 592, loss = 1474598086.84228396\n",
            "Iteration 593, loss = 1474492398.62670994\n",
            "Iteration 594, loss = 1474386297.71536016\n",
            "Iteration 595, loss = 1474281314.55629754\n",
            "Iteration 596, loss = 1474175556.30945635\n",
            "Iteration 597, loss = 1474070639.06401706\n",
            "Iteration 598, loss = 1473964375.47479224\n",
            "Iteration 599, loss = 1473860326.53308129\n",
            "Iteration 600, loss = 1473754458.70347834\n",
            "Iteration 601, loss = 1473649158.09444499\n",
            "Iteration 602, loss = 1473544044.41110754\n",
            "Iteration 603, loss = 1473439018.30787492\n",
            "Iteration 604, loss = 1473333310.05190611\n",
            "Iteration 605, loss = 1473227757.02179360\n",
            "Iteration 606, loss = 1473122571.79235554\n",
            "Iteration 607, loss = 1473017801.12817049\n",
            "Iteration 608, loss = 1472911873.06048322\n",
            "Iteration 609, loss = 1472807013.55240631\n",
            "Iteration 610, loss = 1472701516.47619772\n",
            "Iteration 611, loss = 1472596713.69022155\n",
            "Iteration 612, loss = 1472491460.38113022\n",
            "Iteration 613, loss = 1472386153.53469515\n",
            "Iteration 614, loss = 1472281105.43762374\n",
            "Iteration 615, loss = 1472175508.97759962\n",
            "Iteration 616, loss = 1472070603.23096728\n",
            "Iteration 617, loss = 1471965072.81375480\n",
            "Iteration 618, loss = 1471860343.84298658\n",
            "Iteration 619, loss = 1471755342.31764984\n",
            "Iteration 620, loss = 1471650108.36273861\n",
            "Iteration 621, loss = 1471544895.45798874\n",
            "Iteration 622, loss = 1471440623.22015476\n",
            "Iteration 623, loss = 1471334999.78187490\n",
            "Iteration 624, loss = 1471229544.57936954\n",
            "Iteration 625, loss = 1471124599.77396989\n",
            "Iteration 626, loss = 1471019358.14007163\n",
            "Iteration 627, loss = 1470914485.10566545\n",
            "Iteration 628, loss = 1470808603.25221634\n",
            "Iteration 629, loss = 1470703414.47717094\n",
            "Iteration 630, loss = 1470599190.78358459\n",
            "Iteration 631, loss = 1470493620.47981358\n",
            "Iteration 632, loss = 1470388416.69166541\n",
            "Iteration 633, loss = 1470283876.67178631\n",
            "Iteration 634, loss = 1470179117.25041437\n",
            "Iteration 635, loss = 1470074890.53072858\n",
            "Iteration 636, loss = 1469970042.25166869\n",
            "Iteration 637, loss = 1469864814.99510193\n",
            "Iteration 638, loss = 1469761302.68026972\n",
            "Iteration 639, loss = 1469656433.78441405\n",
            "Iteration 640, loss = 1469551906.94679379\n",
            "Iteration 641, loss = 1469447134.43302774\n",
            "Iteration 642, loss = 1469342031.84693408\n",
            "Iteration 643, loss = 1469237165.16840315\n",
            "Iteration 644, loss = 1469132798.53530073\n",
            "Iteration 645, loss = 1469027650.86016631\n",
            "Iteration 646, loss = 1468922068.63717127\n",
            "Iteration 647, loss = 1468817637.13943839\n",
            "Iteration 648, loss = 1468712352.32979465\n",
            "Iteration 649, loss = 1468606982.15960670\n",
            "Iteration 650, loss = 1468502735.84738350\n",
            "Iteration 651, loss = 1468396587.07621670\n",
            "Iteration 652, loss = 1468292744.29136872\n",
            "Iteration 653, loss = 1468187376.41802454\n",
            "Iteration 654, loss = 1468082339.41828752\n",
            "Iteration 655, loss = 1467977728.52867746\n",
            "Iteration 656, loss = 1467873400.07918453\n",
            "Iteration 657, loss = 1467767670.94371057\n",
            "Iteration 658, loss = 1467663825.32996821\n",
            "Iteration 659, loss = 1467557824.95751119\n",
            "Iteration 660, loss = 1467453219.89986157\n",
            "Iteration 661, loss = 1467347595.40698981\n",
            "Iteration 662, loss = 1467242610.27432275\n",
            "Iteration 663, loss = 1467137528.09681916\n",
            "Iteration 664, loss = 1467032373.96346855\n",
            "Iteration 665, loss = 1466926818.00465250\n",
            "Iteration 666, loss = 1466822086.90156770\n",
            "Iteration 667, loss = 1466717232.85856986\n",
            "Iteration 668, loss = 1466612200.57299519\n",
            "Iteration 669, loss = 1466507782.14228010\n",
            "Iteration 670, loss = 1466402729.58484435\n",
            "Iteration 671, loss = 1466298396.33205795\n",
            "Iteration 672, loss = 1466193884.17502785\n",
            "Iteration 673, loss = 1466089145.70923257\n",
            "Iteration 674, loss = 1465985280.45041442\n",
            "Iteration 675, loss = 1465881310.42385912\n",
            "Iteration 676, loss = 1465777200.85841417\n",
            "Iteration 677, loss = 1465673018.73432732\n",
            "Iteration 678, loss = 1465569268.33223248\n",
            "Iteration 679, loss = 1465465291.84876966\n",
            "Iteration 680, loss = 1465361793.36251640\n",
            "Iteration 681, loss = 1465257666.47909141\n",
            "Iteration 682, loss = 1465153379.36036611\n",
            "Iteration 683, loss = 1465050086.28294730\n",
            "Iteration 684, loss = 1464945278.75572896\n",
            "Iteration 685, loss = 1464841628.29120088\n",
            "Iteration 686, loss = 1464736543.59853411\n",
            "Iteration 687, loss = 1464631739.95306373\n",
            "Iteration 688, loss = 1464527354.08000064\n",
            "Iteration 689, loss = 1464422575.65129566\n",
            "Iteration 690, loss = 1464317843.05559087\n",
            "Iteration 691, loss = 1464213420.68602777\n",
            "Iteration 692, loss = 1464109967.20867229\n",
            "Iteration 693, loss = 1464005466.62825012\n",
            "Iteration 694, loss = 1463900653.72940135\n",
            "Iteration 695, loss = 1463798280.76912975\n",
            "Iteration 696, loss = 1463692622.13340425\n",
            "Iteration 697, loss = 1463589150.74307942\n",
            "Iteration 698, loss = 1463484859.16772318\n",
            "Iteration 699, loss = 1463380355.06955624\n",
            "Iteration 700, loss = 1463275796.17889690\n",
            "Iteration 701, loss = 1463171687.33240819\n",
            "Iteration 702, loss = 1463067028.73563075\n",
            "Iteration 703, loss = 1462962796.97537756\n",
            "Iteration 704, loss = 1462858306.16407251\n",
            "Iteration 705, loss = 1462753838.92725682\n",
            "Iteration 706, loss = 1462649614.19358015\n",
            "Iteration 707, loss = 1462544631.18694162\n",
            "Iteration 708, loss = 1462439913.92934847\n",
            "Iteration 709, loss = 1462334649.68027163\n",
            "Iteration 710, loss = 1462229989.98279643\n",
            "Iteration 711, loss = 1462124554.19637275\n",
            "Iteration 712, loss = 1462019351.06623793\n",
            "Iteration 713, loss = 1461913907.31751132\n",
            "Iteration 714, loss = 1461808630.78859878\n",
            "Iteration 715, loss = 1461703551.78652596\n",
            "Iteration 716, loss = 1461598562.81463552\n",
            "Iteration 717, loss = 1461494179.77708983\n",
            "Iteration 718, loss = 1461388662.81255960\n",
            "Iteration 719, loss = 1461283698.25419807\n",
            "Iteration 720, loss = 1461179695.14977551\n",
            "Iteration 721, loss = 1461074960.12633443\n",
            "Iteration 722, loss = 1460969889.38299847\n",
            "Iteration 723, loss = 1460864991.35085797\n",
            "Iteration 724, loss = 1460760782.80150914\n",
            "Iteration 725, loss = 1460656250.48607278\n",
            "Iteration 726, loss = 1460551122.98487473\n",
            "Iteration 727, loss = 1460446636.59238267\n",
            "Iteration 728, loss = 1460341635.13948202\n",
            "Iteration 729, loss = 1460237417.07755470\n",
            "Iteration 730, loss = 1460132525.80376244\n",
            "Iteration 731, loss = 1460027867.86430120\n",
            "Iteration 732, loss = 1459923312.63968301\n",
            "Iteration 733, loss = 1459818235.69617629\n",
            "Iteration 734, loss = 1459714302.90979505\n",
            "Iteration 735, loss = 1459609255.54407978\n",
            "Iteration 736, loss = 1459505653.58311296\n",
            "Iteration 737, loss = 1459400727.39236355\n",
            "Iteration 738, loss = 1459296899.65014315\n",
            "Iteration 739, loss = 1459192757.29069138\n",
            "Iteration 740, loss = 1459089180.10277271\n",
            "Iteration 741, loss = 1458984876.60565948\n",
            "Iteration 742, loss = 1458881181.81668115\n",
            "Iteration 743, loss = 1458776751.52765751\n",
            "Iteration 744, loss = 1458672936.18318510\n",
            "Iteration 745, loss = 1458568579.07391548\n",
            "Iteration 746, loss = 1458464251.35117388\n",
            "Iteration 747, loss = 1458360451.55981588\n",
            "Iteration 748, loss = 1458255743.25713825\n",
            "Iteration 749, loss = 1458151397.22037721\n",
            "Iteration 750, loss = 1458047150.38352489\n",
            "Iteration 751, loss = 1457942613.29603457\n",
            "Iteration 752, loss = 1457837677.16843200\n",
            "Iteration 753, loss = 1457733135.78392339\n",
            "Iteration 754, loss = 1457628247.84301829\n",
            "Iteration 755, loss = 1457524146.98285294\n",
            "Iteration 756, loss = 1457419174.43427014\n",
            "Iteration 757, loss = 1457314648.30995393\n",
            "Iteration 758, loss = 1457210098.90683746\n",
            "Iteration 759, loss = 1457105770.53112841\n",
            "Iteration 760, loss = 1457001662.50867581\n",
            "Iteration 761, loss = 1456896651.31995153\n",
            "Iteration 762, loss = 1456792182.74267817\n",
            "Iteration 763, loss = 1456688146.20246196\n",
            "Iteration 764, loss = 1456583584.21283507\n",
            "Iteration 765, loss = 1456478812.36636448\n",
            "Iteration 766, loss = 1456374714.64423800\n",
            "Iteration 767, loss = 1456270821.16657305\n",
            "Iteration 768, loss = 1456165309.50796652\n",
            "Iteration 769, loss = 1456062081.64225316\n",
            "Iteration 770, loss = 1455957427.98372078\n",
            "Iteration 771, loss = 1455852321.42192292\n",
            "Iteration 772, loss = 1455748042.36665106\n",
            "Iteration 773, loss = 1455643531.44086885\n",
            "Iteration 774, loss = 1455538764.43863916\n",
            "Iteration 775, loss = 1455434326.67519164\n",
            "Iteration 776, loss = 1455329708.79969764\n",
            "Iteration 777, loss = 1455224522.20872545\n",
            "Iteration 778, loss = 1455119960.05210304\n",
            "Iteration 779, loss = 1455015148.89865470\n",
            "Iteration 780, loss = 1454910614.46447992\n",
            "Iteration 781, loss = 1454805630.38986421\n",
            "Iteration 782, loss = 1454700758.25077820\n",
            "Iteration 783, loss = 1454596115.88412118\n",
            "Iteration 784, loss = 1454491810.18915033\n",
            "Iteration 785, loss = 1454386605.76603603\n",
            "Iteration 786, loss = 1454281923.78781223\n",
            "Iteration 787, loss = 1454177860.07118702\n",
            "Iteration 788, loss = 1454073788.17375422\n",
            "Iteration 789, loss = 1453968565.67473078\n",
            "Iteration 790, loss = 1453864697.55835104\n",
            "Iteration 791, loss = 1453760598.25550437\n",
            "Iteration 792, loss = 1453656538.13207960\n",
            "Iteration 793, loss = 1453552002.54467297\n",
            "Iteration 794, loss = 1453448604.78164697\n",
            "Iteration 795, loss = 1453343919.60001779\n",
            "Iteration 796, loss = 1453239349.51215744\n",
            "Iteration 797, loss = 1453135271.56639504\n",
            "Iteration 798, loss = 1453030924.05714655\n",
            "Iteration 799, loss = 1452925789.86149955\n",
            "Iteration 800, loss = 1452820756.07009077\n",
            "Iteration 801, loss = 1452717073.37895060\n",
            "Iteration 802, loss = 1452612109.35034180\n",
            "Iteration 803, loss = 1452507274.70288897\n",
            "Iteration 804, loss = 1452403109.55758548\n",
            "Iteration 805, loss = 1452298628.03879118\n",
            "Iteration 806, loss = 1452194434.10745788\n",
            "Iteration 807, loss = 1452090301.53962159\n",
            "Iteration 808, loss = 1451985580.47695231\n",
            "Iteration 809, loss = 1451881134.66849923\n",
            "Iteration 810, loss = 1451777113.39882183\n",
            "Iteration 811, loss = 1451673031.17749381\n",
            "Iteration 812, loss = 1451567984.44236732\n",
            "Iteration 813, loss = 1451463942.88873386\n",
            "Iteration 814, loss = 1451359320.02453995\n",
            "Iteration 815, loss = 1451255156.30389094\n",
            "Iteration 816, loss = 1451150813.70831084\n",
            "Iteration 817, loss = 1451046508.94516444\n",
            "Iteration 818, loss = 1450941788.65390849\n",
            "Iteration 819, loss = 1450837232.28037763\n",
            "Iteration 820, loss = 1450733250.79149866\n",
            "Iteration 821, loss = 1450628466.01770544\n",
            "Iteration 822, loss = 1450523724.84155130\n",
            "Iteration 823, loss = 1450419681.45160484\n",
            "Iteration 824, loss = 1450315410.46399426\n",
            "Iteration 825, loss = 1450210922.07515883\n",
            "Iteration 826, loss = 1450106711.01128173\n",
            "Iteration 827, loss = 1450002673.17563772\n",
            "Iteration 828, loss = 1449898426.08402252\n",
            "Iteration 829, loss = 1449794689.73706889\n",
            "Iteration 830, loss = 1449689801.25884724\n",
            "Iteration 831, loss = 1449586304.26007342\n",
            "Iteration 832, loss = 1449481720.28114486\n",
            "Iteration 833, loss = 1449377925.32887030\n",
            "Iteration 834, loss = 1449272527.64053082\n",
            "Iteration 835, loss = 1449169151.24973440\n",
            "Iteration 836, loss = 1449064575.82521486\n",
            "Iteration 837, loss = 1448959910.90107489\n",
            "Iteration 838, loss = 1448855764.75766706\n",
            "Iteration 839, loss = 1448751412.51512861\n",
            "Iteration 840, loss = 1448647567.16981792\n",
            "Iteration 841, loss = 1448543178.33874083\n",
            "Iteration 842, loss = 1448439069.39494681\n",
            "Iteration 843, loss = 1448335319.41979432\n",
            "Iteration 844, loss = 1448231966.48867536\n",
            "Iteration 845, loss = 1448127923.15714645\n",
            "Iteration 846, loss = 1448024877.70545244\n",
            "Iteration 847, loss = 1447920757.29547405\n",
            "Iteration 848, loss = 1447817419.66112375\n",
            "Iteration 849, loss = 1447714478.46057510\n",
            "Iteration 850, loss = 1447610562.62529516\n",
            "Iteration 851, loss = 1447507064.32781863\n",
            "Iteration 852, loss = 1447403707.00627971\n",
            "Iteration 853, loss = 1447300333.58228755\n",
            "Iteration 854, loss = 1447196992.93572974\n",
            "Iteration 855, loss = 1447093451.09369254\n",
            "Iteration 856, loss = 1446989869.61225128\n",
            "Iteration 857, loss = 1446886839.30540848\n",
            "Iteration 858, loss = 1446782532.23824334\n",
            "Iteration 859, loss = 1446678883.64147615\n",
            "Iteration 860, loss = 1446574700.28638268\n",
            "Iteration 861, loss = 1446471045.65184402\n",
            "Iteration 862, loss = 1446366571.22064900\n",
            "Iteration 863, loss = 1446262062.15895271\n",
            "Iteration 864, loss = 1446158321.38123369\n",
            "Iteration 865, loss = 1446053560.98358679\n",
            "Iteration 866, loss = 1445949393.76396441\n",
            "Iteration 867, loss = 1445845172.94688773\n",
            "Iteration 868, loss = 1445740372.60687923\n",
            "Iteration 869, loss = 1445636883.94751287\n",
            "Iteration 870, loss = 1445531724.66164851\n",
            "Iteration 871, loss = 1445427490.56777215\n",
            "Iteration 872, loss = 1445323184.11888862\n",
            "Iteration 873, loss = 1445218360.60778427\n",
            "Iteration 874, loss = 1445114025.43398213\n",
            "Iteration 875, loss = 1445009542.78283763\n",
            "Iteration 876, loss = 1444905498.98886800\n",
            "Iteration 877, loss = 1444801405.57908654\n",
            "Iteration 878, loss = 1444696736.28080559\n",
            "Iteration 879, loss = 1444592586.24499226\n",
            "Iteration 880, loss = 1444488839.29404569\n",
            "Iteration 881, loss = 1444385058.18271995\n",
            "Iteration 882, loss = 1444281096.40100956\n",
            "Iteration 883, loss = 1444177171.99127531\n",
            "Iteration 884, loss = 1444074238.62159848\n",
            "Iteration 885, loss = 1443970335.04354620\n",
            "Iteration 886, loss = 1443866654.84954476\n",
            "Iteration 887, loss = 1443762999.80341101\n",
            "Iteration 888, loss = 1443660179.12670994\n",
            "Iteration 889, loss = 1443555423.16818500\n",
            "Iteration 890, loss = 1443452241.85092974\n",
            "Iteration 891, loss = 1443348186.24225616\n",
            "Iteration 892, loss = 1443244750.85205817\n",
            "Iteration 893, loss = 1443140202.51317763\n",
            "Iteration 894, loss = 1443036335.17568731\n",
            "Iteration 895, loss = 1442932774.21237206\n",
            "Iteration 896, loss = 1442829035.47514582\n",
            "Iteration 897, loss = 1442724943.76561546\n",
            "Iteration 898, loss = 1442621763.97120690\n",
            "Iteration 899, loss = 1442517866.57613397\n",
            "Iteration 900, loss = 1442414267.90821886\n",
            "Iteration 901, loss = 1442310212.66383481\n",
            "Iteration 902, loss = 1442206266.40586591\n",
            "Iteration 903, loss = 1442102733.91109228\n",
            "Iteration 904, loss = 1441998978.24436975\n",
            "Iteration 905, loss = 1441895066.44215512\n",
            "Iteration 906, loss = 1441791006.24216127\n",
            "Iteration 907, loss = 1441687382.52399039\n",
            "Iteration 908, loss = 1441583541.88624763\n",
            "Iteration 909, loss = 1441479753.98416066\n",
            "Iteration 910, loss = 1441376044.19228125\n",
            "Iteration 911, loss = 1441272585.14803600\n",
            "Iteration 912, loss = 1441168064.94589686\n",
            "Iteration 913, loss = 1441065142.07179165\n",
            "Iteration 914, loss = 1440961337.94044566\n",
            "Iteration 915, loss = 1440858140.16792512\n",
            "Iteration 916, loss = 1440754179.51782513\n",
            "Iteration 917, loss = 1440650845.34178686\n",
            "Iteration 918, loss = 1440547585.72059035\n",
            "Iteration 919, loss = 1440443766.51831985\n",
            "Iteration 920, loss = 1440339112.75191069\n",
            "Iteration 921, loss = 1440236229.42801261\n",
            "Iteration 922, loss = 1440132092.02083635\n",
            "Iteration 923, loss = 1440028318.05194449\n",
            "Iteration 924, loss = 1439924158.64560461\n",
            "Iteration 925, loss = 1439820410.85384488\n",
            "Iteration 926, loss = 1439716941.99612236\n",
            "Iteration 927, loss = 1439613300.45054841\n",
            "Iteration 928, loss = 1439509403.20223308\n",
            "Iteration 929, loss = 1439406256.20323014\n",
            "Iteration 930, loss = 1439302838.79226351\n",
            "Iteration 931, loss = 1439199642.10837436\n",
            "Iteration 932, loss = 1439095924.15393591\n",
            "Iteration 933, loss = 1438992294.86409235\n",
            "Iteration 934, loss = 1438888994.34310603\n",
            "Iteration 935, loss = 1438785022.43894839\n",
            "Iteration 936, loss = 1438681539.79059148\n",
            "Iteration 937, loss = 1438577606.15092373\n",
            "Iteration 938, loss = 1438473255.05189657\n",
            "Iteration 939, loss = 1438369577.92017841\n",
            "Iteration 940, loss = 1438265639.11104417\n",
            "Iteration 941, loss = 1438161814.77782941\n",
            "Iteration 942, loss = 1438057403.68578267\n",
            "Iteration 943, loss = 1437953651.86508584\n",
            "Iteration 944, loss = 1437850157.33667350\n",
            "Iteration 945, loss = 1437746626.14988947\n",
            "Iteration 946, loss = 1437642610.19616127\n",
            "Iteration 947, loss = 1437539060.59102011\n",
            "Iteration 948, loss = 1437435838.84637094\n",
            "Iteration 949, loss = 1437331673.31756496\n",
            "Iteration 950, loss = 1437227984.58354831\n",
            "Iteration 951, loss = 1437124321.39173055\n",
            "Iteration 952, loss = 1437019739.12137175\n",
            "Iteration 953, loss = 1436915723.93806362\n",
            "Iteration 954, loss = 1436811280.72890043\n",
            "Iteration 955, loss = 1436707937.51184201\n",
            "Iteration 956, loss = 1436603795.04190230\n",
            "Iteration 957, loss = 1436499497.48715353\n",
            "Iteration 958, loss = 1436396309.35035682\n",
            "Iteration 959, loss = 1436293761.85788155\n",
            "Iteration 960, loss = 1436190343.73023248\n",
            "Iteration 961, loss = 1436087439.52941799\n",
            "Iteration 962, loss = 1435984508.89560723\n",
            "Iteration 963, loss = 1435880960.77095842\n",
            "Iteration 964, loss = 1435779504.25972533\n",
            "Iteration 965, loss = 1435675620.89414334\n",
            "Iteration 966, loss = 1435573034.43578982\n",
            "Iteration 967, loss = 1435470136.66350555\n",
            "Iteration 968, loss = 1435367621.81474209\n",
            "Iteration 969, loss = 1435264163.60431075\n",
            "Iteration 970, loss = 1435162369.36779642\n",
            "Iteration 971, loss = 1435059171.18279386\n",
            "Iteration 972, loss = 1434956101.57803798\n",
            "Iteration 973, loss = 1434852824.00986981\n",
            "Iteration 974, loss = 1434750545.73806286\n",
            "Iteration 975, loss = 1434646453.19807816\n",
            "Iteration 976, loss = 1434543662.94641376\n",
            "Iteration 977, loss = 1434440722.53642106\n",
            "Iteration 978, loss = 1434337427.89241743\n",
            "Iteration 979, loss = 1434233978.47717047\n",
            "Iteration 980, loss = 1434131011.25120544\n",
            "Iteration 981, loss = 1434027570.17267871\n",
            "Iteration 982, loss = 1433925872.67439246\n",
            "Iteration 983, loss = 1433821780.02864814\n",
            "Iteration 984, loss = 1433718589.22939968\n",
            "Iteration 985, loss = 1433617094.40287280\n",
            "Iteration 986, loss = 1433513166.60848570\n",
            "Iteration 987, loss = 1433410039.02884173\n",
            "Iteration 988, loss = 1433307336.89733315\n",
            "Iteration 989, loss = 1433204110.00987840\n",
            "Iteration 990, loss = 1433100490.09338927\n",
            "Iteration 991, loss = 1432998376.91546488\n",
            "Iteration 992, loss = 1432894874.71682763\n",
            "Iteration 993, loss = 1432791822.03725386\n",
            "Iteration 994, loss = 1432689173.29632068\n",
            "Iteration 995, loss = 1432585836.67698002\n",
            "Iteration 996, loss = 1432482860.32085943\n",
            "Iteration 997, loss = 1432379993.45066929\n",
            "Iteration 998, loss = 1432277016.11186147\n",
            "Iteration 999, loss = 1432173127.79499650\n",
            "Iteration 1000, loss = 1432070457.78438354\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1536820626.57952118\n",
            "Iteration 2, loss = 1620733582.14949703\n",
            "Iteration 3, loss = 643711939.40927529\n",
            "Iteration 4, loss = 423496612.01889592\n",
            "Iteration 5, loss = 418919942.64726186\n",
            "Iteration 6, loss = 309220855.20222926\n",
            "Iteration 7, loss = 332781191.62487876\n",
            "Iteration 8, loss = 340588308.13843119\n",
            "Iteration 9, loss = 249772061.39954236\n",
            "Iteration 10, loss = 218482583.34701914\n",
            "Iteration 11, loss = 176620082.30234975\n",
            "Iteration 12, loss = 182936243.51976901\n",
            "Iteration 13, loss = 210700860.34229183\n",
            "Iteration 14, loss = 229830918.80328625\n",
            "Iteration 15, loss = 237642676.71527967\n",
            "Iteration 16, loss = 312831250.39715040\n",
            "Iteration 17, loss = 442938830.77922076\n",
            "Iteration 18, loss = 596358906.38964164\n",
            "Iteration 19, loss = 750329473.18824625\n",
            "Iteration 20, loss = 892687677.44102490\n",
            "Iteration 21, loss = 1020959176.17349327\n",
            "Iteration 22, loss = 1132942367.65334821\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538833022.92488861\n",
            "Iteration 2, loss = 1538670482.41975069\n",
            "Iteration 3, loss = 1538507358.79861474\n",
            "Iteration 4, loss = 1538339191.68086839\n",
            "Iteration 5, loss = 1538145476.66470790\n",
            "Iteration 6, loss = 1537973460.99335766\n",
            "Iteration 7, loss = 1537833844.48752737\n",
            "Iteration 8, loss = 1537701568.01907396\n",
            "Iteration 9, loss = 1537572818.32463932\n",
            "Iteration 10, loss = 1537450056.94687510\n",
            "Iteration 11, loss = 1537329955.12143898\n",
            "Iteration 12, loss = 1537209111.11335254\n",
            "Iteration 13, loss = 1537089328.85268211\n",
            "Iteration 14, loss = 1536969997.96433234\n",
            "Iteration 15, loss = 1536849515.57296395\n",
            "Iteration 16, loss = 1536730519.72531867\n",
            "Iteration 17, loss = 1536610778.47445273\n",
            "Iteration 18, loss = 1536492423.52428913\n",
            "Iteration 19, loss = 1536373585.05267024\n",
            "Iteration 20, loss = 1536254688.62514639\n",
            "Iteration 21, loss = 1536137484.09342098\n",
            "Iteration 22, loss = 1536019556.10250735\n",
            "Iteration 23, loss = 1535902402.14445829\n",
            "Iteration 24, loss = 1535784844.92021537\n",
            "Iteration 25, loss = 1535668030.86996126\n",
            "Iteration 26, loss = 1535551743.94826841\n",
            "Iteration 27, loss = 1535435383.51729631\n",
            "Iteration 28, loss = 1535319472.22997165\n",
            "Iteration 29, loss = 1535203999.15344238\n",
            "Iteration 30, loss = 1535088163.63822889\n",
            "Iteration 31, loss = 1534973961.57519031\n",
            "Iteration 32, loss = 1534858988.27034688\n",
            "Iteration 33, loss = 1534744499.71095562\n",
            "Iteration 34, loss = 1534630264.94494629\n",
            "Iteration 35, loss = 1534516000.04750872\n",
            "Iteration 36, loss = 1534402120.96136069\n",
            "Iteration 37, loss = 1534288648.35884333\n",
            "Iteration 38, loss = 1534174535.10811710\n",
            "Iteration 39, loss = 1534061192.22913361\n",
            "Iteration 40, loss = 1533947669.81734324\n",
            "Iteration 41, loss = 1533834445.09956574\n",
            "Iteration 42, loss = 1533721249.91506243\n",
            "Iteration 43, loss = 1533608899.03533363\n",
            "Iteration 44, loss = 1533495099.69108105\n",
            "Iteration 45, loss = 1533382672.36209726\n",
            "Iteration 46, loss = 1533269565.75141954\n",
            "Iteration 47, loss = 1533157428.16881204\n",
            "Iteration 48, loss = 1533043769.80981946\n",
            "Iteration 49, loss = 1532932106.14863610\n",
            "Iteration 50, loss = 1532819158.45140386\n",
            "Iteration 51, loss = 1532707217.97800136\n",
            "Iteration 52, loss = 1532594528.84596109\n",
            "Iteration 53, loss = 1532482990.95042849\n",
            "Iteration 54, loss = 1532370952.12703466\n",
            "Iteration 55, loss = 1532258920.95734787\n",
            "Iteration 56, loss = 1532148097.67207432\n",
            "Iteration 57, loss = 1532036407.29400587\n",
            "Iteration 58, loss = 1531924741.18640137\n",
            "Iteration 59, loss = 1531814066.64016581\n",
            "Iteration 60, loss = 1531702376.82185125\n",
            "Iteration 61, loss = 1531591959.65919423\n",
            "Iteration 62, loss = 1531480185.19304323\n",
            "Iteration 63, loss = 1531370006.05095768\n",
            "Iteration 64, loss = 1531258183.34246969\n",
            "Iteration 65, loss = 1531147298.70547771\n",
            "Iteration 66, loss = 1531036335.91786027\n",
            "Iteration 67, loss = 1530925540.01961946\n",
            "Iteration 68, loss = 1530814114.71477914\n",
            "Iteration 69, loss = 1530703461.97960711\n",
            "Iteration 70, loss = 1530592261.12424946\n",
            "Iteration 71, loss = 1530481618.48231196\n",
            "Iteration 72, loss = 1530370338.09024358\n",
            "Iteration 73, loss = 1530259495.30585289\n",
            "Iteration 74, loss = 1530149390.99210095\n",
            "Iteration 75, loss = 1530037853.39022517\n",
            "Iteration 76, loss = 1529926922.97276711\n",
            "Iteration 77, loss = 1529816455.49645877\n",
            "Iteration 78, loss = 1529706096.18019271\n",
            "Iteration 79, loss = 1529595294.75783062\n",
            "Iteration 80, loss = 1529484691.17423630\n",
            "Iteration 81, loss = 1529374138.66942334\n",
            "Iteration 82, loss = 1529263912.30419040\n",
            "Iteration 83, loss = 1529153707.99947381\n",
            "Iteration 84, loss = 1529043017.87961912\n",
            "Iteration 85, loss = 1528932707.72614264\n",
            "Iteration 86, loss = 1528822070.35619521\n",
            "Iteration 87, loss = 1528711744.28594065\n",
            "Iteration 88, loss = 1528600913.42769670\n",
            "Iteration 89, loss = 1528490611.96074486\n",
            "Iteration 90, loss = 1528379815.00835609\n",
            "Iteration 91, loss = 1528269191.90282130\n",
            "Iteration 92, loss = 1528158618.10690737\n",
            "Iteration 93, loss = 1528049017.08128214\n",
            "Iteration 94, loss = 1527938343.66950059\n",
            "Iteration 95, loss = 1527828325.28135228\n",
            "Iteration 96, loss = 1527718227.02578807\n",
            "Iteration 97, loss = 1527608614.46424913\n",
            "Iteration 98, loss = 1527498684.34555006\n",
            "Iteration 99, loss = 1527388873.48048186\n",
            "Iteration 100, loss = 1527278842.11837578\n",
            "Iteration 101, loss = 1527169904.89636254\n",
            "Iteration 102, loss = 1527060152.50180387\n",
            "Iteration 103, loss = 1526950552.78292537\n",
            "Iteration 104, loss = 1526841194.82560039\n",
            "Iteration 105, loss = 1526731165.77638865\n",
            "Iteration 106, loss = 1526622684.47041440\n",
            "Iteration 107, loss = 1526513414.50792027\n",
            "Iteration 108, loss = 1526404377.18062997\n",
            "Iteration 109, loss = 1526294613.27646112\n",
            "Iteration 110, loss = 1526187141.29822707\n",
            "Iteration 111, loss = 1526076902.80750895\n",
            "Iteration 112, loss = 1525968549.63761544\n",
            "Iteration 113, loss = 1525859789.49357939\n",
            "Iteration 114, loss = 1525751058.88288498\n",
            "Iteration 115, loss = 1525642692.35097313\n",
            "Iteration 116, loss = 1525532960.80518556\n",
            "Iteration 117, loss = 1525424982.57270503\n",
            "Iteration 118, loss = 1525315995.25995731\n",
            "Iteration 119, loss = 1525207000.20746684\n",
            "Iteration 120, loss = 1525097995.06495309\n",
            "Iteration 121, loss = 1524988847.41656399\n",
            "Iteration 122, loss = 1524879826.82926011\n",
            "Iteration 123, loss = 1524770988.68903041\n",
            "Iteration 124, loss = 1524662016.81589365\n",
            "Iteration 125, loss = 1524551649.85985279\n",
            "Iteration 126, loss = 1524443774.22045755\n",
            "Iteration 127, loss = 1524334288.49332690\n",
            "Iteration 128, loss = 1524225352.88644934\n",
            "Iteration 129, loss = 1524116351.58116746\n",
            "Iteration 130, loss = 1524007734.00998020\n",
            "Iteration 131, loss = 1523898019.81439900\n",
            "Iteration 132, loss = 1523789172.03994370\n",
            "Iteration 133, loss = 1523679920.71560097\n",
            "Iteration 134, loss = 1523571401.84921145\n",
            "Iteration 135, loss = 1523461613.99243689\n",
            "Iteration 136, loss = 1523351770.49782038\n",
            "Iteration 137, loss = 1523242784.31864166\n",
            "Iteration 138, loss = 1523133898.45949817\n",
            "Iteration 139, loss = 1523024181.15740037\n",
            "Iteration 140, loss = 1522915257.43405247\n",
            "Iteration 141, loss = 1522806440.78174758\n",
            "Iteration 142, loss = 1522697251.83799863\n",
            "Iteration 143, loss = 1522588480.14507079\n",
            "Iteration 144, loss = 1522480415.50243068\n",
            "Iteration 145, loss = 1522370634.03034306\n",
            "Iteration 146, loss = 1522263024.33635020\n",
            "Iteration 147, loss = 1522153965.87145686\n",
            "Iteration 148, loss = 1522045340.22017288\n",
            "Iteration 149, loss = 1521937614.67882919\n",
            "Iteration 150, loss = 1521828478.12507582\n",
            "Iteration 151, loss = 1521720802.02696729\n",
            "Iteration 152, loss = 1521612271.56031084\n",
            "Iteration 153, loss = 1521504937.88822770\n",
            "Iteration 154, loss = 1521396456.85052276\n",
            "Iteration 155, loss = 1521288370.64637423\n",
            "Iteration 156, loss = 1521180901.82627296\n",
            "Iteration 157, loss = 1521072482.72498393\n",
            "Iteration 158, loss = 1520964040.99863362\n",
            "Iteration 159, loss = 1520855670.96367121\n",
            "Iteration 160, loss = 1520747623.30317354\n",
            "Iteration 161, loss = 1520638572.04816198\n",
            "Iteration 162, loss = 1520529772.63859963\n",
            "Iteration 163, loss = 1520421475.34202313\n",
            "Iteration 164, loss = 1520312572.99600625\n",
            "Iteration 165, loss = 1520204520.42416453\n",
            "Iteration 166, loss = 1520095416.11162162\n",
            "Iteration 167, loss = 1519987428.12369895\n",
            "Iteration 168, loss = 1519878914.87616324\n",
            "Iteration 169, loss = 1519770172.57224870\n",
            "Iteration 170, loss = 1519662175.17269921\n",
            "Iteration 171, loss = 1519553533.19444060\n",
            "Iteration 172, loss = 1519444735.51573825\n",
            "Iteration 173, loss = 1519336637.02281928\n",
            "Iteration 174, loss = 1519227660.33813763\n",
            "Iteration 175, loss = 1519118986.62215114\n",
            "Iteration 176, loss = 1519010069.68216085\n",
            "Iteration 177, loss = 1518901540.77797484\n",
            "Iteration 178, loss = 1518792273.97036767\n",
            "Iteration 179, loss = 1518683809.11594439\n",
            "Iteration 180, loss = 1518575043.54154563\n",
            "Iteration 181, loss = 1518466249.55322289\n",
            "Iteration 182, loss = 1518357458.03647876\n",
            "Iteration 183, loss = 1518249531.17606878\n",
            "Iteration 184, loss = 1518140281.43760467\n",
            "Iteration 185, loss = 1518031546.60177231\n",
            "Iteration 186, loss = 1517923133.10429335\n",
            "Iteration 187, loss = 1517814056.70368528\n",
            "Iteration 188, loss = 1517705871.63562107\n",
            "Iteration 189, loss = 1517596902.62115645\n",
            "Iteration 190, loss = 1517488506.04594445\n",
            "Iteration 191, loss = 1517380472.82874274\n",
            "Iteration 192, loss = 1517271583.01816940\n",
            "Iteration 193, loss = 1517163635.69330144\n",
            "Iteration 194, loss = 1517055161.74438477\n",
            "Iteration 195, loss = 1516946969.93324661\n",
            "Iteration 196, loss = 1516838995.80595946\n",
            "Iteration 197, loss = 1516729774.50164652\n",
            "Iteration 198, loss = 1516621788.51604629\n",
            "Iteration 199, loss = 1516513416.30207872\n",
            "Iteration 200, loss = 1516404777.33886218\n",
            "Iteration 201, loss = 1516296655.03916812\n",
            "Iteration 202, loss = 1516187343.61364031\n",
            "Iteration 203, loss = 1516079712.11318159\n",
            "Iteration 204, loss = 1515971239.34585309\n",
            "Iteration 205, loss = 1515862319.26322150\n",
            "Iteration 206, loss = 1515754462.35284233\n",
            "Iteration 207, loss = 1515645598.14792347\n",
            "Iteration 208, loss = 1515537584.71113348\n",
            "Iteration 209, loss = 1515429009.97771144\n",
            "Iteration 210, loss = 1515320633.87701011\n",
            "Iteration 211, loss = 1515212121.77364635\n",
            "Iteration 212, loss = 1515103273.91319370\n",
            "Iteration 213, loss = 1514995350.88194466\n",
            "Iteration 214, loss = 1514887026.09731174\n",
            "Iteration 215, loss = 1514778600.78919935\n",
            "Iteration 216, loss = 1514670250.25154519\n",
            "Iteration 217, loss = 1514562436.69641566\n",
            "Iteration 218, loss = 1514454203.93535304\n",
            "Iteration 219, loss = 1514347221.81515527\n",
            "Iteration 220, loss = 1514238583.08684158\n",
            "Iteration 221, loss = 1514131488.27531099\n",
            "Iteration 222, loss = 1514024086.80581522\n",
            "Iteration 223, loss = 1513917111.31230330\n",
            "Iteration 224, loss = 1513809077.43785763\n",
            "Iteration 225, loss = 1513701640.72672606\n",
            "Iteration 226, loss = 1513594079.74969983\n",
            "Iteration 227, loss = 1513485757.40668607\n",
            "Iteration 228, loss = 1513378319.73380327\n",
            "Iteration 229, loss = 1513269860.35320973\n",
            "Iteration 230, loss = 1513161937.66352177\n",
            "Iteration 231, loss = 1513054252.80729723\n",
            "Iteration 232, loss = 1512946094.75241566\n",
            "Iteration 233, loss = 1512838338.90869737\n",
            "Iteration 234, loss = 1512730671.90660357\n",
            "Iteration 235, loss = 1512622733.64796782\n",
            "Iteration 236, loss = 1512515172.87389016\n",
            "Iteration 237, loss = 1512407341.10441542\n",
            "Iteration 238, loss = 1512299500.07276964\n",
            "Iteration 239, loss = 1512191949.71585917\n",
            "Iteration 240, loss = 1512083466.93886566\n",
            "Iteration 241, loss = 1511975910.89725542\n",
            "Iteration 242, loss = 1511867909.95928216\n",
            "Iteration 243, loss = 1511760441.47886395\n",
            "Iteration 244, loss = 1511652602.07094288\n",
            "Iteration 245, loss = 1511544703.72047687\n",
            "Iteration 246, loss = 1511437739.19579601\n",
            "Iteration 247, loss = 1511329943.32909226\n",
            "Iteration 248, loss = 1511222478.50181675\n",
            "Iteration 249, loss = 1511116067.04103279\n",
            "Iteration 250, loss = 1511007241.34095931\n",
            "Iteration 251, loss = 1510900672.78899455\n",
            "Iteration 252, loss = 1510792894.35782576\n",
            "Iteration 253, loss = 1510684741.65884089\n",
            "Iteration 254, loss = 1510577992.63532090\n",
            "Iteration 255, loss = 1510469557.07109737\n",
            "Iteration 256, loss = 1510361906.96574306\n",
            "Iteration 257, loss = 1510254041.78015637\n",
            "Iteration 258, loss = 1510146551.07766151\n",
            "Iteration 259, loss = 1510038061.77601123\n",
            "Iteration 260, loss = 1509930029.17810464\n",
            "Iteration 261, loss = 1509822009.86860108\n",
            "Iteration 262, loss = 1509714252.15306973\n",
            "Iteration 263, loss = 1509605079.54427791\n",
            "Iteration 264, loss = 1509498413.90582919\n",
            "Iteration 265, loss = 1509389220.48656106\n",
            "Iteration 266, loss = 1509282453.64941120\n",
            "Iteration 267, loss = 1509174301.55298638\n",
            "Iteration 268, loss = 1509066503.25217986\n",
            "Iteration 269, loss = 1508959766.99131155\n",
            "Iteration 270, loss = 1508851842.58489394\n",
            "Iteration 271, loss = 1508744229.07809806\n",
            "Iteration 272, loss = 1508637260.77476311\n",
            "Iteration 273, loss = 1508529240.67154217\n",
            "Iteration 274, loss = 1508422487.48095870\n",
            "Iteration 275, loss = 1508314728.05800867\n",
            "Iteration 276, loss = 1508207379.79566813\n",
            "Iteration 277, loss = 1508100506.75586939\n",
            "Iteration 278, loss = 1507993676.93683767\n",
            "Iteration 279, loss = 1507886162.49543929\n",
            "Iteration 280, loss = 1507778881.25057697\n",
            "Iteration 281, loss = 1507671634.30868721\n",
            "Iteration 282, loss = 1507564344.13798308\n",
            "Iteration 283, loss = 1507457534.70249581\n",
            "Iteration 284, loss = 1507350111.02991796\n",
            "Iteration 285, loss = 1507242032.39944673\n",
            "Iteration 286, loss = 1507136040.72900724\n",
            "Iteration 287, loss = 1507028553.76058674\n",
            "Iteration 288, loss = 1506921538.92361903\n",
            "Iteration 289, loss = 1506814428.37200522\n",
            "Iteration 290, loss = 1506708379.80487657\n",
            "Iteration 291, loss = 1506601775.69488287\n",
            "Iteration 292, loss = 1506494047.35018516\n",
            "Iteration 293, loss = 1506387976.42820954\n",
            "Iteration 294, loss = 1506281141.29809642\n",
            "Iteration 295, loss = 1506174429.00763893\n",
            "Iteration 296, loss = 1506067579.28128600\n",
            "Iteration 297, loss = 1505960690.87477326\n",
            "Iteration 298, loss = 1505853243.48702145\n",
            "Iteration 299, loss = 1505747040.55565524\n",
            "Iteration 300, loss = 1505639929.63804078\n",
            "Iteration 301, loss = 1505532906.04617476\n",
            "Iteration 302, loss = 1505425961.31633687\n",
            "Iteration 303, loss = 1505319145.96363592\n",
            "Iteration 304, loss = 1505211601.72605991\n",
            "Iteration 305, loss = 1505104712.96590686\n",
            "Iteration 306, loss = 1504997569.57073164\n",
            "Iteration 307, loss = 1504889988.76324749\n",
            "Iteration 308, loss = 1504782856.55771494\n",
            "Iteration 309, loss = 1504675363.41961479\n",
            "Iteration 310, loss = 1504568046.07863545\n",
            "Iteration 311, loss = 1504460914.31592512\n",
            "Iteration 312, loss = 1504353942.57077575\n",
            "Iteration 313, loss = 1504246841.11408401\n",
            "Iteration 314, loss = 1504139793.02788544\n",
            "Iteration 315, loss = 1504032682.40634489\n",
            "Iteration 316, loss = 1503925552.23962355\n",
            "Iteration 317, loss = 1503818527.27025175\n",
            "Iteration 318, loss = 1503710934.80481529\n",
            "Iteration 319, loss = 1503603802.75047493\n",
            "Iteration 320, loss = 1503496198.59459805\n",
            "Iteration 321, loss = 1503389047.10619187\n",
            "Iteration 322, loss = 1503281537.13087440\n",
            "Iteration 323, loss = 1503173853.14745402\n",
            "Iteration 324, loss = 1503067401.93667054\n",
            "Iteration 325, loss = 1502960102.62191939\n",
            "Iteration 326, loss = 1502853023.86232281\n",
            "Iteration 327, loss = 1502746785.26146245\n",
            "Iteration 328, loss = 1502638754.03046513\n",
            "Iteration 329, loss = 1502533038.40533376\n",
            "Iteration 330, loss = 1502425739.59978008\n",
            "Iteration 331, loss = 1502318619.17375755\n",
            "Iteration 332, loss = 1502211326.81595874\n",
            "Iteration 333, loss = 1502103979.66576815\n",
            "Iteration 334, loss = 1501997097.79198074\n",
            "Iteration 335, loss = 1501890045.03694439\n",
            "Iteration 336, loss = 1501782737.10940075\n",
            "Iteration 337, loss = 1501676223.30884004\n",
            "Iteration 338, loss = 1501569060.16096425\n",
            "Iteration 339, loss = 1501462013.89062834\n",
            "Iteration 340, loss = 1501356087.92501807\n",
            "Iteration 341, loss = 1501248771.73820424\n",
            "Iteration 342, loss = 1501142737.70335507\n",
            "Iteration 343, loss = 1501035936.27947307\n",
            "Iteration 344, loss = 1500929172.59155035\n",
            "Iteration 345, loss = 1500822509.57389283\n",
            "Iteration 346, loss = 1500715865.52166104\n",
            "Iteration 347, loss = 1500609357.03919744\n",
            "Iteration 348, loss = 1500501900.98090887\n",
            "Iteration 349, loss = 1500394996.74268603\n",
            "Iteration 350, loss = 1500289152.87706017\n",
            "Iteration 351, loss = 1500181720.79739070\n",
            "Iteration 352, loss = 1500075207.23305297\n",
            "Iteration 353, loss = 1499968778.64088964\n",
            "Iteration 354, loss = 1499861644.05781507\n",
            "Iteration 355, loss = 1499755740.03100133\n",
            "Iteration 356, loss = 1499649051.35677242\n",
            "Iteration 357, loss = 1499542484.37367368\n",
            "Iteration 358, loss = 1499435604.78316236\n",
            "Iteration 359, loss = 1499328772.89335036\n",
            "Iteration 360, loss = 1499222692.65486002\n",
            "Iteration 361, loss = 1499115353.36598873\n",
            "Iteration 362, loss = 1499008702.16264629\n",
            "Iteration 363, loss = 1498901578.12054610\n",
            "Iteration 364, loss = 1498794218.56048059\n",
            "Iteration 365, loss = 1498687849.89640832\n",
            "Iteration 366, loss = 1498579863.98383379\n",
            "Iteration 367, loss = 1498473711.58854866\n",
            "Iteration 368, loss = 1498365793.78315282\n",
            "Iteration 369, loss = 1498259228.74432158\n",
            "Iteration 370, loss = 1498152071.27565718\n",
            "Iteration 371, loss = 1498045246.28038645\n",
            "Iteration 372, loss = 1497938293.86337543\n",
            "Iteration 373, loss = 1497831252.61333632\n",
            "Iteration 374, loss = 1497724278.69588470\n",
            "Iteration 375, loss = 1497617431.81963778\n",
            "Iteration 376, loss = 1497511247.04338360\n",
            "Iteration 377, loss = 1497403720.65154958\n",
            "Iteration 378, loss = 1497297846.46244621\n",
            "Iteration 379, loss = 1497191293.05068779\n",
            "Iteration 380, loss = 1497085019.35560942\n",
            "Iteration 381, loss = 1496978176.77094531\n",
            "Iteration 382, loss = 1496872673.32608843\n",
            "Iteration 383, loss = 1496765697.67532849\n",
            "Iteration 384, loss = 1496659772.05153370\n",
            "Iteration 385, loss = 1496554024.09564328\n",
            "Iteration 386, loss = 1496447522.59070945\n",
            "Iteration 387, loss = 1496341250.52229142\n",
            "Iteration 388, loss = 1496235722.69847131\n",
            "Iteration 389, loss = 1496129462.13951230\n",
            "Iteration 390, loss = 1496023328.62804151\n",
            "Iteration 391, loss = 1495917668.57938981\n",
            "Iteration 392, loss = 1495811670.64111209\n",
            "Iteration 393, loss = 1495705021.65748835\n",
            "Iteration 394, loss = 1495599463.76615214\n",
            "Iteration 395, loss = 1495493223.97596216\n",
            "Iteration 396, loss = 1495387229.93996668\n",
            "Iteration 397, loss = 1495280884.01436853\n",
            "Iteration 398, loss = 1495174934.32295322\n",
            "Iteration 399, loss = 1495069288.21756577\n",
            "Iteration 400, loss = 1494962662.66437674\n",
            "Iteration 401, loss = 1494856878.84903526\n",
            "Iteration 402, loss = 1494751341.89849114\n",
            "Iteration 403, loss = 1494645195.26522994\n",
            "Iteration 404, loss = 1494539242.21575332\n",
            "Iteration 405, loss = 1494433267.08075666\n",
            "Iteration 406, loss = 1494327728.31111836\n",
            "Iteration 407, loss = 1494221919.26994753\n",
            "Iteration 408, loss = 1494116144.45694113\n",
            "Iteration 409, loss = 1494009598.23014498\n",
            "Iteration 410, loss = 1493903868.36378694\n",
            "Iteration 411, loss = 1493797028.14278984\n",
            "Iteration 412, loss = 1493690829.61808157\n",
            "Iteration 413, loss = 1493584474.38497734\n",
            "Iteration 414, loss = 1493477186.94097233\n",
            "Iteration 415, loss = 1493370742.49149156\n",
            "Iteration 416, loss = 1493263368.75725961\n",
            "Iteration 417, loss = 1493157230.80001307\n",
            "Iteration 418, loss = 1493049359.84360099\n",
            "Iteration 419, loss = 1492943146.74247122\n",
            "Iteration 420, loss = 1492836633.44965744\n",
            "Iteration 421, loss = 1492729674.92378211\n",
            "Iteration 422, loss = 1492623411.14058304\n",
            "Iteration 423, loss = 1492517433.98908663\n",
            "Iteration 424, loss = 1492411117.29710698\n",
            "Iteration 425, loss = 1492304851.95523620\n",
            "Iteration 426, loss = 1492199339.81939149\n",
            "Iteration 427, loss = 1492093137.67163968\n",
            "Iteration 428, loss = 1491987736.70513701\n",
            "Iteration 429, loss = 1491881676.34674263\n",
            "Iteration 430, loss = 1491776320.12100387\n",
            "Iteration 431, loss = 1491671190.49560332\n",
            "Iteration 432, loss = 1491565614.11211753\n",
            "Iteration 433, loss = 1491460052.33316588\n",
            "Iteration 434, loss = 1491354862.85182095\n",
            "Iteration 435, loss = 1491248743.04577327\n",
            "Iteration 436, loss = 1491143020.06105208\n",
            "Iteration 437, loss = 1491037953.36726618\n",
            "Iteration 438, loss = 1490931337.25982857\n",
            "Iteration 439, loss = 1490824964.55754471\n",
            "Iteration 440, loss = 1490719986.23961306\n",
            "Iteration 441, loss = 1490613423.58408022\n",
            "Iteration 442, loss = 1490507904.43559599\n",
            "Iteration 443, loss = 1490401919.21505475\n",
            "Iteration 444, loss = 1490296764.54736686\n",
            "Iteration 445, loss = 1490190199.51955557\n",
            "Iteration 446, loss = 1490085103.59666467\n",
            "Iteration 447, loss = 1489979342.37240648\n",
            "Iteration 448, loss = 1489873198.13093567\n",
            "Iteration 449, loss = 1489767282.94250298\n",
            "Iteration 450, loss = 1489660791.05283237\n",
            "Iteration 451, loss = 1489554553.98669672\n",
            "Iteration 452, loss = 1489448443.86851454\n",
            "Iteration 453, loss = 1489342191.94456506\n",
            "Iteration 454, loss = 1489234409.99785089\n",
            "Iteration 455, loss = 1489129088.02177238\n",
            "Iteration 456, loss = 1489021886.87223959\n",
            "Iteration 457, loss = 1488915406.65076423\n",
            "Iteration 458, loss = 1488809621.93548179\n",
            "Iteration 459, loss = 1488703342.20398021\n",
            "Iteration 460, loss = 1488596564.15521359\n",
            "Iteration 461, loss = 1488491268.47078395\n",
            "Iteration 462, loss = 1488385014.40391636\n",
            "Iteration 463, loss = 1488279399.67855477\n",
            "Iteration 464, loss = 1488173454.22710800\n",
            "Iteration 465, loss = 1488067560.39122343\n",
            "Iteration 466, loss = 1487962805.26786971\n",
            "Iteration 467, loss = 1487856720.42852426\n",
            "Iteration 468, loss = 1487751384.32396460\n",
            "Iteration 469, loss = 1487645421.47246218\n",
            "Iteration 470, loss = 1487539897.12191653\n",
            "Iteration 471, loss = 1487433907.45300555\n",
            "Iteration 472, loss = 1487327249.25366163\n",
            "Iteration 473, loss = 1487221410.19260502\n",
            "Iteration 474, loss = 1487114791.24464798\n",
            "Iteration 475, loss = 1487008804.94521165\n",
            "Iteration 476, loss = 1486902115.73787427\n",
            "Iteration 477, loss = 1486796513.50594115\n",
            "Iteration 478, loss = 1486689744.93238187\n",
            "Iteration 479, loss = 1486583963.04623008\n",
            "Iteration 480, loss = 1486477830.05455184\n",
            "Iteration 481, loss = 1486371778.83758879\n",
            "Iteration 482, loss = 1486266293.28383684\n",
            "Iteration 483, loss = 1486159917.88925385\n",
            "Iteration 484, loss = 1486054506.85978055\n",
            "Iteration 485, loss = 1485948320.99377513\n",
            "Iteration 486, loss = 1485842924.36199236\n",
            "Iteration 487, loss = 1485737106.70471573\n",
            "Iteration 488, loss = 1485631257.88422227\n",
            "Iteration 489, loss = 1485525519.35647082\n",
            "Iteration 490, loss = 1485419115.68442106\n",
            "Iteration 491, loss = 1485314036.62503934\n",
            "Iteration 492, loss = 1485207376.12972307\n",
            "Iteration 493, loss = 1485101735.09609008\n",
            "Iteration 494, loss = 1484995469.37429547\n",
            "Iteration 495, loss = 1484888759.86687875\n",
            "Iteration 496, loss = 1484783069.32232833\n",
            "Iteration 497, loss = 1484677011.76402020\n",
            "Iteration 498, loss = 1484570011.88382959\n",
            "Iteration 499, loss = 1484464098.10422182\n",
            "Iteration 500, loss = 1484358300.55204868\n",
            "Iteration 501, loss = 1484251642.11008573\n",
            "Iteration 502, loss = 1484145678.53771091\n",
            "Iteration 503, loss = 1484039269.96607184\n",
            "Iteration 504, loss = 1483932809.68088150\n",
            "Iteration 505, loss = 1483827020.77055216\n",
            "Iteration 506, loss = 1483720373.38402367\n",
            "Iteration 507, loss = 1483614112.99682140\n",
            "Iteration 508, loss = 1483507916.30808067\n",
            "Iteration 509, loss = 1483401468.54941988\n",
            "Iteration 510, loss = 1483294640.34395289\n",
            "Iteration 511, loss = 1483188577.05994344\n",
            "Iteration 512, loss = 1483081914.16178083\n",
            "Iteration 513, loss = 1482975222.28961444\n",
            "Iteration 514, loss = 1482868633.39323711\n",
            "Iteration 515, loss = 1482761980.12399483\n",
            "Iteration 516, loss = 1482655053.57029033\n",
            "Iteration 517, loss = 1482548586.93123078\n",
            "Iteration 518, loss = 1482441879.02032924\n",
            "Iteration 519, loss = 1482336108.75263834\n",
            "Iteration 520, loss = 1482230125.96637273\n",
            "Iteration 521, loss = 1482124148.91637897\n",
            "Iteration 522, loss = 1482018413.71061707\n",
            "Iteration 523, loss = 1481912948.47772384\n",
            "Iteration 524, loss = 1481807182.58470225\n",
            "Iteration 525, loss = 1481702136.24606586\n",
            "Iteration 526, loss = 1481595852.54897356\n",
            "Iteration 527, loss = 1481490097.11898208\n",
            "Iteration 528, loss = 1481384545.12970543\n",
            "Iteration 529, loss = 1481279004.84432268\n",
            "Iteration 530, loss = 1481172564.37419558\n",
            "Iteration 531, loss = 1481067740.84637475\n",
            "Iteration 532, loss = 1480961574.53720403\n",
            "Iteration 533, loss = 1480857124.17045355\n",
            "Iteration 534, loss = 1480751218.12974620\n",
            "Iteration 535, loss = 1480646289.19440413\n",
            "Iteration 536, loss = 1480541246.11895776\n",
            "Iteration 537, loss = 1480436003.37313128\n",
            "Iteration 538, loss = 1480331079.88971829\n",
            "Iteration 539, loss = 1480226039.36320066\n",
            "Iteration 540, loss = 1480120716.82713914\n",
            "Iteration 541, loss = 1480015265.65368509\n",
            "Iteration 542, loss = 1479910346.93199086\n",
            "Iteration 543, loss = 1479805174.99345827\n",
            "Iteration 544, loss = 1479699558.80310845\n",
            "Iteration 545, loss = 1479594332.61058855\n",
            "Iteration 546, loss = 1479489030.49714732\n",
            "Iteration 547, loss = 1479383221.63055921\n",
            "Iteration 548, loss = 1479278206.75389981\n",
            "Iteration 549, loss = 1479171951.88273787\n",
            "Iteration 550, loss = 1479066898.98293734\n",
            "Iteration 551, loss = 1478961269.51363373\n",
            "Iteration 552, loss = 1478855563.93879366\n",
            "Iteration 553, loss = 1478749497.48316073\n",
            "Iteration 554, loss = 1478644449.24136758\n",
            "Iteration 555, loss = 1478538134.30023599\n",
            "Iteration 556, loss = 1478432828.58125544\n",
            "Iteration 557, loss = 1478326062.59765649\n",
            "Iteration 558, loss = 1478220256.08681250\n",
            "Iteration 559, loss = 1478114911.06999779\n",
            "Iteration 560, loss = 1478007099.46918845\n",
            "Iteration 561, loss = 1477901910.93331647\n",
            "Iteration 562, loss = 1477795934.51229000\n",
            "Iteration 563, loss = 1477689495.42946720\n",
            "Iteration 564, loss = 1477583730.70689273\n",
            "Iteration 565, loss = 1477477864.81727576\n",
            "Iteration 566, loss = 1477372714.49456406\n",
            "Iteration 567, loss = 1477267159.77603507\n",
            "Iteration 568, loss = 1477161566.83073926\n",
            "Iteration 569, loss = 1477056176.41387892\n",
            "Iteration 570, loss = 1476950855.56587648\n",
            "Iteration 571, loss = 1476845459.36421442\n",
            "Iteration 572, loss = 1476740147.79449582\n",
            "Iteration 573, loss = 1476635252.79392791\n",
            "Iteration 574, loss = 1476530600.13787913\n",
            "Iteration 575, loss = 1476424679.25021577\n",
            "Iteration 576, loss = 1476320742.12908602\n",
            "Iteration 577, loss = 1476215460.54866672\n",
            "Iteration 578, loss = 1476111678.85385799\n",
            "Iteration 579, loss = 1476005879.78182006\n",
            "Iteration 580, loss = 1475902098.17701817\n",
            "Iteration 581, loss = 1475796452.19324565\n",
            "Iteration 582, loss = 1475691993.05283928\n",
            "Iteration 583, loss = 1475587010.09471869\n",
            "Iteration 584, loss = 1475482489.23160481\n",
            "Iteration 585, loss = 1475377195.84531474\n",
            "Iteration 586, loss = 1475272363.61198711\n",
            "Iteration 587, loss = 1475167160.31368828\n",
            "Iteration 588, loss = 1475062633.30201221\n",
            "Iteration 589, loss = 1474957274.87930751\n",
            "Iteration 590, loss = 1474852334.38172722\n",
            "Iteration 591, loss = 1474747123.65162539\n",
            "Iteration 592, loss = 1474641956.20147204\n",
            "Iteration 593, loss = 1474536501.60410857\n",
            "Iteration 594, loss = 1474431584.71602225\n",
            "Iteration 595, loss = 1474327034.04345584\n",
            "Iteration 596, loss = 1474221180.74463916\n",
            "Iteration 597, loss = 1474116780.68684649\n",
            "Iteration 598, loss = 1474012296.17361712\n",
            "Iteration 599, loss = 1473907227.61319041\n",
            "Iteration 600, loss = 1473802849.83684468\n",
            "Iteration 601, loss = 1473697904.87751269\n",
            "Iteration 602, loss = 1473592728.91821766\n",
            "Iteration 603, loss = 1473487959.80314422\n",
            "Iteration 604, loss = 1473382046.34619427\n",
            "Iteration 605, loss = 1473277001.82113910\n",
            "Iteration 606, loss = 1473171636.57083726\n",
            "Iteration 607, loss = 1473065272.17994809\n",
            "Iteration 608, loss = 1472959973.13370061\n",
            "Iteration 609, loss = 1472854114.88095474\n",
            "Iteration 610, loss = 1472748628.03282547\n",
            "Iteration 611, loss = 1472642813.87173343\n",
            "Iteration 612, loss = 1472537972.68253589\n",
            "Iteration 613, loss = 1472431774.23516440\n",
            "Iteration 614, loss = 1472327531.87683916\n",
            "Iteration 615, loss = 1472222120.29493737\n",
            "Iteration 616, loss = 1472116812.73891306\n",
            "Iteration 617, loss = 1472011695.90534544\n",
            "Iteration 618, loss = 1471907468.50406241\n",
            "Iteration 619, loss = 1471801940.60310149\n",
            "Iteration 620, loss = 1471696686.04494476\n",
            "Iteration 621, loss = 1471591989.70325136\n",
            "Iteration 622, loss = 1471486983.99088764\n",
            "Iteration 623, loss = 1471381851.96715426\n",
            "Iteration 624, loss = 1471277157.12059999\n",
            "Iteration 625, loss = 1471171476.02051616\n",
            "Iteration 626, loss = 1471066569.62555146\n",
            "Iteration 627, loss = 1470961672.92009449\n",
            "Iteration 628, loss = 1470856178.42254329\n",
            "Iteration 629, loss = 1470750749.25276589\n",
            "Iteration 630, loss = 1470645205.56227541\n",
            "Iteration 631, loss = 1470540367.38822532\n",
            "Iteration 632, loss = 1470435000.10961771\n",
            "Iteration 633, loss = 1470329634.88341999\n",
            "Iteration 634, loss = 1470224475.05283237\n",
            "Iteration 635, loss = 1470120048.70572305\n",
            "Iteration 636, loss = 1470014386.64089894\n",
            "Iteration 637, loss = 1469909457.04567313\n",
            "Iteration 638, loss = 1469804894.51862097\n",
            "Iteration 639, loss = 1469699466.28572679\n",
            "Iteration 640, loss = 1469595112.92777491\n",
            "Iteration 641, loss = 1469488922.70656681\n",
            "Iteration 642, loss = 1469385147.68176365\n",
            "Iteration 643, loss = 1469279699.01014185\n",
            "Iteration 644, loss = 1469174861.14208317\n",
            "Iteration 645, loss = 1469070023.06647515\n",
            "Iteration 646, loss = 1468965540.70489931\n",
            "Iteration 647, loss = 1468859979.38230133\n",
            "Iteration 648, loss = 1468755698.13893223\n",
            "Iteration 649, loss = 1468650405.77192545\n",
            "Iteration 650, loss = 1468546149.52502823\n",
            "Iteration 651, loss = 1468440820.01526737\n",
            "Iteration 652, loss = 1468335779.28960824\n",
            "Iteration 653, loss = 1468231075.36387300\n",
            "Iteration 654, loss = 1468125335.58064151\n",
            "Iteration 655, loss = 1468021445.31844878\n",
            "Iteration 656, loss = 1467915446.58742094\n",
            "Iteration 657, loss = 1467810771.52805567\n",
            "Iteration 658, loss = 1467706305.53129029\n",
            "Iteration 659, loss = 1467601054.18432736\n",
            "Iteration 660, loss = 1467497280.75817227\n",
            "Iteration 661, loss = 1467391990.04930019\n",
            "Iteration 662, loss = 1467287354.47917724\n",
            "Iteration 663, loss = 1467183277.95655560\n",
            "Iteration 664, loss = 1467078228.53995752\n",
            "Iteration 665, loss = 1466973763.25210333\n",
            "Iteration 666, loss = 1466869150.29063749\n",
            "Iteration 667, loss = 1466764557.82785821\n",
            "Iteration 668, loss = 1466659618.06102085\n",
            "Iteration 669, loss = 1466555417.71999264\n",
            "Iteration 670, loss = 1466450858.99401951\n",
            "Iteration 671, loss = 1466346329.83965945\n",
            "Iteration 672, loss = 1466242109.11928511\n",
            "Iteration 673, loss = 1466138094.10089183\n",
            "Iteration 674, loss = 1466033868.70366192\n",
            "Iteration 675, loss = 1465929690.60510278\n",
            "Iteration 676, loss = 1465825542.96530914\n",
            "Iteration 677, loss = 1465721687.88087678\n",
            "Iteration 678, loss = 1465616728.40095663\n",
            "Iteration 679, loss = 1465513332.26953244\n",
            "Iteration 680, loss = 1465408515.12726259\n",
            "Iteration 681, loss = 1465304179.64134598\n",
            "Iteration 682, loss = 1465199692.59715104\n",
            "Iteration 683, loss = 1465095801.23413968\n",
            "Iteration 684, loss = 1464991013.49522400\n",
            "Iteration 685, loss = 1464886239.88829494\n",
            "Iteration 686, loss = 1464782090.42375326\n",
            "Iteration 687, loss = 1464677230.26866841\n",
            "Iteration 688, loss = 1464572475.68567657\n",
            "Iteration 689, loss = 1464467909.99765158\n",
            "Iteration 690, loss = 1464362920.55371523\n",
            "Iteration 691, loss = 1464259038.52853012\n",
            "Iteration 692, loss = 1464153193.80357552\n",
            "Iteration 693, loss = 1464048617.50850892\n",
            "Iteration 694, loss = 1463943934.79695892\n",
            "Iteration 695, loss = 1463838784.93895555\n",
            "Iteration 696, loss = 1463733960.44368124\n",
            "Iteration 697, loss = 1463628741.37799120\n",
            "Iteration 698, loss = 1463523743.87206674\n",
            "Iteration 699, loss = 1463419318.98866963\n",
            "Iteration 700, loss = 1463313957.38115454\n",
            "Iteration 701, loss = 1463209500.09814262\n",
            "Iteration 702, loss = 1463104556.82005906\n",
            "Iteration 703, loss = 1462999705.16596389\n",
            "Iteration 704, loss = 1462895079.71592855\n",
            "Iteration 705, loss = 1462789476.89934540\n",
            "Iteration 706, loss = 1462685252.52771330\n",
            "Iteration 707, loss = 1462581273.47947955\n",
            "Iteration 708, loss = 1462475458.88418245\n",
            "Iteration 709, loss = 1462371204.15483689\n",
            "Iteration 710, loss = 1462267339.15962219\n",
            "Iteration 711, loss = 1462161861.34995127\n",
            "Iteration 712, loss = 1462057141.25231647\n",
            "Iteration 713, loss = 1461952879.12124586\n",
            "Iteration 714, loss = 1461848178.69572449\n",
            "Iteration 715, loss = 1461743769.30615401\n",
            "Iteration 716, loss = 1461638018.76551008\n",
            "Iteration 717, loss = 1461534677.61672854\n",
            "Iteration 718, loss = 1461429157.27066779\n",
            "Iteration 719, loss = 1461324273.06672955\n",
            "Iteration 720, loss = 1461219946.01035595\n",
            "Iteration 721, loss = 1461114878.30024529\n",
            "Iteration 722, loss = 1461009854.79190636\n",
            "Iteration 723, loss = 1460905256.38925409\n",
            "Iteration 724, loss = 1460799805.93368220\n",
            "Iteration 725, loss = 1460694507.70189047\n",
            "Iteration 726, loss = 1460589838.59555578\n",
            "Iteration 727, loss = 1460484130.50137067\n",
            "Iteration 728, loss = 1460379725.33478785\n",
            "Iteration 729, loss = 1460273862.86304402\n",
            "Iteration 730, loss = 1460168574.02031827\n",
            "Iteration 731, loss = 1460063791.11972022\n",
            "Iteration 732, loss = 1459958461.17336512\n",
            "Iteration 733, loss = 1459853947.79068375\n",
            "Iteration 734, loss = 1459748731.25351048\n",
            "Iteration 735, loss = 1459644061.49620438\n",
            "Iteration 736, loss = 1459539433.21904874\n",
            "Iteration 737, loss = 1459435276.06260610\n",
            "Iteration 738, loss = 1459330892.88779187\n",
            "Iteration 739, loss = 1459226619.67424583\n",
            "Iteration 740, loss = 1459122058.98025417\n",
            "Iteration 741, loss = 1459018349.73654103\n",
            "Iteration 742, loss = 1458914191.24288344\n",
            "Iteration 743, loss = 1458809243.70089817\n",
            "Iteration 744, loss = 1458705221.17650390\n",
            "Iteration 745, loss = 1458600679.01691604\n",
            "Iteration 746, loss = 1458496410.98991847\n",
            "Iteration 747, loss = 1458391241.67812824\n",
            "Iteration 748, loss = 1458286976.68853354\n",
            "Iteration 749, loss = 1458182575.86712956\n",
            "Iteration 750, loss = 1458077131.51991153\n",
            "Iteration 751, loss = 1457971741.22298241\n",
            "Iteration 752, loss = 1457867541.50741315\n",
            "Iteration 753, loss = 1457762207.14771414\n",
            "Iteration 754, loss = 1457657353.05881548\n",
            "Iteration 755, loss = 1457551909.15501857\n",
            "Iteration 756, loss = 1457447034.60627699\n",
            "Iteration 757, loss = 1457342535.26479745\n",
            "Iteration 758, loss = 1457238003.15901732\n",
            "Iteration 759, loss = 1457132790.04700637\n",
            "Iteration 760, loss = 1457028620.39117241\n",
            "Iteration 761, loss = 1456923877.74450660\n",
            "Iteration 762, loss = 1456819203.44900036\n",
            "Iteration 763, loss = 1456714784.46372724\n",
            "Iteration 764, loss = 1456610450.22556448\n",
            "Iteration 765, loss = 1456505566.35632300\n",
            "Iteration 766, loss = 1456400949.92195678\n",
            "Iteration 767, loss = 1456297015.44640827\n",
            "Iteration 768, loss = 1456192638.28335381\n",
            "Iteration 769, loss = 1456088408.76429105\n",
            "Iteration 770, loss = 1455983849.13290524\n",
            "Iteration 771, loss = 1455879694.13537598\n",
            "Iteration 772, loss = 1455775136.55392504\n",
            "Iteration 773, loss = 1455671260.69694567\n",
            "Iteration 774, loss = 1455566876.99867702\n",
            "Iteration 775, loss = 1455461823.19318390\n",
            "Iteration 776, loss = 1455357548.32181072\n",
            "Iteration 777, loss = 1455252826.24361444\n",
            "Iteration 778, loss = 1455148619.78681731\n",
            "Iteration 779, loss = 1455043174.34228992\n",
            "Iteration 780, loss = 1454938512.69748068\n",
            "Iteration 781, loss = 1454833532.08613062\n",
            "Iteration 782, loss = 1454729276.35493708\n",
            "Iteration 783, loss = 1454624439.06433892\n",
            "Iteration 784, loss = 1454519721.26117849\n",
            "Iteration 785, loss = 1454415383.03209281\n",
            "Iteration 786, loss = 1454310606.17809176\n",
            "Iteration 787, loss = 1454206716.31431413\n",
            "Iteration 788, loss = 1454101634.38070774\n",
            "Iteration 789, loss = 1453997973.73895383\n",
            "Iteration 790, loss = 1453893284.92703867\n",
            "Iteration 791, loss = 1453789129.29108024\n",
            "Iteration 792, loss = 1453684504.20967269\n",
            "Iteration 793, loss = 1453579820.61785078\n",
            "Iteration 794, loss = 1453475781.70439076\n",
            "Iteration 795, loss = 1453371039.00404167\n",
            "Iteration 796, loss = 1453267140.66010189\n",
            "Iteration 797, loss = 1453161990.13372207\n",
            "Iteration 798, loss = 1453057525.01469302\n",
            "Iteration 799, loss = 1452953578.76009631\n",
            "Iteration 800, loss = 1452848849.51439309\n",
            "Iteration 801, loss = 1452743852.95157599\n",
            "Iteration 802, loss = 1452639704.46852708\n",
            "Iteration 803, loss = 1452535217.82606173\n",
            "Iteration 804, loss = 1452430272.77779174\n",
            "Iteration 805, loss = 1452326465.79472446\n",
            "Iteration 806, loss = 1452222342.85719848\n",
            "Iteration 807, loss = 1452117556.62919021\n",
            "Iteration 808, loss = 1452013754.25333214\n",
            "Iteration 809, loss = 1451909713.85295320\n",
            "Iteration 810, loss = 1451805779.82651091\n",
            "Iteration 811, loss = 1451701424.96749759\n",
            "Iteration 812, loss = 1451597529.67456651\n",
            "Iteration 813, loss = 1451494185.30931592\n",
            "Iteration 814, loss = 1451389259.33972955\n",
            "Iteration 815, loss = 1451285773.48831916\n",
            "Iteration 816, loss = 1451182323.85304761\n",
            "Iteration 817, loss = 1451078450.36180854\n",
            "Iteration 818, loss = 1450974293.21240234\n",
            "Iteration 819, loss = 1450870742.08224225\n",
            "Iteration 820, loss = 1450766479.13322353\n",
            "Iteration 821, loss = 1450661592.47538280\n",
            "Iteration 822, loss = 1450558703.39418888\n",
            "Iteration 823, loss = 1450454113.94271159\n",
            "Iteration 824, loss = 1450349884.09150314\n",
            "Iteration 825, loss = 1450246202.24328065\n",
            "Iteration 826, loss = 1450141766.02424788\n",
            "Iteration 827, loss = 1450038038.33827424\n",
            "Iteration 828, loss = 1449934846.70813322\n",
            "Iteration 829, loss = 1449830781.70556927\n",
            "Iteration 830, loss = 1449726996.81008291\n",
            "Iteration 831, loss = 1449622806.26272607\n",
            "Iteration 832, loss = 1449519445.97038174\n",
            "Iteration 833, loss = 1449415440.20290852\n",
            "Iteration 834, loss = 1449311261.59206533\n",
            "Iteration 835, loss = 1449206838.93276262\n",
            "Iteration 836, loss = 1449102603.88337517\n",
            "Iteration 837, loss = 1448998183.95083237\n",
            "Iteration 838, loss = 1448893846.30224752\n",
            "Iteration 839, loss = 1448789004.44914079\n",
            "Iteration 840, loss = 1448685688.20652080\n",
            "Iteration 841, loss = 1448580408.76059437\n",
            "Iteration 842, loss = 1448476522.62877631\n",
            "Iteration 843, loss = 1448372010.27054238\n",
            "Iteration 844, loss = 1448268153.42875981\n",
            "Iteration 845, loss = 1448163824.57846594\n",
            "Iteration 846, loss = 1448060310.33993006\n",
            "Iteration 847, loss = 1447956456.71457195\n",
            "Iteration 848, loss = 1447852703.76313210\n",
            "Iteration 849, loss = 1447748869.56169510\n",
            "Iteration 850, loss = 1447645263.34174895\n",
            "Iteration 851, loss = 1447542245.10503292\n",
            "Iteration 852, loss = 1447438266.84508157\n",
            "Iteration 853, loss = 1447334512.60431767\n",
            "Iteration 854, loss = 1447230837.98121142\n",
            "Iteration 855, loss = 1447126774.75823069\n",
            "Iteration 856, loss = 1447022526.11989212\n",
            "Iteration 857, loss = 1446918751.03234649\n",
            "Iteration 858, loss = 1446815006.27902007\n",
            "Iteration 859, loss = 1446710844.10239577\n",
            "Iteration 860, loss = 1446607055.05511975\n",
            "Iteration 861, loss = 1446502844.03693962\n",
            "Iteration 862, loss = 1446399727.15230083\n",
            "Iteration 863, loss = 1446295899.05713916\n",
            "Iteration 864, loss = 1446191783.87925053\n",
            "Iteration 865, loss = 1446088701.26489139\n",
            "Iteration 866, loss = 1445985155.38378215\n",
            "Iteration 867, loss = 1445882060.63385916\n",
            "Iteration 868, loss = 1445778196.15353036\n",
            "Iteration 869, loss = 1445674988.11935234\n",
            "Iteration 870, loss = 1445572228.96567321\n",
            "Iteration 871, loss = 1445468944.58563828\n",
            "Iteration 872, loss = 1445365317.48519945\n",
            "Iteration 873, loss = 1445262295.34555507\n",
            "Iteration 874, loss = 1445159316.90183735\n",
            "Iteration 875, loss = 1445056062.59383965\n",
            "Iteration 876, loss = 1444953292.60393620\n",
            "Iteration 877, loss = 1444850208.11330366\n",
            "Iteration 878, loss = 1444747027.14776301\n",
            "Iteration 879, loss = 1444644552.19816780\n",
            "Iteration 880, loss = 1444541884.07222438\n",
            "Iteration 881, loss = 1444438638.69085670\n",
            "Iteration 882, loss = 1444335971.90151024\n",
            "Iteration 883, loss = 1444232779.06891775\n",
            "Iteration 884, loss = 1444129104.75329924\n",
            "Iteration 885, loss = 1444025366.63800335\n",
            "Iteration 886, loss = 1443922229.40488553\n",
            "Iteration 887, loss = 1443817804.38477421\n",
            "Iteration 888, loss = 1443714078.85086846\n",
            "Iteration 889, loss = 1443610126.14858603\n",
            "Iteration 890, loss = 1443507001.80496502\n",
            "Iteration 891, loss = 1443402174.99590683\n",
            "Iteration 892, loss = 1443298910.50628448\n",
            "Iteration 893, loss = 1443194967.08946514\n",
            "Iteration 894, loss = 1443091887.80544353\n",
            "Iteration 895, loss = 1442987658.25019693\n",
            "Iteration 896, loss = 1442883724.53725624\n",
            "Iteration 897, loss = 1442779997.87301326\n",
            "Iteration 898, loss = 1442676248.62930751\n",
            "Iteration 899, loss = 1442572643.92741585\n",
            "Iteration 900, loss = 1442468472.05940485\n",
            "Iteration 901, loss = 1442364704.57506418\n",
            "Iteration 902, loss = 1442261775.54117727\n",
            "Iteration 903, loss = 1442156882.10588121\n",
            "Iteration 904, loss = 1442053858.23704982\n",
            "Iteration 905, loss = 1441950176.44239831\n",
            "Iteration 906, loss = 1441846041.32975745\n",
            "Iteration 907, loss = 1441742206.99427772\n",
            "Iteration 908, loss = 1441639193.76800227\n",
            "Iteration 909, loss = 1441535968.85197330\n",
            "Iteration 910, loss = 1441432699.57849813\n",
            "Iteration 911, loss = 1441330026.35505366\n",
            "Iteration 912, loss = 1441226925.59136701\n",
            "Iteration 913, loss = 1441124618.64923286\n",
            "Iteration 914, loss = 1441022329.82675600\n",
            "Iteration 915, loss = 1440919468.21791363\n",
            "Iteration 916, loss = 1440817460.67740273\n",
            "Iteration 917, loss = 1440714192.14044714\n",
            "Iteration 918, loss = 1440611896.34547806\n",
            "Iteration 919, loss = 1440508774.47759008\n",
            "Iteration 920, loss = 1440406613.04808259\n",
            "Iteration 921, loss = 1440303057.20296836\n",
            "Iteration 922, loss = 1440199732.42998242\n",
            "Iteration 923, loss = 1440096360.77993107\n",
            "Iteration 924, loss = 1439993482.66670585\n",
            "Iteration 925, loss = 1439889974.17526555\n",
            "Iteration 926, loss = 1439785830.58766198\n",
            "Iteration 927, loss = 1439682614.42540431\n",
            "Iteration 928, loss = 1439578923.24573779\n",
            "Iteration 929, loss = 1439475001.92434192\n",
            "Iteration 930, loss = 1439371834.34138489\n",
            "Iteration 931, loss = 1439267826.15915060\n",
            "Iteration 932, loss = 1439164663.46443129\n",
            "Iteration 933, loss = 1439060068.48365760\n",
            "Iteration 934, loss = 1438956823.96819019\n",
            "Iteration 935, loss = 1438853420.33608747\n",
            "Iteration 936, loss = 1438749502.79044914\n",
            "Iteration 937, loss = 1438646170.96144009\n",
            "Iteration 938, loss = 1438542387.36507702\n",
            "Iteration 939, loss = 1438438754.75270748\n",
            "Iteration 940, loss = 1438335465.62312341\n",
            "Iteration 941, loss = 1438231613.01102352\n",
            "Iteration 942, loss = 1438128380.38597012\n",
            "Iteration 943, loss = 1438023805.16807437\n",
            "Iteration 944, loss = 1437920469.85876083\n",
            "Iteration 945, loss = 1437817250.87345219\n",
            "Iteration 946, loss = 1437713559.31862473\n",
            "Iteration 947, loss = 1437609221.04213572\n",
            "Iteration 948, loss = 1437506349.61383080\n",
            "Iteration 949, loss = 1437403034.96353817\n",
            "Iteration 950, loss = 1437299054.87380171\n",
            "Iteration 951, loss = 1437195399.32336712\n",
            "Iteration 952, loss = 1437091938.64430165\n",
            "Iteration 953, loss = 1436988350.40118909\n",
            "Iteration 954, loss = 1436884586.16459560\n",
            "Iteration 955, loss = 1436780907.99398828\n",
            "Iteration 956, loss = 1436678311.05437303\n",
            "Iteration 957, loss = 1436574530.25275230\n",
            "Iteration 958, loss = 1436471083.65540528\n",
            "Iteration 959, loss = 1436368808.56661510\n",
            "Iteration 960, loss = 1436265231.10846305\n",
            "Iteration 961, loss = 1436163164.95911956\n",
            "Iteration 962, loss = 1436059582.63511562\n",
            "Iteration 963, loss = 1435956642.51442075\n",
            "Iteration 964, loss = 1435853370.78906775\n",
            "Iteration 965, loss = 1435750674.12027431\n",
            "Iteration 966, loss = 1435647352.46344495\n",
            "Iteration 967, loss = 1435543448.61717868\n",
            "Iteration 968, loss = 1435441165.40798688\n",
            "Iteration 969, loss = 1435337111.29925275\n",
            "Iteration 970, loss = 1435233884.63268757\n",
            "Iteration 971, loss = 1435130234.67003965\n",
            "Iteration 972, loss = 1435026704.11349988\n",
            "Iteration 973, loss = 1434922873.82785749\n",
            "Iteration 974, loss = 1434819123.76669002\n",
            "Iteration 975, loss = 1434715112.32582283\n",
            "Iteration 976, loss = 1434611850.00009537\n",
            "Iteration 977, loss = 1434507240.38974667\n",
            "Iteration 978, loss = 1434404221.92594147\n",
            "Iteration 979, loss = 1434300545.28945446\n",
            "Iteration 980, loss = 1434197598.26219010\n",
            "Iteration 981, loss = 1434094620.66724563\n",
            "Iteration 982, loss = 1433990533.95848584\n",
            "Iteration 983, loss = 1433887393.52503467\n",
            "Iteration 984, loss = 1433784454.89213300\n",
            "Iteration 985, loss = 1433681324.90618229\n",
            "Iteration 986, loss = 1433577805.01711845\n",
            "Iteration 987, loss = 1433474224.87194109\n",
            "Iteration 988, loss = 1433371102.05661058\n",
            "Iteration 989, loss = 1433267874.68009138\n",
            "Iteration 990, loss = 1433163959.09919691\n",
            "Iteration 991, loss = 1433060978.33254933\n",
            "Iteration 992, loss = 1432957738.51585269\n",
            "Iteration 993, loss = 1432853596.47211003\n",
            "Iteration 994, loss = 1432751222.78418565\n",
            "Iteration 995, loss = 1432647009.57932019\n",
            "Iteration 996, loss = 1432543496.92653179\n",
            "Iteration 997, loss = 1432441300.73737383\n",
            "Iteration 998, loss = 1432336986.44599724\n",
            "Iteration 999, loss = 1432233812.28792453\n",
            "Iteration 1000, loss = 1432130767.10486984\n",
            "Iteration 1, loss = 1327712804.40553069\n",
            "Iteration 2, loss = 185878143.24777225\n",
            "Iteration 3, loss = 174549986.48420885\n",
            "Iteration 4, loss = 102362270.10194613\n",
            "Iteration 5, loss = 103013901.18131956\n",
            "Iteration 6, loss = 103802019.65021892\n",
            "Iteration 7, loss = 96597217.06666225\n",
            "Iteration 8, loss = 96000888.81979282\n",
            "Iteration 9, loss = 96490852.66615887\n",
            "Iteration 10, loss = 97586793.45044836\n",
            "Iteration 11, loss = 96267441.50720888\n",
            "Iteration 12, loss = 95645290.18365721\n",
            "Iteration 13, loss = 95844503.44045879\n",
            "Iteration 14, loss = 96130810.96660498\n",
            "Iteration 15, loss = 98133965.99664253\n",
            "Iteration 16, loss = 96343395.04065906\n",
            "Iteration 17, loss = 95873525.57574391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 18, loss = 95777132.22626689\n",
            "Iteration 19, loss = 95961417.50622648\n",
            "Iteration 20, loss = 96184716.21059769\n",
            "Iteration 21, loss = 95905887.51580526\n",
            "Iteration 22, loss = 96024659.71495332\n",
            "Iteration 23, loss = 97775623.47664247\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538787974.21251607\n",
            "Iteration 2, loss = 1538652055.51994848\n",
            "Iteration 3, loss = 1538541054.55697751\n",
            "Iteration 4, loss = 1538452286.93732405\n",
            "Iteration 5, loss = 1538372541.07519817\n",
            "Iteration 6, loss = 1538295004.33286023\n",
            "Iteration 7, loss = 1538215917.03220892\n",
            "Iteration 8, loss = 1538132281.50493455\n",
            "Iteration 9, loss = 1538046890.36464500\n",
            "Iteration 10, loss = 1537962247.89453530\n",
            "Iteration 11, loss = 1537879229.97570562\n",
            "Iteration 12, loss = 1537797785.23642015\n",
            "Iteration 13, loss = 1537716527.60072088\n",
            "Iteration 14, loss = 1537634611.15377426\n",
            "Iteration 15, loss = 1537550405.16903567\n",
            "Iteration 16, loss = 1537464036.54036093\n",
            "Iteration 17, loss = 1537377826.10892892\n",
            "Iteration 18, loss = 1537290752.96705794\n",
            "Iteration 19, loss = 1537205129.36697698\n",
            "Iteration 20, loss = 1537118917.12705755\n",
            "Iteration 21, loss = 1537029881.02676034\n",
            "Iteration 22, loss = 1536941570.32272220\n",
            "Iteration 23, loss = 1536852743.92230892\n",
            "Iteration 24, loss = 1536763836.00038934\n",
            "Iteration 25, loss = 1536673612.08936715\n",
            "Iteration 26, loss = 1536580796.30599809\n",
            "Iteration 27, loss = 1536483604.32874036\n",
            "Iteration 28, loss = 1536382816.93506145\n",
            "Iteration 29, loss = 1536281893.83724904\n",
            "Iteration 30, loss = 1536183627.22860599\n",
            "Iteration 31, loss = 1536086237.42407107\n",
            "Iteration 32, loss = 1535990251.33896279\n",
            "Iteration 33, loss = 1535893683.68060684\n",
            "Iteration 34, loss = 1535797669.68800545\n",
            "Iteration 35, loss = 1535700811.97715378\n",
            "Iteration 36, loss = 1535605460.15968966\n",
            "Iteration 37, loss = 1535508364.84225368\n",
            "Iteration 38, loss = 1535410763.55630755\n",
            "Iteration 39, loss = 1535311879.38630009\n",
            "Iteration 40, loss = 1535214593.11427546\n",
            "Iteration 41, loss = 1535118673.16914105\n",
            "Iteration 42, loss = 1535021393.67304659\n",
            "Iteration 43, loss = 1534924868.05012631\n",
            "Iteration 44, loss = 1534828552.47839570\n",
            "Iteration 45, loss = 1534732611.91070008\n",
            "Iteration 46, loss = 1534637076.65930319\n",
            "Iteration 47, loss = 1534541082.84794950\n",
            "Iteration 48, loss = 1534445286.93322730\n",
            "Iteration 49, loss = 1534349755.76486731\n",
            "Iteration 50, loss = 1534253197.04167795\n",
            "Iteration 51, loss = 1534155539.94377708\n",
            "Iteration 52, loss = 1534056709.73461103\n",
            "Iteration 53, loss = 1533959811.04255676\n",
            "Iteration 54, loss = 1533863445.16943932\n",
            "Iteration 55, loss = 1533765927.36171436\n",
            "Iteration 56, loss = 1533669863.09528041\n",
            "Iteration 57, loss = 1533573131.89688802\n",
            "Iteration 58, loss = 1533476877.81582832\n",
            "Iteration 59, loss = 1533380367.49501228\n",
            "Iteration 60, loss = 1533284407.01585531\n",
            "Iteration 61, loss = 1533189072.98057652\n",
            "Iteration 62, loss = 1533093101.52653933\n",
            "Iteration 63, loss = 1532997388.98660994\n",
            "Iteration 64, loss = 1532901949.47315693\n",
            "Iteration 65, loss = 1532806756.36464739\n",
            "Iteration 66, loss = 1532710116.94617033\n",
            "Iteration 67, loss = 1532611691.49900436\n",
            "Iteration 68, loss = 1532506971.79011703\n",
            "Iteration 69, loss = 1532401196.40277600\n",
            "Iteration 70, loss = 1532298248.00209856\n",
            "Iteration 71, loss = 1532195768.24664712\n",
            "Iteration 72, loss = 1532093498.74304628\n",
            "Iteration 73, loss = 1531991977.15187001\n",
            "Iteration 74, loss = 1531890082.94041848\n",
            "Iteration 75, loss = 1531788255.30758572\n",
            "Iteration 76, loss = 1531687434.88496685\n",
            "Iteration 77, loss = 1531586135.61466789\n",
            "Iteration 78, loss = 1531484888.28067327\n",
            "Iteration 79, loss = 1531381348.74236202\n",
            "Iteration 80, loss = 1531276265.86104560\n",
            "Iteration 81, loss = 1531172909.37773108\n",
            "Iteration 82, loss = 1531070368.06142569\n",
            "Iteration 83, loss = 1530967417.35596728\n",
            "Iteration 84, loss = 1530865096.79624295\n",
            "Iteration 85, loss = 1530761454.91538978\n",
            "Iteration 86, loss = 1530655928.53440142\n",
            "Iteration 87, loss = 1530550920.74251676\n",
            "Iteration 88, loss = 1530446462.79575014\n",
            "Iteration 89, loss = 1530341944.75977921\n",
            "Iteration 90, loss = 1530237646.78827500\n",
            "Iteration 91, loss = 1530130657.61963654\n",
            "Iteration 92, loss = 1530023098.50242925\n",
            "Iteration 93, loss = 1529915630.38331389\n",
            "Iteration 94, loss = 1529809372.88496208\n",
            "Iteration 95, loss = 1529703035.32747459\n",
            "Iteration 96, loss = 1529596950.39087129\n",
            "Iteration 97, loss = 1529491164.52500916\n",
            "Iteration 98, loss = 1529384563.47858739\n",
            "Iteration 99, loss = 1529280269.79129839\n",
            "Iteration 100, loss = 1529174644.01323986\n",
            "Iteration 101, loss = 1529070008.87087655\n",
            "Iteration 102, loss = 1528966071.16800857\n",
            "Iteration 103, loss = 1528861154.86527252\n",
            "Iteration 104, loss = 1528757932.49028683\n",
            "Iteration 105, loss = 1528654712.87769103\n",
            "Iteration 106, loss = 1528551062.77674222\n",
            "Iteration 107, loss = 1528448233.40098071\n",
            "Iteration 108, loss = 1528345137.44274020\n",
            "Iteration 109, loss = 1528242511.75907707\n",
            "Iteration 110, loss = 1528140720.19701409\n",
            "Iteration 111, loss = 1528038120.43475699\n",
            "Iteration 112, loss = 1527935818.77836394\n",
            "Iteration 113, loss = 1527833918.79666567\n",
            "Iteration 114, loss = 1527732001.67165327\n",
            "Iteration 115, loss = 1527630170.86918879\n",
            "Iteration 116, loss = 1527528032.62042999\n",
            "Iteration 117, loss = 1527425884.49958706\n",
            "Iteration 118, loss = 1527324556.43355393\n",
            "Iteration 119, loss = 1527222894.09241748\n",
            "Iteration 120, loss = 1527121390.19567728\n",
            "Iteration 121, loss = 1527020065.09941626\n",
            "Iteration 122, loss = 1526919395.50552559\n",
            "Iteration 123, loss = 1526817606.39000058\n",
            "Iteration 124, loss = 1526716757.24622846\n",
            "Iteration 125, loss = 1526616071.17862177\n",
            "Iteration 126, loss = 1526514228.51832604\n",
            "Iteration 127, loss = 1526411577.62075758\n",
            "Iteration 128, loss = 1526306252.44465327\n",
            "Iteration 129, loss = 1526201117.03413224\n",
            "Iteration 130, loss = 1526097968.41890216\n",
            "Iteration 131, loss = 1525993649.29970908\n",
            "Iteration 132, loss = 1525889500.20961976\n",
            "Iteration 133, loss = 1525786266.15546918\n",
            "Iteration 134, loss = 1525681170.58145046\n",
            "Iteration 135, loss = 1525578400.81947136\n",
            "Iteration 136, loss = 1525474882.07700372\n",
            "Iteration 137, loss = 1525371206.18876410\n",
            "Iteration 138, loss = 1525268474.72447920\n",
            "Iteration 139, loss = 1525165575.83547068\n",
            "Iteration 140, loss = 1525062708.44043684\n",
            "Iteration 141, loss = 1524960905.04099965\n",
            "Iteration 142, loss = 1524858302.40151191\n",
            "Iteration 143, loss = 1524756779.16635418\n",
            "Iteration 144, loss = 1524655067.47701097\n",
            "Iteration 145, loss = 1524553277.01636457\n",
            "Iteration 146, loss = 1524451902.29027796\n",
            "Iteration 147, loss = 1524350377.11802506\n",
            "Iteration 148, loss = 1524248908.80053616\n",
            "Iteration 149, loss = 1524146457.23890185\n",
            "Iteration 150, loss = 1524041148.51455164\n",
            "Iteration 151, loss = 1523935719.51630139\n",
            "Iteration 152, loss = 1523831353.60339093\n",
            "Iteration 153, loss = 1523726541.96304703\n",
            "Iteration 154, loss = 1523621502.39062881\n",
            "Iteration 155, loss = 1523516216.87665939\n",
            "Iteration 156, loss = 1523411201.33311582\n",
            "Iteration 157, loss = 1523306478.56690407\n",
            "Iteration 158, loss = 1523201751.92585349\n",
            "Iteration 159, loss = 1523096665.05365181\n",
            "Iteration 160, loss = 1522992057.67230248\n",
            "Iteration 161, loss = 1522887885.10299492\n",
            "Iteration 162, loss = 1522783235.51945567\n",
            "Iteration 163, loss = 1522679415.49693322\n",
            "Iteration 164, loss = 1522575280.43114400\n",
            "Iteration 165, loss = 1522471941.56271529\n",
            "Iteration 166, loss = 1522367669.33739352\n",
            "Iteration 167, loss = 1522264707.91642165\n",
            "Iteration 168, loss = 1522161108.39252257\n",
            "Iteration 169, loss = 1522058579.27552533\n",
            "Iteration 170, loss = 1521954625.86632133\n",
            "Iteration 171, loss = 1521853238.18081117\n",
            "Iteration 172, loss = 1521749569.14183211\n",
            "Iteration 173, loss = 1521647212.14236212\n",
            "Iteration 174, loss = 1521544962.38565803\n",
            "Iteration 175, loss = 1521443027.33071876\n",
            "Iteration 176, loss = 1521340463.84668612\n",
            "Iteration 177, loss = 1521238012.55029488\n",
            "Iteration 178, loss = 1521135987.68990302\n",
            "Iteration 179, loss = 1521033844.46300626\n",
            "Iteration 180, loss = 1520931189.37033844\n",
            "Iteration 181, loss = 1520828971.18868756\n",
            "Iteration 182, loss = 1520726920.40882087\n",
            "Iteration 183, loss = 1520624461.25007415\n",
            "Iteration 184, loss = 1520522322.69083452\n",
            "Iteration 185, loss = 1520420148.41801953\n",
            "Iteration 186, loss = 1520318033.81621313\n",
            "Iteration 187, loss = 1520216173.61712718\n",
            "Iteration 188, loss = 1520114373.24320507\n",
            "Iteration 189, loss = 1520012665.61100721\n",
            "Iteration 190, loss = 1519911353.74274230\n",
            "Iteration 191, loss = 1519809984.81797719\n",
            "Iteration 192, loss = 1519708056.32512474\n",
            "Iteration 193, loss = 1519607965.39883327\n",
            "Iteration 194, loss = 1519506061.01161528\n",
            "Iteration 195, loss = 1519405233.58429694\n",
            "Iteration 196, loss = 1519304397.13768077\n",
            "Iteration 197, loss = 1519203648.33459806\n",
            "Iteration 198, loss = 1519102584.24481153\n",
            "Iteration 199, loss = 1519000125.78357148\n",
            "Iteration 200, loss = 1518894339.79302549\n",
            "Iteration 201, loss = 1518789577.20667720\n",
            "Iteration 202, loss = 1518684985.96718550\n",
            "Iteration 203, loss = 1518579109.64062500\n",
            "Iteration 204, loss = 1518470640.88294935\n",
            "Iteration 205, loss = 1518359990.28479838\n",
            "Iteration 206, loss = 1518251369.83963299\n",
            "Iteration 207, loss = 1518142359.05807304\n",
            "Iteration 208, loss = 1518033600.16152573\n",
            "Iteration 209, loss = 1517924358.69112587\n",
            "Iteration 210, loss = 1517816635.03292799\n",
            "Iteration 211, loss = 1517706489.41882658\n",
            "Iteration 212, loss = 1517593624.28752279\n",
            "Iteration 213, loss = 1517481283.72531796\n",
            "Iteration 214, loss = 1517369525.57927036\n",
            "Iteration 215, loss = 1517258676.65045118\n",
            "Iteration 216, loss = 1517146694.45235777\n",
            "Iteration 217, loss = 1517035074.07795262\n",
            "Iteration 218, loss = 1516923962.12045431\n",
            "Iteration 219, loss = 1516813252.24715590\n",
            "Iteration 220, loss = 1516702326.83712816\n",
            "Iteration 221, loss = 1516591513.05474925\n",
            "Iteration 222, loss = 1516481414.29071808\n",
            "Iteration 223, loss = 1516371387.05081344\n",
            "Iteration 224, loss = 1516261364.63228226\n",
            "Iteration 225, loss = 1516151135.75070524\n",
            "Iteration 226, loss = 1516040790.47814727\n",
            "Iteration 227, loss = 1515932402.51753521\n",
            "Iteration 228, loss = 1515822573.59293675\n",
            "Iteration 229, loss = 1515712727.81736732\n",
            "Iteration 230, loss = 1515603770.16193581\n",
            "Iteration 231, loss = 1515494586.79637218\n",
            "Iteration 232, loss = 1515386490.75579667\n",
            "Iteration 233, loss = 1515276803.88892031\n",
            "Iteration 234, loss = 1515169410.39334226\n",
            "Iteration 235, loss = 1515060639.18063402\n",
            "Iteration 236, loss = 1514952708.51137447\n",
            "Iteration 237, loss = 1514845312.49308324\n",
            "Iteration 238, loss = 1514737427.23403573\n",
            "Iteration 239, loss = 1514630208.77520180\n",
            "Iteration 240, loss = 1514522781.24665475\n",
            "Iteration 241, loss = 1514416268.08029151\n",
            "Iteration 242, loss = 1514308394.01855230\n",
            "Iteration 243, loss = 1514201417.36170650\n",
            "Iteration 244, loss = 1514092845.54353929\n",
            "Iteration 245, loss = 1513981191.76001716\n",
            "Iteration 246, loss = 1513869873.56704378\n",
            "Iteration 247, loss = 1513758925.10345626\n",
            "Iteration 248, loss = 1513648722.48909497\n",
            "Iteration 249, loss = 1513537121.94682193\n",
            "Iteration 250, loss = 1513426590.95833278\n",
            "Iteration 251, loss = 1513316180.15339375\n",
            "Iteration 252, loss = 1513204853.14075732\n",
            "Iteration 253, loss = 1513094849.51889825\n",
            "Iteration 254, loss = 1512985145.02489209\n",
            "Iteration 255, loss = 1512875329.66373158\n",
            "Iteration 256, loss = 1512765707.71610379\n",
            "Iteration 257, loss = 1512656593.45705628\n",
            "Iteration 258, loss = 1512547296.63526368\n",
            "Iteration 259, loss = 1512438134.76719594\n",
            "Iteration 260, loss = 1512329332.67362475\n",
            "Iteration 261, loss = 1512220224.92735386\n",
            "Iteration 262, loss = 1512111100.02762294\n",
            "Iteration 263, loss = 1512002656.04593825\n",
            "Iteration 264, loss = 1511893346.42201471\n",
            "Iteration 265, loss = 1511784917.54837656\n",
            "Iteration 266, loss = 1511676460.03375649\n",
            "Iteration 267, loss = 1511566956.75694823\n",
            "Iteration 268, loss = 1511454862.65097880\n",
            "Iteration 269, loss = 1511340669.07767296\n",
            "Iteration 270, loss = 1511228076.84604645\n",
            "Iteration 271, loss = 1511114805.16973042\n",
            "Iteration 272, loss = 1511001798.11722803\n",
            "Iteration 273, loss = 1510889167.42940402\n",
            "Iteration 274, loss = 1510775872.79747057\n",
            "Iteration 275, loss = 1510662505.99387264\n",
            "Iteration 276, loss = 1510550603.23450732\n",
            "Iteration 277, loss = 1510438180.32677770\n",
            "Iteration 278, loss = 1510326257.03471160\n",
            "Iteration 279, loss = 1510215466.94353557\n",
            "Iteration 280, loss = 1510104234.24730706\n",
            "Iteration 281, loss = 1509993351.79280734\n",
            "Iteration 282, loss = 1509883790.05856371\n",
            "Iteration 283, loss = 1509773648.53861713\n",
            "Iteration 284, loss = 1509663561.08871579\n",
            "Iteration 285, loss = 1509553472.11135721\n",
            "Iteration 286, loss = 1509444271.96557856\n",
            "Iteration 287, loss = 1509334684.05955720\n",
            "Iteration 288, loss = 1509224509.90881014\n",
            "Iteration 289, loss = 1509115538.64280963\n",
            "Iteration 290, loss = 1509005687.23418283\n",
            "Iteration 291, loss = 1508897054.57007241\n",
            "Iteration 292, loss = 1508787710.95739412\n",
            "Iteration 293, loss = 1508679029.83806419\n",
            "Iteration 294, loss = 1508570150.62606740\n",
            "Iteration 295, loss = 1508462050.87718558\n",
            "Iteration 296, loss = 1508353207.41495347\n",
            "Iteration 297, loss = 1508245710.09788489\n",
            "Iteration 298, loss = 1508137606.91745067\n",
            "Iteration 299, loss = 1508029300.78509116\n",
            "Iteration 300, loss = 1507921131.57480192\n",
            "Iteration 301, loss = 1507813447.94182491\n",
            "Iteration 302, loss = 1507705088.50803971\n",
            "Iteration 303, loss = 1507596252.71021748\n",
            "Iteration 304, loss = 1507486363.66639614\n",
            "Iteration 305, loss = 1507371071.44548321\n",
            "Iteration 306, loss = 1507259010.06866741\n",
            "Iteration 307, loss = 1507145797.16996503\n",
            "Iteration 308, loss = 1507033318.47335410\n",
            "Iteration 309, loss = 1506920667.33091116\n",
            "Iteration 310, loss = 1506807586.69901109\n",
            "Iteration 311, loss = 1506695312.16895747\n",
            "Iteration 312, loss = 1506582701.87858868\n",
            "Iteration 313, loss = 1506470511.62842488\n",
            "Iteration 314, loss = 1506357743.67836070\n",
            "Iteration 315, loss = 1506245041.51953506\n",
            "Iteration 316, loss = 1506127061.91713643\n",
            "Iteration 317, loss = 1506010777.24546385\n",
            "Iteration 318, loss = 1505894295.59040666\n",
            "Iteration 319, loss = 1505777360.04737425\n",
            "Iteration 320, loss = 1505661949.53158712\n",
            "Iteration 321, loss = 1505544563.32332134\n",
            "Iteration 322, loss = 1505428661.21427512\n",
            "Iteration 323, loss = 1505312995.92085719\n",
            "Iteration 324, loss = 1505196993.33938956\n",
            "Iteration 325, loss = 1505081940.11423588\n",
            "Iteration 326, loss = 1504966597.24590969\n",
            "Iteration 327, loss = 1504852067.15711737\n",
            "Iteration 328, loss = 1504737234.15847540\n",
            "Iteration 329, loss = 1504622808.60357022\n",
            "Iteration 330, loss = 1504508061.57851267\n",
            "Iteration 331, loss = 1504388406.27653456\n",
            "Iteration 332, loss = 1504270330.28838038\n",
            "Iteration 333, loss = 1504152617.48340011\n",
            "Iteration 334, loss = 1504035156.62174177\n",
            "Iteration 335, loss = 1503918002.67220998\n",
            "Iteration 336, loss = 1503800046.71563482\n",
            "Iteration 337, loss = 1503679320.05869555\n",
            "Iteration 338, loss = 1503555687.52445364\n",
            "Iteration 339, loss = 1503434510.38863802\n",
            "Iteration 340, loss = 1503313027.91274261\n",
            "Iteration 341, loss = 1503191359.03798819\n",
            "Iteration 342, loss = 1503070403.08626556\n",
            "Iteration 343, loss = 1502948281.99261236\n",
            "Iteration 344, loss = 1502824849.56105661\n",
            "Iteration 345, loss = 1502697482.77678847\n",
            "Iteration 346, loss = 1502572423.42784619\n",
            "Iteration 347, loss = 1502448277.16771436\n",
            "Iteration 348, loss = 1502322953.76059413\n",
            "Iteration 349, loss = 1502198204.84412503\n",
            "Iteration 350, loss = 1502073600.49917769\n",
            "Iteration 351, loss = 1501950010.10533428\n",
            "Iteration 352, loss = 1501825242.90338492\n",
            "Iteration 353, loss = 1501703187.84713697\n",
            "Iteration 354, loss = 1501578839.92136455\n",
            "Iteration 355, loss = 1501457179.00258446\n",
            "Iteration 356, loss = 1501334448.96123767\n",
            "Iteration 357, loss = 1501211598.76489091\n",
            "Iteration 358, loss = 1501089847.24032831\n",
            "Iteration 359, loss = 1500968020.23809409\n",
            "Iteration 360, loss = 1500846820.47224522\n",
            "Iteration 361, loss = 1500724958.82783270\n",
            "Iteration 362, loss = 1500603775.66198206\n",
            "Iteration 363, loss = 1500483496.59926343\n",
            "Iteration 364, loss = 1500362453.47587180\n",
            "Iteration 365, loss = 1500242403.08181262\n",
            "Iteration 366, loss = 1500122273.68201852\n",
            "Iteration 367, loss = 1500003350.23636103\n",
            "Iteration 368, loss = 1499883794.94825220\n",
            "Iteration 369, loss = 1499765045.29165506\n",
            "Iteration 370, loss = 1499645996.24319911\n",
            "Iteration 371, loss = 1499528481.47846651\n",
            "Iteration 372, loss = 1499409939.41669464\n",
            "Iteration 373, loss = 1499291922.68921280\n",
            "Iteration 374, loss = 1499174647.39437127\n",
            "Iteration 375, loss = 1499056875.76674414\n",
            "Iteration 376, loss = 1498939493.68631911\n",
            "Iteration 377, loss = 1498821887.78373694\n",
            "Iteration 378, loss = 1498704914.00536942\n",
            "Iteration 379, loss = 1498587838.24082208\n",
            "Iteration 380, loss = 1498470662.46551490\n",
            "Iteration 381, loss = 1498354292.03010726\n",
            "Iteration 382, loss = 1498237783.55140328\n",
            "Iteration 383, loss = 1498121126.27850270\n",
            "Iteration 384, loss = 1498004473.67459178\n",
            "Iteration 385, loss = 1497889079.99775553\n",
            "Iteration 386, loss = 1497772580.36974669\n",
            "Iteration 387, loss = 1497656290.70509338\n",
            "Iteration 388, loss = 1497540481.58473182\n",
            "Iteration 389, loss = 1497424855.91550803\n",
            "Iteration 390, loss = 1497309034.21531940\n",
            "Iteration 391, loss = 1497193349.21378636\n",
            "Iteration 392, loss = 1497078097.01605582\n",
            "Iteration 393, loss = 1496962574.24256968\n",
            "Iteration 394, loss = 1496847908.11230087\n",
            "Iteration 395, loss = 1496732601.66991138\n",
            "Iteration 396, loss = 1496618287.40608954\n",
            "Iteration 397, loss = 1496502791.71697807\n",
            "Iteration 398, loss = 1496388654.26150179\n",
            "Iteration 399, loss = 1496273548.17573929\n",
            "Iteration 400, loss = 1496158473.46820974\n",
            "Iteration 401, loss = 1496043952.65759611\n",
            "Iteration 402, loss = 1495928814.35334516\n",
            "Iteration 403, loss = 1495813918.37877011\n",
            "Iteration 404, loss = 1495698933.45511675\n",
            "Iteration 405, loss = 1495584100.79285097\n",
            "Iteration 406, loss = 1495470783.63059235\n",
            "Iteration 407, loss = 1495355294.69977880\n",
            "Iteration 408, loss = 1495241869.56333447\n",
            "Iteration 409, loss = 1495127663.81120110\n",
            "Iteration 410, loss = 1495014524.25479531\n",
            "Iteration 411, loss = 1494900330.53599763\n",
            "Iteration 412, loss = 1494787197.11838102\n",
            "Iteration 413, loss = 1494673345.84394836\n",
            "Iteration 414, loss = 1494559546.40494394\n",
            "Iteration 415, loss = 1494446424.72588253\n",
            "Iteration 416, loss = 1494332625.21343446\n",
            "Iteration 417, loss = 1494219235.14554763\n",
            "Iteration 418, loss = 1494105693.34901667\n",
            "Iteration 419, loss = 1493991307.89564013\n",
            "Iteration 420, loss = 1493878058.07901216\n",
            "Iteration 421, loss = 1493764998.33505607\n",
            "Iteration 422, loss = 1493650712.25993204\n",
            "Iteration 423, loss = 1493537662.43764353\n",
            "Iteration 424, loss = 1493424976.09017730\n",
            "Iteration 425, loss = 1493311939.34160995\n",
            "Iteration 426, loss = 1493198867.86470079\n",
            "Iteration 427, loss = 1493086564.70382881\n",
            "Iteration 428, loss = 1492973993.65053320\n",
            "Iteration 429, loss = 1492860738.30560803\n",
            "Iteration 430, loss = 1492749035.15477180\n",
            "Iteration 431, loss = 1492636366.79656315\n",
            "Iteration 432, loss = 1492523016.31762218\n",
            "Iteration 433, loss = 1492411120.35725904\n",
            "Iteration 434, loss = 1492298104.78984499\n",
            "Iteration 435, loss = 1492185593.60239959\n",
            "Iteration 436, loss = 1492071953.26586342\n",
            "Iteration 437, loss = 1491960717.86980319\n",
            "Iteration 438, loss = 1491846440.17157102\n",
            "Iteration 439, loss = 1491733841.98140335\n",
            "Iteration 440, loss = 1491621320.99239135\n",
            "Iteration 441, loss = 1491508175.23540258\n",
            "Iteration 442, loss = 1491395526.74204350\n",
            "Iteration 443, loss = 1491282961.40111279\n",
            "Iteration 444, loss = 1491170296.82699203\n",
            "Iteration 445, loss = 1491057540.04076815\n",
            "Iteration 446, loss = 1490944609.99367785\n",
            "Iteration 447, loss = 1490832920.27408123\n",
            "Iteration 448, loss = 1490718745.22960496\n",
            "Iteration 449, loss = 1490606682.67347431\n",
            "Iteration 450, loss = 1490493627.49446130\n",
            "Iteration 451, loss = 1490381692.94600248\n",
            "Iteration 452, loss = 1490268765.23771930\n",
            "Iteration 453, loss = 1490156226.06368661\n",
            "Iteration 454, loss = 1490043713.56577468\n",
            "Iteration 455, loss = 1489932189.93551326\n",
            "Iteration 456, loss = 1489819400.63008356\n",
            "Iteration 457, loss = 1489707622.94064498\n",
            "Iteration 458, loss = 1489595487.37861347\n",
            "Iteration 459, loss = 1489484467.68605018\n",
            "Iteration 460, loss = 1489372169.34147620\n",
            "Iteration 461, loss = 1489260738.99286246\n",
            "Iteration 462, loss = 1489149867.79721045\n",
            "Iteration 463, loss = 1489038288.85111237\n",
            "Iteration 464, loss = 1488927640.59497452\n",
            "Iteration 465, loss = 1488816245.85563517\n",
            "Iteration 466, loss = 1488704794.50536966\n",
            "Iteration 467, loss = 1488593446.01643181\n",
            "Iteration 468, loss = 1488482802.54696774\n",
            "Iteration 469, loss = 1488370694.25220180\n",
            "Iteration 470, loss = 1488259778.25005984\n",
            "Iteration 471, loss = 1488148794.53981137\n",
            "Iteration 472, loss = 1488037494.29648733\n",
            "Iteration 473, loss = 1487926200.04131770\n",
            "Iteration 474, loss = 1487815425.25716305\n",
            "Iteration 475, loss = 1487704199.42402363\n",
            "Iteration 476, loss = 1487592348.33808756\n",
            "Iteration 477, loss = 1487480821.92293048\n",
            "Iteration 478, loss = 1487369933.86934376\n",
            "Iteration 479, loss = 1487258722.30374408\n",
            "Iteration 480, loss = 1487146303.44785357\n",
            "Iteration 481, loss = 1487035868.12814021\n",
            "Iteration 482, loss = 1486924350.90837312\n",
            "Iteration 483, loss = 1486813045.83284926\n",
            "Iteration 484, loss = 1486702961.28170681\n",
            "Iteration 485, loss = 1486591281.86604309\n",
            "Iteration 486, loss = 1486480962.26622295\n",
            "Iteration 487, loss = 1486370647.29574466\n",
            "Iteration 488, loss = 1486260206.74309993\n",
            "Iteration 489, loss = 1486149679.30486012\n",
            "Iteration 490, loss = 1486040126.97218561\n",
            "Iteration 491, loss = 1485930566.55391455\n",
            "Iteration 492, loss = 1485820765.46480298\n",
            "Iteration 493, loss = 1485710896.47845435\n",
            "Iteration 494, loss = 1485601682.50000715\n",
            "Iteration 495, loss = 1485491966.10382986\n",
            "Iteration 496, loss = 1485382114.96955800\n",
            "Iteration 497, loss = 1485273044.60898685\n",
            "Iteration 498, loss = 1485162511.32013941\n",
            "Iteration 499, loss = 1485052578.63864207\n",
            "Iteration 500, loss = 1484943021.00058293\n",
            "Iteration 501, loss = 1484832948.09544635\n",
            "Iteration 502, loss = 1484722541.67436910\n",
            "Iteration 503, loss = 1484613121.75892997\n",
            "Iteration 504, loss = 1484502215.97572994\n",
            "Iteration 505, loss = 1484393472.87665462\n",
            "Iteration 506, loss = 1484282990.96544147\n",
            "Iteration 507, loss = 1484173478.28648257\n",
            "Iteration 508, loss = 1484063568.43923974\n",
            "Iteration 509, loss = 1483954210.53148556\n",
            "Iteration 510, loss = 1483844506.76061320\n",
            "Iteration 511, loss = 1483734574.06974101\n",
            "Iteration 512, loss = 1483624980.77541780\n",
            "Iteration 513, loss = 1483515489.22451496\n",
            "Iteration 514, loss = 1483405918.97558522\n",
            "Iteration 515, loss = 1483295943.42678475\n",
            "Iteration 516, loss = 1483186151.46769071\n",
            "Iteration 517, loss = 1483076756.19400716\n",
            "Iteration 518, loss = 1482966796.19326997\n",
            "Iteration 519, loss = 1482857412.60988545\n",
            "Iteration 520, loss = 1482747887.04224086\n",
            "Iteration 521, loss = 1482638700.82910013\n",
            "Iteration 522, loss = 1482528548.36646628\n",
            "Iteration 523, loss = 1482419671.80022931\n",
            "Iteration 524, loss = 1482310619.91716528\n",
            "Iteration 525, loss = 1482200856.26622391\n",
            "Iteration 526, loss = 1482091863.86951804\n",
            "Iteration 527, loss = 1481982741.28843021\n",
            "Iteration 528, loss = 1481873829.96833301\n",
            "Iteration 529, loss = 1481764357.65368938\n",
            "Iteration 530, loss = 1481656373.15237784\n",
            "Iteration 531, loss = 1481547104.10053897\n",
            "Iteration 532, loss = 1481437997.31356645\n",
            "Iteration 533, loss = 1481329735.56171560\n",
            "Iteration 534, loss = 1481220831.72091269\n",
            "Iteration 535, loss = 1481112680.79114509\n",
            "Iteration 536, loss = 1481003117.87078285\n",
            "Iteration 537, loss = 1480894947.23793769\n",
            "Iteration 538, loss = 1480785588.48555207\n",
            "Iteration 539, loss = 1480677365.55175281\n",
            "Iteration 540, loss = 1480568609.98082852\n",
            "Iteration 541, loss = 1480459802.85549998\n",
            "Iteration 542, loss = 1480350556.24335361\n",
            "Iteration 543, loss = 1480241588.98466301\n",
            "Iteration 544, loss = 1480132575.22319961\n",
            "Iteration 545, loss = 1480024116.07542443\n",
            "Iteration 546, loss = 1479914044.77646685\n",
            "Iteration 547, loss = 1479804910.05181456\n",
            "Iteration 548, loss = 1479696018.71626091\n",
            "Iteration 549, loss = 1479587153.00170398\n",
            "Iteration 550, loss = 1479477303.18516374\n",
            "Iteration 551, loss = 1479368796.88466430\n",
            "Iteration 552, loss = 1479260329.54906988\n",
            "Iteration 553, loss = 1479151911.70961428\n",
            "Iteration 554, loss = 1479043303.66353869\n",
            "Iteration 555, loss = 1478934904.71730065\n",
            "Iteration 556, loss = 1478827152.43423414\n",
            "Iteration 557, loss = 1478718683.72997856\n",
            "Iteration 558, loss = 1478610208.63033748\n",
            "Iteration 559, loss = 1478502256.05428433\n",
            "Iteration 560, loss = 1478393288.80984163\n",
            "Iteration 561, loss = 1478285197.80372643\n",
            "Iteration 562, loss = 1478176232.71061897\n",
            "Iteration 563, loss = 1478067656.19763470\n",
            "Iteration 564, loss = 1477959120.99977779\n",
            "Iteration 565, loss = 1477850781.29507279\n",
            "Iteration 566, loss = 1477741737.80449271\n",
            "Iteration 567, loss = 1477633842.20154572\n",
            "Iteration 568, loss = 1477525266.24284840\n",
            "Iteration 569, loss = 1477417195.91612792\n",
            "Iteration 570, loss = 1477308119.49560595\n",
            "Iteration 571, loss = 1477200511.18234205\n",
            "Iteration 572, loss = 1477091190.77105165\n",
            "Iteration 573, loss = 1476983400.77715254\n",
            "Iteration 574, loss = 1476874942.02590799\n",
            "Iteration 575, loss = 1476766902.52236581\n",
            "Iteration 576, loss = 1476657975.29235792\n",
            "Iteration 577, loss = 1476550348.21512318\n",
            "Iteration 578, loss = 1476441913.16185594\n",
            "Iteration 579, loss = 1476333924.09950733\n",
            "Iteration 580, loss = 1476225277.52125001\n",
            "Iteration 581, loss = 1476116547.48613906\n",
            "Iteration 582, loss = 1476008621.61692429\n",
            "Iteration 583, loss = 1475899591.44534612\n",
            "Iteration 584, loss = 1475792038.86167431\n",
            "Iteration 585, loss = 1475683060.34053779\n",
            "Iteration 586, loss = 1475574727.33387947\n",
            "Iteration 587, loss = 1475467004.21716309\n",
            "Iteration 588, loss = 1475358359.39339805\n",
            "Iteration 589, loss = 1475250269.22342157\n",
            "Iteration 590, loss = 1475142144.69201517\n",
            "Iteration 591, loss = 1475033744.71889997\n",
            "Iteration 592, loss = 1474925464.10271263\n",
            "Iteration 593, loss = 1474817133.51368785\n",
            "Iteration 594, loss = 1474708360.70652556\n",
            "Iteration 595, loss = 1474600392.56020927\n",
            "Iteration 596, loss = 1474492140.49988532\n",
            "Iteration 597, loss = 1474384011.44461465\n",
            "Iteration 598, loss = 1474276526.86718273\n",
            "Iteration 599, loss = 1474168314.24736261\n",
            "Iteration 600, loss = 1474061706.21391892\n",
            "Iteration 601, loss = 1473953696.24299955\n",
            "Iteration 602, loss = 1473846535.91931605\n",
            "Iteration 603, loss = 1473740052.37931347\n",
            "Iteration 604, loss = 1473632009.11537242\n",
            "Iteration 605, loss = 1473524530.45547295\n",
            "Iteration 606, loss = 1473417227.80955625\n",
            "Iteration 607, loss = 1473309356.16997886\n",
            "Iteration 608, loss = 1473201947.73613715\n",
            "Iteration 609, loss = 1473093736.96624494\n",
            "Iteration 610, loss = 1472985759.84806299\n",
            "Iteration 611, loss = 1472877171.36709857\n",
            "Iteration 612, loss = 1472769709.02445626\n",
            "Iteration 613, loss = 1472661747.77925467\n",
            "Iteration 614, loss = 1472553694.43854475\n",
            "Iteration 615, loss = 1472446256.51280665\n",
            "Iteration 616, loss = 1472338088.91199112\n",
            "Iteration 617, loss = 1472230943.86353660\n",
            "Iteration 618, loss = 1472122944.74485707\n",
            "Iteration 619, loss = 1472015965.02359366\n",
            "Iteration 620, loss = 1471908272.54897523\n",
            "Iteration 621, loss = 1471800082.12776780\n",
            "Iteration 622, loss = 1471692746.40844059\n",
            "Iteration 623, loss = 1471585302.05675936\n",
            "Iteration 624, loss = 1471477630.13515162\n",
            "Iteration 625, loss = 1471369160.71767569\n",
            "Iteration 626, loss = 1471261717.53801155\n",
            "Iteration 627, loss = 1471154543.31989646\n",
            "Iteration 628, loss = 1471046369.85401678\n",
            "Iteration 629, loss = 1470939116.22741938\n",
            "Iteration 630, loss = 1470832551.23246527\n",
            "Iteration 631, loss = 1470724610.01945472\n",
            "Iteration 632, loss = 1470617345.94033718\n",
            "Iteration 633, loss = 1470510081.86862421\n",
            "Iteration 634, loss = 1470403122.63152552\n",
            "Iteration 635, loss = 1470296125.40215015\n",
            "Iteration 636, loss = 1470188317.91071153\n",
            "Iteration 637, loss = 1470081204.25021887\n",
            "Iteration 638, loss = 1469974455.59129405\n",
            "Iteration 639, loss = 1469867171.29861617\n",
            "Iteration 640, loss = 1469760192.96021485\n",
            "Iteration 641, loss = 1469651539.68434215\n",
            "Iteration 642, loss = 1469545461.82671165\n",
            "Iteration 643, loss = 1469437584.37456298\n",
            "Iteration 644, loss = 1469329481.95907927\n",
            "Iteration 645, loss = 1469222427.29702353\n",
            "Iteration 646, loss = 1469114054.88720059\n",
            "Iteration 647, loss = 1469007048.01846814\n",
            "Iteration 648, loss = 1468899555.62212372\n",
            "Iteration 649, loss = 1468792135.46177721\n",
            "Iteration 650, loss = 1468684763.64066339\n",
            "Iteration 651, loss = 1468577932.84059668\n",
            "Iteration 652, loss = 1468470708.79978776\n",
            "Iteration 653, loss = 1468364123.05801916\n",
            "Iteration 654, loss = 1468256547.01569128\n",
            "Iteration 655, loss = 1468150283.22172403\n",
            "Iteration 656, loss = 1468043275.14340568\n",
            "Iteration 657, loss = 1467936653.56244230\n",
            "Iteration 658, loss = 1467829702.51602721\n",
            "Iteration 659, loss = 1467722244.86269641\n",
            "Iteration 660, loss = 1467615376.98819470\n",
            "Iteration 661, loss = 1467508618.10822439\n",
            "Iteration 662, loss = 1467401530.66579127\n",
            "Iteration 663, loss = 1467294812.07996178\n",
            "Iteration 664, loss = 1467187180.95534754\n",
            "Iteration 665, loss = 1467080873.40311861\n",
            "Iteration 666, loss = 1466973800.62487650\n",
            "Iteration 667, loss = 1466867387.32972455\n",
            "Iteration 668, loss = 1466759616.66281939\n",
            "Iteration 669, loss = 1466653312.14013362\n",
            "Iteration 670, loss = 1466546559.16323829\n",
            "Iteration 671, loss = 1466438645.60218191\n",
            "Iteration 672, loss = 1466331645.75103092\n",
            "Iteration 673, loss = 1466224166.98454809\n",
            "Iteration 674, loss = 1466116796.69668055\n",
            "Iteration 675, loss = 1466008931.62248397\n",
            "Iteration 676, loss = 1465902037.40361452\n",
            "Iteration 677, loss = 1465794277.16500998\n",
            "Iteration 678, loss = 1465686511.07667780\n",
            "Iteration 679, loss = 1465579534.20093656\n",
            "Iteration 680, loss = 1465472307.93576097\n",
            "Iteration 681, loss = 1465365659.48679209\n",
            "Iteration 682, loss = 1465257854.25431943\n",
            "Iteration 683, loss = 1465151586.30783486\n",
            "Iteration 684, loss = 1465044125.57292318\n",
            "Iteration 685, loss = 1464937243.10568261\n",
            "Iteration 686, loss = 1464830189.57939577\n",
            "Iteration 687, loss = 1464723890.88665915\n",
            "Iteration 688, loss = 1464616279.99758720\n",
            "Iteration 689, loss = 1464509878.21783328\n",
            "Iteration 690, loss = 1464403171.07030511\n",
            "Iteration 691, loss = 1464296317.82280231\n",
            "Iteration 692, loss = 1464190242.46275687\n",
            "Iteration 693, loss = 1464082863.55347252\n",
            "Iteration 694, loss = 1463976931.53209138\n",
            "Iteration 695, loss = 1463870336.26253676\n",
            "Iteration 696, loss = 1463763840.14676070\n",
            "Iteration 697, loss = 1463657475.23637056\n",
            "Iteration 698, loss = 1463551216.17512798\n",
            "Iteration 699, loss = 1463445068.60343170\n",
            "Iteration 700, loss = 1463337761.60502887\n",
            "Iteration 701, loss = 1463232306.49370646\n",
            "Iteration 702, loss = 1463125286.13211775\n",
            "Iteration 703, loss = 1463018452.64853048\n",
            "Iteration 704, loss = 1462912658.65604401\n",
            "Iteration 705, loss = 1462805056.50468373\n",
            "Iteration 706, loss = 1462699977.11191845\n",
            "Iteration 707, loss = 1462592236.08394432\n",
            "Iteration 708, loss = 1462486004.56663036\n",
            "Iteration 709, loss = 1462379364.94475627\n",
            "Iteration 710, loss = 1462273246.28288317\n",
            "Iteration 711, loss = 1462165822.40918660\n",
            "Iteration 712, loss = 1462060117.70338464\n",
            "Iteration 713, loss = 1461952914.57954121\n",
            "Iteration 714, loss = 1461846705.90712547\n",
            "Iteration 715, loss = 1461740188.19994116\n",
            "Iteration 716, loss = 1461633791.44426894\n",
            "Iteration 717, loss = 1461527580.45893979\n",
            "Iteration 718, loss = 1461421098.29709458\n",
            "Iteration 719, loss = 1461315272.39892101\n",
            "Iteration 720, loss = 1461209192.84440851\n",
            "Iteration 721, loss = 1461102801.49895334\n",
            "Iteration 722, loss = 1460996367.70242333\n",
            "Iteration 723, loss = 1460891037.54171443\n",
            "Iteration 724, loss = 1460784468.37687325\n",
            "Iteration 725, loss = 1460678120.31983972\n",
            "Iteration 726, loss = 1460572101.03259873\n",
            "Iteration 727, loss = 1460465856.25442696\n",
            "Iteration 728, loss = 1460359752.56244564\n",
            "Iteration 729, loss = 1460253200.28497815\n",
            "Iteration 730, loss = 1460146910.16708279\n",
            "Iteration 731, loss = 1460040943.86679053\n",
            "Iteration 732, loss = 1459934757.29405761\n",
            "Iteration 733, loss = 1459828052.56581044\n",
            "Iteration 734, loss = 1459722619.11221242\n",
            "Iteration 735, loss = 1459616057.90224624\n",
            "Iteration 736, loss = 1459509977.18872213\n",
            "Iteration 737, loss = 1459403674.49816704\n",
            "Iteration 738, loss = 1459297432.57407594\n",
            "Iteration 739, loss = 1459191020.57191181\n",
            "Iteration 740, loss = 1459084134.83305669\n",
            "Iteration 741, loss = 1458978621.75202084\n",
            "Iteration 742, loss = 1458871956.31290793\n",
            "Iteration 743, loss = 1458765101.25574565\n",
            "Iteration 744, loss = 1458660001.45616269\n",
            "Iteration 745, loss = 1458553043.95092249\n",
            "Iteration 746, loss = 1458447427.09713817\n",
            "Iteration 747, loss = 1458341188.33517146\n",
            "Iteration 748, loss = 1458234986.21404958\n",
            "Iteration 749, loss = 1458128803.48316073\n",
            "Iteration 750, loss = 1458022021.43214464\n",
            "Iteration 751, loss = 1457915911.11647296\n",
            "Iteration 752, loss = 1457809153.30715632\n",
            "Iteration 753, loss = 1457702607.45716143\n",
            "Iteration 754, loss = 1457595663.10760307\n",
            "Iteration 755, loss = 1457489489.78248239\n",
            "Iteration 756, loss = 1457383080.15610027\n",
            "Iteration 757, loss = 1457276803.13223171\n",
            "Iteration 758, loss = 1457170955.36336470\n",
            "Iteration 759, loss = 1457065538.92364287\n",
            "Iteration 760, loss = 1456959199.90891576\n",
            "Iteration 761, loss = 1456853671.52177954\n",
            "Iteration 762, loss = 1456748787.89671254\n",
            "Iteration 763, loss = 1456642380.88716388\n",
            "Iteration 764, loss = 1456537402.00611973\n",
            "Iteration 765, loss = 1456431402.79531193\n",
            "Iteration 766, loss = 1456325975.31542683\n",
            "Iteration 767, loss = 1456219747.01797724\n",
            "Iteration 768, loss = 1456114038.55516338\n",
            "Iteration 769, loss = 1456008208.87567592\n",
            "Iteration 770, loss = 1455902115.24176049\n",
            "Iteration 771, loss = 1455795890.69658017\n",
            "Iteration 772, loss = 1455690710.89335465\n",
            "Iteration 773, loss = 1455584432.45074487\n",
            "Iteration 774, loss = 1455477929.41939950\n",
            "Iteration 775, loss = 1455372378.88895321\n",
            "Iteration 776, loss = 1455266592.22652698\n",
            "Iteration 777, loss = 1455160338.38770127\n",
            "Iteration 778, loss = 1455054948.67466712\n",
            "Iteration 779, loss = 1454949593.86043596\n",
            "Iteration 780, loss = 1454843925.53404331\n",
            "Iteration 781, loss = 1454737473.75032520\n",
            "Iteration 782, loss = 1454632546.96405864\n",
            "Iteration 783, loss = 1454526187.80282903\n",
            "Iteration 784, loss = 1454420981.55085874\n",
            "Iteration 785, loss = 1454314293.86292863\n",
            "Iteration 786, loss = 1454208431.48858666\n",
            "Iteration 787, loss = 1454102744.54626417\n",
            "Iteration 788, loss = 1453996738.59937191\n",
            "Iteration 789, loss = 1453891950.99892831\n",
            "Iteration 790, loss = 1453785461.91078258\n",
            "Iteration 791, loss = 1453680315.12596440\n",
            "Iteration 792, loss = 1453574534.52708435\n",
            "Iteration 793, loss = 1453469026.10629225\n",
            "Iteration 794, loss = 1453363595.24635983\n",
            "Iteration 795, loss = 1453258016.06928849\n",
            "Iteration 796, loss = 1453152904.35759616\n",
            "Iteration 797, loss = 1453047385.48224926\n",
            "Iteration 798, loss = 1452941454.61080074\n",
            "Iteration 799, loss = 1452836611.76847410\n",
            "Iteration 800, loss = 1452730849.83559275\n",
            "Iteration 801, loss = 1452625516.60742712\n",
            "Iteration 802, loss = 1452519955.95144892\n",
            "Iteration 803, loss = 1452415811.56088114\n",
            "Iteration 804, loss = 1452309158.96121669\n",
            "Iteration 805, loss = 1452204673.49373388\n",
            "Iteration 806, loss = 1452100291.33457375\n",
            "Iteration 807, loss = 1451994961.94399571\n",
            "Iteration 808, loss = 1451889966.89904952\n",
            "Iteration 809, loss = 1451785066.22160220\n",
            "Iteration 810, loss = 1451680843.97102237\n",
            "Iteration 811, loss = 1451575437.16770458\n",
            "Iteration 812, loss = 1451471278.70386243\n",
            "Iteration 813, loss = 1451366413.88675380\n",
            "Iteration 814, loss = 1451261712.77707982\n",
            "Iteration 815, loss = 1451156962.57361674\n",
            "Iteration 816, loss = 1451051794.40698624\n",
            "Iteration 817, loss = 1450947003.31718016\n",
            "Iteration 818, loss = 1450841631.58104801\n",
            "Iteration 819, loss = 1450736495.50728178\n",
            "Iteration 820, loss = 1450630885.00938368\n",
            "Iteration 821, loss = 1450525622.64331937\n",
            "Iteration 822, loss = 1450420301.98630333\n",
            "Iteration 823, loss = 1450314956.92886639\n",
            "Iteration 824, loss = 1450209868.73090506\n",
            "Iteration 825, loss = 1450104599.63356161\n",
            "Iteration 826, loss = 1449999874.75781202\n",
            "Iteration 827, loss = 1449894768.07356834\n",
            "Iteration 828, loss = 1449789774.09335804\n",
            "Iteration 829, loss = 1449684855.46691799\n",
            "Iteration 830, loss = 1449579848.74760890\n",
            "Iteration 831, loss = 1449474712.69226813\n",
            "Iteration 832, loss = 1449369596.33246136\n",
            "Iteration 833, loss = 1449264330.97045779\n",
            "Iteration 834, loss = 1449159091.30601478\n",
            "Iteration 835, loss = 1449053783.21007323\n",
            "Iteration 836, loss = 1448949445.08476353\n",
            "Iteration 837, loss = 1448843604.80780482\n",
            "Iteration 838, loss = 1448738973.12281156\n",
            "Iteration 839, loss = 1448634091.26876640\n",
            "Iteration 840, loss = 1448528535.34448600\n",
            "Iteration 841, loss = 1448423788.77667403\n",
            "Iteration 842, loss = 1448318400.00997567\n",
            "Iteration 843, loss = 1448213272.55732870\n",
            "Iteration 844, loss = 1448108278.57732677\n",
            "Iteration 845, loss = 1448002507.03857970\n",
            "Iteration 846, loss = 1447897996.06926203\n",
            "Iteration 847, loss = 1447792537.26919818\n",
            "Iteration 848, loss = 1447687468.03051448\n",
            "Iteration 849, loss = 1447582236.15275192\n",
            "Iteration 850, loss = 1447477699.99111795\n",
            "Iteration 851, loss = 1447372108.12086868\n",
            "Iteration 852, loss = 1447266639.14151144\n",
            "Iteration 853, loss = 1447162011.96693587\n",
            "Iteration 854, loss = 1447056957.65520477\n",
            "Iteration 855, loss = 1446951935.73538351\n",
            "Iteration 856, loss = 1446846560.41493058\n",
            "Iteration 857, loss = 1446741719.02501559\n",
            "Iteration 858, loss = 1446637067.03260231\n",
            "Iteration 859, loss = 1446531993.21879172\n",
            "Iteration 860, loss = 1446426781.48952317\n",
            "Iteration 861, loss = 1446321222.41800737\n",
            "Iteration 862, loss = 1446217133.25093579\n",
            "Iteration 863, loss = 1446111934.55284691\n",
            "Iteration 864, loss = 1446005841.49789000\n",
            "Iteration 865, loss = 1445900961.95650744\n",
            "Iteration 866, loss = 1445795383.67965627\n",
            "Iteration 867, loss = 1445690477.67613077\n",
            "Iteration 868, loss = 1445585363.60028005\n",
            "Iteration 869, loss = 1445480482.41393352\n",
            "Iteration 870, loss = 1445374869.54758501\n",
            "Iteration 871, loss = 1445269724.73662353\n",
            "Iteration 872, loss = 1445165682.33825588\n",
            "Iteration 873, loss = 1445060703.45594811\n",
            "Iteration 874, loss = 1444955710.19788909\n",
            "Iteration 875, loss = 1444850606.15627813\n",
            "Iteration 876, loss = 1444746616.98534918\n",
            "Iteration 877, loss = 1444641105.52416134\n",
            "Iteration 878, loss = 1444536806.87396955\n",
            "Iteration 879, loss = 1444432527.93689871\n",
            "Iteration 880, loss = 1444327532.73710084\n",
            "Iteration 881, loss = 1444223532.58766985\n",
            "Iteration 882, loss = 1444118863.14861727\n",
            "Iteration 883, loss = 1444013998.30798578\n",
            "Iteration 884, loss = 1443910199.12846756\n",
            "Iteration 885, loss = 1443805237.57262707\n",
            "Iteration 886, loss = 1443700886.68372369\n",
            "Iteration 887, loss = 1443596900.20400429\n",
            "Iteration 888, loss = 1443491426.56499863\n",
            "Iteration 889, loss = 1443388075.20759702\n",
            "Iteration 890, loss = 1443283258.01161289\n",
            "Iteration 891, loss = 1443178043.52269149\n",
            "Iteration 892, loss = 1443074406.80027843\n",
            "Iteration 893, loss = 1442968953.40049124\n",
            "Iteration 894, loss = 1442864041.23629260\n",
            "Iteration 895, loss = 1442758623.90452576\n",
            "Iteration 896, loss = 1442654255.26088405\n",
            "Iteration 897, loss = 1442549225.44110703\n",
            "Iteration 898, loss = 1442443969.73931861\n",
            "Iteration 899, loss = 1442338802.20637798\n",
            "Iteration 900, loss = 1442234065.15875793\n",
            "Iteration 901, loss = 1442129959.65054679\n",
            "Iteration 902, loss = 1442024694.46918559\n",
            "Iteration 903, loss = 1441920302.08898783\n",
            "Iteration 904, loss = 1441815141.43138552\n",
            "Iteration 905, loss = 1441710610.70955086\n",
            "Iteration 906, loss = 1441605784.31356072\n",
            "Iteration 907, loss = 1441501598.70681286\n",
            "Iteration 908, loss = 1441396304.54814267\n",
            "Iteration 909, loss = 1441291939.80297017\n",
            "Iteration 910, loss = 1441187296.51501918\n",
            "Iteration 911, loss = 1441082453.71009970\n",
            "Iteration 912, loss = 1440977715.76308274\n",
            "Iteration 913, loss = 1440873618.05795097\n",
            "Iteration 914, loss = 1440768401.53636909\n",
            "Iteration 915, loss = 1440663574.66549706\n",
            "Iteration 916, loss = 1440558520.44299865\n",
            "Iteration 917, loss = 1440453662.98883152\n",
            "Iteration 918, loss = 1440348359.49509239\n",
            "Iteration 919, loss = 1440243864.48973489\n",
            "Iteration 920, loss = 1440138593.64227891\n",
            "Iteration 921, loss = 1440033387.30401897\n",
            "Iteration 922, loss = 1439928845.17613459\n",
            "Iteration 923, loss = 1439824129.38820481\n",
            "Iteration 924, loss = 1439719137.77078724\n",
            "Iteration 925, loss = 1439614511.84341693\n",
            "Iteration 926, loss = 1439509585.60761738\n",
            "Iteration 927, loss = 1439404955.07898140\n",
            "Iteration 928, loss = 1439300342.42108941\n",
            "Iteration 929, loss = 1439195522.49333191\n",
            "Iteration 930, loss = 1439090565.86421084\n",
            "Iteration 931, loss = 1438985569.18491435\n",
            "Iteration 932, loss = 1438881660.65831804\n",
            "Iteration 933, loss = 1438776173.97702599\n",
            "Iteration 934, loss = 1438671281.26626110\n",
            "Iteration 935, loss = 1438567629.41479850\n",
            "Iteration 936, loss = 1438462997.29752064\n",
            "Iteration 937, loss = 1438358134.69279552\n",
            "Iteration 938, loss = 1438254498.51374698\n",
            "Iteration 939, loss = 1438150141.66424918\n",
            "Iteration 940, loss = 1438046172.91389346\n",
            "Iteration 941, loss = 1437941530.87273479\n",
            "Iteration 942, loss = 1437837827.21151710\n",
            "Iteration 943, loss = 1437733014.07282019\n",
            "Iteration 944, loss = 1437628716.82620430\n",
            "Iteration 945, loss = 1437524002.11409473\n",
            "Iteration 946, loss = 1437419550.86845565\n",
            "Iteration 947, loss = 1437314253.71203446\n",
            "Iteration 948, loss = 1437210094.80578709\n",
            "Iteration 949, loss = 1437105184.28870201\n",
            "Iteration 950, loss = 1437000772.94014478\n",
            "Iteration 951, loss = 1436895663.21542835\n",
            "Iteration 952, loss = 1436791605.01306701\n",
            "Iteration 953, loss = 1436686733.51841712\n",
            "Iteration 954, loss = 1436582683.47873998\n",
            "Iteration 955, loss = 1436477913.03966832\n",
            "Iteration 956, loss = 1436373603.55036879\n",
            "Iteration 957, loss = 1436269371.09298611\n",
            "Iteration 958, loss = 1436164877.22020698\n",
            "Iteration 959, loss = 1436060680.43043208\n",
            "Iteration 960, loss = 1435956051.50755429\n",
            "Iteration 961, loss = 1435851349.11581182\n",
            "Iteration 962, loss = 1435746873.93642855\n",
            "Iteration 963, loss = 1435642666.01128197\n",
            "Iteration 964, loss = 1435537924.11707091\n",
            "Iteration 965, loss = 1435433754.74114037\n",
            "Iteration 966, loss = 1435329029.30893707\n",
            "Iteration 967, loss = 1435225354.34733438\n",
            "Iteration 968, loss = 1435121080.64309001\n",
            "Iteration 969, loss = 1435016353.55920124\n",
            "Iteration 970, loss = 1434913275.75962925\n",
            "Iteration 971, loss = 1434808579.65287590\n",
            "Iteration 972, loss = 1434704724.81765032\n",
            "Iteration 973, loss = 1434601049.55618739\n",
            "Iteration 974, loss = 1434497064.32566762\n",
            "Iteration 975, loss = 1434393558.87791800\n",
            "Iteration 976, loss = 1434289467.22922873\n",
            "Iteration 977, loss = 1434185840.11394095\n",
            "Iteration 978, loss = 1434082141.71315145\n",
            "Iteration 979, loss = 1433978497.85542727\n",
            "Iteration 980, loss = 1433874546.29563284\n",
            "Iteration 981, loss = 1433771101.87827992\n",
            "Iteration 982, loss = 1433667418.55803585\n",
            "Iteration 983, loss = 1433563586.68616295\n",
            "Iteration 984, loss = 1433460750.13679099\n",
            "Iteration 985, loss = 1433356358.21622443\n",
            "Iteration 986, loss = 1433252588.22614956\n",
            "Iteration 987, loss = 1433149122.99835181\n",
            "Iteration 988, loss = 1433045409.77292538\n",
            "Iteration 989, loss = 1432942020.10079145\n",
            "Iteration 990, loss = 1432838083.14196062\n",
            "Iteration 991, loss = 1432734871.48916340\n",
            "Iteration 992, loss = 1432631334.16691613\n",
            "Iteration 993, loss = 1432527981.77303863\n",
            "Iteration 994, loss = 1432424223.80436945\n",
            "Iteration 995, loss = 1432320943.07401967\n",
            "Iteration 996, loss = 1432217425.25711155\n",
            "Iteration 997, loss = 1432113535.15507603\n",
            "Iteration 998, loss = 1432010246.62623239\n",
            "Iteration 999, loss = 1431906699.46555185\n",
            "Iteration 1000, loss = 1431803424.69754696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1324528570.04612327\n",
            "Iteration 2, loss = 188904999.30235627\n",
            "Iteration 3, loss = 151270305.29689118\n",
            "Iteration 4, loss = 106727624.20239218\n",
            "Iteration 5, loss = 99289075.31629393\n",
            "Iteration 6, loss = 96009121.67096218\n",
            "Iteration 7, loss = 95785621.69893025\n",
            "Iteration 8, loss = 95933262.03419262\n",
            "Iteration 9, loss = 96562413.10947461\n",
            "Iteration 10, loss = 97992054.13822134\n",
            "Iteration 11, loss = 95728720.01446056\n",
            "Iteration 12, loss = 96721063.52643147\n",
            "Iteration 13, loss = 96822867.53813703\n",
            "Iteration 14, loss = 96801511.58234689\n",
            "Iteration 15, loss = 103402411.57324280\n",
            "Iteration 16, loss = 95892845.65562983\n",
            "Iteration 17, loss = 99545894.88984174\n",
            "Iteration 18, loss = 95719917.21553928\n",
            "Iteration 19, loss = 96981256.38011681\n",
            "Iteration 20, loss = 95955091.61791886\n",
            "Iteration 21, loss = 95837958.40580755\n",
            "Iteration 22, loss = 96480748.18096429\n",
            "Iteration 23, loss = 98819819.24710970\n",
            "Iteration 24, loss = 96402722.71475218\n",
            "Iteration 25, loss = 95870301.43987334\n",
            "Iteration 26, loss = 96675931.93013501\n",
            "Iteration 27, loss = 95766870.92406748\n",
            "Iteration 28, loss = 95839188.89896040\n",
            "Iteration 29, loss = 95835517.51897308\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538776907.23517513\n",
            "Iteration 2, loss = 1538639439.35559583\n",
            "Iteration 3, loss = 1538528171.31612992\n",
            "Iteration 4, loss = 1538438814.33928251\n",
            "Iteration 5, loss = 1538358240.30865908\n",
            "Iteration 6, loss = 1538278319.94659495\n",
            "Iteration 7, loss = 1538195249.10316038\n",
            "Iteration 8, loss = 1538110839.21825624\n",
            "Iteration 9, loss = 1538023662.97683001\n",
            "Iteration 10, loss = 1537936708.93971038\n",
            "Iteration 11, loss = 1537850696.69982386\n",
            "Iteration 12, loss = 1537764096.06078935\n",
            "Iteration 13, loss = 1537677750.47416997\n",
            "Iteration 14, loss = 1537590124.32691646\n",
            "Iteration 15, loss = 1537501258.56716824\n",
            "Iteration 16, loss = 1537411108.97848296\n",
            "Iteration 17, loss = 1537320295.30542278\n",
            "Iteration 18, loss = 1537230059.06212497\n",
            "Iteration 19, loss = 1537138470.57395959\n",
            "Iteration 20, loss = 1537044065.75776863\n",
            "Iteration 21, loss = 1536948194.60518813\n",
            "Iteration 22, loss = 1536850842.50500250\n",
            "Iteration 23, loss = 1536754562.98419452\n",
            "Iteration 24, loss = 1536659468.78083253\n",
            "Iteration 25, loss = 1536564633.19733882\n",
            "Iteration 26, loss = 1536469885.64873123\n",
            "Iteration 27, loss = 1536373136.39899063\n",
            "Iteration 28, loss = 1536275999.23794413\n",
            "Iteration 29, loss = 1536180274.58038998\n",
            "Iteration 30, loss = 1536083486.82902479\n",
            "Iteration 31, loss = 1535985740.84006834\n",
            "Iteration 32, loss = 1535887709.03009963\n",
            "Iteration 33, loss = 1535788169.53348708\n",
            "Iteration 34, loss = 1535689526.26074123\n",
            "Iteration 35, loss = 1535590439.79409528\n",
            "Iteration 36, loss = 1535492706.01560211\n",
            "Iteration 37, loss = 1535394751.62299705\n",
            "Iteration 38, loss = 1535297684.38338304\n",
            "Iteration 39, loss = 1535199378.71206784\n",
            "Iteration 40, loss = 1535102796.85133719\n",
            "Iteration 41, loss = 1535005988.52280569\n",
            "Iteration 42, loss = 1534908580.93708944\n",
            "Iteration 43, loss = 1534812790.34701920\n",
            "Iteration 44, loss = 1534716554.08128738\n",
            "Iteration 45, loss = 1534620632.86886859\n",
            "Iteration 46, loss = 1534524489.92604756\n",
            "Iteration 47, loss = 1534428827.46552992\n",
            "Iteration 48, loss = 1534333567.23426962\n",
            "Iteration 49, loss = 1534237996.32269526\n",
            "Iteration 50, loss = 1534142973.97753477\n",
            "Iteration 51, loss = 1534047925.12176156\n",
            "Iteration 52, loss = 1533953201.70249319\n",
            "Iteration 53, loss = 1533859508.78062391\n",
            "Iteration 54, loss = 1533764801.48865128\n",
            "Iteration 55, loss = 1533671205.07151008\n",
            "Iteration 56, loss = 1533577825.62958741\n",
            "Iteration 57, loss = 1533484391.16498327\n",
            "Iteration 58, loss = 1533390772.07758427\n",
            "Iteration 59, loss = 1533297724.12246037\n",
            "Iteration 60, loss = 1533204093.10298586\n",
            "Iteration 61, loss = 1533110753.44648099\n",
            "Iteration 62, loss = 1533017499.30759811\n",
            "Iteration 63, loss = 1532924262.88276935\n",
            "Iteration 64, loss = 1532830973.90659356\n",
            "Iteration 65, loss = 1532737357.92904758\n",
            "Iteration 66, loss = 1532644529.19026256\n",
            "Iteration 67, loss = 1532551068.10514712\n",
            "Iteration 68, loss = 1532457906.63252711\n",
            "Iteration 69, loss = 1532365174.82286096\n",
            "Iteration 70, loss = 1532272132.31323385\n",
            "Iteration 71, loss = 1532179097.25640750\n",
            "Iteration 72, loss = 1532086946.63214874\n",
            "Iteration 73, loss = 1531994287.46779704\n",
            "Iteration 74, loss = 1531901717.94456244\n",
            "Iteration 75, loss = 1531809644.63382959\n",
            "Iteration 76, loss = 1531716581.53191829\n",
            "Iteration 77, loss = 1531621585.80890918\n",
            "Iteration 78, loss = 1531521672.67187953\n",
            "Iteration 79, loss = 1531423837.14551997\n",
            "Iteration 80, loss = 1531327652.68149376\n",
            "Iteration 81, loss = 1531229580.09499216\n",
            "Iteration 82, loss = 1531133165.10546088\n",
            "Iteration 83, loss = 1531036663.40435719\n",
            "Iteration 84, loss = 1530939310.16761160\n",
            "Iteration 85, loss = 1530842816.01594877\n",
            "Iteration 86, loss = 1530745727.88762498\n",
            "Iteration 87, loss = 1530648911.77055311\n",
            "Iteration 88, loss = 1530551725.14821649\n",
            "Iteration 89, loss = 1530455223.90897989\n",
            "Iteration 90, loss = 1530355519.47523451\n",
            "Iteration 91, loss = 1530255034.59197307\n",
            "Iteration 92, loss = 1530152840.50419188\n",
            "Iteration 93, loss = 1530050406.06531549\n",
            "Iteration 94, loss = 1529949479.36959720\n",
            "Iteration 95, loss = 1529847631.99789739\n",
            "Iteration 96, loss = 1529746411.37178707\n",
            "Iteration 97, loss = 1529645290.74964547\n",
            "Iteration 98, loss = 1529543243.00471735\n",
            "Iteration 99, loss = 1529442681.36125517\n",
            "Iteration 100, loss = 1529340592.01846218\n",
            "Iteration 101, loss = 1529239945.91242790\n",
            "Iteration 102, loss = 1529138527.96513820\n",
            "Iteration 103, loss = 1529037572.77058625\n",
            "Iteration 104, loss = 1528936452.11479735\n",
            "Iteration 105, loss = 1528833635.68266845\n",
            "Iteration 106, loss = 1528729026.24616718\n",
            "Iteration 107, loss = 1528624313.38704348\n",
            "Iteration 108, loss = 1528521789.51283765\n",
            "Iteration 109, loss = 1528417985.54015970\n",
            "Iteration 110, loss = 1528315450.26253963\n",
            "Iteration 111, loss = 1528212005.35656595\n",
            "Iteration 112, loss = 1528109368.17781949\n",
            "Iteration 113, loss = 1528006991.81616187\n",
            "Iteration 114, loss = 1527904312.68872309\n",
            "Iteration 115, loss = 1527802686.35611796\n",
            "Iteration 116, loss = 1527700644.29359388\n",
            "Iteration 117, loss = 1527598810.01943851\n",
            "Iteration 118, loss = 1527497326.20036983\n",
            "Iteration 119, loss = 1527396798.99619603\n",
            "Iteration 120, loss = 1527295807.49842286\n",
            "Iteration 121, loss = 1527194307.77669954\n",
            "Iteration 122, loss = 1527093868.44229245\n",
            "Iteration 123, loss = 1526993370.10596514\n",
            "Iteration 124, loss = 1526892326.38518000\n",
            "Iteration 125, loss = 1526791119.52957988\n",
            "Iteration 126, loss = 1526691386.48136616\n",
            "Iteration 127, loss = 1526590484.48441124\n",
            "Iteration 128, loss = 1526490542.67124653\n",
            "Iteration 129, loss = 1526390003.21021342\n",
            "Iteration 130, loss = 1526290386.17167687\n",
            "Iteration 131, loss = 1526190111.06623626\n",
            "Iteration 132, loss = 1526090707.57885695\n",
            "Iteration 133, loss = 1525991244.10714984\n",
            "Iteration 134, loss = 1525892026.89770126\n",
            "Iteration 135, loss = 1525792504.61421251\n",
            "Iteration 136, loss = 1525693379.15882421\n",
            "Iteration 137, loss = 1525594218.77475691\n",
            "Iteration 138, loss = 1525495487.36902690\n",
            "Iteration 139, loss = 1525396526.47516227\n",
            "Iteration 140, loss = 1525298021.64357281\n",
            "Iteration 141, loss = 1525199059.26424336\n",
            "Iteration 142, loss = 1525100999.12888718\n",
            "Iteration 143, loss = 1524999781.39893746\n",
            "Iteration 144, loss = 1524897505.91440153\n",
            "Iteration 145, loss = 1524795928.64891386\n",
            "Iteration 146, loss = 1524694841.95983458\n",
            "Iteration 147, loss = 1524592958.49219918\n",
            "Iteration 148, loss = 1524492037.31823707\n",
            "Iteration 149, loss = 1524389763.21764374\n",
            "Iteration 150, loss = 1524287692.39598775\n",
            "Iteration 151, loss = 1524186862.91979742\n",
            "Iteration 152, loss = 1524084126.92647481\n",
            "Iteration 153, loss = 1523982929.23126054\n",
            "Iteration 154, loss = 1523881914.10002017\n",
            "Iteration 155, loss = 1523779963.42704320\n",
            "Iteration 156, loss = 1523679506.18950224\n",
            "Iteration 157, loss = 1523578487.70395947\n",
            "Iteration 158, loss = 1523478180.05262971\n",
            "Iteration 159, loss = 1523377355.54000998\n",
            "Iteration 160, loss = 1523276926.57310605\n",
            "Iteration 161, loss = 1523176161.38918638\n",
            "Iteration 162, loss = 1523072663.21820545\n",
            "Iteration 163, loss = 1522968079.18654656\n",
            "Iteration 164, loss = 1522864522.44613481\n",
            "Iteration 165, loss = 1522761203.95435166\n",
            "Iteration 166, loss = 1522657179.45889115\n",
            "Iteration 167, loss = 1522552385.25915766\n",
            "Iteration 168, loss = 1522443978.19854856\n",
            "Iteration 169, loss = 1522336021.13560081\n",
            "Iteration 170, loss = 1522229365.40840220\n",
            "Iteration 171, loss = 1522122610.61068392\n",
            "Iteration 172, loss = 1522015151.68202949\n",
            "Iteration 173, loss = 1521905617.41720653\n",
            "Iteration 174, loss = 1521794498.14532614\n",
            "Iteration 175, loss = 1521684339.99587488\n",
            "Iteration 176, loss = 1521571700.97010469\n",
            "Iteration 177, loss = 1521457173.86165690\n",
            "Iteration 178, loss = 1521344887.10619140\n",
            "Iteration 179, loss = 1521231502.76215458\n",
            "Iteration 180, loss = 1521118347.97157693\n",
            "Iteration 181, loss = 1521006188.32722425\n",
            "Iteration 182, loss = 1520892525.20141101\n",
            "Iteration 183, loss = 1520779516.10843349\n",
            "Iteration 184, loss = 1520667204.35651731\n",
            "Iteration 185, loss = 1520555075.93391562\n",
            "Iteration 186, loss = 1520443048.68763685\n",
            "Iteration 187, loss = 1520330939.52078938\n",
            "Iteration 188, loss = 1520220387.48491979\n",
            "Iteration 189, loss = 1520108641.89657378\n",
            "Iteration 190, loss = 1519998481.21655726\n",
            "Iteration 191, loss = 1519887650.02686477\n",
            "Iteration 192, loss = 1519777657.82984996\n",
            "Iteration 193, loss = 1519667883.31979275\n",
            "Iteration 194, loss = 1519557781.27660036\n",
            "Iteration 195, loss = 1519448188.30053759\n",
            "Iteration 196, loss = 1519338758.68595409\n",
            "Iteration 197, loss = 1519227451.46623135\n",
            "Iteration 198, loss = 1519113005.48829484\n",
            "Iteration 199, loss = 1519001184.00399375\n",
            "Iteration 200, loss = 1518889001.83492637\n",
            "Iteration 201, loss = 1518776392.80382800\n",
            "Iteration 202, loss = 1518664546.66772461\n",
            "Iteration 203, loss = 1518553336.45545149\n",
            "Iteration 204, loss = 1518440603.67768049\n",
            "Iteration 205, loss = 1518328678.49898911\n",
            "Iteration 206, loss = 1518218124.61417127\n",
            "Iteration 207, loss = 1518106542.72832203\n",
            "Iteration 208, loss = 1517995665.91843700\n",
            "Iteration 209, loss = 1517885429.68570304\n",
            "Iteration 210, loss = 1517774890.57056880\n",
            "Iteration 211, loss = 1517665068.03918147\n",
            "Iteration 212, loss = 1517555276.54056716\n",
            "Iteration 213, loss = 1517445547.96465635\n",
            "Iteration 214, loss = 1517336219.98121262\n",
            "Iteration 215, loss = 1517227346.15630746\n",
            "Iteration 216, loss = 1517118276.39249396\n",
            "Iteration 217, loss = 1517009423.22029185\n",
            "Iteration 218, loss = 1516899094.10562491\n",
            "Iteration 219, loss = 1516786204.41388893\n",
            "Iteration 220, loss = 1516673367.15549493\n",
            "Iteration 221, loss = 1516561177.34225774\n",
            "Iteration 222, loss = 1516449642.86702824\n",
            "Iteration 223, loss = 1516336954.17712021\n",
            "Iteration 224, loss = 1516224554.85878158\n",
            "Iteration 225, loss = 1516112093.66788650\n",
            "Iteration 226, loss = 1515998830.71292639\n",
            "Iteration 227, loss = 1515883951.30086946\n",
            "Iteration 228, loss = 1515766092.47068167\n",
            "Iteration 229, loss = 1515650493.67260957\n",
            "Iteration 230, loss = 1515536190.92410994\n",
            "Iteration 231, loss = 1515420170.81847024\n",
            "Iteration 232, loss = 1515305895.60755968\n",
            "Iteration 233, loss = 1515190027.06680036\n",
            "Iteration 234, loss = 1515076048.04916954\n",
            "Iteration 235, loss = 1514961218.39949369\n",
            "Iteration 236, loss = 1514847207.05259633\n",
            "Iteration 237, loss = 1514731998.39117193\n",
            "Iteration 238, loss = 1514618200.83653235\n",
            "Iteration 239, loss = 1514505239.61795402\n",
            "Iteration 240, loss = 1514390546.82104349\n",
            "Iteration 241, loss = 1514278137.74250674\n",
            "Iteration 242, loss = 1514164608.04332852\n",
            "Iteration 243, loss = 1514051885.56611085\n",
            "Iteration 244, loss = 1513939638.02600503\n",
            "Iteration 245, loss = 1513827013.07455850\n",
            "Iteration 246, loss = 1513715243.02226973\n",
            "Iteration 247, loss = 1513602684.41960335\n",
            "Iteration 248, loss = 1513491349.82783866\n",
            "Iteration 249, loss = 1513378528.24594927\n",
            "Iteration 250, loss = 1513259346.23893142\n",
            "Iteration 251, loss = 1513136198.50914502\n",
            "Iteration 252, loss = 1513016324.27295494\n",
            "Iteration 253, loss = 1512896417.94110608\n",
            "Iteration 254, loss = 1512772366.93655992\n",
            "Iteration 255, loss = 1512646031.21700454\n",
            "Iteration 256, loss = 1512522017.60777974\n",
            "Iteration 257, loss = 1512398165.22981191\n",
            "Iteration 258, loss = 1512273008.90785742\n",
            "Iteration 259, loss = 1512149408.50003600\n",
            "Iteration 260, loss = 1512025317.95298219\n",
            "Iteration 261, loss = 1511901432.96882582\n",
            "Iteration 262, loss = 1511777843.47612953\n",
            "Iteration 263, loss = 1511654936.98971272\n",
            "Iteration 264, loss = 1511532673.07917571\n",
            "Iteration 265, loss = 1511410056.21982098\n",
            "Iteration 266, loss = 1511288221.98658276\n",
            "Iteration 267, loss = 1511167024.22106695\n",
            "Iteration 268, loss = 1511046400.41061592\n",
            "Iteration 269, loss = 1510926099.58888173\n",
            "Iteration 270, loss = 1510806062.73960996\n",
            "Iteration 271, loss = 1510686646.00166178\n",
            "Iteration 272, loss = 1510567609.77897096\n",
            "Iteration 273, loss = 1510449575.04789352\n",
            "Iteration 274, loss = 1510331186.33497500\n",
            "Iteration 275, loss = 1510212343.34760880\n",
            "Iteration 276, loss = 1510095832.24764872\n",
            "Iteration 277, loss = 1509977794.58010483\n",
            "Iteration 278, loss = 1509860972.50645018\n",
            "Iteration 279, loss = 1509744453.93536878\n",
            "Iteration 280, loss = 1509626832.92361903\n",
            "Iteration 281, loss = 1509511084.84018469\n",
            "Iteration 282, loss = 1509393792.21627021\n",
            "Iteration 283, loss = 1509277639.52794528\n",
            "Iteration 284, loss = 1509161324.60107517\n",
            "Iteration 285, loss = 1509045321.18061829\n",
            "Iteration 286, loss = 1508928493.38141465\n",
            "Iteration 287, loss = 1508812657.37016487\n",
            "Iteration 288, loss = 1508696011.44274688\n",
            "Iteration 289, loss = 1508579620.88750672\n",
            "Iteration 290, loss = 1508464519.20605993\n",
            "Iteration 291, loss = 1508348160.85469484\n",
            "Iteration 292, loss = 1508232350.13660836\n",
            "Iteration 293, loss = 1508117674.84382772\n",
            "Iteration 294, loss = 1508002023.79025006\n",
            "Iteration 295, loss = 1507887142.34167624\n",
            "Iteration 296, loss = 1507773184.53962827\n",
            "Iteration 297, loss = 1507657946.31497622\n",
            "Iteration 298, loss = 1507543452.74993038\n",
            "Iteration 299, loss = 1507429979.54960990\n",
            "Iteration 300, loss = 1507315238.60139942\n",
            "Iteration 301, loss = 1507201473.25621605\n",
            "Iteration 302, loss = 1507087074.53586912\n",
            "Iteration 303, loss = 1506973080.23864222\n",
            "Iteration 304, loss = 1506853816.03951716\n",
            "Iteration 305, loss = 1506735075.81581759\n",
            "Iteration 306, loss = 1506617771.95447612\n",
            "Iteration 307, loss = 1506499274.64649606\n",
            "Iteration 308, loss = 1506380451.65154171\n",
            "Iteration 309, loss = 1506262929.82789207\n",
            "Iteration 310, loss = 1506144268.55455565\n",
            "Iteration 311, loss = 1506026558.77296519\n",
            "Iteration 312, loss = 1505907966.44138837\n",
            "Iteration 313, loss = 1505791568.85472417\n",
            "Iteration 314, loss = 1505673056.61025858\n",
            "Iteration 315, loss = 1505556747.87351775\n",
            "Iteration 316, loss = 1505439161.99221253\n",
            "Iteration 317, loss = 1505322589.44350147\n",
            "Iteration 318, loss = 1505205720.87004113\n",
            "Iteration 319, loss = 1505089659.30282426\n",
            "Iteration 320, loss = 1504972350.59392667\n",
            "Iteration 321, loss = 1504855566.06311846\n",
            "Iteration 322, loss = 1504738983.80823636\n",
            "Iteration 323, loss = 1504622789.21387577\n",
            "Iteration 324, loss = 1504506751.09696674\n",
            "Iteration 325, loss = 1504390751.55959511\n",
            "Iteration 326, loss = 1504274607.97747207\n",
            "Iteration 327, loss = 1504158531.20591331\n",
            "Iteration 328, loss = 1504044139.46877360\n",
            "Iteration 329, loss = 1503927840.23814726\n",
            "Iteration 330, loss = 1503813189.30871105\n",
            "Iteration 331, loss = 1503697898.94335270\n",
            "Iteration 332, loss = 1503583525.16810465\n",
            "Iteration 333, loss = 1503467807.60248995\n",
            "Iteration 334, loss = 1503353786.68771458\n",
            "Iteration 335, loss = 1503239680.28382945\n",
            "Iteration 336, loss = 1503124890.89103317\n",
            "Iteration 337, loss = 1503011017.85529852\n",
            "Iteration 338, loss = 1502896860.88239789\n",
            "Iteration 339, loss = 1502782994.07370782\n",
            "Iteration 340, loss = 1502669604.15929222\n",
            "Iteration 341, loss = 1502555383.30649638\n",
            "Iteration 342, loss = 1502441480.92611265\n",
            "Iteration 343, loss = 1502328301.01612973\n",
            "Iteration 344, loss = 1502214941.60303521\n",
            "Iteration 345, loss = 1502101301.57448912\n",
            "Iteration 346, loss = 1501988060.25076842\n",
            "Iteration 347, loss = 1501874443.00635600\n",
            "Iteration 348, loss = 1501762150.81749225\n",
            "Iteration 349, loss = 1501648407.36603522\n",
            "Iteration 350, loss = 1501535855.60149741\n",
            "Iteration 351, loss = 1501422692.81246257\n",
            "Iteration 352, loss = 1501309358.62781978\n",
            "Iteration 353, loss = 1501197303.96484613\n",
            "Iteration 354, loss = 1501083695.87543488\n",
            "Iteration 355, loss = 1500970866.46280789\n",
            "Iteration 356, loss = 1500858367.36669016\n",
            "Iteration 357, loss = 1500745090.49155784\n",
            "Iteration 358, loss = 1500632417.49989843\n",
            "Iteration 359, loss = 1500519356.00569773\n",
            "Iteration 360, loss = 1500406809.27325249\n",
            "Iteration 361, loss = 1500294113.79382133\n",
            "Iteration 362, loss = 1500181832.66743207\n",
            "Iteration 363, loss = 1500069147.33925772\n",
            "Iteration 364, loss = 1499956771.57948446\n",
            "Iteration 365, loss = 1499845227.63209629\n",
            "Iteration 366, loss = 1499732612.11856151\n",
            "Iteration 367, loss = 1499621845.66972899\n",
            "Iteration 368, loss = 1499508953.61713815\n",
            "Iteration 369, loss = 1499397269.10737705\n",
            "Iteration 370, loss = 1499285306.75112391\n",
            "Iteration 371, loss = 1499173561.41762447\n",
            "Iteration 372, loss = 1499061714.64820600\n",
            "Iteration 373, loss = 1498949737.35848260\n",
            "Iteration 374, loss = 1498837715.76380181\n",
            "Iteration 375, loss = 1498726387.28669310\n",
            "Iteration 376, loss = 1498614727.83566952\n",
            "Iteration 377, loss = 1498503290.42644691\n",
            "Iteration 378, loss = 1498392316.13179111\n",
            "Iteration 379, loss = 1498280540.75811696\n",
            "Iteration 380, loss = 1498169393.21915221\n",
            "Iteration 381, loss = 1498058079.32776642\n",
            "Iteration 382, loss = 1497946928.73955512\n",
            "Iteration 383, loss = 1497835590.95288348\n",
            "Iteration 384, loss = 1497724269.31947517\n",
            "Iteration 385, loss = 1497613371.12408876\n",
            "Iteration 386, loss = 1497502036.85713482\n",
            "Iteration 387, loss = 1497391375.92551231\n",
            "Iteration 388, loss = 1497280714.91448450\n",
            "Iteration 389, loss = 1497169958.41950178\n",
            "Iteration 390, loss = 1497059770.92669320\n",
            "Iteration 391, loss = 1496948846.49971366\n",
            "Iteration 392, loss = 1496838237.93221211\n",
            "Iteration 393, loss = 1496727507.15422773\n",
            "Iteration 394, loss = 1496616999.83986068\n",
            "Iteration 395, loss = 1496506133.17747068\n",
            "Iteration 396, loss = 1496395161.46084809\n",
            "Iteration 397, loss = 1496285010.64117289\n",
            "Iteration 398, loss = 1496173453.88235116\n",
            "Iteration 399, loss = 1496063472.45206475\n",
            "Iteration 400, loss = 1495953478.90652156\n",
            "Iteration 401, loss = 1495842696.89103866\n",
            "Iteration 402, loss = 1495732754.62940478\n",
            "Iteration 403, loss = 1495623394.24190450\n",
            "Iteration 404, loss = 1495512691.62236643\n",
            "Iteration 405, loss = 1495403010.75562310\n",
            "Iteration 406, loss = 1495293331.13886094\n",
            "Iteration 407, loss = 1495183029.86695075\n",
            "Iteration 408, loss = 1495072439.30999470\n",
            "Iteration 409, loss = 1494962827.47611952\n",
            "Iteration 410, loss = 1494852453.93472648\n",
            "Iteration 411, loss = 1494743398.71816778\n",
            "Iteration 412, loss = 1494632546.07315755\n",
            "Iteration 413, loss = 1494523295.31260633\n",
            "Iteration 414, loss = 1494413612.45124769\n",
            "Iteration 415, loss = 1494304405.54112911\n",
            "Iteration 416, loss = 1494194645.68988419\n",
            "Iteration 417, loss = 1494084318.45203662\n",
            "Iteration 418, loss = 1493975346.98170924\n",
            "Iteration 419, loss = 1493865497.37831283\n",
            "Iteration 420, loss = 1493755832.02799654\n",
            "Iteration 421, loss = 1493646732.74236703\n",
            "Iteration 422, loss = 1493537027.91399384\n",
            "Iteration 423, loss = 1493426749.39732790\n",
            "Iteration 424, loss = 1493311558.53842282\n",
            "Iteration 425, loss = 1493196606.69560838\n",
            "Iteration 426, loss = 1493082272.67719102\n",
            "Iteration 427, loss = 1492966563.34748125\n",
            "Iteration 428, loss = 1492852336.28506708\n",
            "Iteration 429, loss = 1492735957.64344096\n",
            "Iteration 430, loss = 1492621579.71970415\n",
            "Iteration 431, loss = 1492506258.87128878\n",
            "Iteration 432, loss = 1492391051.29537463\n",
            "Iteration 433, loss = 1492276387.74099088\n",
            "Iteration 434, loss = 1492162077.85660386\n",
            "Iteration 435, loss = 1492046544.99046564\n",
            "Iteration 436, loss = 1491932261.21659684\n",
            "Iteration 437, loss = 1491817981.13561916\n",
            "Iteration 438, loss = 1491703147.60872364\n",
            "Iteration 439, loss = 1491588723.74572825\n",
            "Iteration 440, loss = 1491475365.64391375\n",
            "Iteration 441, loss = 1491360661.91148686\n",
            "Iteration 442, loss = 1491246657.91250134\n",
            "Iteration 443, loss = 1491133867.31974173\n",
            "Iteration 444, loss = 1491019797.20368600\n",
            "Iteration 445, loss = 1490906129.13236117\n",
            "Iteration 446, loss = 1490793676.83078384\n",
            "Iteration 447, loss = 1490679925.40589190\n",
            "Iteration 448, loss = 1490567141.25764227\n",
            "Iteration 449, loss = 1490455431.56253505\n",
            "Iteration 450, loss = 1490341854.66086960\n",
            "Iteration 451, loss = 1490229913.53028083\n",
            "Iteration 452, loss = 1490118162.87555313\n",
            "Iteration 453, loss = 1490005949.62775755\n",
            "Iteration 454, loss = 1489893506.38929057\n",
            "Iteration 455, loss = 1489781620.27220702\n",
            "Iteration 456, loss = 1489669609.03770208\n",
            "Iteration 457, loss = 1489557583.19682288\n",
            "Iteration 458, loss = 1489445499.90493369\n",
            "Iteration 459, loss = 1489334617.35365415\n",
            "Iteration 460, loss = 1489221923.81167126\n",
            "Iteration 461, loss = 1489110594.81612420\n",
            "Iteration 462, loss = 1488999866.94819450\n",
            "Iteration 463, loss = 1488888619.24360156\n",
            "Iteration 464, loss = 1488777565.65884495\n",
            "Iteration 465, loss = 1488667192.36885953\n",
            "Iteration 466, loss = 1488556174.67729259\n",
            "Iteration 467, loss = 1488445682.87709379\n",
            "Iteration 468, loss = 1488335169.70384049\n",
            "Iteration 469, loss = 1488224534.30756259\n",
            "Iteration 470, loss = 1488114631.43755126\n",
            "Iteration 471, loss = 1488003362.79124093\n",
            "Iteration 472, loss = 1487892899.04509401\n",
            "Iteration 473, loss = 1487782274.33411002\n",
            "Iteration 474, loss = 1487670859.28621697\n",
            "Iteration 475, loss = 1487560779.97798109\n",
            "Iteration 476, loss = 1487449765.92661262\n",
            "Iteration 477, loss = 1487339217.28105593\n",
            "Iteration 478, loss = 1487228557.04396176\n",
            "Iteration 479, loss = 1487118075.61680865\n",
            "Iteration 480, loss = 1487007784.69697380\n",
            "Iteration 481, loss = 1486897860.90543175\n",
            "Iteration 482, loss = 1486786942.07071137\n",
            "Iteration 483, loss = 1486677253.58820677\n",
            "Iteration 484, loss = 1486566648.13550472\n",
            "Iteration 485, loss = 1486456285.81988335\n",
            "Iteration 486, loss = 1486346529.78526402\n",
            "Iteration 487, loss = 1486235731.11587691\n",
            "Iteration 488, loss = 1486124825.65554619\n",
            "Iteration 489, loss = 1486015544.47194695\n",
            "Iteration 490, loss = 1485904096.34903049\n",
            "Iteration 491, loss = 1485793442.82460380\n",
            "Iteration 492, loss = 1485682879.80514288\n",
            "Iteration 493, loss = 1485572595.96657896\n",
            "Iteration 494, loss = 1485461794.80071974\n",
            "Iteration 495, loss = 1485350978.48084235\n",
            "Iteration 496, loss = 1485240058.89135790\n",
            "Iteration 497, loss = 1485130060.96413708\n",
            "Iteration 498, loss = 1485018529.45272374\n",
            "Iteration 499, loss = 1484908990.31162047\n",
            "Iteration 500, loss = 1484797548.72904229\n",
            "Iteration 501, loss = 1484687239.88378859\n",
            "Iteration 502, loss = 1484577069.71674347\n",
            "Iteration 503, loss = 1484465782.75082469\n",
            "Iteration 504, loss = 1484355892.09850240\n",
            "Iteration 505, loss = 1484245249.59390402\n",
            "Iteration 506, loss = 1484134707.28161979\n",
            "Iteration 507, loss = 1484024150.67573404\n",
            "Iteration 508, loss = 1483913855.89324832\n",
            "Iteration 509, loss = 1483803595.61936307\n",
            "Iteration 510, loss = 1483692812.08623075\n",
            "Iteration 511, loss = 1483583229.64585876\n",
            "Iteration 512, loss = 1483472876.08316255\n",
            "Iteration 513, loss = 1483363281.00823021\n",
            "Iteration 514, loss = 1483253127.03027344\n",
            "Iteration 515, loss = 1483143339.70851636\n",
            "Iteration 516, loss = 1483033618.63930368\n",
            "Iteration 517, loss = 1482923447.64723539\n",
            "Iteration 518, loss = 1482813890.58418298\n",
            "Iteration 519, loss = 1482703707.34155726\n",
            "Iteration 520, loss = 1482594599.11208701\n",
            "Iteration 521, loss = 1482484664.43416166\n",
            "Iteration 522, loss = 1482375539.18630505\n",
            "Iteration 523, loss = 1482266089.92003274\n",
            "Iteration 524, loss = 1482156677.45464921\n",
            "Iteration 525, loss = 1482047279.70189452\n",
            "Iteration 526, loss = 1481939113.05788565\n",
            "Iteration 527, loss = 1481828955.11827874\n",
            "Iteration 528, loss = 1481720176.22581792\n",
            "Iteration 529, loss = 1481610779.64460039\n",
            "Iteration 530, loss = 1481501692.52735066\n",
            "Iteration 531, loss = 1481392139.08379030\n",
            "Iteration 532, loss = 1481282119.04701400\n",
            "Iteration 533, loss = 1481173556.38449025\n",
            "Iteration 534, loss = 1481063602.39077878\n",
            "Iteration 535, loss = 1480954089.49347496\n",
            "Iteration 536, loss = 1480844782.20387602\n",
            "Iteration 537, loss = 1480736022.54560041\n",
            "Iteration 538, loss = 1480626541.10739231\n",
            "Iteration 539, loss = 1480518089.24376273\n",
            "Iteration 540, loss = 1480409036.30056691\n",
            "Iteration 541, loss = 1480300331.04094577\n",
            "Iteration 542, loss = 1480191885.30057049\n",
            "Iteration 543, loss = 1480083280.02273798\n",
            "Iteration 544, loss = 1479974554.84331608\n",
            "Iteration 545, loss = 1479866022.91510391\n",
            "Iteration 546, loss = 1479757483.58871555\n",
            "Iteration 547, loss = 1479649065.58887410\n",
            "Iteration 548, loss = 1479540023.11236930\n",
            "Iteration 549, loss = 1479431936.67428374\n",
            "Iteration 550, loss = 1479323607.80816388\n",
            "Iteration 551, loss = 1479214693.59421682\n",
            "Iteration 552, loss = 1479106452.80084991\n",
            "Iteration 553, loss = 1478998136.09427547\n",
            "Iteration 554, loss = 1478889730.97722292\n",
            "Iteration 555, loss = 1478781353.64010382\n",
            "Iteration 556, loss = 1478672854.68360782\n",
            "Iteration 557, loss = 1478564149.20144629\n",
            "Iteration 558, loss = 1478455537.95120931\n",
            "Iteration 559, loss = 1478347828.06886959\n",
            "Iteration 560, loss = 1478238352.92017579\n",
            "Iteration 561, loss = 1478130472.78131342\n",
            "Iteration 562, loss = 1478021379.62276292\n",
            "Iteration 563, loss = 1477913044.92148829\n",
            "Iteration 564, loss = 1477804225.20842910\n",
            "Iteration 565, loss = 1477695746.67462826\n",
            "Iteration 566, loss = 1477586568.50848079\n",
            "Iteration 567, loss = 1477478457.62611675\n",
            "Iteration 568, loss = 1477368882.24501276\n",
            "Iteration 569, loss = 1477261445.49647880\n",
            "Iteration 570, loss = 1477152573.31436467\n",
            "Iteration 571, loss = 1477044225.85284591\n",
            "Iteration 572, loss = 1476935922.13940167\n",
            "Iteration 573, loss = 1476827194.80258226\n",
            "Iteration 574, loss = 1476718911.17468762\n",
            "Iteration 575, loss = 1476610639.64325953\n",
            "Iteration 576, loss = 1476501826.10784101\n",
            "Iteration 577, loss = 1476393259.37428546\n",
            "Iteration 578, loss = 1476284901.04306746\n",
            "Iteration 579, loss = 1476176156.03795409\n",
            "Iteration 580, loss = 1476067050.43772244\n",
            "Iteration 581, loss = 1475958952.81953239\n",
            "Iteration 582, loss = 1475850400.76699376\n",
            "Iteration 583, loss = 1475741762.01950741\n",
            "Iteration 584, loss = 1475633584.88058114\n",
            "Iteration 585, loss = 1475524816.29144502\n",
            "Iteration 586, loss = 1475416833.53476620\n",
            "Iteration 587, loss = 1475308693.39298964\n",
            "Iteration 588, loss = 1475200308.28537512\n",
            "Iteration 589, loss = 1475092418.15716767\n",
            "Iteration 590, loss = 1474983074.20977807\n",
            "Iteration 591, loss = 1474875911.84219384\n",
            "Iteration 592, loss = 1474767004.13182831\n",
            "Iteration 593, loss = 1474659208.73477769\n",
            "Iteration 594, loss = 1474550733.95795941\n",
            "Iteration 595, loss = 1474443090.09943700\n",
            "Iteration 596, loss = 1474335004.80721116\n",
            "Iteration 597, loss = 1474226968.87069917\n",
            "Iteration 598, loss = 1474119041.20246124\n",
            "Iteration 599, loss = 1474011863.28990340\n",
            "Iteration 600, loss = 1473903478.78624511\n",
            "Iteration 601, loss = 1473795735.28493357\n",
            "Iteration 602, loss = 1473688475.77395701\n",
            "Iteration 603, loss = 1473580724.90202832\n",
            "Iteration 604, loss = 1473472960.66082716\n",
            "Iteration 605, loss = 1473366037.74861431\n",
            "Iteration 606, loss = 1473258577.15900517\n",
            "Iteration 607, loss = 1473151602.83253860\n",
            "Iteration 608, loss = 1473044087.48362279\n",
            "Iteration 609, loss = 1472937517.93817639\n",
            "Iteration 610, loss = 1472829868.82800794\n",
            "Iteration 611, loss = 1472723778.66412425\n",
            "Iteration 612, loss = 1472616119.15166426\n",
            "Iteration 613, loss = 1472508075.84960699\n",
            "Iteration 614, loss = 1472401279.83835101\n",
            "Iteration 615, loss = 1472293641.40557265\n",
            "Iteration 616, loss = 1472186094.14165688\n",
            "Iteration 617, loss = 1472078297.63333440\n",
            "Iteration 618, loss = 1471970489.00263357\n",
            "Iteration 619, loss = 1471863477.94138479\n",
            "Iteration 620, loss = 1471755424.79544282\n",
            "Iteration 621, loss = 1471647692.96359420\n",
            "Iteration 622, loss = 1471540191.33116937\n",
            "Iteration 623, loss = 1471432252.12766242\n",
            "Iteration 624, loss = 1471324273.02103782\n",
            "Iteration 625, loss = 1471216489.56984067\n",
            "Iteration 626, loss = 1471109550.50471020\n",
            "Iteration 627, loss = 1471001859.47457862\n",
            "Iteration 628, loss = 1470894101.74074411\n",
            "Iteration 629, loss = 1470786940.83156991\n",
            "Iteration 630, loss = 1470679359.38915920\n",
            "Iteration 631, loss = 1470572357.53334856\n",
            "Iteration 632, loss = 1470464948.52776933\n",
            "Iteration 633, loss = 1470356865.14603710\n",
            "Iteration 634, loss = 1470250038.52320051\n",
            "Iteration 635, loss = 1470142197.27002358\n",
            "Iteration 636, loss = 1470034775.39593530\n",
            "Iteration 637, loss = 1469926850.50261593\n",
            "Iteration 638, loss = 1469819670.46093321\n",
            "Iteration 639, loss = 1469712393.05493689\n",
            "Iteration 640, loss = 1469604502.72992396\n",
            "Iteration 641, loss = 1469497397.71026278\n",
            "Iteration 642, loss = 1469390567.62911010\n",
            "Iteration 643, loss = 1469283082.90987992\n",
            "Iteration 644, loss = 1469176218.08586574\n",
            "Iteration 645, loss = 1469069007.96958327\n",
            "Iteration 646, loss = 1468962073.59099054\n",
            "Iteration 647, loss = 1468855494.35591865\n",
            "Iteration 648, loss = 1468748794.37055731\n",
            "Iteration 649, loss = 1468641594.08091831\n",
            "Iteration 650, loss = 1468535805.90560555\n",
            "Iteration 651, loss = 1468428548.75413108\n",
            "Iteration 652, loss = 1468322055.78101015\n",
            "Iteration 653, loss = 1468215234.51338387\n",
            "Iteration 654, loss = 1468108063.46766090\n",
            "Iteration 655, loss = 1468001503.71279955\n",
            "Iteration 656, loss = 1467894384.46647429\n",
            "Iteration 657, loss = 1467786994.11661792\n",
            "Iteration 658, loss = 1467679977.89323068\n",
            "Iteration 659, loss = 1467572701.30791569\n",
            "Iteration 660, loss = 1467465152.56325603\n",
            "Iteration 661, loss = 1467357884.57636619\n",
            "Iteration 662, loss = 1467250546.32354736\n",
            "Iteration 663, loss = 1467143745.23553276\n",
            "Iteration 664, loss = 1467036034.30552793\n",
            "Iteration 665, loss = 1466928731.01637483\n",
            "Iteration 666, loss = 1466822024.59205413\n",
            "Iteration 667, loss = 1466715766.75971603\n",
            "Iteration 668, loss = 1466607792.01578355\n",
            "Iteration 669, loss = 1466501658.78671741\n",
            "Iteration 670, loss = 1466395132.90714669\n",
            "Iteration 671, loss = 1466287877.85190630\n",
            "Iteration 672, loss = 1466181597.71528149\n",
            "Iteration 673, loss = 1466075203.61858082\n",
            "Iteration 674, loss = 1465968403.42955089\n",
            "Iteration 675, loss = 1465862015.32687664\n",
            "Iteration 676, loss = 1465755759.51655388\n",
            "Iteration 677, loss = 1465649114.58886027\n",
            "Iteration 678, loss = 1465542166.79107499\n",
            "Iteration 679, loss = 1465435517.91851401\n",
            "Iteration 680, loss = 1465328944.33584905\n",
            "Iteration 681, loss = 1465222211.00482392\n",
            "Iteration 682, loss = 1465114958.77382970\n",
            "Iteration 683, loss = 1465008981.45946288\n",
            "Iteration 684, loss = 1464901921.02848005\n",
            "Iteration 685, loss = 1464794603.50220704\n",
            "Iteration 686, loss = 1464688916.31346416\n",
            "Iteration 687, loss = 1464581162.94705272\n",
            "Iteration 688, loss = 1464475523.12044334\n",
            "Iteration 689, loss = 1464368684.83603382\n",
            "Iteration 690, loss = 1464262215.39462352\n",
            "Iteration 691, loss = 1464156468.54840350\n",
            "Iteration 692, loss = 1464050933.32921290\n",
            "Iteration 693, loss = 1463944614.13859940\n",
            "Iteration 694, loss = 1463839497.49983954\n",
            "Iteration 695, loss = 1463733456.33033967\n",
            "Iteration 696, loss = 1463627389.73697209\n",
            "Iteration 697, loss = 1463522041.43245721\n",
            "Iteration 698, loss = 1463415687.05942774\n",
            "Iteration 699, loss = 1463309865.19976687\n",
            "Iteration 700, loss = 1463204246.55877614\n",
            "Iteration 701, loss = 1463097954.67515731\n",
            "Iteration 702, loss = 1462992443.94751906\n",
            "Iteration 703, loss = 1462886966.47789383\n",
            "Iteration 704, loss = 1462781018.70993376\n",
            "Iteration 705, loss = 1462675792.17622185\n",
            "Iteration 706, loss = 1462570198.70290732\n",
            "Iteration 707, loss = 1462464454.05648208\n",
            "Iteration 708, loss = 1462358750.31447554\n",
            "Iteration 709, loss = 1462252942.46589851\n",
            "Iteration 710, loss = 1462147349.43767738\n",
            "Iteration 711, loss = 1462041392.74686503\n",
            "Iteration 712, loss = 1461935473.95607567\n",
            "Iteration 713, loss = 1461829763.19789481\n",
            "Iteration 714, loss = 1461723576.57217526\n",
            "Iteration 715, loss = 1461617832.65778995\n",
            "Iteration 716, loss = 1461510843.06521130\n",
            "Iteration 717, loss = 1461406005.82721782\n",
            "Iteration 718, loss = 1461298916.76599979\n",
            "Iteration 719, loss = 1461193153.75097728\n",
            "Iteration 720, loss = 1461086964.61509848\n",
            "Iteration 721, loss = 1460980959.77822495\n",
            "Iteration 722, loss = 1460874674.72407126\n",
            "Iteration 723, loss = 1460768644.98668861\n",
            "Iteration 724, loss = 1460662787.23123789\n",
            "Iteration 725, loss = 1460556348.38751602\n",
            "Iteration 726, loss = 1460451069.93080831\n",
            "Iteration 727, loss = 1460344756.43611097\n",
            "Iteration 728, loss = 1460239061.49233484\n",
            "Iteration 729, loss = 1460133192.94454598\n",
            "Iteration 730, loss = 1460027961.02082801\n",
            "Iteration 731, loss = 1459921984.51222324\n",
            "Iteration 732, loss = 1459815621.93372416\n",
            "Iteration 733, loss = 1459710376.97652745\n",
            "Iteration 734, loss = 1459602988.86719084\n",
            "Iteration 735, loss = 1459497475.49183536\n",
            "Iteration 736, loss = 1459391519.79783487\n",
            "Iteration 737, loss = 1459284601.64111400\n",
            "Iteration 738, loss = 1459178532.78112698\n",
            "Iteration 739, loss = 1459072834.49920487\n",
            "Iteration 740, loss = 1458966811.24076605\n",
            "Iteration 741, loss = 1458861228.49765897\n",
            "Iteration 742, loss = 1458754823.15096474\n",
            "Iteration 743, loss = 1458649561.11792684\n",
            "Iteration 744, loss = 1458543545.89210677\n",
            "Iteration 745, loss = 1458438315.89693427\n",
            "Iteration 746, loss = 1458331812.89245272\n",
            "Iteration 747, loss = 1458226897.60285664\n",
            "Iteration 748, loss = 1458120531.26069522\n",
            "Iteration 749, loss = 1458014894.16692901\n",
            "Iteration 750, loss = 1457909345.58066344\n",
            "Iteration 751, loss = 1457803582.51138926\n",
            "Iteration 752, loss = 1457697059.76475549\n",
            "Iteration 753, loss = 1457591078.70390177\n",
            "Iteration 754, loss = 1457485076.45857882\n",
            "Iteration 755, loss = 1457379503.40410924\n",
            "Iteration 756, loss = 1457273119.05683804\n",
            "Iteration 757, loss = 1457167019.87583733\n",
            "Iteration 758, loss = 1457061543.97041798\n",
            "Iteration 759, loss = 1456955599.63293719\n",
            "Iteration 760, loss = 1456849163.07977247\n",
            "Iteration 761, loss = 1456743333.63129592\n",
            "Iteration 762, loss = 1456637182.90568137\n",
            "Iteration 763, loss = 1456531000.48031783\n",
            "Iteration 764, loss = 1456425024.81679344\n",
            "Iteration 765, loss = 1456317867.68493128\n",
            "Iteration 766, loss = 1456211918.02612877\n",
            "Iteration 767, loss = 1456105553.21033788\n",
            "Iteration 768, loss = 1455999221.61179686\n",
            "Iteration 769, loss = 1455893415.92598963\n",
            "Iteration 770, loss = 1455786769.75859666\n",
            "Iteration 771, loss = 1455681447.60795617\n",
            "Iteration 772, loss = 1455575775.48142123\n",
            "Iteration 773, loss = 1455469801.59963179\n",
            "Iteration 774, loss = 1455364949.74868035\n",
            "Iteration 775, loss = 1455259712.01917744\n",
            "Iteration 776, loss = 1455153043.57521391\n",
            "Iteration 777, loss = 1455048537.76137114\n",
            "Iteration 778, loss = 1454942889.37075114\n",
            "Iteration 779, loss = 1454837075.43625784\n",
            "Iteration 780, loss = 1454732360.43272448\n",
            "Iteration 781, loss = 1454625727.58608675\n",
            "Iteration 782, loss = 1454520524.62224746\n",
            "Iteration 783, loss = 1454415357.55392766\n",
            "Iteration 784, loss = 1454309699.51224065\n",
            "Iteration 785, loss = 1454204616.75152254\n",
            "Iteration 786, loss = 1454099383.94911814\n",
            "Iteration 787, loss = 1453993330.61596394\n",
            "Iteration 788, loss = 1453889395.15745640\n",
            "Iteration 789, loss = 1453782878.62673855\n",
            "Iteration 790, loss = 1453677813.24070144\n",
            "Iteration 791, loss = 1453572399.26431990\n",
            "Iteration 792, loss = 1453466110.31729341\n",
            "Iteration 793, loss = 1453361078.87162971\n",
            "Iteration 794, loss = 1453255192.89855981\n",
            "Iteration 795, loss = 1453149090.70229483\n",
            "Iteration 796, loss = 1453043331.93310857\n",
            "Iteration 797, loss = 1452937798.18901300\n",
            "Iteration 798, loss = 1452832182.47748566\n",
            "Iteration 799, loss = 1452726419.61801600\n",
            "Iteration 800, loss = 1452620564.38910580\n",
            "Iteration 801, loss = 1452514731.80590439\n",
            "Iteration 802, loss = 1452409384.00597024\n",
            "Iteration 803, loss = 1452303984.80952644\n",
            "Iteration 804, loss = 1452198063.45347214\n",
            "Iteration 805, loss = 1452092831.99554706\n",
            "Iteration 806, loss = 1451987673.02445984\n",
            "Iteration 807, loss = 1451881318.04727721\n",
            "Iteration 808, loss = 1451776368.28523946\n",
            "Iteration 809, loss = 1451670104.30161715\n",
            "Iteration 810, loss = 1451564912.45667458\n",
            "Iteration 811, loss = 1451458660.87697434\n",
            "Iteration 812, loss = 1451353480.81269884\n",
            "Iteration 813, loss = 1451247032.17097187\n",
            "Iteration 814, loss = 1451142145.66668224\n",
            "Iteration 815, loss = 1451036157.63454723\n",
            "Iteration 816, loss = 1450930645.13408613\n",
            "Iteration 817, loss = 1450825010.49422431\n",
            "Iteration 818, loss = 1450719563.21566939\n",
            "Iteration 819, loss = 1450613727.41961002\n",
            "Iteration 820, loss = 1450507566.90430117\n",
            "Iteration 821, loss = 1450402004.14070082\n",
            "Iteration 822, loss = 1450295762.36329246\n",
            "Iteration 823, loss = 1450190575.41276455\n",
            "Iteration 824, loss = 1450084723.85984898\n",
            "Iteration 825, loss = 1449979791.80779886\n",
            "Iteration 826, loss = 1449873811.24437118\n",
            "Iteration 827, loss = 1449768803.94637942\n",
            "Iteration 828, loss = 1449663735.00899553\n",
            "Iteration 829, loss = 1449558323.19273973\n",
            "Iteration 830, loss = 1449453317.91674256\n",
            "Iteration 831, loss = 1449348129.49849939\n",
            "Iteration 832, loss = 1449242562.25221539\n",
            "Iteration 833, loss = 1449137250.02291274\n",
            "Iteration 834, loss = 1449032262.75259852\n",
            "Iteration 835, loss = 1448927006.26913595\n",
            "Iteration 836, loss = 1448821275.05607533\n",
            "Iteration 837, loss = 1448716332.29881787\n",
            "Iteration 838, loss = 1448610503.85835791\n",
            "Iteration 839, loss = 1448505090.16133451\n",
            "Iteration 840, loss = 1448399648.18037581\n",
            "Iteration 841, loss = 1448293878.62645698\n",
            "Iteration 842, loss = 1448188181.54685235\n",
            "Iteration 843, loss = 1448082156.96960974\n",
            "Iteration 844, loss = 1447976311.46974063\n",
            "Iteration 845, loss = 1447870397.19295573\n",
            "Iteration 846, loss = 1447764189.22693825\n",
            "Iteration 847, loss = 1447658093.94374681\n",
            "Iteration 848, loss = 1447552176.99826741\n",
            "Iteration 849, loss = 1447446373.66190600\n",
            "Iteration 850, loss = 1447340451.84005570\n",
            "Iteration 851, loss = 1447234326.53395653\n",
            "Iteration 852, loss = 1447129265.10365033\n",
            "Iteration 853, loss = 1447023703.33326268\n",
            "Iteration 854, loss = 1446918346.51936626\n",
            "Iteration 855, loss = 1446812719.36238718\n",
            "Iteration 856, loss = 1446707611.20478845\n",
            "Iteration 857, loss = 1446602526.13431787\n",
            "Iteration 858, loss = 1446496839.62698245\n",
            "Iteration 859, loss = 1446392093.05045915\n",
            "Iteration 860, loss = 1446286727.40870070\n",
            "Iteration 861, loss = 1446181847.28928185\n",
            "Iteration 862, loss = 1446076351.81809187\n",
            "Iteration 863, loss = 1445971973.11764669\n",
            "Iteration 864, loss = 1445867116.34582996\n",
            "Iteration 865, loss = 1445761924.16942334\n",
            "Iteration 866, loss = 1445657568.77561760\n",
            "Iteration 867, loss = 1445552875.03717303\n",
            "Iteration 868, loss = 1445448377.58098125\n",
            "Iteration 869, loss = 1445343372.56300616\n",
            "Iteration 870, loss = 1445238544.77358961\n",
            "Iteration 871, loss = 1445133885.62586522\n",
            "Iteration 872, loss = 1445028541.28070831\n",
            "Iteration 873, loss = 1444923616.34824181\n",
            "Iteration 874, loss = 1444818167.02837968\n",
            "Iteration 875, loss = 1444713044.13011909\n",
            "Iteration 876, loss = 1444608337.34190011\n",
            "Iteration 877, loss = 1444502875.31915879\n",
            "Iteration 878, loss = 1444398346.19572759\n",
            "Iteration 879, loss = 1444293937.47439742\n",
            "Iteration 880, loss = 1444189372.85858750\n",
            "Iteration 881, loss = 1444085542.60032153\n",
            "Iteration 882, loss = 1443980919.44916511\n",
            "Iteration 883, loss = 1443876430.31352782\n",
            "Iteration 884, loss = 1443772405.22478580\n",
            "Iteration 885, loss = 1443667981.71904945\n",
            "Iteration 886, loss = 1443562896.99893641\n",
            "Iteration 887, loss = 1443458840.49640489\n",
            "Iteration 888, loss = 1443353903.59147239\n",
            "Iteration 889, loss = 1443248618.14078379\n",
            "Iteration 890, loss = 1443143651.22418332\n",
            "Iteration 891, loss = 1443038370.85026670\n",
            "Iteration 892, loss = 1442933086.92847061\n",
            "Iteration 893, loss = 1442828194.45850086\n",
            "Iteration 894, loss = 1442722289.16101170\n",
            "Iteration 895, loss = 1442617124.40882802\n",
            "Iteration 896, loss = 1442511449.26618624\n",
            "Iteration 897, loss = 1442405903.43131661\n",
            "Iteration 898, loss = 1442300446.37894964\n",
            "Iteration 899, loss = 1442195117.23603606\n",
            "Iteration 900, loss = 1442089737.98975563\n",
            "Iteration 901, loss = 1441984095.31420994\n",
            "Iteration 902, loss = 1441878709.18644428\n",
            "Iteration 903, loss = 1441774052.74895954\n",
            "Iteration 904, loss = 1441669710.22706652\n",
            "Iteration 905, loss = 1441564178.06127954\n",
            "Iteration 906, loss = 1441459612.60170031\n",
            "Iteration 907, loss = 1441355715.29338551\n",
            "Iteration 908, loss = 1441250898.77329421\n",
            "Iteration 909, loss = 1441147254.13726115\n",
            "Iteration 910, loss = 1441042544.00440001\n",
            "Iteration 911, loss = 1440938395.92556095\n",
            "Iteration 912, loss = 1440834521.50438380\n",
            "Iteration 913, loss = 1440730159.94883466\n",
            "Iteration 914, loss = 1440626245.08907342\n",
            "Iteration 915, loss = 1440522392.19091964\n",
            "Iteration 916, loss = 1440417791.22984886\n",
            "Iteration 917, loss = 1440313646.33549380\n",
            "Iteration 918, loss = 1440208890.29165816\n",
            "Iteration 919, loss = 1440105086.45201325\n",
            "Iteration 920, loss = 1439999778.64792347\n",
            "Iteration 921, loss = 1439894966.33043098\n",
            "Iteration 922, loss = 1439790899.32941937\n",
            "Iteration 923, loss = 1439686777.43445921\n",
            "Iteration 924, loss = 1439581946.71439934\n",
            "Iteration 925, loss = 1439477573.40903306\n",
            "Iteration 926, loss = 1439374320.82083035\n",
            "Iteration 927, loss = 1439269275.34630704\n",
            "Iteration 928, loss = 1439166090.39921618\n",
            "Iteration 929, loss = 1439061964.45317364\n",
            "Iteration 930, loss = 1438957912.62613130\n",
            "Iteration 931, loss = 1438853635.11285996\n",
            "Iteration 932, loss = 1438750067.18020582\n",
            "Iteration 933, loss = 1438646027.12135744\n",
            "Iteration 934, loss = 1438541501.83642960\n",
            "Iteration 935, loss = 1438438210.72611070\n",
            "Iteration 936, loss = 1438334090.31914234\n",
            "Iteration 937, loss = 1438229807.36461496\n",
            "Iteration 938, loss = 1438126637.84120607\n",
            "Iteration 939, loss = 1438021857.46075416\n",
            "Iteration 940, loss = 1437918875.31068277\n",
            "Iteration 941, loss = 1437814139.88128972\n",
            "Iteration 942, loss = 1437710865.43503356\n",
            "Iteration 943, loss = 1437606773.16572785\n",
            "Iteration 944, loss = 1437502476.22545934\n",
            "Iteration 945, loss = 1437398471.82506371\n",
            "Iteration 946, loss = 1437294402.79142761\n",
            "Iteration 947, loss = 1437190427.80682683\n",
            "Iteration 948, loss = 1437086589.24498796\n",
            "Iteration 949, loss = 1436981491.53744555\n",
            "Iteration 950, loss = 1436877642.35088086\n",
            "Iteration 951, loss = 1436773979.22678494\n",
            "Iteration 952, loss = 1436669070.62000918\n",
            "Iteration 953, loss = 1436565255.24823523\n",
            "Iteration 954, loss = 1436460820.04587412\n",
            "Iteration 955, loss = 1436356561.97720551\n",
            "Iteration 956, loss = 1436252399.93407774\n",
            "Iteration 957, loss = 1436148286.58814406\n",
            "Iteration 958, loss = 1436043201.63859224\n",
            "Iteration 959, loss = 1435939162.66691589\n",
            "Iteration 960, loss = 1435835206.18032193\n",
            "Iteration 961, loss = 1435729669.30771303\n",
            "Iteration 962, loss = 1435625460.58545160\n",
            "Iteration 963, loss = 1435521660.42950392\n",
            "Iteration 964, loss = 1435415898.81754446\n",
            "Iteration 965, loss = 1435311592.29364848\n",
            "Iteration 966, loss = 1435207619.61647105\n",
            "Iteration 967, loss = 1435103659.71986532\n",
            "Iteration 968, loss = 1434998545.52169919\n",
            "Iteration 969, loss = 1434894728.41809297\n",
            "Iteration 970, loss = 1434790603.49884248\n",
            "Iteration 971, loss = 1434687236.15510273\n",
            "Iteration 972, loss = 1434582471.54036641\n",
            "Iteration 973, loss = 1434479615.04071426\n",
            "Iteration 974, loss = 1434375087.29623294\n",
            "Iteration 975, loss = 1434271780.05658650\n",
            "Iteration 976, loss = 1434167703.82458997\n",
            "Iteration 977, loss = 1434064317.83105063\n",
            "Iteration 978, loss = 1433961073.45496440\n",
            "Iteration 979, loss = 1433856919.55254197\n",
            "Iteration 980, loss = 1433753853.24879646\n",
            "Iteration 981, loss = 1433650230.46235394\n",
            "Iteration 982, loss = 1433546844.55452156\n",
            "Iteration 983, loss = 1433442758.71057200\n",
            "Iteration 984, loss = 1433340023.82990599\n",
            "Iteration 985, loss = 1433235622.56189203\n",
            "Iteration 986, loss = 1433132063.91789937\n",
            "Iteration 987, loss = 1433027711.07029700\n",
            "Iteration 988, loss = 1432924866.81465077\n",
            "Iteration 989, loss = 1432820368.32544231\n",
            "Iteration 990, loss = 1432716940.95723939\n",
            "Iteration 991, loss = 1432612612.70385218\n",
            "Iteration 992, loss = 1432509244.08754253\n",
            "Iteration 993, loss = 1432405782.23332167\n",
            "Iteration 994, loss = 1432301118.52686572\n",
            "Iteration 995, loss = 1432197972.27574039\n",
            "Iteration 996, loss = 1432094451.89745498\n",
            "Iteration 997, loss = 1431990296.97928572\n",
            "Iteration 998, loss = 1431886964.18491220\n",
            "Iteration 999, loss = 1431782756.74330139\n",
            "Iteration 1000, loss = 1431679656.77093983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1313944922.08949399\n",
            "Iteration 2, loss = 195146235.17326009\n",
            "Iteration 3, loss = 195831030.21978724\n",
            "Iteration 4, loss = 101267354.99833450\n",
            "Iteration 5, loss = 97969803.69341679\n",
            "Iteration 6, loss = 95905079.75350712\n",
            "Iteration 7, loss = 97312710.88997120\n",
            "Iteration 8, loss = 102976883.25636885\n",
            "Iteration 9, loss = 96065372.97366272\n",
            "Iteration 10, loss = 96270431.61489311\n",
            "Iteration 11, loss = 95679537.94100551\n",
            "Iteration 12, loss = 96362584.84549928\n",
            "Iteration 13, loss = 99364956.25305189\n",
            "Iteration 14, loss = 96072031.94322287\n",
            "Iteration 15, loss = 95802066.81756882\n",
            "Iteration 16, loss = 96796789.81713285\n",
            "Iteration 17, loss = 95955998.47249135\n",
            "Iteration 18, loss = 96681768.91452517\n",
            "Iteration 19, loss = 99709178.01439092\n",
            "Iteration 20, loss = 96015163.68359911\n",
            "Iteration 21, loss = 96051334.77157877\n",
            "Iteration 22, loss = 99169594.55854040\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538787463.89981627\n",
            "Iteration 2, loss = 1538637447.58914232\n",
            "Iteration 3, loss = 1538515983.32759881\n",
            "Iteration 4, loss = 1538422583.00800824\n",
            "Iteration 5, loss = 1538343320.34046388\n",
            "Iteration 6, loss = 1538267002.01594996\n",
            "Iteration 7, loss = 1538190501.50813532\n",
            "Iteration 8, loss = 1538112393.74407911\n",
            "Iteration 9, loss = 1538032446.43186927\n",
            "Iteration 10, loss = 1537951664.58236504\n",
            "Iteration 11, loss = 1537871487.76471043\n",
            "Iteration 12, loss = 1537790992.36066580\n",
            "Iteration 13, loss = 1537711100.42933846\n",
            "Iteration 14, loss = 1537630361.60582042\n",
            "Iteration 15, loss = 1537550454.84520364\n",
            "Iteration 16, loss = 1537470552.83832169\n",
            "Iteration 17, loss = 1537390578.84709382\n",
            "Iteration 18, loss = 1537309283.64253926\n",
            "Iteration 19, loss = 1537226852.63625383\n",
            "Iteration 20, loss = 1537142583.87375093\n",
            "Iteration 21, loss = 1537056350.54795408\n",
            "Iteration 22, loss = 1536968148.95349503\n",
            "Iteration 23, loss = 1536879006.83647585\n",
            "Iteration 24, loss = 1536790458.66588926\n",
            "Iteration 25, loss = 1536704121.97574401\n",
            "Iteration 26, loss = 1536618141.66922259\n",
            "Iteration 27, loss = 1536531491.96193457\n",
            "Iteration 28, loss = 1536445196.81655741\n",
            "Iteration 29, loss = 1536358221.67324400\n",
            "Iteration 30, loss = 1536270450.67463613\n",
            "Iteration 31, loss = 1536181153.52899647\n",
            "Iteration 32, loss = 1536093824.69416571\n",
            "Iteration 33, loss = 1536006477.25877404\n",
            "Iteration 34, loss = 1535919599.01884770\n",
            "Iteration 35, loss = 1535832531.50026655\n",
            "Iteration 36, loss = 1535745367.80862975\n",
            "Iteration 37, loss = 1535656914.75875258\n",
            "Iteration 38, loss = 1535567273.56027150\n",
            "Iteration 39, loss = 1535478485.74897528\n",
            "Iteration 40, loss = 1535389455.38589287\n",
            "Iteration 41, loss = 1535301713.24508595\n",
            "Iteration 42, loss = 1535214150.59782195\n",
            "Iteration 43, loss = 1535126288.41778541\n",
            "Iteration 44, loss = 1535038711.23913741\n",
            "Iteration 45, loss = 1534951337.02935219\n",
            "Iteration 46, loss = 1534864077.14870548\n",
            "Iteration 47, loss = 1534777159.50239420\n",
            "Iteration 48, loss = 1534690684.46195698\n",
            "Iteration 49, loss = 1534603766.73860002\n",
            "Iteration 50, loss = 1534517590.97017002\n",
            "Iteration 51, loss = 1534430506.85810971\n",
            "Iteration 52, loss = 1534344420.54002714\n",
            "Iteration 53, loss = 1534256524.06679535\n",
            "Iteration 54, loss = 1534168007.28260684\n",
            "Iteration 55, loss = 1534078178.86322975\n",
            "Iteration 56, loss = 1533989688.78506231\n",
            "Iteration 57, loss = 1533901758.84784508\n",
            "Iteration 58, loss = 1533813638.11953330\n",
            "Iteration 59, loss = 1533725803.91354537\n",
            "Iteration 60, loss = 1533638310.76984763\n",
            "Iteration 61, loss = 1533550085.89408755\n",
            "Iteration 62, loss = 1533463020.08491492\n",
            "Iteration 63, loss = 1533375367.04454732\n",
            "Iteration 64, loss = 1533288323.86520123\n",
            "Iteration 65, loss = 1533200872.57676792\n",
            "Iteration 66, loss = 1533114047.05582094\n",
            "Iteration 67, loss = 1533026642.65681410\n",
            "Iteration 68, loss = 1532940031.14903617\n",
            "Iteration 69, loss = 1532852399.04736567\n",
            "Iteration 70, loss = 1532765553.79255104\n",
            "Iteration 71, loss = 1532675393.07249379\n",
            "Iteration 72, loss = 1532585285.90244651\n",
            "Iteration 73, loss = 1532495869.30888534\n",
            "Iteration 74, loss = 1532407689.15878534\n",
            "Iteration 75, loss = 1532318832.78163362\n",
            "Iteration 76, loss = 1532230481.49987936\n",
            "Iteration 77, loss = 1532141926.32697368\n",
            "Iteration 78, loss = 1532053557.00037980\n",
            "Iteration 79, loss = 1531965274.81676936\n",
            "Iteration 80, loss = 1531876756.92126274\n",
            "Iteration 81, loss = 1531788430.30899310\n",
            "Iteration 82, loss = 1531700501.31416941\n",
            "Iteration 83, loss = 1531612645.37842655\n",
            "Iteration 84, loss = 1531524742.04091859\n",
            "Iteration 85, loss = 1531436734.68633294\n",
            "Iteration 86, loss = 1531349261.25958157\n",
            "Iteration 87, loss = 1531262120.39317250\n",
            "Iteration 88, loss = 1531173889.76081443\n",
            "Iteration 89, loss = 1531086477.52264929\n",
            "Iteration 90, loss = 1530998676.31615734\n",
            "Iteration 91, loss = 1530910829.55152869\n",
            "Iteration 92, loss = 1530823085.34723997\n",
            "Iteration 93, loss = 1530735197.49681282\n",
            "Iteration 94, loss = 1530647050.99315834\n",
            "Iteration 95, loss = 1530559574.86019707\n",
            "Iteration 96, loss = 1530471509.54205728\n",
            "Iteration 97, loss = 1530383578.99513316\n",
            "Iteration 98, loss = 1530295660.60019112\n",
            "Iteration 99, loss = 1530204505.69029951\n",
            "Iteration 100, loss = 1530113267.76915598\n",
            "Iteration 101, loss = 1530023351.32095385\n",
            "Iteration 102, loss = 1529932868.11043668\n",
            "Iteration 103, loss = 1529844183.30731702\n",
            "Iteration 104, loss = 1529754286.07731485\n",
            "Iteration 105, loss = 1529664620.84016943\n",
            "Iteration 106, loss = 1529575389.00940490\n",
            "Iteration 107, loss = 1529485733.69383979\n",
            "Iteration 108, loss = 1529396820.77947497\n",
            "Iteration 109, loss = 1529307249.68758202\n",
            "Iteration 110, loss = 1529216501.84900737\n",
            "Iteration 111, loss = 1529122397.58958030\n",
            "Iteration 112, loss = 1529031110.91616583\n",
            "Iteration 113, loss = 1528938371.50271368\n",
            "Iteration 114, loss = 1528843440.06885839\n",
            "Iteration 115, loss = 1528747767.70001125\n",
            "Iteration 116, loss = 1528651103.96355391\n",
            "Iteration 117, loss = 1528553052.06675291\n",
            "Iteration 118, loss = 1528454726.43438649\n",
            "Iteration 119, loss = 1528357736.55419016\n",
            "Iteration 120, loss = 1528259397.09968090\n",
            "Iteration 121, loss = 1528158576.84656262\n",
            "Iteration 122, loss = 1528055983.13555527\n",
            "Iteration 123, loss = 1527953382.92826176\n",
            "Iteration 124, loss = 1527847626.95182300\n",
            "Iteration 125, loss = 1527744089.48683429\n",
            "Iteration 126, loss = 1527640335.33155751\n",
            "Iteration 127, loss = 1527537234.64399242\n",
            "Iteration 128, loss = 1527433344.22604704\n",
            "Iteration 129, loss = 1527330701.10627079\n",
            "Iteration 130, loss = 1527227420.84882927\n",
            "Iteration 131, loss = 1527124682.94787669\n",
            "Iteration 132, loss = 1527022071.63388824\n",
            "Iteration 133, loss = 1526920328.26714087\n",
            "Iteration 134, loss = 1526818564.10213089\n",
            "Iteration 135, loss = 1526716475.26548886\n",
            "Iteration 136, loss = 1526613111.82685089\n",
            "Iteration 137, loss = 1526505992.50880384\n",
            "Iteration 138, loss = 1526400116.38873315\n",
            "Iteration 139, loss = 1526291322.78528500\n",
            "Iteration 140, loss = 1526184817.20882106\n",
            "Iteration 141, loss = 1526079037.30723882\n",
            "Iteration 142, loss = 1525972048.94148445\n",
            "Iteration 143, loss = 1525865970.25555134\n",
            "Iteration 144, loss = 1525759453.50328612\n",
            "Iteration 145, loss = 1525649653.33464432\n",
            "Iteration 146, loss = 1525540420.04781008\n",
            "Iteration 147, loss = 1525431694.46096587\n",
            "Iteration 148, loss = 1525323885.63869357\n",
            "Iteration 149, loss = 1525214643.27640033\n",
            "Iteration 150, loss = 1525102388.01061511\n",
            "Iteration 151, loss = 1524990189.75110435\n",
            "Iteration 152, loss = 1524879501.20558405\n",
            "Iteration 153, loss = 1524769492.02614474\n",
            "Iteration 154, loss = 1524658614.85869980\n",
            "Iteration 155, loss = 1524547399.01356173\n",
            "Iteration 156, loss = 1524433103.68416953\n",
            "Iteration 157, loss = 1524320307.07038403\n",
            "Iteration 158, loss = 1524208409.27861571\n",
            "Iteration 159, loss = 1524096114.12002945\n",
            "Iteration 160, loss = 1523984391.36196113\n",
            "Iteration 161, loss = 1523873019.67012858\n",
            "Iteration 162, loss = 1523761169.32261181\n",
            "Iteration 163, loss = 1523649966.37046361\n",
            "Iteration 164, loss = 1523539996.53906226\n",
            "Iteration 165, loss = 1523428479.76491022\n",
            "Iteration 166, loss = 1523317160.98190737\n",
            "Iteration 167, loss = 1523202423.07817626\n",
            "Iteration 168, loss = 1523088739.49066830\n",
            "Iteration 169, loss = 1522976172.64186263\n",
            "Iteration 170, loss = 1522863624.30893731\n",
            "Iteration 171, loss = 1522751366.64039826\n",
            "Iteration 172, loss = 1522639022.50362611\n",
            "Iteration 173, loss = 1522527133.04687834\n",
            "Iteration 174, loss = 1522415724.65699744\n",
            "Iteration 175, loss = 1522304642.67646670\n",
            "Iteration 176, loss = 1522193778.03399777\n",
            "Iteration 177, loss = 1522083308.11778808\n",
            "Iteration 178, loss = 1521973885.70527172\n",
            "Iteration 179, loss = 1521864112.53023553\n",
            "Iteration 180, loss = 1521754680.43774009\n",
            "Iteration 181, loss = 1521645979.75525022\n",
            "Iteration 182, loss = 1521537127.89963055\n",
            "Iteration 183, loss = 1521429624.76848626\n",
            "Iteration 184, loss = 1521321916.69076133\n",
            "Iteration 185, loss = 1521214043.50508118\n",
            "Iteration 186, loss = 1521106523.58575511\n",
            "Iteration 187, loss = 1520998928.72450089\n",
            "Iteration 188, loss = 1520892189.31053877\n",
            "Iteration 189, loss = 1520785036.79884601\n",
            "Iteration 190, loss = 1520677863.48267484\n",
            "Iteration 191, loss = 1520570560.96464181\n",
            "Iteration 192, loss = 1520463907.35461593\n",
            "Iteration 193, loss = 1520357209.18342638\n",
            "Iteration 194, loss = 1520251091.48159909\n",
            "Iteration 195, loss = 1520145770.59468746\n",
            "Iteration 196, loss = 1520039507.96468425\n",
            "Iteration 197, loss = 1519933959.89632344\n",
            "Iteration 198, loss = 1519828920.47346497\n",
            "Iteration 199, loss = 1519723176.70950913\n",
            "Iteration 200, loss = 1519618275.61872172\n",
            "Iteration 201, loss = 1519512545.79547787\n",
            "Iteration 202, loss = 1519407606.21997905\n",
            "Iteration 203, loss = 1519302817.44849062\n",
            "Iteration 204, loss = 1519196851.21504307\n",
            "Iteration 205, loss = 1519092484.41226816\n",
            "Iteration 206, loss = 1518987922.95922542\n",
            "Iteration 207, loss = 1518883343.74855113\n",
            "Iteration 208, loss = 1518778657.03218937\n",
            "Iteration 209, loss = 1518674420.76638365\n",
            "Iteration 210, loss = 1518571019.22721052\n",
            "Iteration 211, loss = 1518466553.44427609\n",
            "Iteration 212, loss = 1518363039.50182939\n",
            "Iteration 213, loss = 1518260336.22872972\n",
            "Iteration 214, loss = 1518156475.72251153\n",
            "Iteration 215, loss = 1518053201.76017594\n",
            "Iteration 216, loss = 1517949794.45529604\n",
            "Iteration 217, loss = 1517846248.39725494\n",
            "Iteration 218, loss = 1517737621.49173951\n",
            "Iteration 219, loss = 1517623140.46252227\n",
            "Iteration 220, loss = 1517512953.17194057\n",
            "Iteration 221, loss = 1517400547.84602618\n",
            "Iteration 222, loss = 1517290090.63118458\n",
            "Iteration 223, loss = 1517177362.16232610\n",
            "Iteration 224, loss = 1517065853.62475586\n",
            "Iteration 225, loss = 1516954107.45164275\n",
            "Iteration 226, loss = 1516842496.16292763\n",
            "Iteration 227, loss = 1516728905.56709051\n",
            "Iteration 228, loss = 1516613657.14056706\n",
            "Iteration 229, loss = 1516498867.02671337\n",
            "Iteration 230, loss = 1516384860.37618899\n",
            "Iteration 231, loss = 1516270427.57414770\n",
            "Iteration 232, loss = 1516157061.08438730\n",
            "Iteration 233, loss = 1516043246.69035435\n",
            "Iteration 234, loss = 1515929856.73311257\n",
            "Iteration 235, loss = 1515816287.15144897\n",
            "Iteration 236, loss = 1515703563.10782266\n",
            "Iteration 237, loss = 1515590574.93164802\n",
            "Iteration 238, loss = 1515478577.63439083\n",
            "Iteration 239, loss = 1515366440.79427314\n",
            "Iteration 240, loss = 1515254984.88891959\n",
            "Iteration 241, loss = 1515143235.35696530\n",
            "Iteration 242, loss = 1515032050.33456802\n",
            "Iteration 243, loss = 1514921043.91944981\n",
            "Iteration 244, loss = 1514809899.40153408\n",
            "Iteration 245, loss = 1514700205.49049306\n",
            "Iteration 246, loss = 1514588374.04578829\n",
            "Iteration 247, loss = 1514478450.10205817\n",
            "Iteration 248, loss = 1514368070.43225265\n",
            "Iteration 249, loss = 1514257820.74353909\n",
            "Iteration 250, loss = 1514147989.87420106\n",
            "Iteration 251, loss = 1514038293.88335180\n",
            "Iteration 252, loss = 1513928556.52615666\n",
            "Iteration 253, loss = 1513819414.38880086\n",
            "Iteration 254, loss = 1513710577.67202973\n",
            "Iteration 255, loss = 1513601500.45720625\n",
            "Iteration 256, loss = 1513492696.98590136\n",
            "Iteration 257, loss = 1513384185.02911401\n",
            "Iteration 258, loss = 1513276133.58247018\n",
            "Iteration 259, loss = 1513167410.39807582\n",
            "Iteration 260, loss = 1513059924.27683115\n",
            "Iteration 261, loss = 1512951706.27173352\n",
            "Iteration 262, loss = 1512844244.39825344\n",
            "Iteration 263, loss = 1512737395.45074630\n",
            "Iteration 264, loss = 1512629280.06471682\n",
            "Iteration 265, loss = 1512521905.53460932\n",
            "Iteration 266, loss = 1512415375.50597548\n",
            "Iteration 267, loss = 1512307753.33635616\n",
            "Iteration 268, loss = 1512200878.93766141\n",
            "Iteration 269, loss = 1512094296.05184126\n",
            "Iteration 270, loss = 1511986739.44881392\n",
            "Iteration 271, loss = 1511880346.31505179\n",
            "Iteration 272, loss = 1511772818.61041903\n",
            "Iteration 273, loss = 1511666476.15056062\n",
            "Iteration 274, loss = 1511557936.05172038\n",
            "Iteration 275, loss = 1511445182.72609878\n",
            "Iteration 276, loss = 1511334081.72049403\n",
            "Iteration 277, loss = 1511223687.79975104\n",
            "Iteration 278, loss = 1511112318.63771510\n",
            "Iteration 279, loss = 1510998471.71804285\n",
            "Iteration 280, loss = 1510880155.94852972\n",
            "Iteration 281, loss = 1510765056.80670977\n",
            "Iteration 282, loss = 1510650074.86622477\n",
            "Iteration 283, loss = 1510534284.27193666\n",
            "Iteration 284, loss = 1510419349.53569698\n",
            "Iteration 285, loss = 1510304322.91781306\n",
            "Iteration 286, loss = 1510189880.73865414\n",
            "Iteration 287, loss = 1510074434.51683640\n",
            "Iteration 288, loss = 1509960362.27974224\n",
            "Iteration 289, loss = 1509843625.53564739\n",
            "Iteration 290, loss = 1509724470.95203900\n",
            "Iteration 291, loss = 1509605266.23377252\n",
            "Iteration 292, loss = 1509488822.90115666\n",
            "Iteration 293, loss = 1509371166.94783902\n",
            "Iteration 294, loss = 1509253763.38874793\n",
            "Iteration 295, loss = 1509136330.53767395\n",
            "Iteration 296, loss = 1509019532.25069523\n",
            "Iteration 297, loss = 1508902596.84296227\n",
            "Iteration 298, loss = 1508785866.26559973\n",
            "Iteration 299, loss = 1508669320.76646948\n",
            "Iteration 300, loss = 1508553294.15853286\n",
            "Iteration 301, loss = 1508437155.65887475\n",
            "Iteration 302, loss = 1508321373.10516095\n",
            "Iteration 303, loss = 1508206230.91040730\n",
            "Iteration 304, loss = 1508090846.48476362\n",
            "Iteration 305, loss = 1507976747.14756227\n",
            "Iteration 306, loss = 1507861618.82663918\n",
            "Iteration 307, loss = 1507748294.58877087\n",
            "Iteration 308, loss = 1507634021.95922756\n",
            "Iteration 309, loss = 1507521442.14770532\n",
            "Iteration 310, loss = 1507407338.91547680\n",
            "Iteration 311, loss = 1507294657.87395334\n",
            "Iteration 312, loss = 1507181395.04344010\n",
            "Iteration 313, loss = 1507068246.69201946\n",
            "Iteration 314, loss = 1506948765.52865386\n",
            "Iteration 315, loss = 1506831897.91942501\n",
            "Iteration 316, loss = 1506715577.56254768\n",
            "Iteration 317, loss = 1506598631.22625709\n",
            "Iteration 318, loss = 1506481770.28512645\n",
            "Iteration 319, loss = 1506365801.00491929\n",
            "Iteration 320, loss = 1506248632.98815465\n",
            "Iteration 321, loss = 1506132001.55886316\n",
            "Iteration 322, loss = 1506016159.47417974\n",
            "Iteration 323, loss = 1505899639.41966033\n",
            "Iteration 324, loss = 1505783928.15385294\n",
            "Iteration 325, loss = 1505667999.50161076\n",
            "Iteration 326, loss = 1505553811.00989866\n",
            "Iteration 327, loss = 1505437438.09277773\n",
            "Iteration 328, loss = 1505323619.97856712\n",
            "Iteration 329, loss = 1505208702.36718011\n",
            "Iteration 330, loss = 1505094537.10697889\n",
            "Iteration 331, loss = 1504980505.14348865\n",
            "Iteration 332, loss = 1504865094.72481656\n",
            "Iteration 333, loss = 1504745191.31806731\n",
            "Iteration 334, loss = 1504626625.45856476\n",
            "Iteration 335, loss = 1504508132.76189327\n",
            "Iteration 336, loss = 1504389565.38051629\n",
            "Iteration 337, loss = 1504271415.06718063\n",
            "Iteration 338, loss = 1504153610.04857612\n",
            "Iteration 339, loss = 1504035402.58824277\n",
            "Iteration 340, loss = 1503917649.00759006\n",
            "Iteration 341, loss = 1503800702.29460430\n",
            "Iteration 342, loss = 1503683957.09674478\n",
            "Iteration 343, loss = 1503566954.69033504\n",
            "Iteration 344, loss = 1503450704.58166361\n",
            "Iteration 345, loss = 1503333830.34277797\n",
            "Iteration 346, loss = 1503217145.99631810\n",
            "Iteration 347, loss = 1503101760.11739278\n",
            "Iteration 348, loss = 1502985898.62221503\n",
            "Iteration 349, loss = 1502868935.33858943\n",
            "Iteration 350, loss = 1502753348.63215256\n",
            "Iteration 351, loss = 1502637520.53915286\n",
            "Iteration 352, loss = 1502521715.85355449\n",
            "Iteration 353, loss = 1502406639.98326278\n",
            "Iteration 354, loss = 1502290606.40114403\n",
            "Iteration 355, loss = 1502174971.13235688\n",
            "Iteration 356, loss = 1502059449.43620062\n",
            "Iteration 357, loss = 1501939422.89543486\n",
            "Iteration 358, loss = 1501818772.44704533\n",
            "Iteration 359, loss = 1501700526.02489233\n",
            "Iteration 360, loss = 1501580950.17398524\n",
            "Iteration 361, loss = 1501462281.93785453\n",
            "Iteration 362, loss = 1501342658.02569675\n",
            "Iteration 363, loss = 1501223877.51700091\n",
            "Iteration 364, loss = 1501105498.82479596\n",
            "Iteration 365, loss = 1500986883.23424959\n",
            "Iteration 366, loss = 1500868582.05006289\n",
            "Iteration 367, loss = 1500750051.45215964\n",
            "Iteration 368, loss = 1500632293.36510324\n",
            "Iteration 369, loss = 1500514737.24164152\n",
            "Iteration 370, loss = 1500393223.83316159\n",
            "Iteration 371, loss = 1500270115.39476800\n",
            "Iteration 372, loss = 1500149139.44379354\n",
            "Iteration 373, loss = 1500028563.37735534\n",
            "Iteration 374, loss = 1499907291.13997769\n",
            "Iteration 375, loss = 1499785456.82311654\n",
            "Iteration 376, loss = 1499664086.34644651\n",
            "Iteration 377, loss = 1499544091.74502468\n",
            "Iteration 378, loss = 1499422292.84691072\n",
            "Iteration 379, loss = 1499301044.32437873\n",
            "Iteration 380, loss = 1499180784.49550915\n",
            "Iteration 381, loss = 1499060490.43900585\n",
            "Iteration 382, loss = 1498939710.33805275\n",
            "Iteration 383, loss = 1498820621.33491468\n",
            "Iteration 384, loss = 1498700830.21432447\n",
            "Iteration 385, loss = 1498581370.74517703\n",
            "Iteration 386, loss = 1498461237.66536927\n",
            "Iteration 387, loss = 1498340454.12527132\n",
            "Iteration 388, loss = 1498215188.69185615\n",
            "Iteration 389, loss = 1498092562.82268620\n",
            "Iteration 390, loss = 1497969155.93894792\n",
            "Iteration 391, loss = 1497847175.69775653\n",
            "Iteration 392, loss = 1497723423.45665073\n",
            "Iteration 393, loss = 1497600652.74151063\n",
            "Iteration 394, loss = 1497478268.08755064\n",
            "Iteration 395, loss = 1497357221.98636317\n",
            "Iteration 396, loss = 1497234205.61843634\n",
            "Iteration 397, loss = 1497111956.46582484\n",
            "Iteration 398, loss = 1496990740.83952999\n",
            "Iteration 399, loss = 1496868621.96216345\n",
            "Iteration 400, loss = 1496748058.54409552\n",
            "Iteration 401, loss = 1496626177.35660911\n",
            "Iteration 402, loss = 1496504485.68296957\n",
            "Iteration 403, loss = 1496384047.48957992\n",
            "Iteration 404, loss = 1496263972.24968505\n",
            "Iteration 405, loss = 1496143301.32062650\n",
            "Iteration 406, loss = 1496022993.66756606\n",
            "Iteration 407, loss = 1495903373.12804890\n",
            "Iteration 408, loss = 1495784048.66708302\n",
            "Iteration 409, loss = 1495664418.67699528\n",
            "Iteration 410, loss = 1495544793.59306502\n",
            "Iteration 411, loss = 1495425065.17243624\n",
            "Iteration 412, loss = 1495305870.83351612\n",
            "Iteration 413, loss = 1495187018.36982965\n",
            "Iteration 414, loss = 1495067277.61105824\n",
            "Iteration 415, loss = 1494948439.58273840\n",
            "Iteration 416, loss = 1494829490.42981195\n",
            "Iteration 417, loss = 1494711537.84657979\n",
            "Iteration 418, loss = 1494591846.23300385\n",
            "Iteration 419, loss = 1494474205.28603888\n",
            "Iteration 420, loss = 1494356477.39778185\n",
            "Iteration 421, loss = 1494238367.71803164\n",
            "Iteration 422, loss = 1494120467.02045107\n",
            "Iteration 423, loss = 1494002786.24159503\n",
            "Iteration 424, loss = 1493885642.14748883\n",
            "Iteration 425, loss = 1493768478.70334005\n",
            "Iteration 426, loss = 1493651971.24931908\n",
            "Iteration 427, loss = 1493534594.76828170\n",
            "Iteration 428, loss = 1493418232.56180501\n",
            "Iteration 429, loss = 1493301580.97798109\n",
            "Iteration 430, loss = 1493185194.47854757\n",
            "Iteration 431, loss = 1493068765.32379675\n",
            "Iteration 432, loss = 1492952061.03265333\n",
            "Iteration 433, loss = 1492835526.40341544\n",
            "Iteration 434, loss = 1492719008.67057395\n",
            "Iteration 435, loss = 1492602939.63094592\n",
            "Iteration 436, loss = 1492486103.98371339\n",
            "Iteration 437, loss = 1492369820.80588508\n",
            "Iteration 438, loss = 1492254288.98542953\n",
            "Iteration 439, loss = 1492137820.46353555\n",
            "Iteration 440, loss = 1492021992.94910049\n",
            "Iteration 441, loss = 1491906942.16604424\n",
            "Iteration 442, loss = 1491790175.40857482\n",
            "Iteration 443, loss = 1491675394.17412901\n",
            "Iteration 444, loss = 1491559371.77232027\n",
            "Iteration 445, loss = 1491444419.57160902\n",
            "Iteration 446, loss = 1491328262.62371373\n",
            "Iteration 447, loss = 1491213189.15794587\n",
            "Iteration 448, loss = 1491097982.83433580\n",
            "Iteration 449, loss = 1490982757.99608850\n",
            "Iteration 450, loss = 1490867013.67017508\n",
            "Iteration 451, loss = 1490753088.52410913\n",
            "Iteration 452, loss = 1490637005.50182104\n",
            "Iteration 453, loss = 1490522372.34328699\n",
            "Iteration 454, loss = 1490407483.89608622\n",
            "Iteration 455, loss = 1490292760.85554862\n",
            "Iteration 456, loss = 1490178277.58951378\n",
            "Iteration 457, loss = 1490064108.21553278\n",
            "Iteration 458, loss = 1489949285.07921243\n",
            "Iteration 459, loss = 1489834869.56472349\n",
            "Iteration 460, loss = 1489721622.73306775\n",
            "Iteration 461, loss = 1489607343.55562830\n",
            "Iteration 462, loss = 1489493619.33357906\n",
            "Iteration 463, loss = 1489379095.58896112\n",
            "Iteration 464, loss = 1489265845.71359444\n",
            "Iteration 465, loss = 1489152121.82716727\n",
            "Iteration 466, loss = 1489038463.63042927\n",
            "Iteration 467, loss = 1488925069.27510858\n",
            "Iteration 468, loss = 1488811054.09751964\n",
            "Iteration 469, loss = 1488699068.05012035\n",
            "Iteration 470, loss = 1488585634.01421976\n",
            "Iteration 471, loss = 1488472676.59488463\n",
            "Iteration 472, loss = 1488359557.53116965\n",
            "Iteration 473, loss = 1488246636.19243479\n",
            "Iteration 474, loss = 1488133289.54514980\n",
            "Iteration 475, loss = 1488020026.14315057\n",
            "Iteration 476, loss = 1487906927.73692966\n",
            "Iteration 477, loss = 1487793152.50562596\n",
            "Iteration 478, loss = 1487680552.78992724\n",
            "Iteration 479, loss = 1487566724.07320619\n",
            "Iteration 480, loss = 1487453239.87156987\n",
            "Iteration 481, loss = 1487340071.87889719\n",
            "Iteration 482, loss = 1487227470.04857278\n",
            "Iteration 483, loss = 1487115090.26795602\n",
            "Iteration 484, loss = 1487001985.05935073\n",
            "Iteration 485, loss = 1486889651.14223003\n",
            "Iteration 486, loss = 1486777137.12301421\n",
            "Iteration 487, loss = 1486665405.91914916\n",
            "Iteration 488, loss = 1486553210.32173109\n",
            "Iteration 489, loss = 1486440521.14247704\n",
            "Iteration 490, loss = 1486328711.75727129\n",
            "Iteration 491, loss = 1486215637.00661922\n",
            "Iteration 492, loss = 1486103696.53393698\n",
            "Iteration 493, loss = 1485991097.68858624\n",
            "Iteration 494, loss = 1485878488.39384604\n",
            "Iteration 495, loss = 1485766424.37165594\n",
            "Iteration 496, loss = 1485654121.12231350\n",
            "Iteration 497, loss = 1485541456.67842650\n",
            "Iteration 498, loss = 1485430016.49967051\n",
            "Iteration 499, loss = 1485316539.65292335\n",
            "Iteration 500, loss = 1485205689.60563660\n",
            "Iteration 501, loss = 1485092238.04742122\n",
            "Iteration 502, loss = 1484981262.09492707\n",
            "Iteration 503, loss = 1484868887.58794260\n",
            "Iteration 504, loss = 1484757001.15572572\n",
            "Iteration 505, loss = 1484645463.61460280\n",
            "Iteration 506, loss = 1484533394.93580079\n",
            "Iteration 507, loss = 1484421662.05683422\n",
            "Iteration 508, loss = 1484310841.89661479\n",
            "Iteration 509, loss = 1484198327.21301246\n",
            "Iteration 510, loss = 1484087178.66514468\n",
            "Iteration 511, loss = 1483975067.32685184\n",
            "Iteration 512, loss = 1483863295.57781506\n",
            "Iteration 513, loss = 1483751984.67993355\n",
            "Iteration 514, loss = 1483639511.85386038\n",
            "Iteration 515, loss = 1483527594.23897409\n",
            "Iteration 516, loss = 1483416234.67598891\n",
            "Iteration 517, loss = 1483303681.72669625\n",
            "Iteration 518, loss = 1483191340.99252629\n",
            "Iteration 519, loss = 1483079865.54678226\n",
            "Iteration 520, loss = 1482967810.46874142\n",
            "Iteration 521, loss = 1482855621.50613523\n",
            "Iteration 522, loss = 1482743949.19250560\n",
            "Iteration 523, loss = 1482632136.18400717\n",
            "Iteration 524, loss = 1482520404.59947991\n",
            "Iteration 525, loss = 1482409353.70905352\n",
            "Iteration 526, loss = 1482297587.37564564\n",
            "Iteration 527, loss = 1482186414.83978057\n",
            "Iteration 528, loss = 1482075731.02143312\n",
            "Iteration 529, loss = 1481964683.42004156\n",
            "Iteration 530, loss = 1481853209.12604189\n",
            "Iteration 531, loss = 1481742651.02595377\n",
            "Iteration 532, loss = 1481631731.39690948\n",
            "Iteration 533, loss = 1481521036.05087805\n",
            "Iteration 534, loss = 1481409748.07578945\n",
            "Iteration 535, loss = 1481299357.33496428\n",
            "Iteration 536, loss = 1481188539.23113179\n",
            "Iteration 537, loss = 1481078123.24311781\n",
            "Iteration 538, loss = 1480966996.38077903\n",
            "Iteration 539, loss = 1480856624.40778852\n",
            "Iteration 540, loss = 1480745928.88931918\n",
            "Iteration 541, loss = 1480635749.49924707\n",
            "Iteration 542, loss = 1480525020.03462052\n",
            "Iteration 543, loss = 1480414550.33283019\n",
            "Iteration 544, loss = 1480303990.50182509\n",
            "Iteration 545, loss = 1480193650.78449941\n",
            "Iteration 546, loss = 1480082927.88526130\n",
            "Iteration 547, loss = 1479972383.28026700\n",
            "Iteration 548, loss = 1479861417.14051914\n",
            "Iteration 549, loss = 1479750644.18002510\n",
            "Iteration 550, loss = 1479640504.02220035\n",
            "Iteration 551, loss = 1479529265.77365184\n",
            "Iteration 552, loss = 1479419452.78172779\n",
            "Iteration 553, loss = 1479308648.46886468\n",
            "Iteration 554, loss = 1479198737.30207515\n",
            "Iteration 555, loss = 1479088919.45560145\n",
            "Iteration 556, loss = 1478979623.03350782\n",
            "Iteration 557, loss = 1478869511.47578335\n",
            "Iteration 558, loss = 1478759901.34428930\n",
            "Iteration 559, loss = 1478650757.24543595\n",
            "Iteration 560, loss = 1478540515.16953039\n",
            "Iteration 561, loss = 1478431361.25389457\n",
            "Iteration 562, loss = 1478321149.70122099\n",
            "Iteration 563, loss = 1478211746.19778156\n",
            "Iteration 564, loss = 1478101676.94218779\n",
            "Iteration 565, loss = 1477992169.65169621\n",
            "Iteration 566, loss = 1477882208.80941200\n",
            "Iteration 567, loss = 1477773197.93244386\n",
            "Iteration 568, loss = 1477663811.14762688\n",
            "Iteration 569, loss = 1477554006.45289969\n",
            "Iteration 570, loss = 1477445062.86748195\n",
            "Iteration 571, loss = 1477335074.06201649\n",
            "Iteration 572, loss = 1477226061.79139304\n",
            "Iteration 573, loss = 1477116579.60626578\n",
            "Iteration 574, loss = 1477006867.81427503\n",
            "Iteration 575, loss = 1476897508.29877472\n",
            "Iteration 576, loss = 1476787643.37379432\n",
            "Iteration 577, loss = 1476679008.87113810\n",
            "Iteration 578, loss = 1476568668.02531099\n",
            "Iteration 579, loss = 1476459463.99517250\n",
            "Iteration 580, loss = 1476350193.02636933\n",
            "Iteration 581, loss = 1476240588.84961796\n",
            "Iteration 582, loss = 1476131349.23978496\n",
            "Iteration 583, loss = 1476022268.85010099\n",
            "Iteration 584, loss = 1475912205.35097766\n",
            "Iteration 585, loss = 1475803886.42011833\n",
            "Iteration 586, loss = 1475694212.57571363\n",
            "Iteration 587, loss = 1475585109.85531211\n",
            "Iteration 588, loss = 1475475781.82975507\n",
            "Iteration 589, loss = 1475367344.25050235\n",
            "Iteration 590, loss = 1475258558.29688907\n",
            "Iteration 591, loss = 1475149807.49428678\n",
            "Iteration 592, loss = 1475040821.19148493\n",
            "Iteration 593, loss = 1474932492.26162505\n",
            "Iteration 594, loss = 1474823997.09283686\n",
            "Iteration 595, loss = 1474714015.07095957\n",
            "Iteration 596, loss = 1474605662.16273713\n",
            "Iteration 597, loss = 1474495776.93773127\n",
            "Iteration 598, loss = 1474387097.63735557\n",
            "Iteration 599, loss = 1474277190.31177545\n",
            "Iteration 600, loss = 1474168488.46017838\n",
            "Iteration 601, loss = 1474058380.84283471\n",
            "Iteration 602, loss = 1473949215.19986725\n",
            "Iteration 603, loss = 1473839789.21739531\n",
            "Iteration 604, loss = 1473730648.95769143\n",
            "Iteration 605, loss = 1473621231.81577158\n",
            "Iteration 606, loss = 1473511865.52011085\n",
            "Iteration 607, loss = 1473402237.91561770\n",
            "Iteration 608, loss = 1473293905.70255256\n",
            "Iteration 609, loss = 1473183920.59906340\n",
            "Iteration 610, loss = 1473075584.76480079\n",
            "Iteration 611, loss = 1472966767.64191580\n",
            "Iteration 612, loss = 1472857832.91782880\n",
            "Iteration 613, loss = 1472749216.84954762\n",
            "Iteration 614, loss = 1472640551.23522544\n",
            "Iteration 615, loss = 1472532786.13674498\n",
            "Iteration 616, loss = 1472423617.44817519\n",
            "Iteration 617, loss = 1472315997.27877641\n",
            "Iteration 618, loss = 1472207030.45227623\n",
            "Iteration 619, loss = 1472098432.41083121\n",
            "Iteration 620, loss = 1471990294.29394341\n",
            "Iteration 621, loss = 1471882140.54709840\n",
            "Iteration 622, loss = 1471773280.43786621\n",
            "Iteration 623, loss = 1471665196.69749546\n",
            "Iteration 624, loss = 1471556757.05125833\n",
            "Iteration 625, loss = 1471449282.21060491\n",
            "Iteration 626, loss = 1471340711.96627593\n",
            "Iteration 627, loss = 1471232116.87094212\n",
            "Iteration 628, loss = 1471124063.59081697\n",
            "Iteration 629, loss = 1471015881.85818410\n",
            "Iteration 630, loss = 1470906858.55131531\n",
            "Iteration 631, loss = 1470798108.89597416\n",
            "Iteration 632, loss = 1470690582.15255308\n",
            "Iteration 633, loss = 1470580589.79265904\n",
            "Iteration 634, loss = 1470472518.96612453\n",
            "Iteration 635, loss = 1470363622.85326362\n",
            "Iteration 636, loss = 1470255210.15062642\n",
            "Iteration 637, loss = 1470146626.89228296\n",
            "Iteration 638, loss = 1470037890.27920747\n",
            "Iteration 639, loss = 1469929956.34147167\n",
            "Iteration 640, loss = 1469820924.43895316\n",
            "Iteration 641, loss = 1469712287.05137014\n",
            "Iteration 642, loss = 1469603526.16263890\n",
            "Iteration 643, loss = 1469494761.87747002\n",
            "Iteration 644, loss = 1469386066.77059674\n",
            "Iteration 645, loss = 1469276629.28454995\n",
            "Iteration 646, loss = 1469167961.56648159\n",
            "Iteration 647, loss = 1469058679.04268146\n",
            "Iteration 648, loss = 1468950048.83871794\n",
            "Iteration 649, loss = 1468841715.28209305\n",
            "Iteration 650, loss = 1468732549.47489738\n",
            "Iteration 651, loss = 1468624144.83747387\n",
            "Iteration 652, loss = 1468516054.05906463\n",
            "Iteration 653, loss = 1468407903.08364773\n",
            "Iteration 654, loss = 1468299063.88922191\n",
            "Iteration 655, loss = 1468191077.38592219\n",
            "Iteration 656, loss = 1468082521.50273561\n",
            "Iteration 657, loss = 1467975278.20586967\n",
            "Iteration 658, loss = 1467866323.13361549\n",
            "Iteration 659, loss = 1467758075.88898826\n",
            "Iteration 660, loss = 1467650634.72604752\n",
            "Iteration 661, loss = 1467542022.51658297\n",
            "Iteration 662, loss = 1467433846.64088225\n",
            "Iteration 663, loss = 1467325992.04548550\n",
            "Iteration 664, loss = 1467217958.58874059\n",
            "Iteration 665, loss = 1467109495.36312270\n",
            "Iteration 666, loss = 1467001954.57528996\n",
            "Iteration 667, loss = 1466893280.82616210\n",
            "Iteration 668, loss = 1466785773.56137323\n",
            "Iteration 669, loss = 1466677394.82201219\n",
            "Iteration 670, loss = 1466569877.92667699\n",
            "Iteration 671, loss = 1466461576.09961319\n",
            "Iteration 672, loss = 1466353782.74317718\n",
            "Iteration 673, loss = 1466245958.44172120\n",
            "Iteration 674, loss = 1466137830.78412461\n",
            "Iteration 675, loss = 1466030267.03172493\n",
            "Iteration 676, loss = 1465922065.78797078\n",
            "Iteration 677, loss = 1465814711.74876523\n",
            "Iteration 678, loss = 1465707106.27709389\n",
            "Iteration 679, loss = 1465599723.15420198\n",
            "Iteration 680, loss = 1465492092.09083986\n",
            "Iteration 681, loss = 1465384920.39248753\n",
            "Iteration 682, loss = 1465277322.08563614\n",
            "Iteration 683, loss = 1465169770.89906502\n",
            "Iteration 684, loss = 1465062567.37400150\n",
            "Iteration 685, loss = 1464954926.42003369\n",
            "Iteration 686, loss = 1464847878.97173786\n",
            "Iteration 687, loss = 1464740889.04175806\n",
            "Iteration 688, loss = 1464633166.12052894\n",
            "Iteration 689, loss = 1464525263.80912066\n",
            "Iteration 690, loss = 1464418905.73920560\n",
            "Iteration 691, loss = 1464311763.56115961\n",
            "Iteration 692, loss = 1464204327.96652341\n",
            "Iteration 693, loss = 1464097066.89826822\n",
            "Iteration 694, loss = 1463989576.73390532\n",
            "Iteration 695, loss = 1463882112.98551702\n",
            "Iteration 696, loss = 1463774400.43867445\n",
            "Iteration 697, loss = 1463667643.86135387\n",
            "Iteration 698, loss = 1463559940.53521800\n",
            "Iteration 699, loss = 1463453067.80358624\n",
            "Iteration 700, loss = 1463345726.15897727\n",
            "Iteration 701, loss = 1463238853.14962530\n",
            "Iteration 702, loss = 1463132258.30552745\n",
            "Iteration 703, loss = 1463025150.58597398\n",
            "Iteration 704, loss = 1462919425.81832194\n",
            "Iteration 705, loss = 1462811852.70028162\n",
            "Iteration 706, loss = 1462705677.30453348\n",
            "Iteration 707, loss = 1462598283.94227815\n",
            "Iteration 708, loss = 1462492072.39265990\n",
            "Iteration 709, loss = 1462385217.62274384\n",
            "Iteration 710, loss = 1462277886.22664809\n",
            "Iteration 711, loss = 1462171168.92249322\n",
            "Iteration 712, loss = 1462063889.10195875\n",
            "Iteration 713, loss = 1461956724.75450563\n",
            "Iteration 714, loss = 1461849831.85677600\n",
            "Iteration 715, loss = 1461742148.12966442\n",
            "Iteration 716, loss = 1461635297.48018980\n",
            "Iteration 717, loss = 1461528459.46809983\n",
            "Iteration 718, loss = 1461420983.04368901\n",
            "Iteration 719, loss = 1461314701.93269253\n",
            "Iteration 720, loss = 1461207644.63382936\n",
            "Iteration 721, loss = 1461100811.51428032\n",
            "Iteration 722, loss = 1460994438.08423233\n",
            "Iteration 723, loss = 1460887857.88429856\n",
            "Iteration 724, loss = 1460780904.04657960\n",
            "Iteration 725, loss = 1460673765.95695400\n",
            "Iteration 726, loss = 1460567395.59174895\n",
            "Iteration 727, loss = 1460461076.42024565\n",
            "Iteration 728, loss = 1460354017.73973894\n",
            "Iteration 729, loss = 1460246962.68435264\n",
            "Iteration 730, loss = 1460139943.77414823\n",
            "Iteration 731, loss = 1460033469.06560206\n",
            "Iteration 732, loss = 1459927050.79925942\n",
            "Iteration 733, loss = 1459820109.08384371\n",
            "Iteration 734, loss = 1459712699.44850945\n",
            "Iteration 735, loss = 1459606450.50754094\n",
            "Iteration 736, loss = 1459499260.41326332\n",
            "Iteration 737, loss = 1459392616.29015541\n",
            "Iteration 738, loss = 1459286239.61058736\n",
            "Iteration 739, loss = 1459178516.59833050\n",
            "Iteration 740, loss = 1459072439.21910310\n",
            "Iteration 741, loss = 1458966061.00259089\n",
            "Iteration 742, loss = 1458858807.10420632\n",
            "Iteration 743, loss = 1458751234.38366127\n",
            "Iteration 744, loss = 1458645771.69589949\n",
            "Iteration 745, loss = 1458538092.63484144\n",
            "Iteration 746, loss = 1458431733.59776664\n",
            "Iteration 747, loss = 1458324469.37966037\n",
            "Iteration 748, loss = 1458218147.93743682\n",
            "Iteration 749, loss = 1458111279.54560471\n",
            "Iteration 750, loss = 1458004701.75370884\n",
            "Iteration 751, loss = 1457897786.53457141\n",
            "Iteration 752, loss = 1457790737.28040338\n",
            "Iteration 753, loss = 1457684074.51443839\n",
            "Iteration 754, loss = 1457576815.60690284\n",
            "Iteration 755, loss = 1457469822.83626962\n",
            "Iteration 756, loss = 1457362524.80951762\n",
            "Iteration 757, loss = 1457254784.44977808\n",
            "Iteration 758, loss = 1457147674.96159506\n",
            "Iteration 759, loss = 1457040947.06871772\n",
            "Iteration 760, loss = 1456932987.05108523\n",
            "Iteration 761, loss = 1456825736.39678288\n",
            "Iteration 762, loss = 1456719240.17927909\n",
            "Iteration 763, loss = 1456612566.73083186\n",
            "Iteration 764, loss = 1456505720.28862000\n",
            "Iteration 765, loss = 1456399241.69120288\n",
            "Iteration 766, loss = 1456293164.69762993\n",
            "Iteration 767, loss = 1456186696.31807494\n",
            "Iteration 768, loss = 1456080270.85277104\n",
            "Iteration 769, loss = 1455973965.82735443\n",
            "Iteration 770, loss = 1455867526.33724618\n",
            "Iteration 771, loss = 1455761119.37321687\n",
            "Iteration 772, loss = 1455655046.31816387\n",
            "Iteration 773, loss = 1455548410.25819087\n",
            "Iteration 774, loss = 1455441585.50315523\n",
            "Iteration 775, loss = 1455335123.58044052\n",
            "Iteration 776, loss = 1455228385.73306513\n",
            "Iteration 777, loss = 1455121131.27758503\n",
            "Iteration 778, loss = 1455014905.92607212\n",
            "Iteration 779, loss = 1454907630.65970230\n",
            "Iteration 780, loss = 1454800468.95621705\n",
            "Iteration 781, loss = 1454694934.61778593\n",
            "Iteration 782, loss = 1454588189.67313933\n",
            "Iteration 783, loss = 1454482363.52888942\n",
            "Iteration 784, loss = 1454376386.04918051\n",
            "Iteration 785, loss = 1454270527.89718819\n",
            "Iteration 786, loss = 1454164427.86377954\n",
            "Iteration 787, loss = 1454058403.58172917\n",
            "Iteration 788, loss = 1453952469.17755795\n",
            "Iteration 789, loss = 1453846427.04416418\n",
            "Iteration 790, loss = 1453740125.12397051\n",
            "Iteration 791, loss = 1453633744.53709626\n",
            "Iteration 792, loss = 1453527444.56020355\n",
            "Iteration 793, loss = 1453420951.37096882\n",
            "Iteration 794, loss = 1453314421.73997211\n",
            "Iteration 795, loss = 1453208148.87786341\n",
            "Iteration 796, loss = 1453102272.14101553\n",
            "Iteration 797, loss = 1452995864.89954329\n",
            "Iteration 798, loss = 1452889508.22863650\n",
            "Iteration 799, loss = 1452783845.36951232\n",
            "Iteration 800, loss = 1452677580.60043502\n",
            "Iteration 801, loss = 1452571956.65455770\n",
            "Iteration 802, loss = 1452466439.37663746\n",
            "Iteration 803, loss = 1452360297.02101779\n",
            "Iteration 804, loss = 1452253909.69575906\n",
            "Iteration 805, loss = 1452148187.34385824\n",
            "Iteration 806, loss = 1452042082.20501685\n",
            "Iteration 807, loss = 1451936386.10196614\n",
            "Iteration 808, loss = 1451829574.52223682\n",
            "Iteration 809, loss = 1451723519.19322515\n",
            "Iteration 810, loss = 1451617315.57558084\n",
            "Iteration 811, loss = 1451511338.69472170\n",
            "Iteration 812, loss = 1451404628.37525082\n",
            "Iteration 813, loss = 1451299062.48241663\n",
            "Iteration 814, loss = 1451192877.40683699\n",
            "Iteration 815, loss = 1451087174.10023570\n",
            "Iteration 816, loss = 1450981559.27243161\n",
            "Iteration 817, loss = 1450876481.35148239\n",
            "Iteration 818, loss = 1450770426.84061527\n",
            "Iteration 819, loss = 1450664832.74737406\n",
            "Iteration 820, loss = 1450559436.68320012\n",
            "Iteration 821, loss = 1450453443.30398703\n",
            "Iteration 822, loss = 1450348148.06210446\n",
            "Iteration 823, loss = 1450241462.78727269\n",
            "Iteration 824, loss = 1450135584.08762503\n",
            "Iteration 825, loss = 1450029148.15782690\n",
            "Iteration 826, loss = 1449922465.52602434\n",
            "Iteration 827, loss = 1449816064.55194855\n",
            "Iteration 828, loss = 1449709874.52169156\n",
            "Iteration 829, loss = 1449603808.54782510\n",
            "Iteration 830, loss = 1449497846.04145527\n",
            "Iteration 831, loss = 1449391499.48751092\n",
            "Iteration 832, loss = 1449286420.11634779\n",
            "Iteration 833, loss = 1449179971.71113610\n",
            "Iteration 834, loss = 1449073577.70868301\n",
            "Iteration 835, loss = 1448968846.80415511\n",
            "Iteration 836, loss = 1448862750.48041487\n",
            "Iteration 837, loss = 1448756162.17927504\n",
            "Iteration 838, loss = 1448650641.51794910\n",
            "Iteration 839, loss = 1448545299.59543586\n",
            "Iteration 840, loss = 1448439596.74391580\n",
            "Iteration 841, loss = 1448333626.05490351\n",
            "Iteration 842, loss = 1448228646.32199216\n",
            "Iteration 843, loss = 1448122828.68778539\n",
            "Iteration 844, loss = 1448017514.53305244\n",
            "Iteration 845, loss = 1447912176.27190781\n",
            "Iteration 846, loss = 1447807111.93293881\n",
            "Iteration 847, loss = 1447700862.14046168\n",
            "Iteration 848, loss = 1447596411.24855828\n",
            "Iteration 849, loss = 1447489981.99920154\n",
            "Iteration 850, loss = 1447385257.91377592\n",
            "Iteration 851, loss = 1447279381.82744861\n",
            "Iteration 852, loss = 1447174016.60099435\n",
            "Iteration 853, loss = 1447069214.45743227\n",
            "Iteration 854, loss = 1446963350.12596965\n",
            "Iteration 855, loss = 1446858262.75652075\n",
            "Iteration 856, loss = 1446753419.91740370\n",
            "Iteration 857, loss = 1446648056.39445901\n",
            "Iteration 858, loss = 1446542660.50180435\n",
            "Iteration 859, loss = 1446438033.15710926\n",
            "Iteration 860, loss = 1446332016.79852176\n",
            "Iteration 861, loss = 1446227519.13282108\n",
            "Iteration 862, loss = 1446122542.51230025\n",
            "Iteration 863, loss = 1446016275.00119352\n",
            "Iteration 864, loss = 1445912338.84536505\n",
            "Iteration 865, loss = 1445806315.36382794\n",
            "Iteration 866, loss = 1445700976.89961147\n",
            "Iteration 867, loss = 1445595180.86243939\n",
            "Iteration 868, loss = 1445490442.80044723\n",
            "Iteration 869, loss = 1445385623.63505435\n",
            "Iteration 870, loss = 1445279449.66323018\n",
            "Iteration 871, loss = 1445174640.37240529\n",
            "Iteration 872, loss = 1445069881.07420516\n",
            "Iteration 873, loss = 1444964850.89039159\n",
            "Iteration 874, loss = 1444860195.53965712\n",
            "Iteration 875, loss = 1444754783.67970347\n",
            "Iteration 876, loss = 1444649690.11024594\n",
            "Iteration 877, loss = 1444544776.59385872\n",
            "Iteration 878, loss = 1444439091.76304865\n",
            "Iteration 879, loss = 1444334234.46305752\n",
            "Iteration 880, loss = 1444228425.67546511\n",
            "Iteration 881, loss = 1444122140.79378223\n",
            "Iteration 882, loss = 1444017517.34175158\n",
            "Iteration 883, loss = 1443911089.79289007\n",
            "Iteration 884, loss = 1443805490.44990301\n",
            "Iteration 885, loss = 1443700045.79309487\n",
            "Iteration 886, loss = 1443594450.88034797\n",
            "Iteration 887, loss = 1443489342.28645945\n",
            "Iteration 888, loss = 1443384141.31241393\n",
            "Iteration 889, loss = 1443278623.35518932\n",
            "Iteration 890, loss = 1443172950.98375869\n",
            "Iteration 891, loss = 1443067581.11734700\n",
            "Iteration 892, loss = 1442962584.66244602\n",
            "Iteration 893, loss = 1442857589.56819963\n",
            "Iteration 894, loss = 1442751692.21687818\n",
            "Iteration 895, loss = 1442646788.17869663\n",
            "Iteration 896, loss = 1442542244.19131923\n",
            "Iteration 897, loss = 1442437285.36620951\n",
            "Iteration 898, loss = 1442331747.84929872\n",
            "Iteration 899, loss = 1442227688.46789598\n",
            "Iteration 900, loss = 1442122210.86468577\n",
            "Iteration 901, loss = 1442017825.90242887\n",
            "Iteration 902, loss = 1441912780.30965614\n",
            "Iteration 903, loss = 1441807464.74624348\n",
            "Iteration 904, loss = 1441702895.51951265\n",
            "Iteration 905, loss = 1441598108.50380540\n",
            "Iteration 906, loss = 1441493391.07480478\n",
            "Iteration 907, loss = 1441387781.75132561\n",
            "Iteration 908, loss = 1441283902.33899593\n",
            "Iteration 909, loss = 1441178131.96003747\n",
            "Iteration 910, loss = 1441073304.43030429\n",
            "Iteration 911, loss = 1440968263.72743487\n",
            "Iteration 912, loss = 1440862618.06389785\n",
            "Iteration 913, loss = 1440757878.91003060\n",
            "Iteration 914, loss = 1440652705.25810051\n",
            "Iteration 915, loss = 1440547215.99809885\n",
            "Iteration 916, loss = 1440442175.13244605\n",
            "Iteration 917, loss = 1440337103.97495151\n",
            "Iteration 918, loss = 1440232501.07517099\n",
            "Iteration 919, loss = 1440127352.17478848\n",
            "Iteration 920, loss = 1440022396.69908834\n",
            "Iteration 921, loss = 1439917876.20582652\n",
            "Iteration 922, loss = 1439812973.38576913\n",
            "Iteration 923, loss = 1439708904.16883445\n",
            "Iteration 924, loss = 1439603240.71100783\n",
            "Iteration 925, loss = 1439499512.29948974\n",
            "Iteration 926, loss = 1439394282.97940278\n",
            "Iteration 927, loss = 1439289420.69567919\n",
            "Iteration 928, loss = 1439184379.22645617\n",
            "Iteration 929, loss = 1439079286.77997971\n",
            "Iteration 930, loss = 1438974497.28520441\n",
            "Iteration 931, loss = 1438869083.15148640\n",
            "Iteration 932, loss = 1438763703.57762098\n",
            "Iteration 933, loss = 1438659192.50868797\n",
            "Iteration 934, loss = 1438554588.93928623\n",
            "Iteration 935, loss = 1438449322.17368412\n",
            "Iteration 936, loss = 1438344725.19429684\n",
            "Iteration 937, loss = 1438239651.78350902\n",
            "Iteration 938, loss = 1438135757.10109353\n",
            "Iteration 939, loss = 1438030616.17761707\n",
            "Iteration 940, loss = 1437925734.81901193\n",
            "Iteration 941, loss = 1437821075.29649377\n",
            "Iteration 942, loss = 1437715551.84968615\n",
            "Iteration 943, loss = 1437611177.69872928\n",
            "Iteration 944, loss = 1437505436.12521315\n",
            "Iteration 945, loss = 1437400121.12591887\n",
            "Iteration 946, loss = 1437294804.27321649\n",
            "Iteration 947, loss = 1437189966.20467329\n",
            "Iteration 948, loss = 1437084746.28852510\n",
            "Iteration 949, loss = 1436979561.77120805\n",
            "Iteration 950, loss = 1436874441.67188716\n",
            "Iteration 951, loss = 1436769348.59328985\n",
            "Iteration 952, loss = 1436664729.32431841\n",
            "Iteration 953, loss = 1436559094.50214005\n",
            "Iteration 954, loss = 1436454465.14050436\n",
            "Iteration 955, loss = 1436350128.70683670\n",
            "Iteration 956, loss = 1436244113.34054303\n",
            "Iteration 957, loss = 1436139989.73813272\n",
            "Iteration 958, loss = 1436034675.57388330\n",
            "Iteration 959, loss = 1435930611.14529395\n",
            "Iteration 960, loss = 1435825678.36343837\n",
            "Iteration 961, loss = 1435720596.74141574\n",
            "Iteration 962, loss = 1435617116.62945890\n",
            "Iteration 963, loss = 1435512105.46762419\n",
            "Iteration 964, loss = 1435407872.23163962\n",
            "Iteration 965, loss = 1435303676.41868567\n",
            "Iteration 966, loss = 1435199104.65364861\n",
            "Iteration 967, loss = 1435094796.28102732\n",
            "Iteration 968, loss = 1434990551.76599216\n",
            "Iteration 969, loss = 1434885102.82540655\n",
            "Iteration 970, loss = 1434780664.31098175\n",
            "Iteration 971, loss = 1434676759.33965015\n",
            "Iteration 972, loss = 1434571187.63157439\n",
            "Iteration 973, loss = 1434466852.94623566\n",
            "Iteration 974, loss = 1434361998.44517541\n",
            "Iteration 975, loss = 1434257367.00474596\n",
            "Iteration 976, loss = 1434152276.16755390\n",
            "Iteration 977, loss = 1434047573.21252918\n",
            "Iteration 978, loss = 1433942522.08150578\n",
            "Iteration 979, loss = 1433837530.57686782\n",
            "Iteration 980, loss = 1433732335.84235716\n",
            "Iteration 981, loss = 1433627333.83618593\n",
            "Iteration 982, loss = 1433522688.43284583\n",
            "Iteration 983, loss = 1433417641.67788219\n",
            "Iteration 984, loss = 1433312904.91035271\n",
            "Iteration 985, loss = 1433208526.11356926\n",
            "Iteration 986, loss = 1433103615.41504335\n",
            "Iteration 987, loss = 1432999515.99475479\n",
            "Iteration 988, loss = 1432895388.84841251\n",
            "Iteration 989, loss = 1432790973.26945496\n",
            "Iteration 990, loss = 1432686749.43424201\n",
            "Iteration 991, loss = 1432582720.21274710\n",
            "Iteration 992, loss = 1432479203.51159239\n",
            "Iteration 993, loss = 1432375290.64527369\n",
            "Iteration 994, loss = 1432271166.10812116\n",
            "Iteration 995, loss = 1432166987.40856862\n",
            "Iteration 996, loss = 1432063280.41866422\n",
            "Iteration 997, loss = 1431959755.41584420\n",
            "Iteration 998, loss = 1431855530.01087904\n",
            "Iteration 999, loss = 1431751666.74146104\n",
            "Iteration 1000, loss = 1431647587.83169508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\_methods.py:127: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:174: RuntimeWarning: invalid value encountered in add\n",
            "  activations[i + 1] += self.intercepts_[i]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 36082212462612496384.00000000\n",
            "Iteration 2, loss = inf\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50, 50, 50), relu, 0.0001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538813082.12976122\n",
            "Iteration 2, loss = 1538731081.34479594\n",
            "Iteration 3, loss = 1538602771.91795135\n",
            "Iteration 4, loss = 1538374956.43592024\n",
            "Iteration 5, loss = 1537982683.15781021\n",
            "Iteration 6, loss = 1537367975.60981870\n",
            "Iteration 7, loss = 1536426064.02693081\n",
            "Iteration 8, loss = 1535047956.45768714\n",
            "Iteration 9, loss = 1533051008.81807184\n",
            "Iteration 10, loss = 1530275348.56557989\n",
            "Iteration 11, loss = 1526456467.44789457\n",
            "Iteration 12, loss = 1521316071.85504508\n",
            "Iteration 13, loss = 1514487960.14333105\n",
            "Iteration 14, loss = 1505591701.67499280\n",
            "Iteration 15, loss = 1493947226.06419992\n",
            "Iteration 16, loss = 1479352245.39792538\n",
            "Iteration 17, loss = 1460869049.70703483\n",
            "Iteration 18, loss = 1437978219.02719831\n",
            "Iteration 19, loss = 1409483812.45832300\n",
            "Iteration 20, loss = 1375094483.06851768\n",
            "Iteration 21, loss = 1333468787.14651704\n",
            "Iteration 22, loss = 1284117899.31213880\n",
            "Iteration 23, loss = 1226170032.24025774\n",
            "Iteration 24, loss = 1159170154.41077948\n",
            "Iteration 25, loss = 1081446083.58707571\n",
            "Iteration 26, loss = 993869005.76692259\n",
            "Iteration 27, loss = 897478421.34883952\n",
            "Iteration 28, loss = 791939296.15718675\n",
            "Iteration 29, loss = 682314439.40065706\n",
            "Iteration 30, loss = 567229936.71593654\n",
            "Iteration 31, loss = 457067799.82828164\n",
            "Iteration 32, loss = 357089738.61794364\n",
            "Iteration 33, loss = 268578327.14841491\n",
            "Iteration 34, loss = 205164634.63949415\n",
            "Iteration 35, loss = 169489329.23365730\n",
            "Iteration 36, loss = 150886523.69825625\n",
            "Iteration 37, loss = 148324093.74004319\n",
            "Iteration 38, loss = 152230529.38298300\n",
            "Iteration 39, loss = 155597306.06879097\n",
            "Iteration 40, loss = 151016155.04302248\n",
            "Iteration 41, loss = 140786036.83412221\n",
            "Iteration 42, loss = 125942779.57047255\n",
            "Iteration 43, loss = 113043546.41549015\n",
            "Iteration 44, loss = 104470241.76800384\n",
            "Iteration 45, loss = 100907085.23360811\n",
            "Iteration 46, loss = 99543669.90199190\n",
            "Iteration 47, loss = 99798436.52420609\n",
            "Iteration 48, loss = 99353752.17546983\n",
            "Iteration 49, loss = 97868082.54768163\n",
            "Iteration 50, loss = 95083290.66104296\n",
            "Iteration 51, loss = 91653553.82817127\n",
            "Iteration 52, loss = 87800662.92383038\n",
            "Iteration 53, loss = 83588419.59517877\n",
            "Iteration 54, loss = 79966937.63053815\n",
            "Iteration 55, loss = 77024265.55390888\n",
            "Iteration 56, loss = 74577984.71117817\n",
            "Iteration 57, loss = 72746573.13755341\n",
            "Iteration 58, loss = 70941856.28357022\n",
            "Iteration 59, loss = 69130136.40161493\n",
            "Iteration 60, loss = 67067671.56720382\n",
            "Iteration 61, loss = 64912778.71778801\n",
            "Iteration 62, loss = 62678084.63828447\n",
            "Iteration 63, loss = 60696483.69837591\n",
            "Iteration 64, loss = 58775940.91705704\n",
            "Iteration 65, loss = 57101683.11071113\n",
            "Iteration 66, loss = 55568026.64859098\n",
            "Iteration 67, loss = 54149836.38498653\n",
            "Iteration 68, loss = 52878364.97336403\n",
            "Iteration 69, loss = 51668964.64795530\n",
            "Iteration 70, loss = 50551216.98568578\n",
            "Iteration 71, loss = 49516613.61535161\n",
            "Iteration 72, loss = 48508131.97321505\n",
            "Iteration 73, loss = 47509206.87223079\n",
            "Iteration 74, loss = 46564085.76201429\n",
            "Iteration 75, loss = 45622977.31972564\n",
            "Iteration 76, loss = 44767446.32300510\n",
            "Iteration 77, loss = 43911953.85161263\n",
            "Iteration 78, loss = 43076665.14654166\n",
            "Iteration 79, loss = 42228710.45823061\n",
            "Iteration 80, loss = 41390835.95911695\n",
            "Iteration 81, loss = 40598929.11757331\n",
            "Iteration 82, loss = 39860865.05292256\n",
            "Iteration 83, loss = 39069846.56001627\n",
            "Iteration 84, loss = 38345219.79435040\n",
            "Iteration 85, loss = 37601200.79069125\n",
            "Iteration 86, loss = 36814351.72703109\n",
            "Iteration 87, loss = 36113242.04202922\n",
            "Iteration 88, loss = 35402437.13894697\n",
            "Iteration 89, loss = 34701991.23947391\n",
            "Iteration 90, loss = 33978643.73350075\n",
            "Iteration 91, loss = 33278382.91117483\n",
            "Iteration 92, loss = 32588255.26735906\n",
            "Iteration 93, loss = 31881596.75103671\n",
            "Iteration 94, loss = 31130768.84486905\n",
            "Iteration 95, loss = 30462515.43391560\n",
            "Iteration 96, loss = 29753147.51558762\n",
            "Iteration 97, loss = 29044277.69548403\n",
            "Iteration 98, loss = 28335722.43767977\n",
            "Iteration 99, loss = 27572568.80922509\n",
            "Iteration 100, loss = 26828393.12557499\n",
            "Iteration 101, loss = 26093432.43742630\n",
            "Iteration 102, loss = 25350670.52558478\n",
            "Iteration 103, loss = 24615998.46956598\n",
            "Iteration 104, loss = 23885023.22424973\n",
            "Iteration 105, loss = 23182964.27166993\n",
            "Iteration 106, loss = 22466933.74760063\n",
            "Iteration 107, loss = 21742409.73804115\n",
            "Iteration 108, loss = 21074597.80851917\n",
            "Iteration 109, loss = 20337629.19271669\n",
            "Iteration 110, loss = 19671799.25860308\n",
            "Iteration 111, loss = 19079347.66310905\n",
            "Iteration 112, loss = 18431798.75372240\n",
            "Iteration 113, loss = 17874408.89299352\n",
            "Iteration 114, loss = 17316189.87790279\n",
            "Iteration 115, loss = 16776425.47114230\n",
            "Iteration 116, loss = 16255507.55708794\n",
            "Iteration 117, loss = 15745772.01711554\n",
            "Iteration 118, loss = 15196059.22545677\n",
            "Iteration 119, loss = 14627882.54160165\n",
            "Iteration 120, loss = 14079730.47386205\n",
            "Iteration 121, loss = 13555335.96011698\n",
            "Iteration 122, loss = 13084880.61924273\n",
            "Iteration 123, loss = 12683629.38285935\n",
            "Iteration 124, loss = 12244197.34479170\n",
            "Iteration 125, loss = 11799654.79208345\n",
            "Iteration 126, loss = 11362960.99228698\n",
            "Iteration 127, loss = 10980093.53941420\n",
            "Iteration 128, loss = 10602483.71344093\n",
            "Iteration 129, loss = 10270078.03465346\n",
            "Iteration 130, loss = 9950878.47991466\n",
            "Iteration 131, loss = 9640699.72233643\n",
            "Iteration 132, loss = 9308896.03542189\n",
            "Iteration 133, loss = 9008838.85849881\n",
            "Iteration 134, loss = 8727185.87530983\n",
            "Iteration 135, loss = 8441944.05574786\n",
            "Iteration 136, loss = 8182863.86396097\n",
            "Iteration 137, loss = 7900332.83906897\n",
            "Iteration 138, loss = 7634129.57629187\n",
            "Iteration 139, loss = 7364727.63000623\n",
            "Iteration 140, loss = 7125855.16685085\n",
            "Iteration 141, loss = 6871459.92165547\n",
            "Iteration 142, loss = 6645450.23404434\n",
            "Iteration 143, loss = 6423816.12142255\n",
            "Iteration 144, loss = 6229510.60721212\n",
            "Iteration 145, loss = 6051436.39311795\n",
            "Iteration 146, loss = 5878140.77889587\n",
            "Iteration 147, loss = 5723914.42915675\n",
            "Iteration 148, loss = 5572158.95789927\n",
            "Iteration 149, loss = 5434167.35035411\n",
            "Iteration 150, loss = 5302330.44392887\n",
            "Iteration 151, loss = 5143256.88588444\n",
            "Iteration 152, loss = 4994706.40444439\n",
            "Iteration 153, loss = 4858108.13027743\n",
            "Iteration 154, loss = 4718912.32534032\n",
            "Iteration 155, loss = 4583822.71444756\n",
            "Iteration 156, loss = 4457922.36799414\n",
            "Iteration 157, loss = 4337799.12351931\n",
            "Iteration 158, loss = 4212832.54557733\n",
            "Iteration 159, loss = 4092471.34777945\n",
            "Iteration 160, loss = 3981223.65475847\n",
            "Iteration 161, loss = 3872514.21475793\n",
            "Iteration 162, loss = 3780694.13826756\n",
            "Iteration 163, loss = 3685585.07546184\n",
            "Iteration 164, loss = 3596414.15703060\n",
            "Iteration 165, loss = 3516954.12137799\n",
            "Iteration 166, loss = 3435921.13971084\n",
            "Iteration 167, loss = 3350277.12118279\n",
            "Iteration 168, loss = 3268434.76008212\n",
            "Iteration 169, loss = 3190398.67607487\n",
            "Iteration 170, loss = 3118417.92152660\n",
            "Iteration 171, loss = 3047880.24548446\n",
            "Iteration 172, loss = 2982440.90283302\n",
            "Iteration 173, loss = 2921100.89209694\n",
            "Iteration 174, loss = 2868629.21153386\n",
            "Iteration 175, loss = 2811595.95896622\n",
            "Iteration 176, loss = 2758611.04733894\n",
            "Iteration 177, loss = 2703851.89460049\n",
            "Iteration 178, loss = 2652537.67164955\n",
            "Iteration 179, loss = 2606054.98235035\n",
            "Iteration 180, loss = 2555460.89659518\n",
            "Iteration 181, loss = 2508819.95462526\n",
            "Iteration 182, loss = 2463054.31558913\n",
            "Iteration 183, loss = 2420208.76743705\n",
            "Iteration 184, loss = 2386347.57171566\n",
            "Iteration 185, loss = 2346489.99251894\n",
            "Iteration 186, loss = 2311345.74515881\n",
            "Iteration 187, loss = 2278914.90469729\n",
            "Iteration 188, loss = 2252878.71861004\n",
            "Iteration 189, loss = 2224434.50884610\n",
            "Iteration 190, loss = 2194887.86930969\n",
            "Iteration 191, loss = 2169676.44697599\n",
            "Iteration 192, loss = 2147270.13181480\n",
            "Iteration 193, loss = 2125978.24692209\n",
            "Iteration 194, loss = 2101066.34966826\n",
            "Iteration 195, loss = 2074394.31698233\n",
            "Iteration 196, loss = 2044700.47217126\n",
            "Iteration 197, loss = 2021077.03604123\n",
            "Iteration 198, loss = 1998821.10526958\n",
            "Iteration 199, loss = 1976703.88535333\n",
            "Iteration 200, loss = 1957075.97549254\n",
            "Iteration 201, loss = 1937457.67710607\n",
            "Iteration 202, loss = 1921100.18901091\n",
            "Iteration 203, loss = 1908305.99816804\n",
            "Iteration 204, loss = 1898660.75824787\n",
            "Iteration 205, loss = 1883878.48351415\n",
            "Iteration 206, loss = 1859881.75090775\n",
            "Iteration 207, loss = 1842572.86271687\n",
            "Iteration 208, loss = 1821802.55824214\n",
            "Iteration 209, loss = 1805120.83033412\n",
            "Iteration 210, loss = 1790407.97551318\n",
            "Iteration 211, loss = 1775293.34585830\n",
            "Iteration 212, loss = 1760963.77120842\n",
            "Iteration 213, loss = 1747764.56419818\n",
            "Iteration 214, loss = 1735041.85255234\n",
            "Iteration 215, loss = 1720518.48404795\n",
            "Iteration 216, loss = 1707852.48853042\n",
            "Iteration 217, loss = 1697711.67030369\n",
            "Iteration 218, loss = 1687125.39416429\n",
            "Iteration 219, loss = 1674801.56018952\n",
            "Iteration 220, loss = 1661809.40675669\n",
            "Iteration 221, loss = 1649529.21973492\n",
            "Iteration 222, loss = 1637371.66402663\n",
            "Iteration 223, loss = 1626170.54571037\n",
            "Iteration 224, loss = 1613680.49921189\n",
            "Iteration 225, loss = 1603262.06429184\n",
            "Iteration 226, loss = 1592863.57196448\n",
            "Iteration 227, loss = 1583327.89962215\n",
            "Iteration 228, loss = 1573942.30525734\n",
            "Iteration 229, loss = 1561948.07503781\n",
            "Iteration 230, loss = 1547321.03752537\n",
            "Iteration 231, loss = 1536750.81912768\n",
            "Iteration 232, loss = 1528506.49193122\n",
            "Iteration 233, loss = 1524690.63895307\n",
            "Iteration 234, loss = 1517673.53664143\n",
            "Iteration 235, loss = 1505885.00074576\n",
            "Iteration 236, loss = 1494177.42341210\n",
            "Iteration 237, loss = 1479421.19176903\n",
            "Iteration 238, loss = 1470985.87284543\n",
            "Iteration 239, loss = 1462688.19081476\n",
            "Iteration 240, loss = 1455901.85479105\n",
            "Iteration 241, loss = 1446899.43036343\n",
            "Iteration 242, loss = 1439746.46695999\n",
            "Iteration 243, loss = 1431358.38141343\n",
            "Iteration 244, loss = 1425912.15139386\n",
            "Iteration 245, loss = 1422138.36921475\n",
            "Iteration 246, loss = 1411722.08001086\n",
            "Iteration 247, loss = 1404295.27138106\n",
            "Iteration 248, loss = 1399950.57599347\n",
            "Iteration 249, loss = 1396614.48715961\n",
            "Iteration 250, loss = 1391755.97357746\n",
            "Iteration 251, loss = 1386953.99534343\n",
            "Iteration 252, loss = 1376357.69767761\n",
            "Iteration 253, loss = 1372691.30967000\n",
            "Iteration 254, loss = 1373891.11983309\n",
            "Iteration 255, loss = 1372689.02455790\n",
            "Iteration 256, loss = 1367317.17778877\n",
            "Iteration 257, loss = 1360430.01570792\n",
            "Iteration 258, loss = 1352632.12036170\n",
            "Iteration 259, loss = 1346186.95937878\n",
            "Iteration 260, loss = 1340649.58021417\n",
            "Iteration 261, loss = 1332758.15569915\n",
            "Iteration 262, loss = 1326799.68342338\n",
            "Iteration 263, loss = 1322567.20114695\n",
            "Iteration 264, loss = 1318000.33170842\n",
            "Iteration 265, loss = 1315122.56044355\n",
            "Iteration 266, loss = 1313679.73004940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 267, loss = 1316677.58290172\n",
            "Iteration 268, loss = 1319019.88881186\n",
            "Iteration 269, loss = 1310229.72708989\n",
            "Iteration 270, loss = 1296915.55290788\n",
            "Iteration 271, loss = 1286693.40158263\n",
            "Iteration 272, loss = 1290757.19372972\n",
            "Iteration 273, loss = 1293306.09175233\n",
            "Iteration 274, loss = 1289484.19912049\n",
            "Iteration 275, loss = 1279290.26994255\n",
            "Iteration 276, loss = 1268169.17178542\n",
            "Iteration 277, loss = 1268007.49098609\n",
            "Iteration 278, loss = 1270225.88916311\n",
            "Iteration 279, loss = 1269265.82493106\n",
            "Iteration 280, loss = 1265912.89719589\n",
            "Iteration 281, loss = 1259202.82939613\n",
            "Iteration 282, loss = 1254472.25737352\n",
            "Iteration 283, loss = 1249098.57110037\n",
            "Iteration 284, loss = 1247187.47289623\n",
            "Iteration 285, loss = 1244238.28217521\n",
            "Iteration 286, loss = 1241929.96113876\n",
            "Iteration 287, loss = 1238905.97875730\n",
            "Iteration 288, loss = 1235059.11221814\n",
            "Iteration 289, loss = 1233990.25764318\n",
            "Iteration 290, loss = 1230153.11360429\n",
            "Iteration 291, loss = 1227215.58238485\n",
            "Iteration 292, loss = 1224751.78858950\n",
            "Iteration 293, loss = 1224790.08833316\n",
            "Iteration 294, loss = 1224006.53717594\n",
            "Iteration 295, loss = 1222310.54496070\n",
            "Iteration 296, loss = 1218319.21292665\n",
            "Iteration 297, loss = 1214863.11380397\n",
            "Iteration 298, loss = 1210325.50340865\n",
            "Iteration 299, loss = 1206295.15655896\n",
            "Iteration 300, loss = 1206896.27703856\n",
            "Iteration 301, loss = 1215253.78374462\n",
            "Iteration 302, loss = 1210154.90007534\n",
            "Iteration 303, loss = 1202759.67055941\n",
            "Iteration 304, loss = 1200116.47402511\n",
            "Iteration 305, loss = 1196497.43629941\n",
            "Iteration 306, loss = 1193192.46247995\n",
            "Iteration 307, loss = 1189024.03778133\n",
            "Iteration 308, loss = 1186698.14359255\n",
            "Iteration 309, loss = 1186924.79180140\n",
            "Iteration 310, loss = 1188267.76406984\n",
            "Iteration 311, loss = 1187449.41765648\n",
            "Iteration 312, loss = 1182189.99906905\n",
            "Iteration 313, loss = 1174959.08465816\n",
            "Iteration 314, loss = 1177300.57912243\n",
            "Iteration 315, loss = 1179152.72732050\n",
            "Iteration 316, loss = 1177685.80300167\n",
            "Iteration 317, loss = 1171822.57445816\n",
            "Iteration 318, loss = 1166952.61921201\n",
            "Iteration 319, loss = 1166732.52155099\n",
            "Iteration 320, loss = 1169661.96188697\n",
            "Iteration 321, loss = 1169346.28648270\n",
            "Iteration 322, loss = 1166983.37271276\n",
            "Iteration 323, loss = 1162772.43418345\n",
            "Iteration 324, loss = 1160232.22117070\n",
            "Iteration 325, loss = 1157674.61546437\n",
            "Iteration 326, loss = 1156431.11406200\n",
            "Iteration 327, loss = 1155779.16578909\n",
            "Iteration 328, loss = 1157281.54402126\n",
            "Iteration 329, loss = 1158475.77018864\n",
            "Iteration 330, loss = 1152708.16302461\n",
            "Iteration 331, loss = 1148208.31810685\n",
            "Iteration 332, loss = 1149115.01872478\n",
            "Iteration 333, loss = 1160623.38501259\n",
            "Iteration 334, loss = 1163778.27742260\n",
            "Iteration 335, loss = 1156832.17606613\n",
            "Iteration 336, loss = 1147733.02065665\n",
            "Iteration 337, loss = 1144297.88319613\n",
            "Iteration 338, loss = 1142261.40537571\n",
            "Iteration 339, loss = 1140083.09793366\n",
            "Iteration 340, loss = 1137573.61351143\n",
            "Iteration 341, loss = 1136463.42909901\n",
            "Iteration 342, loss = 1135729.34579737\n",
            "Iteration 343, loss = 1134877.59901182\n",
            "Iteration 344, loss = 1133388.49835417\n",
            "Iteration 345, loss = 1136629.64679605\n",
            "Iteration 346, loss = 1141818.08751219\n",
            "Iteration 347, loss = 1144043.36706462\n",
            "Iteration 348, loss = 1138131.44108020\n",
            "Iteration 349, loss = 1132219.01424421\n",
            "Iteration 350, loss = 1125336.96747056\n",
            "Iteration 351, loss = 1126450.09799342\n",
            "Iteration 352, loss = 1125640.76653689\n",
            "Iteration 353, loss = 1125657.08001134\n",
            "Iteration 354, loss = 1124838.63187197\n",
            "Iteration 355, loss = 1122622.69501658\n",
            "Iteration 356, loss = 1120476.04212323\n",
            "Iteration 357, loss = 1120695.65656014\n",
            "Iteration 358, loss = 1120239.15080771\n",
            "Iteration 359, loss = 1117545.12499793\n",
            "Iteration 360, loss = 1114003.98798334\n",
            "Iteration 361, loss = 1115887.10683353\n",
            "Iteration 362, loss = 1116271.68470689\n",
            "Iteration 363, loss = 1115556.00530183\n",
            "Iteration 364, loss = 1115370.64332010\n",
            "Iteration 365, loss = 1112068.23123524\n",
            "Iteration 366, loss = 1111279.15443315\n",
            "Iteration 367, loss = 1110410.02224039\n",
            "Iteration 368, loss = 1108617.97747604\n",
            "Iteration 369, loss = 1106150.76330878\n",
            "Iteration 370, loss = 1107065.07978273\n",
            "Iteration 371, loss = 1104135.55263632\n",
            "Iteration 372, loss = 1102394.54425642\n",
            "Iteration 373, loss = 1102196.86104279\n",
            "Iteration 374, loss = 1103062.50885556\n",
            "Iteration 375, loss = 1102635.01449290\n",
            "Iteration 376, loss = 1100422.43833016\n",
            "Iteration 377, loss = 1100488.22308604\n",
            "Iteration 378, loss = 1103320.77126376\n",
            "Iteration 379, loss = 1102220.37003801\n",
            "Iteration 380, loss = 1097292.60445213\n",
            "Iteration 381, loss = 1098305.57648505\n",
            "Iteration 382, loss = 1098754.94072262\n",
            "Iteration 383, loss = 1096165.27775355\n",
            "Iteration 384, loss = 1094179.67196209\n",
            "Iteration 385, loss = 1090915.75016877\n",
            "Iteration 386, loss = 1089689.60496428\n",
            "Iteration 387, loss = 1088496.65798438\n",
            "Iteration 388, loss = 1087763.83794986\n",
            "Iteration 389, loss = 1088214.99577943\n",
            "Iteration 390, loss = 1088429.38581004\n",
            "Iteration 391, loss = 1084886.28070389\n",
            "Iteration 392, loss = 1084724.96869066\n",
            "Iteration 393, loss = 1082953.89637089\n",
            "Iteration 394, loss = 1082696.40893931\n",
            "Iteration 395, loss = 1081709.61098094\n",
            "Iteration 396, loss = 1082169.65869875\n",
            "Iteration 397, loss = 1079997.23016945\n",
            "Iteration 398, loss = 1078809.06616107\n",
            "Iteration 399, loss = 1078574.48076361\n",
            "Iteration 400, loss = 1078572.69222877\n",
            "Iteration 401, loss = 1078509.37709153\n",
            "Iteration 402, loss = 1077258.66212288\n",
            "Iteration 403, loss = 1074689.90448879\n",
            "Iteration 404, loss = 1074565.54953406\n",
            "Iteration 405, loss = 1075197.76204076\n",
            "Iteration 406, loss = 1074899.51308019\n",
            "Iteration 407, loss = 1072655.20187880\n",
            "Iteration 408, loss = 1072702.46826132\n",
            "Iteration 409, loss = 1076568.07326092\n",
            "Iteration 410, loss = 1075244.28581671\n",
            "Iteration 411, loss = 1072213.31233591\n",
            "Iteration 412, loss = 1068372.50933599\n",
            "Iteration 413, loss = 1068909.67669422\n",
            "Iteration 414, loss = 1069153.10865639\n",
            "Iteration 415, loss = 1068443.01640575\n",
            "Iteration 416, loss = 1068119.23109676\n",
            "Iteration 417, loss = 1066510.66830979\n",
            "Iteration 418, loss = 1067830.74246724\n",
            "Iteration 419, loss = 1066859.73762676\n",
            "Iteration 420, loss = 1065426.83189115\n",
            "Iteration 421, loss = 1064432.03044894\n",
            "Iteration 422, loss = 1063366.11521193\n",
            "Iteration 423, loss = 1062088.85087875\n",
            "Iteration 424, loss = 1064800.38348172\n",
            "Iteration 425, loss = 1066413.21276014\n",
            "Iteration 426, loss = 1064642.37107700\n",
            "Iteration 427, loss = 1064787.92946243\n",
            "Iteration 428, loss = 1060085.20109571\n",
            "Iteration 429, loss = 1058283.72565774\n",
            "Iteration 430, loss = 1058120.36293328\n",
            "Iteration 431, loss = 1058189.47284161\n",
            "Iteration 432, loss = 1057698.20297995\n",
            "Iteration 433, loss = 1058396.14499656\n",
            "Iteration 434, loss = 1058288.17220927\n",
            "Iteration 435, loss = 1056726.98635080\n",
            "Iteration 436, loss = 1062724.12314885\n",
            "Iteration 437, loss = 1060763.97586021\n",
            "Iteration 438, loss = 1055571.30466040\n",
            "Iteration 439, loss = 1055130.74446255\n",
            "Iteration 440, loss = 1059476.58340032\n",
            "Iteration 441, loss = 1056499.34629205\n",
            "Iteration 442, loss = 1051055.72664021\n",
            "Iteration 443, loss = 1053975.34978329\n",
            "Iteration 444, loss = 1061881.00345297\n",
            "Iteration 445, loss = 1066981.10101568\n",
            "Iteration 446, loss = 1064227.40690808\n",
            "Iteration 447, loss = 1054532.40443306\n",
            "Iteration 448, loss = 1052492.83125379\n",
            "Iteration 449, loss = 1051045.03350836\n",
            "Iteration 450, loss = 1051212.47106661\n",
            "Iteration 451, loss = 1049861.27503659\n",
            "Iteration 452, loss = 1048121.58339517\n",
            "Iteration 453, loss = 1053003.50665282\n",
            "Iteration 454, loss = 1063005.25310554\n",
            "Iteration 455, loss = 1067616.58941476\n",
            "Iteration 456, loss = 1056019.30463758\n",
            "Iteration 457, loss = 1056405.00442129\n",
            "Iteration 458, loss = 1052665.61757247\n",
            "Iteration 459, loss = 1051148.01099540\n",
            "Iteration 460, loss = 1047977.59693852\n",
            "Iteration 461, loss = 1051208.71267131\n",
            "Iteration 462, loss = 1054351.52292717\n",
            "Iteration 463, loss = 1049676.14708625\n",
            "Iteration 464, loss = 1044633.43556894\n",
            "Iteration 465, loss = 1049123.59586222\n",
            "Iteration 466, loss = 1052521.53800882\n",
            "Iteration 467, loss = 1049189.09530208\n",
            "Iteration 468, loss = 1044921.72504368\n",
            "Iteration 469, loss = 1044507.48874172\n",
            "Iteration 470, loss = 1044382.28345259\n",
            "Iteration 471, loss = 1043941.09985689\n",
            "Iteration 472, loss = 1043434.32708231\n",
            "Iteration 473, loss = 1043351.69814377\n",
            "Iteration 474, loss = 1044636.43249414\n",
            "Iteration 475, loss = 1045024.76980316\n",
            "Iteration 476, loss = 1043131.64181641\n",
            "Iteration 477, loss = 1043236.42223646\n",
            "Iteration 478, loss = 1041109.50448597\n",
            "Iteration 479, loss = 1042395.61108912\n",
            "Iteration 480, loss = 1040454.33243856\n",
            "Iteration 481, loss = 1039744.42211196\n",
            "Iteration 482, loss = 1039777.35380163\n",
            "Iteration 483, loss = 1038472.69989212\n",
            "Iteration 484, loss = 1038741.63942461\n",
            "Iteration 485, loss = 1051870.09987108\n",
            "Iteration 486, loss = 1058589.35597421\n",
            "Iteration 487, loss = 1049099.81697549\n",
            "Iteration 488, loss = 1039253.05709099\n",
            "Iteration 489, loss = 1041964.78354724\n",
            "Iteration 490, loss = 1041303.69732051\n",
            "Iteration 491, loss = 1040116.72554580\n",
            "Iteration 492, loss = 1039762.46748912\n",
            "Iteration 493, loss = 1038860.25693483\n",
            "Iteration 494, loss = 1039363.74529279\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 125390642980313546752.00000000\n",
            "Iteration 2, loss = inf\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50, 50, 50), relu, 0.001, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538826776.37870073\n",
            "Iteration 2, loss = 1538773144.39590740\n",
            "Iteration 3, loss = 1538695083.91128850\n",
            "Iteration 4, loss = 1538559138.38529825\n",
            "Iteration 5, loss = 1538323444.86395288\n",
            "Iteration 6, loss = 1537924316.68594003\n",
            "Iteration 7, loss = 1537286100.88475418\n",
            "Iteration 8, loss = 1536355009.30603147\n",
            "Iteration 9, loss = 1534957074.32018256\n",
            "Iteration 10, loss = 1532952805.06414413\n",
            "Iteration 11, loss = 1530068505.32652903\n",
            "Iteration 12, loss = 1526078063.67271781\n",
            "Iteration 13, loss = 1520655316.54338408\n",
            "Iteration 14, loss = 1513560564.98643827\n",
            "Iteration 15, loss = 1504072492.36170888\n",
            "Iteration 16, loss = 1491577857.10161710\n",
            "Iteration 17, loss = 1475314520.01768017\n",
            "Iteration 18, loss = 1455104967.49935007\n",
            "Iteration 19, loss = 1429600182.12731457\n",
            "Iteration 20, loss = 1397501538.19816446\n",
            "Iteration 21, loss = 1358504403.57661557\n",
            "Iteration 22, loss = 1311466982.89640617\n",
            "Iteration 23, loss = 1255037294.73757076\n",
            "Iteration 24, loss = 1187787883.90041828\n",
            "Iteration 25, loss = 1109965778.92586827\n",
            "Iteration 26, loss = 1020934503.90950525\n",
            "Iteration 27, loss = 919727673.00859261\n",
            "Iteration 28, loss = 809579191.78795791\n",
            "Iteration 29, loss = 692404984.57441843\n",
            "Iteration 30, loss = 567888029.89536595\n",
            "Iteration 31, loss = 445301548.99108088\n",
            "Iteration 32, loss = 331713593.89882922\n",
            "Iteration 33, loss = 235813536.03099480\n",
            "Iteration 34, loss = 164576600.57745123\n",
            "Iteration 35, loss = 132690959.25097074\n",
            "Iteration 36, loss = 132038233.36794919\n",
            "Iteration 37, loss = 154421090.31282231\n",
            "Iteration 38, loss = 174412231.25720358\n",
            "Iteration 39, loss = 177294740.12053743\n",
            "Iteration 40, loss = 163474799.86135176\n",
            "Iteration 41, loss = 140625673.14063874\n",
            "Iteration 42, loss = 122830296.49098264\n",
            "Iteration 43, loss = 112549728.75132430\n",
            "Iteration 44, loss = 109423141.30442005\n",
            "Iteration 45, loss = 109986900.39790034\n",
            "Iteration 46, loss = 111897263.74385129\n",
            "Iteration 47, loss = 112726836.11686309\n",
            "Iteration 48, loss = 111374161.64299999\n",
            "Iteration 49, loss = 108214131.95795763\n",
            "Iteration 50, loss = 103859528.05029769\n",
            "Iteration 51, loss = 99451685.02411900\n",
            "Iteration 52, loss = 95474483.10027121\n",
            "Iteration 53, loss = 92470661.43016216\n",
            "Iteration 54, loss = 90336931.01499532\n",
            "Iteration 55, loss = 88539334.73962417\n",
            "Iteration 56, loss = 86741820.06371275\n",
            "Iteration 57, loss = 84704228.03007860\n",
            "Iteration 58, loss = 82348881.02775794\n",
            "Iteration 59, loss = 79762207.27490981\n",
            "Iteration 60, loss = 77308373.34681928\n",
            "Iteration 61, loss = 74963847.28777875\n",
            "Iteration 62, loss = 72734590.62838434\n",
            "Iteration 63, loss = 70709554.96413040\n",
            "Iteration 64, loss = 68435690.74980743\n",
            "Iteration 65, loss = 66261702.26427492\n",
            "Iteration 66, loss = 64209258.69839467\n",
            "Iteration 67, loss = 62212600.87194338\n",
            "Iteration 68, loss = 60205177.01688500\n",
            "Iteration 69, loss = 58363017.07848041\n",
            "Iteration 70, loss = 56670683.36464094\n",
            "Iteration 71, loss = 54924854.27179429\n",
            "Iteration 72, loss = 53245362.87295769\n",
            "Iteration 73, loss = 51623829.01236735\n",
            "Iteration 74, loss = 50094065.54575526\n",
            "Iteration 75, loss = 48645890.53397055\n",
            "Iteration 76, loss = 47156245.86568704\n",
            "Iteration 77, loss = 45686831.75573639\n",
            "Iteration 78, loss = 44256052.56002882\n",
            "Iteration 79, loss = 42909479.09778553\n",
            "Iteration 80, loss = 41554621.11569539\n",
            "Iteration 81, loss = 40251897.06846706\n",
            "Iteration 82, loss = 38973167.73004312\n",
            "Iteration 83, loss = 37734098.04975733\n",
            "Iteration 84, loss = 36571414.40046839\n",
            "Iteration 85, loss = 35406066.45489515\n",
            "Iteration 86, loss = 34297199.22697847\n",
            "Iteration 87, loss = 33230974.55248611\n",
            "Iteration 88, loss = 32193764.12948216\n",
            "Iteration 89, loss = 31185544.10108150\n",
            "Iteration 90, loss = 30231915.72849065\n",
            "Iteration 91, loss = 29266708.86414249\n",
            "Iteration 92, loss = 28304541.75430216\n",
            "Iteration 93, loss = 27310644.54727672\n",
            "Iteration 94, loss = 26381723.80838868\n",
            "Iteration 95, loss = 25427493.05022160\n",
            "Iteration 96, loss = 24553480.83770202\n",
            "Iteration 97, loss = 23662505.41904532\n",
            "Iteration 98, loss = 22788597.38862492\n",
            "Iteration 99, loss = 21974159.54297459\n",
            "Iteration 100, loss = 21149399.89562007\n",
            "Iteration 101, loss = 20350249.79747272\n",
            "Iteration 102, loss = 19581688.37132837\n",
            "Iteration 103, loss = 18835116.70458797\n",
            "Iteration 104, loss = 18154082.73004895\n",
            "Iteration 105, loss = 17493783.05784960\n",
            "Iteration 106, loss = 16913352.33867144\n",
            "Iteration 107, loss = 16367903.45565278\n",
            "Iteration 108, loss = 15819447.41228866\n",
            "Iteration 109, loss = 15270698.05654520\n",
            "Iteration 110, loss = 14734410.86493705\n",
            "Iteration 111, loss = 14194743.46526934\n",
            "Iteration 112, loss = 13713738.82527913\n",
            "Iteration 113, loss = 13152640.10498289\n",
            "Iteration 114, loss = 12663437.09809374\n",
            "Iteration 115, loss = 12146170.66902768\n",
            "Iteration 116, loss = 11705738.48521616\n",
            "Iteration 117, loss = 11263453.22151611\n",
            "Iteration 118, loss = 10843516.27963076\n",
            "Iteration 119, loss = 10432912.85081457\n",
            "Iteration 120, loss = 10037115.70694773\n",
            "Iteration 121, loss = 9643853.91354931\n",
            "Iteration 122, loss = 9288125.60741587\n",
            "Iteration 123, loss = 8919425.20840717\n",
            "Iteration 124, loss = 8577516.11984477\n",
            "Iteration 125, loss = 8269134.27120832\n",
            "Iteration 126, loss = 7975492.94731473\n",
            "Iteration 127, loss = 7698575.29560310\n",
            "Iteration 128, loss = 7449454.77326052\n",
            "Iteration 129, loss = 7216413.11226498\n",
            "Iteration 130, loss = 6966008.38837419\n",
            "Iteration 131, loss = 6754849.51864123\n",
            "Iteration 132, loss = 6547587.98830671\n",
            "Iteration 133, loss = 6350391.62613455\n",
            "Iteration 134, loss = 6155827.49117297\n",
            "Iteration 135, loss = 5969907.67709609\n",
            "Iteration 136, loss = 5799878.72572450\n",
            "Iteration 137, loss = 5628843.95031054\n",
            "Iteration 138, loss = 5502308.10384352\n",
            "Iteration 139, loss = 5329244.31010413\n",
            "Iteration 140, loss = 5180893.29252730\n",
            "Iteration 141, loss = 5040655.93412753\n",
            "Iteration 142, loss = 4916020.63797389\n",
            "Iteration 143, loss = 4807546.41729101\n",
            "Iteration 144, loss = 4698271.86398132\n",
            "Iteration 145, loss = 4583020.35941156\n",
            "Iteration 146, loss = 4476391.78752330\n",
            "Iteration 147, loss = 4376102.42698046\n",
            "Iteration 148, loss = 4286597.08580759\n",
            "Iteration 149, loss = 4186578.80911166\n",
            "Iteration 150, loss = 4088003.29731357\n",
            "Iteration 151, loss = 3984706.43129164\n",
            "Iteration 152, loss = 3904382.02342822\n",
            "Iteration 153, loss = 3811477.59488311\n",
            "Iteration 154, loss = 3737175.74782020\n",
            "Iteration 155, loss = 3657896.51012730\n",
            "Iteration 156, loss = 3577600.08317402\n",
            "Iteration 157, loss = 3496611.87167503\n",
            "Iteration 158, loss = 3417188.24765907\n",
            "Iteration 159, loss = 3344375.02160777\n",
            "Iteration 160, loss = 3286884.07884211\n",
            "Iteration 161, loss = 3224651.75315299\n",
            "Iteration 162, loss = 3159457.40412834\n",
            "Iteration 163, loss = 3087437.26076974\n",
            "Iteration 164, loss = 3028875.74301371\n",
            "Iteration 165, loss = 2966562.22019954\n",
            "Iteration 166, loss = 2912143.09540105\n",
            "Iteration 167, loss = 2861784.49320719\n",
            "Iteration 168, loss = 2811898.86011029\n",
            "Iteration 169, loss = 2760759.13153899\n",
            "Iteration 170, loss = 2704821.66826302\n",
            "Iteration 171, loss = 2665440.49101232\n",
            "Iteration 172, loss = 2606105.65120908\n",
            "Iteration 173, loss = 2563193.68695351\n",
            "Iteration 174, loss = 2524669.83064150\n",
            "Iteration 175, loss = 2479668.82800950\n",
            "Iteration 176, loss = 2440174.09947810\n",
            "Iteration 177, loss = 2408043.09407143\n",
            "Iteration 178, loss = 2387071.21122550\n",
            "Iteration 179, loss = 2360554.38599763\n",
            "Iteration 180, loss = 2329074.37911308\n",
            "Iteration 181, loss = 2291524.94197703\n",
            "Iteration 182, loss = 2256376.97036913\n",
            "Iteration 183, loss = 2225851.02961217\n",
            "Iteration 184, loss = 2196997.66128755\n",
            "Iteration 185, loss = 2174687.93241154\n",
            "Iteration 186, loss = 2144481.03929733\n",
            "Iteration 187, loss = 2117074.16347178\n",
            "Iteration 188, loss = 2089314.98129358\n",
            "Iteration 189, loss = 2065866.40583146\n",
            "Iteration 190, loss = 2048937.76149442\n",
            "Iteration 191, loss = 2030404.35468535\n",
            "Iteration 192, loss = 2010038.68195405\n",
            "Iteration 193, loss = 1986594.11341047\n",
            "Iteration 194, loss = 1967067.70036051\n",
            "Iteration 195, loss = 1947561.36703482\n",
            "Iteration 196, loss = 1928551.53584555\n",
            "Iteration 197, loss = 1912010.94087723\n",
            "Iteration 198, loss = 1895327.70477878\n",
            "Iteration 199, loss = 1881546.47152489\n",
            "Iteration 200, loss = 1867605.09286298\n",
            "Iteration 201, loss = 1859671.66810293\n",
            "Iteration 202, loss = 1846966.95620392\n",
            "Iteration 203, loss = 1829303.70569611\n",
            "Iteration 204, loss = 1810778.42393325\n",
            "Iteration 205, loss = 1789011.13590962\n",
            "Iteration 206, loss = 1768962.28825962\n",
            "Iteration 207, loss = 1746349.79288769\n",
            "Iteration 208, loss = 1733197.95509434\n",
            "Iteration 209, loss = 1720546.81527963\n",
            "Iteration 210, loss = 1712455.98079015\n",
            "Iteration 211, loss = 1692162.02711887\n",
            "Iteration 212, loss = 1677981.81957909\n",
            "Iteration 213, loss = 1660198.26859511\n",
            "Iteration 214, loss = 1649482.07582469\n",
            "Iteration 215, loss = 1638683.53139308\n",
            "Iteration 216, loss = 1624175.98342570\n",
            "Iteration 217, loss = 1610564.81741395\n",
            "Iteration 218, loss = 1598768.39803064\n",
            "Iteration 219, loss = 1589476.36467539\n",
            "Iteration 220, loss = 1581416.31644741\n",
            "Iteration 221, loss = 1566606.95544225\n",
            "Iteration 222, loss = 1555168.88396194\n",
            "Iteration 223, loss = 1539802.68814620\n",
            "Iteration 224, loss = 1529643.19121362\n",
            "Iteration 225, loss = 1519452.77851075\n",
            "Iteration 226, loss = 1510351.59512930\n",
            "Iteration 227, loss = 1500999.84411347\n",
            "Iteration 228, loss = 1493759.29807809\n",
            "Iteration 229, loss = 1482959.51910408\n",
            "Iteration 230, loss = 1472956.90684395\n",
            "Iteration 231, loss = 1463548.71080241\n",
            "Iteration 232, loss = 1456434.70134172\n",
            "Iteration 233, loss = 1448259.94231026\n",
            "Iteration 234, loss = 1445449.69407738\n",
            "Iteration 235, loss = 1447914.21654510\n",
            "Iteration 236, loss = 1443111.56071598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 237, loss = 1433969.35400965\n",
            "Iteration 238, loss = 1419041.42441288\n",
            "Iteration 239, loss = 1410208.86617775\n",
            "Iteration 240, loss = 1404369.08591474\n",
            "Iteration 241, loss = 1399041.87609911\n",
            "Iteration 242, loss = 1392788.30559949\n",
            "Iteration 243, loss = 1384212.53217820\n",
            "Iteration 244, loss = 1376686.98048745\n",
            "Iteration 245, loss = 1370047.85964525\n",
            "Iteration 246, loss = 1363783.08589695\n",
            "Iteration 247, loss = 1355124.30673113\n",
            "Iteration 248, loss = 1345902.12015469\n",
            "Iteration 249, loss = 1342590.28469823\n",
            "Iteration 250, loss = 1337563.75082731\n",
            "Iteration 251, loss = 1332046.56265847\n",
            "Iteration 252, loss = 1322628.24704559\n",
            "Iteration 253, loss = 1317746.66518751\n",
            "Iteration 254, loss = 1320850.39541029\n",
            "Iteration 255, loss = 1321657.84159163\n",
            "Iteration 256, loss = 1314834.40514951\n",
            "Iteration 257, loss = 1304209.00245364\n",
            "Iteration 258, loss = 1294359.97889858\n",
            "Iteration 259, loss = 1284125.45331252\n",
            "Iteration 260, loss = 1280589.53692135\n",
            "Iteration 261, loss = 1275705.33933743\n",
            "Iteration 262, loss = 1269017.77729947\n",
            "Iteration 263, loss = 1266248.87046805\n",
            "Iteration 264, loss = 1261704.64405733\n",
            "Iteration 265, loss = 1257381.33122210\n",
            "Iteration 266, loss = 1250194.30326055\n",
            "Iteration 267, loss = 1244137.54760349\n",
            "Iteration 268, loss = 1241525.91256095\n",
            "Iteration 269, loss = 1239394.73508397\n",
            "Iteration 270, loss = 1237284.99535237\n",
            "Iteration 271, loss = 1232485.99043499\n",
            "Iteration 272, loss = 1228428.74486603\n",
            "Iteration 273, loss = 1220005.68541983\n",
            "Iteration 274, loss = 1216999.97875003\n",
            "Iteration 275, loss = 1214637.61493587\n",
            "Iteration 276, loss = 1211787.87651914\n",
            "Iteration 277, loss = 1207179.05465671\n",
            "Iteration 278, loss = 1202194.29802239\n",
            "Iteration 279, loss = 1196980.22608900\n",
            "Iteration 280, loss = 1197756.61044642\n",
            "Iteration 281, loss = 1193373.22602209\n",
            "Iteration 282, loss = 1189237.86790621\n",
            "Iteration 283, loss = 1184930.42565567\n",
            "Iteration 284, loss = 1181497.46788988\n",
            "Iteration 285, loss = 1178772.37945492\n",
            "Iteration 286, loss = 1177148.38890488\n",
            "Iteration 287, loss = 1175520.66609138\n",
            "Iteration 288, loss = 1172557.56173144\n",
            "Iteration 289, loss = 1168068.17515458\n",
            "Iteration 290, loss = 1165573.18995084\n",
            "Iteration 291, loss = 1164422.49113850\n",
            "Iteration 292, loss = 1161839.99586995\n",
            "Iteration 293, loss = 1158133.17850314\n",
            "Iteration 294, loss = 1155638.62650774\n",
            "Iteration 295, loss = 1153195.03451125\n",
            "Iteration 296, loss = 1148817.42267114\n",
            "Iteration 297, loss = 1149258.87812698\n",
            "Iteration 298, loss = 1150236.81212247\n",
            "Iteration 299, loss = 1148511.19457606\n",
            "Iteration 300, loss = 1146563.12304153\n",
            "Iteration 301, loss = 1139100.25092799\n",
            "Iteration 302, loss = 1137673.54884263\n",
            "Iteration 303, loss = 1132276.80145195\n",
            "Iteration 304, loss = 1139637.97009158\n",
            "Iteration 305, loss = 1133253.07237035\n",
            "Iteration 306, loss = 1128639.63729684\n",
            "Iteration 307, loss = 1128015.77675504\n",
            "Iteration 308, loss = 1127196.18443018\n",
            "Iteration 309, loss = 1125201.09428568\n",
            "Iteration 310, loss = 1122749.09035647\n",
            "Iteration 311, loss = 1120178.75984370\n",
            "Iteration 312, loss = 1118803.16205807\n",
            "Iteration 313, loss = 1117986.44334009\n",
            "Iteration 314, loss = 1117365.72174755\n",
            "Iteration 315, loss = 1114656.20612718\n",
            "Iteration 316, loss = 1112421.60665635\n",
            "Iteration 317, loss = 1112499.23167239\n",
            "Iteration 318, loss = 1111802.58089535\n",
            "Iteration 319, loss = 1110750.94081552\n",
            "Iteration 320, loss = 1108744.97749516\n",
            "Iteration 321, loss = 1108706.44398577\n",
            "Iteration 322, loss = 1106035.97913654\n",
            "Iteration 323, loss = 1104292.15749717\n",
            "Iteration 324, loss = 1103388.41394682\n",
            "Iteration 325, loss = 1103193.10519683\n",
            "Iteration 326, loss = 1102870.70852881\n",
            "Iteration 327, loss = 1105334.85939160\n",
            "Iteration 328, loss = 1102601.97511672\n",
            "Iteration 329, loss = 1098779.13038694\n",
            "Iteration 330, loss = 1096622.40278293\n",
            "Iteration 331, loss = 1094630.02231626\n",
            "Iteration 332, loss = 1092390.25065554\n",
            "Iteration 333, loss = 1092380.39558780\n",
            "Iteration 334, loss = 1091456.83251517\n",
            "Iteration 335, loss = 1090444.69970371\n",
            "Iteration 336, loss = 1089092.79802162\n",
            "Iteration 337, loss = 1089273.70717612\n",
            "Iteration 338, loss = 1089718.09648495\n",
            "Iteration 339, loss = 1090118.72455992\n",
            "Iteration 340, loss = 1091481.57716429\n",
            "Iteration 341, loss = 1090069.46096973\n",
            "Iteration 342, loss = 1090754.60317980\n",
            "Iteration 343, loss = 1086870.48979923\n",
            "Iteration 344, loss = 1085922.62299940\n",
            "Iteration 345, loss = 1084301.81968060\n",
            "Iteration 346, loss = 1082949.16345753\n",
            "Iteration 347, loss = 1081049.16696523\n",
            "Iteration 348, loss = 1081132.51691742\n",
            "Iteration 349, loss = 1083324.96836929\n",
            "Iteration 350, loss = 1083325.49138559\n",
            "Iteration 351, loss = 1080296.76934937\n",
            "Iteration 352, loss = 1077805.53360555\n",
            "Iteration 353, loss = 1080274.33932418\n",
            "Iteration 354, loss = 1089893.24954659\n",
            "Iteration 355, loss = 1089448.09287584\n",
            "Iteration 356, loss = 1079517.89987192\n",
            "Iteration 357, loss = 1073905.17092956\n",
            "Iteration 358, loss = 1080683.71015203\n",
            "Iteration 359, loss = 1083786.15422781\n",
            "Iteration 360, loss = 1080487.93355386\n",
            "Iteration 361, loss = 1075978.99175119\n",
            "Iteration 362, loss = 1071488.28749717\n",
            "Iteration 363, loss = 1075462.00545669\n",
            "Iteration 364, loss = 1076715.56879431\n",
            "Iteration 365, loss = 1075349.93172847\n",
            "Iteration 366, loss = 1073977.84927189\n",
            "Iteration 367, loss = 1068738.02214210\n",
            "Iteration 368, loss = 1067996.95429049\n",
            "Iteration 369, loss = 1067241.28886423\n",
            "Iteration 370, loss = 1067603.95215088\n",
            "Iteration 371, loss = 1067066.71516203\n",
            "Iteration 372, loss = 1066371.62224465\n",
            "Iteration 373, loss = 1066458.55404669\n",
            "Iteration 374, loss = 1063516.23529715\n",
            "Iteration 375, loss = 1064170.59900371\n",
            "Iteration 376, loss = 1066123.89071186\n",
            "Iteration 377, loss = 1064785.84951987\n",
            "Iteration 378, loss = 1061780.31692247\n",
            "Iteration 379, loss = 1062380.58604877\n",
            "Iteration 380, loss = 1068954.05411435\n",
            "Iteration 381, loss = 1070193.81070260\n",
            "Iteration 382, loss = 1063299.50952032\n",
            "Iteration 383, loss = 1062438.97414543\n",
            "Iteration 384, loss = 1061403.50539331\n",
            "Iteration 385, loss = 1062212.81643116\n",
            "Iteration 386, loss = 1060777.13525488\n",
            "Iteration 387, loss = 1061224.44487718\n",
            "Iteration 388, loss = 1060284.17345788\n",
            "Iteration 389, loss = 1059628.41489152\n",
            "Iteration 390, loss = 1059484.46913392\n",
            "Iteration 391, loss = 1058961.96352377\n",
            "Iteration 392, loss = 1056875.90500363\n",
            "Iteration 393, loss = 1055598.76478711\n",
            "Iteration 394, loss = 1056366.01394328\n",
            "Iteration 395, loss = 1057135.88832418\n",
            "Iteration 396, loss = 1060126.50892523\n",
            "Iteration 397, loss = 1056355.74283377\n",
            "Iteration 398, loss = 1055803.66872025\n",
            "Iteration 399, loss = 1059235.57518037\n",
            "Iteration 400, loss = 1059213.36418479\n",
            "Iteration 401, loss = 1058115.98061774\n",
            "Iteration 402, loss = 1052841.56148862\n",
            "Iteration 403, loss = 1052416.46940760\n",
            "Iteration 404, loss = 1051985.79996072\n",
            "Iteration 405, loss = 1052397.48130347\n",
            "Iteration 406, loss = 1050739.89695745\n",
            "Iteration 407, loss = 1050908.67524722\n",
            "Iteration 408, loss = 1054447.67673400\n",
            "Iteration 409, loss = 1058151.94768378\n",
            "Iteration 410, loss = 1057525.97775776\n",
            "Iteration 411, loss = 1054754.97523563\n",
            "Iteration 412, loss = 1049696.54202773\n",
            "Iteration 413, loss = 1049795.88249283\n",
            "Iteration 414, loss = 1050776.40633316\n",
            "Iteration 415, loss = 1051687.08846712\n",
            "Iteration 416, loss = 1050717.39733470\n",
            "Iteration 417, loss = 1048549.32247107\n",
            "Iteration 418, loss = 1051113.49255090\n",
            "Iteration 419, loss = 1054395.24947122\n",
            "Iteration 420, loss = 1050041.67323284\n",
            "Iteration 421, loss = 1047586.20864758\n",
            "Iteration 422, loss = 1049243.58460826\n",
            "Iteration 423, loss = 1048800.10471495\n",
            "Iteration 424, loss = 1046686.57764521\n",
            "Iteration 425, loss = 1047600.67321423\n",
            "Iteration 426, loss = 1045407.77643239\n",
            "Iteration 427, loss = 1046544.74822245\n",
            "Iteration 428, loss = 1055803.90298426\n",
            "Iteration 429, loss = 1056659.40629906\n",
            "Iteration 430, loss = 1047313.23900809\n",
            "Iteration 431, loss = 1041747.68486830\n",
            "Iteration 432, loss = 1049482.57592321\n",
            "Iteration 433, loss = 1061289.24301020\n",
            "Iteration 434, loss = 1060264.29284242\n",
            "Iteration 435, loss = 1045897.96678746\n",
            "Iteration 436, loss = 1044226.73723373\n",
            "Iteration 437, loss = 1054673.84916440\n",
            "Iteration 438, loss = 1058878.62337183\n",
            "Iteration 439, loss = 1051514.39725001\n",
            "Iteration 440, loss = 1045286.82442217\n",
            "Iteration 441, loss = 1041769.46886408\n",
            "Iteration 442, loss = 1043051.01913908\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_base.py:172: RuntimeWarning: overflow encountered in square\n",
            "  return ((y_true - y_pred) ** 2).mean() / 2\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\extmath.py:205: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 93406330358249111552.00000000\n",
            "Iteration 2, loss = inf\n",
            "Iteration 3, loss = nan\n",
            "Iteration 4, loss = nan\n",
            "Iteration 5, loss = nan\n",
            "Iteration 6, loss = nan\n",
            "Iteration 7, loss = nan\n",
            "Iteration 8, loss = nan\n",
            "Iteration 9, loss = nan\n",
            "Iteration 10, loss = nan\n",
            "Iteration 11, loss = nan\n",
            "Iteration 12, loss = nan\n",
            "Iteration 13, loss = nan\n",
            "Iteration 14, loss = nan\n",
            "Iteration 15, loss = nan\n",
            "Iteration 16, loss = nan\n",
            "Iteration 17, loss = nan\n",
            "Iteration 18, loss = nan\n",
            "Iteration 19, loss = nan\n",
            "Iteration 20, loss = nan\n",
            "Iteration 21, loss = nan\n",
            "Iteration 22, loss = nan\n",
            "Iteration 23, loss = nan\n",
            "Iteration 24, loss = nan\n",
            "Iteration 25, loss = nan\n",
            "Iteration 26, loss = nan\n",
            "Iteration 27, loss = nan\n",
            "Iteration 28, loss = nan\n",
            "Iteration 29, loss = nan\n",
            "Iteration 30, loss = nan\n",
            "Iteration 31, loss = nan\n",
            "Iteration 32, loss = nan\n",
            "Iteration 33, loss = nan\n",
            "Iteration 34, loss = nan\n",
            "Iteration 35, loss = nan\n",
            "Iteration 36, loss = nan\n",
            "Iteration 37, loss = nan\n",
            "Iteration 38, loss = nan\n",
            "Iteration 39, loss = nan\n",
            "Iteration 40, loss = nan\n",
            "Iteration 41, loss = nan\n",
            "Iteration 42, loss = nan\n",
            "Iteration 43, loss = nan\n",
            "Iteration 44, loss = nan\n",
            "Iteration 45, loss = nan\n",
            "Iteration 46, loss = nan\n",
            "Iteration 47, loss = nan\n",
            "Iteration 48, loss = nan\n",
            "Iteration 49, loss = nan\n",
            "Iteration 50, loss = nan\n",
            "Iteration 51, loss = nan\n",
            "Iteration 52, loss = nan\n",
            "Iteration 53, loss = nan\n",
            "Iteration 54, loss = nan\n",
            "Iteration 55, loss = nan\n",
            "Iteration 56, loss = nan\n",
            "Iteration 57, loss = nan\n",
            "Iteration 58, loss = nan\n",
            "Iteration 59, loss = nan\n",
            "Iteration 60, loss = nan\n",
            "Iteration 61, loss = nan\n",
            "Iteration 62, loss = nan\n",
            "Iteration 63, loss = nan\n",
            "Iteration 64, loss = nan\n",
            "Iteration 65, loss = nan\n",
            "Iteration 66, loss = nan\n",
            "Iteration 67, loss = nan\n",
            "Iteration 68, loss = nan\n",
            "Iteration 69, loss = nan\n",
            "Iteration 70, loss = nan\n",
            "Iteration 71, loss = nan\n",
            "Iteration 72, loss = nan\n",
            "Iteration 73, loss = nan\n",
            "Iteration 74, loss = nan\n",
            "Iteration 75, loss = nan\n",
            "Iteration 76, loss = nan\n",
            "Iteration 77, loss = nan\n",
            "Iteration 78, loss = nan\n",
            "Iteration 79, loss = nan\n",
            "Iteration 80, loss = nan\n",
            "Iteration 81, loss = nan\n",
            "Iteration 82, loss = nan\n",
            "Iteration 83, loss = nan\n",
            "Iteration 84, loss = nan\n",
            "Iteration 85, loss = nan\n",
            "Iteration 86, loss = nan\n",
            "Iteration 87, loss = nan\n",
            "Iteration 88, loss = nan\n",
            "Iteration 89, loss = nan\n",
            "Iteration 90, loss = nan\n",
            "Iteration 91, loss = nan\n",
            "Iteration 92, loss = nan\n",
            "Iteration 93, loss = nan\n",
            "Iteration 94, loss = nan\n",
            "Iteration 95, loss = nan\n",
            "Iteration 96, loss = nan\n",
            "Iteration 97, loss = nan\n",
            "Iteration 98, loss = nan\n",
            "Iteration 99, loss = nan\n",
            "Iteration 100, loss = nan\n",
            "Iteration 101, loss = nan\n",
            "Iteration 102, loss = nan\n",
            "Iteration 103, loss = nan\n",
            "Iteration 104, loss = nan\n",
            "Iteration 105, loss = nan\n",
            "Iteration 106, loss = nan\n",
            "Iteration 107, loss = nan\n",
            "Iteration 108, loss = nan\n",
            "Iteration 109, loss = nan\n",
            "Iteration 110, loss = nan\n",
            "Iteration 111, loss = nan\n",
            "Iteration 112, loss = nan\n",
            "Iteration 113, loss = nan\n",
            "Iteration 114, loss = nan\n",
            "Iteration 115, loss = nan\n",
            "Iteration 116, loss = nan\n",
            "Iteration 117, loss = nan\n",
            "Iteration 118, loss = nan\n",
            "Iteration 119, loss = nan\n",
            "Iteration 120, loss = nan\n",
            "Iteration 121, loss = nan\n",
            "Iteration 122, loss = nan\n",
            "Iteration 123, loss = nan\n",
            "Iteration 124, loss = nan\n",
            "Iteration 125, loss = nan\n",
            "Iteration 126, loss = nan\n",
            "Iteration 127, loss = nan\n",
            "Iteration 128, loss = nan\n",
            "Iteration 129, loss = nan\n",
            "Iteration 130, loss = nan\n",
            "Iteration 131, loss = nan\n",
            "Iteration 132, loss = nan\n",
            "Iteration 133, loss = nan\n",
            "Iteration 134, loss = nan\n",
            "Iteration 135, loss = nan\n",
            "Iteration 136, loss = nan\n",
            "Iteration 137, loss = nan\n",
            "Iteration 138, loss = nan\n",
            "Iteration 139, loss = nan\n",
            "Iteration 140, loss = nan\n",
            "Iteration 141, loss = nan\n",
            "Iteration 142, loss = nan\n",
            "Iteration 143, loss = nan\n",
            "Iteration 144, loss = nan\n",
            "Iteration 145, loss = nan\n",
            "Iteration 146, loss = nan\n",
            "Iteration 147, loss = nan\n",
            "Iteration 148, loss = nan\n",
            "Iteration 149, loss = nan\n",
            "Iteration 150, loss = nan\n",
            "Iteration 151, loss = nan\n",
            "Iteration 152, loss = nan\n",
            "Iteration 153, loss = nan\n",
            "Iteration 154, loss = nan\n",
            "Iteration 155, loss = nan\n",
            "Iteration 156, loss = nan\n",
            "Iteration 157, loss = nan\n",
            "Iteration 158, loss = nan\n",
            "Iteration 159, loss = nan\n",
            "Iteration 160, loss = nan\n",
            "Iteration 161, loss = nan\n",
            "Iteration 162, loss = nan\n",
            "Iteration 163, loss = nan\n",
            "Iteration 164, loss = nan\n",
            "Iteration 165, loss = nan\n",
            "Iteration 166, loss = nan\n",
            "Iteration 167, loss = nan\n",
            "Iteration 168, loss = nan\n",
            "Iteration 169, loss = nan\n",
            "Iteration 170, loss = nan\n",
            "Iteration 171, loss = nan\n",
            "Iteration 172, loss = nan\n",
            "Iteration 173, loss = nan\n",
            "Iteration 174, loss = nan\n",
            "Iteration 175, loss = nan\n",
            "Iteration 176, loss = nan\n",
            "Iteration 177, loss = nan\n",
            "Iteration 178, loss = nan\n",
            "Iteration 179, loss = nan\n",
            "Iteration 180, loss = nan\n",
            "Iteration 181, loss = nan\n",
            "Iteration 182, loss = nan\n",
            "Iteration 183, loss = nan\n",
            "Iteration 184, loss = nan\n",
            "Iteration 185, loss = nan\n",
            "Iteration 186, loss = nan\n",
            "Iteration 187, loss = nan\n",
            "Iteration 188, loss = nan\n",
            "Iteration 189, loss = nan\n",
            "Iteration 190, loss = nan\n",
            "Iteration 191, loss = nan\n",
            "Iteration 192, loss = nan\n",
            "Iteration 193, loss = nan\n",
            "Iteration 194, loss = nan\n",
            "Iteration 195, loss = nan\n",
            "Iteration 196, loss = nan\n",
            "Iteration 197, loss = nan\n",
            "Iteration 198, loss = nan\n",
            "Iteration 199, loss = nan\n",
            "Iteration 200, loss = nan\n",
            "Iteration 201, loss = nan\n",
            "Iteration 202, loss = nan\n",
            "Iteration 203, loss = nan\n",
            "Iteration 204, loss = nan\n",
            "Iteration 205, loss = nan\n",
            "Iteration 206, loss = nan\n",
            "Iteration 207, loss = nan\n",
            "Iteration 208, loss = nan\n",
            "Iteration 209, loss = nan\n",
            "Iteration 210, loss = nan\n",
            "Iteration 211, loss = nan\n",
            "Iteration 212, loss = nan\n",
            "Iteration 213, loss = nan\n",
            "Iteration 214, loss = nan\n",
            "Iteration 215, loss = nan\n",
            "Iteration 216, loss = nan\n",
            "Iteration 217, loss = nan\n",
            "Iteration 218, loss = nan\n",
            "Iteration 219, loss = nan\n",
            "Iteration 220, loss = nan\n",
            "Iteration 221, loss = nan\n",
            "Iteration 222, loss = nan\n",
            "Iteration 223, loss = nan\n",
            "Iteration 224, loss = nan\n",
            "Iteration 225, loss = nan\n",
            "Iteration 226, loss = nan\n",
            "Iteration 227, loss = nan\n",
            "Iteration 228, loss = nan\n",
            "Iteration 229, loss = nan\n",
            "Iteration 230, loss = nan\n",
            "Iteration 231, loss = nan\n",
            "Iteration 232, loss = nan\n",
            "Iteration 233, loss = nan\n",
            "Iteration 234, loss = nan\n",
            "Iteration 235, loss = nan\n",
            "Iteration 236, loss = nan\n",
            "Iteration 237, loss = nan\n",
            "Iteration 238, loss = nan\n",
            "Iteration 239, loss = nan\n",
            "Iteration 240, loss = nan\n",
            "Iteration 241, loss = nan\n",
            "Iteration 242, loss = nan\n",
            "Iteration 243, loss = nan\n",
            "Iteration 244, loss = nan\n",
            "Iteration 245, loss = nan\n",
            "Iteration 246, loss = nan\n",
            "Iteration 247, loss = nan\n",
            "Iteration 248, loss = nan\n",
            "Iteration 249, loss = nan\n",
            "Iteration 250, loss = nan\n",
            "Iteration 251, loss = nan\n",
            "Iteration 252, loss = nan\n",
            "Iteration 253, loss = nan\n",
            "Iteration 254, loss = nan\n",
            "Iteration 255, loss = nan\n",
            "Iteration 256, loss = nan\n",
            "Iteration 257, loss = nan\n",
            "Iteration 258, loss = nan\n",
            "Iteration 259, loss = nan\n",
            "Iteration 260, loss = nan\n",
            "Iteration 261, loss = nan\n",
            "Iteration 262, loss = nan\n",
            "Iteration 263, loss = nan\n",
            "Iteration 264, loss = nan\n",
            "Iteration 265, loss = nan\n",
            "Iteration 266, loss = nan\n",
            "Iteration 267, loss = nan\n",
            "Iteration 268, loss = nan\n",
            "Iteration 269, loss = nan\n",
            "Iteration 270, loss = nan\n",
            "Iteration 271, loss = nan\n",
            "Iteration 272, loss = nan\n",
            "Iteration 273, loss = nan\n",
            "Iteration 274, loss = nan\n",
            "Iteration 275, loss = nan\n",
            "Iteration 276, loss = nan\n",
            "Iteration 277, loss = nan\n",
            "Iteration 278, loss = nan\n",
            "Iteration 279, loss = nan\n",
            "Iteration 280, loss = nan\n",
            "Iteration 281, loss = nan\n",
            "Iteration 282, loss = nan\n",
            "Iteration 283, loss = nan\n",
            "Iteration 284, loss = nan\n",
            "Iteration 285, loss = nan\n",
            "Iteration 286, loss = nan\n",
            "Iteration 287, loss = nan\n",
            "Iteration 288, loss = nan\n",
            "Iteration 289, loss = nan\n",
            "Iteration 290, loss = nan\n",
            "Iteration 291, loss = nan\n",
            "Iteration 292, loss = nan\n",
            "Iteration 293, loss = nan\n",
            "Iteration 294, loss = nan\n",
            "Iteration 295, loss = nan\n",
            "Iteration 296, loss = nan\n",
            "Iteration 297, loss = nan\n",
            "Iteration 298, loss = nan\n",
            "Iteration 299, loss = nan\n",
            "Iteration 300, loss = nan\n",
            "Iteration 301, loss = nan\n",
            "Iteration 302, loss = nan\n",
            "Iteration 303, loss = nan\n",
            "Iteration 304, loss = nan\n",
            "Iteration 305, loss = nan\n",
            "Iteration 306, loss = nan\n",
            "Iteration 307, loss = nan\n",
            "Iteration 308, loss = nan\n",
            "Iteration 309, loss = nan\n",
            "Iteration 310, loss = nan\n",
            "Iteration 311, loss = nan\n",
            "Iteration 312, loss = nan\n",
            "Iteration 313, loss = nan\n",
            "Iteration 314, loss = nan\n",
            "Iteration 315, loss = nan\n",
            "Iteration 316, loss = nan\n",
            "Iteration 317, loss = nan\n",
            "Iteration 318, loss = nan\n",
            "Iteration 319, loss = nan\n",
            "Iteration 320, loss = nan\n",
            "Iteration 321, loss = nan\n",
            "Iteration 322, loss = nan\n",
            "Iteration 323, loss = nan\n",
            "Iteration 324, loss = nan\n",
            "Iteration 325, loss = nan\n",
            "Iteration 326, loss = nan\n",
            "Iteration 327, loss = nan\n",
            "Iteration 328, loss = nan\n",
            "Iteration 329, loss = nan\n",
            "Iteration 330, loss = nan\n",
            "Iteration 331, loss = nan\n",
            "Iteration 332, loss = nan\n",
            "Iteration 333, loss = nan\n",
            "Iteration 334, loss = nan\n",
            "Iteration 335, loss = nan\n",
            "Iteration 336, loss = nan\n",
            "Iteration 337, loss = nan\n",
            "Iteration 338, loss = nan\n",
            "Iteration 339, loss = nan\n",
            "Iteration 340, loss = nan\n",
            "Iteration 341, loss = nan\n",
            "Iteration 342, loss = nan\n",
            "Iteration 343, loss = nan\n",
            "Iteration 344, loss = nan\n",
            "Iteration 345, loss = nan\n",
            "Iteration 346, loss = nan\n",
            "Iteration 347, loss = nan\n",
            "Iteration 348, loss = nan\n",
            "Iteration 349, loss = nan\n",
            "Iteration 350, loss = nan\n",
            "Iteration 351, loss = nan\n",
            "Iteration 352, loss = nan\n",
            "Iteration 353, loss = nan\n",
            "Iteration 354, loss = nan\n",
            "Iteration 355, loss = nan\n",
            "Iteration 356, loss = nan\n",
            "Iteration 357, loss = nan\n",
            "Iteration 358, loss = nan\n",
            "Iteration 359, loss = nan\n",
            "Iteration 360, loss = nan\n",
            "Iteration 361, loss = nan\n",
            "Iteration 362, loss = nan\n",
            "Iteration 363, loss = nan\n",
            "Iteration 364, loss = nan\n",
            "Iteration 365, loss = nan\n",
            "Iteration 366, loss = nan\n",
            "Iteration 367, loss = nan\n",
            "Iteration 368, loss = nan\n",
            "Iteration 369, loss = nan\n",
            "Iteration 370, loss = nan\n",
            "Iteration 371, loss = nan\n",
            "Iteration 372, loss = nan\n",
            "Iteration 373, loss = nan\n",
            "Iteration 374, loss = nan\n",
            "Iteration 375, loss = nan\n",
            "Iteration 376, loss = nan\n",
            "Iteration 377, loss = nan\n",
            "Iteration 378, loss = nan\n",
            "Iteration 379, loss = nan\n",
            "Iteration 380, loss = nan\n",
            "Iteration 381, loss = nan\n",
            "Iteration 382, loss = nan\n",
            "Iteration 383, loss = nan\n",
            "Iteration 384, loss = nan\n",
            "Iteration 385, loss = nan\n",
            "Iteration 386, loss = nan\n",
            "Iteration 387, loss = nan\n",
            "Iteration 388, loss = nan\n",
            "Iteration 389, loss = nan\n",
            "Iteration 390, loss = nan\n",
            "Iteration 391, loss = nan\n",
            "Iteration 392, loss = nan\n",
            "Iteration 393, loss = nan\n",
            "Iteration 394, loss = nan\n",
            "Iteration 395, loss = nan\n",
            "Iteration 396, loss = nan\n",
            "Iteration 397, loss = nan\n",
            "Iteration 398, loss = nan\n",
            "Iteration 399, loss = nan\n",
            "Iteration 400, loss = nan\n",
            "Iteration 401, loss = nan\n",
            "Iteration 402, loss = nan\n",
            "Iteration 403, loss = nan\n",
            "Iteration 404, loss = nan\n",
            "Iteration 405, loss = nan\n",
            "Iteration 406, loss = nan\n",
            "Iteration 407, loss = nan\n",
            "Iteration 408, loss = nan\n",
            "Iteration 409, loss = nan\n",
            "Iteration 410, loss = nan\n",
            "Iteration 411, loss = nan\n",
            "Iteration 412, loss = nan\n",
            "Iteration 413, loss = nan\n",
            "Iteration 414, loss = nan\n",
            "Iteration 415, loss = nan\n",
            "Iteration 416, loss = nan\n",
            "Iteration 417, loss = nan\n",
            "Iteration 418, loss = nan\n",
            "Iteration 419, loss = nan\n",
            "Iteration 420, loss = nan\n",
            "Iteration 421, loss = nan\n",
            "Iteration 422, loss = nan\n",
            "Iteration 423, loss = nan\n",
            "Iteration 424, loss = nan\n",
            "Iteration 425, loss = nan\n",
            "Iteration 426, loss = nan\n",
            "Iteration 427, loss = nan\n",
            "Iteration 428, loss = nan\n",
            "Iteration 429, loss = nan\n",
            "Iteration 430, loss = nan\n",
            "Iteration 431, loss = nan\n",
            "Iteration 432, loss = nan\n",
            "Iteration 433, loss = nan\n",
            "Iteration 434, loss = nan\n",
            "Iteration 435, loss = nan\n",
            "Iteration 436, loss = nan\n",
            "Iteration 437, loss = nan\n",
            "Iteration 438, loss = nan\n",
            "Iteration 439, loss = nan\n",
            "Iteration 440, loss = nan\n",
            "Iteration 441, loss = nan\n",
            "Iteration 442, loss = nan\n",
            "Iteration 443, loss = nan\n",
            "Iteration 444, loss = nan\n",
            "Iteration 445, loss = nan\n",
            "Iteration 446, loss = nan\n",
            "Iteration 447, loss = nan\n",
            "Iteration 448, loss = nan\n",
            "Iteration 449, loss = nan\n",
            "Iteration 450, loss = nan\n",
            "Iteration 451, loss = nan\n",
            "Iteration 452, loss = nan\n",
            "Iteration 453, loss = nan\n",
            "Iteration 454, loss = nan\n",
            "Iteration 455, loss = nan\n",
            "Iteration 456, loss = nan\n",
            "Iteration 457, loss = nan\n",
            "Iteration 458, loss = nan\n",
            "Iteration 459, loss = nan\n",
            "Iteration 460, loss = nan\n",
            "Iteration 461, loss = nan\n",
            "Iteration 462, loss = nan\n",
            "Iteration 463, loss = nan\n",
            "Iteration 464, loss = nan\n",
            "Iteration 465, loss = nan\n",
            "Iteration 466, loss = nan\n",
            "Iteration 467, loss = nan\n",
            "Iteration 468, loss = nan\n",
            "Iteration 469, loss = nan\n",
            "Iteration 470, loss = nan\n",
            "Iteration 471, loss = nan\n",
            "Iteration 472, loss = nan\n",
            "Iteration 473, loss = nan\n",
            "Iteration 474, loss = nan\n",
            "Iteration 475, loss = nan\n",
            "Iteration 476, loss = nan\n",
            "Iteration 477, loss = nan\n",
            "Iteration 478, loss = nan\n",
            "Iteration 479, loss = nan\n",
            "Iteration 480, loss = nan\n",
            "Iteration 481, loss = nan\n",
            "Iteration 482, loss = nan\n",
            "Iteration 483, loss = nan\n",
            "Iteration 484, loss = nan\n",
            "Iteration 485, loss = nan\n",
            "Iteration 486, loss = nan\n",
            "Iteration 487, loss = nan\n",
            "Iteration 488, loss = nan\n",
            "Iteration 489, loss = nan\n",
            "Iteration 490, loss = nan\n",
            "Iteration 491, loss = nan\n",
            "Iteration 492, loss = nan\n",
            "Iteration 493, loss = nan\n",
            "Iteration 494, loss = nan\n",
            "Iteration 495, loss = nan\n",
            "Iteration 496, loss = nan\n",
            "Iteration 497, loss = nan\n",
            "Iteration 498, loss = nan\n",
            "Iteration 499, loss = nan\n",
            "Iteration 500, loss = nan\n",
            "Iteration 501, loss = nan\n",
            "Iteration 502, loss = nan\n",
            "Iteration 503, loss = nan\n",
            "Iteration 504, loss = nan\n",
            "Iteration 505, loss = nan\n",
            "Iteration 506, loss = nan\n",
            "Iteration 507, loss = nan\n",
            "Iteration 508, loss = nan\n",
            "Iteration 509, loss = nan\n",
            "Iteration 510, loss = nan\n",
            "Iteration 511, loss = nan\n",
            "Iteration 512, loss = nan\n",
            "Iteration 513, loss = nan\n",
            "Iteration 514, loss = nan\n",
            "Iteration 515, loss = nan\n",
            "Iteration 516, loss = nan\n",
            "Iteration 517, loss = nan\n",
            "Iteration 518, loss = nan\n",
            "Iteration 519, loss = nan\n",
            "Iteration 520, loss = nan\n",
            "Iteration 521, loss = nan\n",
            "Iteration 522, loss = nan\n",
            "Iteration 523, loss = nan\n",
            "Iteration 524, loss = nan\n",
            "Iteration 525, loss = nan\n",
            "Iteration 526, loss = nan\n",
            "Iteration 527, loss = nan\n",
            "Iteration 528, loss = nan\n",
            "Iteration 529, loss = nan\n",
            "Iteration 530, loss = nan\n",
            "Iteration 531, loss = nan\n",
            "Iteration 532, loss = nan\n",
            "Iteration 533, loss = nan\n",
            "Iteration 534, loss = nan\n",
            "Iteration 535, loss = nan\n",
            "Iteration 536, loss = nan\n",
            "Iteration 537, loss = nan\n",
            "Iteration 538, loss = nan\n",
            "Iteration 539, loss = nan\n",
            "Iteration 540, loss = nan\n",
            "Iteration 541, loss = nan\n",
            "Iteration 542, loss = nan\n",
            "Iteration 543, loss = nan\n",
            "Iteration 544, loss = nan\n",
            "Iteration 545, loss = nan\n",
            "Iteration 546, loss = nan\n",
            "Iteration 547, loss = nan\n",
            "Iteration 548, loss = nan\n",
            "Iteration 549, loss = nan\n",
            "Iteration 550, loss = nan\n",
            "Iteration 551, loss = nan\n",
            "Iteration 552, loss = nan\n",
            "Iteration 553, loss = nan\n",
            "Iteration 554, loss = nan\n",
            "Iteration 555, loss = nan\n",
            "Iteration 556, loss = nan\n",
            "Iteration 557, loss = nan\n",
            "Iteration 558, loss = nan\n",
            "Iteration 559, loss = nan\n",
            "Iteration 560, loss = nan\n",
            "Iteration 561, loss = nan\n",
            "Iteration 562, loss = nan\n",
            "Iteration 563, loss = nan\n",
            "Iteration 564, loss = nan\n",
            "Iteration 565, loss = nan\n",
            "Iteration 566, loss = nan\n",
            "Iteration 567, loss = nan\n",
            "Iteration 568, loss = nan\n",
            "Iteration 569, loss = nan\n",
            "Iteration 570, loss = nan\n",
            "Iteration 571, loss = nan\n",
            "Iteration 572, loss = nan\n",
            "Iteration 573, loss = nan\n",
            "Iteration 574, loss = nan\n",
            "Iteration 575, loss = nan\n",
            "Iteration 576, loss = nan\n",
            "Iteration 577, loss = nan\n",
            "Iteration 578, loss = nan\n",
            "Iteration 579, loss = nan\n",
            "Iteration 580, loss = nan\n",
            "Iteration 581, loss = nan\n",
            "Iteration 582, loss = nan\n",
            "Iteration 583, loss = nan\n",
            "Iteration 584, loss = nan\n",
            "Iteration 585, loss = nan\n",
            "Iteration 586, loss = nan\n",
            "Iteration 587, loss = nan\n",
            "Iteration 588, loss = nan\n",
            "Iteration 589, loss = nan\n",
            "Iteration 590, loss = nan\n",
            "Iteration 591, loss = nan\n",
            "Iteration 592, loss = nan\n",
            "Iteration 593, loss = nan\n",
            "Iteration 594, loss = nan\n",
            "Iteration 595, loss = nan\n",
            "Iteration 596, loss = nan\n",
            "Iteration 597, loss = nan\n",
            "Iteration 598, loss = nan\n",
            "Iteration 599, loss = nan\n",
            "Iteration 600, loss = nan\n",
            "Iteration 601, loss = nan\n",
            "Iteration 602, loss = nan\n",
            "Iteration 603, loss = nan\n",
            "Iteration 604, loss = nan\n",
            "Iteration 605, loss = nan\n",
            "Iteration 606, loss = nan\n",
            "Iteration 607, loss = nan\n",
            "Iteration 608, loss = nan\n",
            "Iteration 609, loss = nan\n",
            "Iteration 610, loss = nan\n",
            "Iteration 611, loss = nan\n",
            "Iteration 612, loss = nan\n",
            "Iteration 613, loss = nan\n",
            "Iteration 614, loss = nan\n",
            "Iteration 615, loss = nan\n",
            "Iteration 616, loss = nan\n",
            "Iteration 617, loss = nan\n",
            "Iteration 618, loss = nan\n",
            "Iteration 619, loss = nan\n",
            "Iteration 620, loss = nan\n",
            "Iteration 621, loss = nan\n",
            "Iteration 622, loss = nan\n",
            "Iteration 623, loss = nan\n",
            "Iteration 624, loss = nan\n",
            "Iteration 625, loss = nan\n",
            "Iteration 626, loss = nan\n",
            "Iteration 627, loss = nan\n",
            "Iteration 628, loss = nan\n",
            "Iteration 629, loss = nan\n",
            "Iteration 630, loss = nan\n",
            "Iteration 631, loss = nan\n",
            "Iteration 632, loss = nan\n",
            "Iteration 633, loss = nan\n",
            "Iteration 634, loss = nan\n",
            "Iteration 635, loss = nan\n",
            "Iteration 636, loss = nan\n",
            "Iteration 637, loss = nan\n",
            "Iteration 638, loss = nan\n",
            "Iteration 639, loss = nan\n",
            "Iteration 640, loss = nan\n",
            "Iteration 641, loss = nan\n",
            "Iteration 642, loss = nan\n",
            "Iteration 643, loss = nan\n",
            "Iteration 644, loss = nan\n",
            "Iteration 645, loss = nan\n",
            "Iteration 646, loss = nan\n",
            "Iteration 647, loss = nan\n",
            "Iteration 648, loss = nan\n",
            "Iteration 649, loss = nan\n",
            "Iteration 650, loss = nan\n",
            "Iteration 651, loss = nan\n",
            "Iteration 652, loss = nan\n",
            "Iteration 653, loss = nan\n",
            "Iteration 654, loss = nan\n",
            "Iteration 655, loss = nan\n",
            "Iteration 656, loss = nan\n",
            "Iteration 657, loss = nan\n",
            "Iteration 658, loss = nan\n",
            "Iteration 659, loss = nan\n",
            "Iteration 660, loss = nan\n",
            "Iteration 661, loss = nan\n",
            "Iteration 662, loss = nan\n",
            "Iteration 663, loss = nan\n",
            "Iteration 664, loss = nan\n",
            "Iteration 665, loss = nan\n",
            "Iteration 666, loss = nan\n",
            "Iteration 667, loss = nan\n",
            "Iteration 668, loss = nan\n",
            "Iteration 669, loss = nan\n",
            "Iteration 670, loss = nan\n",
            "Iteration 671, loss = nan\n",
            "Iteration 672, loss = nan\n",
            "Iteration 673, loss = nan\n",
            "Iteration 674, loss = nan\n",
            "Iteration 675, loss = nan\n",
            "Iteration 676, loss = nan\n",
            "Iteration 677, loss = nan\n",
            "Iteration 678, loss = nan\n",
            "Iteration 679, loss = nan\n",
            "Iteration 680, loss = nan\n",
            "Iteration 681, loss = nan\n",
            "Iteration 682, loss = nan\n",
            "Iteration 683, loss = nan\n",
            "Iteration 684, loss = nan\n",
            "Iteration 685, loss = nan\n",
            "Iteration 686, loss = nan\n",
            "Iteration 687, loss = nan\n",
            "Iteration 688, loss = nan\n",
            "Iteration 689, loss = nan\n",
            "Iteration 690, loss = nan\n",
            "Iteration 691, loss = nan\n",
            "Iteration 692, loss = nan\n",
            "Iteration 693, loss = nan\n",
            "Iteration 694, loss = nan\n",
            "Iteration 695, loss = nan\n",
            "Iteration 696, loss = nan\n",
            "Iteration 697, loss = nan\n",
            "Iteration 698, loss = nan\n",
            "Iteration 699, loss = nan\n",
            "Iteration 700, loss = nan\n",
            "Iteration 701, loss = nan\n",
            "Iteration 702, loss = nan\n",
            "Iteration 703, loss = nan\n",
            "Iteration 704, loss = nan\n",
            "Iteration 705, loss = nan\n",
            "Iteration 706, loss = nan\n",
            "Iteration 707, loss = nan\n",
            "Iteration 708, loss = nan\n",
            "Iteration 709, loss = nan\n",
            "Iteration 710, loss = nan\n",
            "Iteration 711, loss = nan\n",
            "Iteration 712, loss = nan\n",
            "Iteration 713, loss = nan\n",
            "Iteration 714, loss = nan\n",
            "Iteration 715, loss = nan\n",
            "Iteration 716, loss = nan\n",
            "Iteration 717, loss = nan\n",
            "Iteration 718, loss = nan\n",
            "Iteration 719, loss = nan\n",
            "Iteration 720, loss = nan\n",
            "Iteration 721, loss = nan\n",
            "Iteration 722, loss = nan\n",
            "Iteration 723, loss = nan\n",
            "Iteration 724, loss = nan\n",
            "Iteration 725, loss = nan\n",
            "Iteration 726, loss = nan\n",
            "Iteration 727, loss = nan\n",
            "Iteration 728, loss = nan\n",
            "Iteration 729, loss = nan\n",
            "Iteration 730, loss = nan\n",
            "Iteration 731, loss = nan\n",
            "Iteration 732, loss = nan\n",
            "Iteration 733, loss = nan\n",
            "Iteration 734, loss = nan\n",
            "Iteration 735, loss = nan\n",
            "Iteration 736, loss = nan\n",
            "Iteration 737, loss = nan\n",
            "Iteration 738, loss = nan\n",
            "Iteration 739, loss = nan\n",
            "Iteration 740, loss = nan\n",
            "Iteration 741, loss = nan\n",
            "Iteration 742, loss = nan\n",
            "Iteration 743, loss = nan\n",
            "Iteration 744, loss = nan\n",
            "Iteration 745, loss = nan\n",
            "Iteration 746, loss = nan\n",
            "Iteration 747, loss = nan\n",
            "Iteration 748, loss = nan\n",
            "Iteration 749, loss = nan\n",
            "Iteration 750, loss = nan\n",
            "Iteration 751, loss = nan\n",
            "Iteration 752, loss = nan\n",
            "Iteration 753, loss = nan\n",
            "Iteration 754, loss = nan\n",
            "Iteration 755, loss = nan\n",
            "Iteration 756, loss = nan\n",
            "Iteration 757, loss = nan\n",
            "Iteration 758, loss = nan\n",
            "Iteration 759, loss = nan\n",
            "Iteration 760, loss = nan\n",
            "Iteration 761, loss = nan\n",
            "Iteration 762, loss = nan\n",
            "Iteration 763, loss = nan\n",
            "Iteration 764, loss = nan\n",
            "Iteration 765, loss = nan\n",
            "Iteration 766, loss = nan\n",
            "Iteration 767, loss = nan\n",
            "Iteration 768, loss = nan\n",
            "Iteration 769, loss = nan\n",
            "Iteration 770, loss = nan\n",
            "Iteration 771, loss = nan\n",
            "Iteration 772, loss = nan\n",
            "Iteration 773, loss = nan\n",
            "Iteration 774, loss = nan\n",
            "Iteration 775, loss = nan\n",
            "Iteration 776, loss = nan\n",
            "Iteration 777, loss = nan\n",
            "Iteration 778, loss = nan\n",
            "Iteration 779, loss = nan\n",
            "Iteration 780, loss = nan\n",
            "Iteration 781, loss = nan\n",
            "Iteration 782, loss = nan\n",
            "Iteration 783, loss = nan\n",
            "Iteration 784, loss = nan\n",
            "Iteration 785, loss = nan\n",
            "Iteration 786, loss = nan\n",
            "Iteration 787, loss = nan\n",
            "Iteration 788, loss = nan\n",
            "Iteration 789, loss = nan\n",
            "Iteration 790, loss = nan\n",
            "Iteration 791, loss = nan\n",
            "Iteration 792, loss = nan\n",
            "Iteration 793, loss = nan\n",
            "Iteration 794, loss = nan\n",
            "Iteration 795, loss = nan\n",
            "Iteration 796, loss = nan\n",
            "Iteration 797, loss = nan\n",
            "Iteration 798, loss = nan\n",
            "Iteration 799, loss = nan\n",
            "Iteration 800, loss = nan\n",
            "Iteration 801, loss = nan\n",
            "Iteration 802, loss = nan\n",
            "Iteration 803, loss = nan\n",
            "Iteration 804, loss = nan\n",
            "Iteration 805, loss = nan\n",
            "Iteration 806, loss = nan\n",
            "Iteration 807, loss = nan\n",
            "Iteration 808, loss = nan\n",
            "Iteration 809, loss = nan\n",
            "Iteration 810, loss = nan\n",
            "Iteration 811, loss = nan\n",
            "Iteration 812, loss = nan\n",
            "Iteration 813, loss = nan\n",
            "Iteration 814, loss = nan\n",
            "Iteration 815, loss = nan\n",
            "Iteration 816, loss = nan\n",
            "Iteration 817, loss = nan\n",
            "Iteration 818, loss = nan\n",
            "Iteration 819, loss = nan\n",
            "Iteration 820, loss = nan\n",
            "Iteration 821, loss = nan\n",
            "Iteration 822, loss = nan\n",
            "Iteration 823, loss = nan\n",
            "Iteration 824, loss = nan\n",
            "Iteration 825, loss = nan\n",
            "Iteration 826, loss = nan\n",
            "Iteration 827, loss = nan\n",
            "Iteration 828, loss = nan\n",
            "Iteration 829, loss = nan\n",
            "Iteration 830, loss = nan\n",
            "Iteration 831, loss = nan\n",
            "Iteration 832, loss = nan\n",
            "Iteration 833, loss = nan\n",
            "Iteration 834, loss = nan\n",
            "Iteration 835, loss = nan\n",
            "Iteration 836, loss = nan\n",
            "Iteration 837, loss = nan\n",
            "Iteration 838, loss = nan\n",
            "Iteration 839, loss = nan\n",
            "Iteration 840, loss = nan\n",
            "Iteration 841, loss = nan\n",
            "Iteration 842, loss = nan\n",
            "Iteration 843, loss = nan\n",
            "Iteration 844, loss = nan\n",
            "Iteration 845, loss = nan\n",
            "Iteration 846, loss = nan\n",
            "Iteration 847, loss = nan\n",
            "Iteration 848, loss = nan\n",
            "Iteration 849, loss = nan\n",
            "Iteration 850, loss = nan\n",
            "Iteration 851, loss = nan\n",
            "Iteration 852, loss = nan\n",
            "Iteration 853, loss = nan\n",
            "Iteration 854, loss = nan\n",
            "Iteration 855, loss = nan\n",
            "Iteration 856, loss = nan\n",
            "Iteration 857, loss = nan\n",
            "Iteration 858, loss = nan\n",
            "Iteration 859, loss = nan\n",
            "Iteration 860, loss = nan\n",
            "Iteration 861, loss = nan\n",
            "Iteration 862, loss = nan\n",
            "Iteration 863, loss = nan\n",
            "Iteration 864, loss = nan\n",
            "Iteration 865, loss = nan\n",
            "Iteration 866, loss = nan\n",
            "Iteration 867, loss = nan\n",
            "Iteration 868, loss = nan\n",
            "Iteration 869, loss = nan\n",
            "Iteration 870, loss = nan\n",
            "Iteration 871, loss = nan\n",
            "Iteration 872, loss = nan\n",
            "Iteration 873, loss = nan\n",
            "Iteration 874, loss = nan\n",
            "Iteration 875, loss = nan\n",
            "Iteration 876, loss = nan\n",
            "Iteration 877, loss = nan\n",
            "Iteration 878, loss = nan\n",
            "Iteration 879, loss = nan\n",
            "Iteration 880, loss = nan\n",
            "Iteration 881, loss = nan\n",
            "Iteration 882, loss = nan\n",
            "Iteration 883, loss = nan\n",
            "Iteration 884, loss = nan\n",
            "Iteration 885, loss = nan\n",
            "Iteration 886, loss = nan\n",
            "Iteration 887, loss = nan\n",
            "Iteration 888, loss = nan\n",
            "Iteration 889, loss = nan\n",
            "Iteration 890, loss = nan\n",
            "Iteration 891, loss = nan\n",
            "Iteration 892, loss = nan\n",
            "Iteration 893, loss = nan\n",
            "Iteration 894, loss = nan\n",
            "Iteration 895, loss = nan\n",
            "Iteration 896, loss = nan\n",
            "Iteration 897, loss = nan\n",
            "Iteration 898, loss = nan\n",
            "Iteration 899, loss = nan\n",
            "Iteration 900, loss = nan\n",
            "Iteration 901, loss = nan\n",
            "Iteration 902, loss = nan\n",
            "Iteration 903, loss = nan\n",
            "Iteration 904, loss = nan\n",
            "Iteration 905, loss = nan\n",
            "Iteration 906, loss = nan\n",
            "Iteration 907, loss = nan\n",
            "Iteration 908, loss = nan\n",
            "Iteration 909, loss = nan\n",
            "Iteration 910, loss = nan\n",
            "Iteration 911, loss = nan\n",
            "Iteration 912, loss = nan\n",
            "Iteration 913, loss = nan\n",
            "Iteration 914, loss = nan\n",
            "Iteration 915, loss = nan\n",
            "Iteration 916, loss = nan\n",
            "Iteration 917, loss = nan\n",
            "Iteration 918, loss = nan\n",
            "Iteration 919, loss = nan\n",
            "Iteration 920, loss = nan\n",
            "Iteration 921, loss = nan\n",
            "Iteration 922, loss = nan\n",
            "Iteration 923, loss = nan\n",
            "Iteration 924, loss = nan\n",
            "Iteration 925, loss = nan\n",
            "Iteration 926, loss = nan\n",
            "Iteration 927, loss = nan\n",
            "Iteration 928, loss = nan\n",
            "Iteration 929, loss = nan\n",
            "Iteration 930, loss = nan\n",
            "Iteration 931, loss = nan\n",
            "Iteration 932, loss = nan\n",
            "Iteration 933, loss = nan\n",
            "Iteration 934, loss = nan\n",
            "Iteration 935, loss = nan\n",
            "Iteration 936, loss = nan\n",
            "Iteration 937, loss = nan\n",
            "Iteration 938, loss = nan\n",
            "Iteration 939, loss = nan\n",
            "Iteration 940, loss = nan\n",
            "Iteration 941, loss = nan\n",
            "Iteration 942, loss = nan\n",
            "Iteration 943, loss = nan\n",
            "Iteration 944, loss = nan\n",
            "Iteration 945, loss = nan\n",
            "Iteration 946, loss = nan\n",
            "Iteration 947, loss = nan\n",
            "Iteration 948, loss = nan\n",
            "Iteration 949, loss = nan\n",
            "Iteration 950, loss = nan\n",
            "Iteration 951, loss = nan\n",
            "Iteration 952, loss = nan\n",
            "Iteration 953, loss = nan\n",
            "Iteration 954, loss = nan\n",
            "Iteration 955, loss = nan\n",
            "Iteration 956, loss = nan\n",
            "Iteration 957, loss = nan\n",
            "Iteration 958, loss = nan\n",
            "Iteration 959, loss = nan\n",
            "Iteration 960, loss = nan\n",
            "Iteration 961, loss = nan\n",
            "Iteration 962, loss = nan\n",
            "Iteration 963, loss = nan\n",
            "Iteration 964, loss = nan\n",
            "Iteration 965, loss = nan\n",
            "Iteration 966, loss = nan\n",
            "Iteration 967, loss = nan\n",
            "Iteration 968, loss = nan\n",
            "Iteration 969, loss = nan\n",
            "Iteration 970, loss = nan\n",
            "Iteration 971, loss = nan\n",
            "Iteration 972, loss = nan\n",
            "Iteration 973, loss = nan\n",
            "Iteration 974, loss = nan\n",
            "Iteration 975, loss = nan\n",
            "Iteration 976, loss = nan\n",
            "Iteration 977, loss = nan\n",
            "Iteration 978, loss = nan\n",
            "Iteration 979, loss = nan\n",
            "Iteration 980, loss = nan\n",
            "Iteration 981, loss = nan\n",
            "Iteration 982, loss = nan\n",
            "Iteration 983, loss = nan\n",
            "Iteration 984, loss = nan\n",
            "Iteration 985, loss = nan\n",
            "Iteration 986, loss = nan\n",
            "Iteration 987, loss = nan\n",
            "Iteration 988, loss = nan\n",
            "Iteration 989, loss = nan\n",
            "Iteration 990, loss = nan\n",
            "Iteration 991, loss = nan\n",
            "Iteration 992, loss = nan\n",
            "Iteration 993, loss = nan\n",
            "Iteration 994, loss = nan\n",
            "Iteration 995, loss = nan\n",
            "Iteration 996, loss = nan\n",
            "Iteration 997, loss = nan\n",
            "Iteration 998, loss = nan\n",
            "Iteration 999, loss = nan\n",
            "Iteration 1000, loss = nan\n",
            "Error with parameters (50, 50, 50), relu, 0.01, sgd: Solver produced non-finite parameter weights. The input data may contain large values and need to be preprocessed.\n",
            "Iteration 1, loss = 1538828978.74155426\n",
            "Iteration 2, loss = 1538766715.83995485\n",
            "Iteration 3, loss = 1538686876.03758311\n",
            "Iteration 4, loss = 1538548624.45551872\n",
            "Iteration 5, loss = 1538313768.62473416\n",
            "Iteration 6, loss = 1537926347.70223856\n",
            "Iteration 7, loss = 1537349483.29906702\n",
            "Iteration 8, loss = 1536469724.69855595\n",
            "Iteration 9, loss = 1535180144.46495628\n",
            "Iteration 10, loss = 1533378376.77460074\n",
            "Iteration 11, loss = 1530845048.83823657\n",
            "Iteration 12, loss = 1527344331.69712806\n",
            "Iteration 13, loss = 1522703779.01827836\n",
            "Iteration 14, loss = 1516485639.77247787\n",
            "Iteration 15, loss = 1508335982.60871506\n",
            "Iteration 16, loss = 1498011089.13108993\n",
            "Iteration 17, loss = 1484698734.26094270\n",
            "Iteration 18, loss = 1468128236.33107424\n",
            "Iteration 19, loss = 1447270702.54679346\n",
            "Iteration 20, loss = 1421752621.54763627\n",
            "Iteration 21, loss = 1390833145.41652369\n",
            "Iteration 22, loss = 1353428411.27704811\n",
            "Iteration 23, loss = 1308542051.69790792\n",
            "Iteration 24, loss = 1255850707.00589013\n",
            "Iteration 25, loss = 1195537628.36292720\n",
            "Iteration 26, loss = 1125606498.41228175\n",
            "Iteration 27, loss = 1046063324.25882173\n",
            "Iteration 28, loss = 958901004.34422362\n",
            "Iteration 29, loss = 863481853.95945513\n",
            "Iteration 30, loss = 762410446.15400732\n",
            "Iteration 31, loss = 659531198.91556907\n",
            "Iteration 32, loss = 558413864.43831635\n",
            "Iteration 33, loss = 462830555.97535866\n",
            "Iteration 34, loss = 378730592.65339947\n",
            "Iteration 35, loss = 306734720.26895618\n",
            "Iteration 36, loss = 244567320.41254449\n",
            "Iteration 37, loss = 198029693.84747532\n",
            "Iteration 38, loss = 165061226.28602305\n",
            "Iteration 39, loss = 143733419.82772857\n",
            "Iteration 40, loss = 134738209.30347273\n",
            "Iteration 41, loss = 131714507.14432262\n",
            "Iteration 42, loss = 128452586.62904149\n",
            "Iteration 43, loss = 123738028.62644371\n",
            "Iteration 44, loss = 118771968.80173339\n",
            "Iteration 45, loss = 113443060.46090645\n",
            "Iteration 46, loss = 106921765.50673051\n",
            "Iteration 47, loss = 102722821.22774349\n",
            "Iteration 48, loss = 100157004.57754911\n",
            "Iteration 49, loss = 98108320.67875651\n",
            "Iteration 50, loss = 96345276.83905821\n",
            "Iteration 51, loss = 94172860.41989362\n",
            "Iteration 52, loss = 91209871.09240617\n",
            "Iteration 53, loss = 87528304.57241993\n",
            "Iteration 54, loss = 83368993.95296933\n",
            "Iteration 55, loss = 79257678.41707943\n",
            "Iteration 56, loss = 75734497.92069110\n",
            "Iteration 57, loss = 72893252.00181048\n",
            "Iteration 58, loss = 70367356.60289241\n",
            "Iteration 59, loss = 68407198.11341658\n",
            "Iteration 60, loss = 66831609.87205548\n",
            "Iteration 61, loss = 65073870.36250562\n",
            "Iteration 62, loss = 63225482.19582383\n",
            "Iteration 63, loss = 61251389.41105418\n",
            "Iteration 64, loss = 59462298.11973090\n",
            "Iteration 65, loss = 57697459.82506907\n",
            "Iteration 66, loss = 56169244.28082845\n",
            "Iteration 67, loss = 54693086.72795231\n",
            "Iteration 68, loss = 53402683.23506295\n",
            "Iteration 69, loss = 52183846.52932614\n",
            "Iteration 70, loss = 50999690.99051900\n",
            "Iteration 71, loss = 49886978.32538721\n",
            "Iteration 72, loss = 48824266.08803285\n",
            "Iteration 73, loss = 47836483.54363175\n",
            "Iteration 74, loss = 46935983.82778692\n",
            "Iteration 75, loss = 46032012.37111893\n",
            "Iteration 76, loss = 45150010.80354560\n",
            "Iteration 77, loss = 44333624.21322191\n",
            "Iteration 78, loss = 43501941.50394208\n",
            "Iteration 79, loss = 42710632.22871719\n",
            "Iteration 80, loss = 41975125.74109773\n",
            "Iteration 81, loss = 41205958.86181518\n",
            "Iteration 82, loss = 40505802.62461124\n",
            "Iteration 83, loss = 39798870.61856126\n",
            "Iteration 84, loss = 39094118.58961213\n",
            "Iteration 85, loss = 38415325.24588735\n",
            "Iteration 86, loss = 37766575.70209651\n",
            "Iteration 87, loss = 37170032.32599751\n",
            "Iteration 88, loss = 36594199.18080404\n",
            "Iteration 89, loss = 36086607.36858004\n",
            "Iteration 90, loss = 35514634.45483308\n",
            "Iteration 91, loss = 34931501.17395413\n",
            "Iteration 92, loss = 34324315.38537183\n",
            "Iteration 93, loss = 33736453.67394876\n",
            "Iteration 94, loss = 33142340.79438826\n",
            "Iteration 95, loss = 32536913.61661327\n",
            "Iteration 96, loss = 31948977.81113372\n",
            "Iteration 97, loss = 31368035.41135914\n",
            "Iteration 98, loss = 30727255.72103914\n",
            "Iteration 99, loss = 30078782.92160734\n",
            "Iteration 100, loss = 29499871.64221462\n",
            "Iteration 101, loss = 28868653.06288591\n",
            "Iteration 102, loss = 28283644.78579371\n",
            "Iteration 103, loss = 27717678.24628595\n",
            "Iteration 104, loss = 27149629.25689468\n",
            "Iteration 105, loss = 26539781.44997115\n",
            "Iteration 106, loss = 25941817.21705464\n",
            "Iteration 107, loss = 25343003.93013883\n",
            "Iteration 108, loss = 24741034.55885542\n",
            "Iteration 109, loss = 24151329.07255467\n",
            "Iteration 110, loss = 23609398.37449920\n",
            "Iteration 111, loss = 23022474.49434531\n",
            "Iteration 112, loss = 22450816.56802778\n",
            "Iteration 113, loss = 21907041.14322806\n",
            "Iteration 114, loss = 21328625.92972920\n",
            "Iteration 115, loss = 20786446.92773564\n",
            "Iteration 116, loss = 20220780.44507503\n",
            "Iteration 117, loss = 19728710.14846034\n",
            "Iteration 118, loss = 19156809.14503913\n",
            "Iteration 119, loss = 18620096.53676410\n",
            "Iteration 120, loss = 18069146.66566547\n",
            "Iteration 121, loss = 17560937.10453427\n",
            "Iteration 122, loss = 17011068.50368977\n",
            "Iteration 123, loss = 16499289.03671831\n",
            "Iteration 124, loss = 15991700.36952801\n",
            "Iteration 125, loss = 15508890.68288992\n",
            "Iteration 126, loss = 15051712.44145313\n",
            "Iteration 127, loss = 14598897.88569688\n",
            "Iteration 128, loss = 14169379.98871300\n",
            "Iteration 129, loss = 13743862.54648089\n",
            "Iteration 130, loss = 13335352.32715611\n",
            "Iteration 131, loss = 12927842.19210267\n",
            "Iteration 132, loss = 12536052.50376065\n",
            "Iteration 133, loss = 12138570.00386180\n",
            "Iteration 134, loss = 11780935.54023589\n",
            "Iteration 135, loss = 11394114.63005134\n",
            "Iteration 136, loss = 11023522.18892412\n",
            "Iteration 137, loss = 10667616.35437518\n",
            "Iteration 138, loss = 10309775.40662695\n",
            "Iteration 139, loss = 9957410.45033977\n",
            "Iteration 140, loss = 9629159.86349837\n",
            "Iteration 141, loss = 9335428.20968853\n",
            "Iteration 142, loss = 9049317.76346184\n",
            "Iteration 143, loss = 8778569.16468669\n",
            "Iteration 144, loss = 8508818.04150647\n",
            "Iteration 145, loss = 8249517.30718932\n",
            "Iteration 146, loss = 8011038.55618285\n",
            "Iteration 147, loss = 7746638.00912821\n",
            "Iteration 148, loss = 7502089.13226935\n",
            "Iteration 149, loss = 7270290.23237234\n",
            "Iteration 150, loss = 7022636.59702661\n",
            "Iteration 151, loss = 6817403.77983472\n",
            "Iteration 152, loss = 6588116.33483005\n",
            "Iteration 153, loss = 6379937.22532914\n",
            "Iteration 154, loss = 6184692.83206205\n",
            "Iteration 155, loss = 5995696.04416073\n",
            "Iteration 156, loss = 5814052.70203477\n",
            "Iteration 157, loss = 5645611.55520642\n",
            "Iteration 158, loss = 5490678.13607189\n",
            "Iteration 159, loss = 5333966.77440633\n",
            "Iteration 160, loss = 5177187.86815727\n",
            "Iteration 161, loss = 5026735.52603335\n",
            "Iteration 162, loss = 4893004.98803279\n",
            "Iteration 163, loss = 4761390.57077593\n",
            "Iteration 164, loss = 4625358.82985676\n",
            "Iteration 165, loss = 4488014.32592561\n",
            "Iteration 166, loss = 4379074.56560866\n",
            "Iteration 167, loss = 4285221.11305650\n",
            "Iteration 168, loss = 4200307.68798907\n",
            "Iteration 169, loss = 4127386.70923999\n",
            "Iteration 170, loss = 4063045.31325876\n",
            "Iteration 171, loss = 3973468.07391604\n",
            "Iteration 172, loss = 3869608.28466910\n",
            "Iteration 173, loss = 3794147.29533210\n",
            "Iteration 174, loss = 3716013.10687453\n",
            "Iteration 175, loss = 3646857.45331932\n",
            "Iteration 176, loss = 3581769.83284407\n",
            "Iteration 177, loss = 3518636.35122061\n",
            "Iteration 178, loss = 3457019.91350123\n",
            "Iteration 179, loss = 3396311.36315856\n",
            "Iteration 180, loss = 3327921.22083186\n",
            "Iteration 181, loss = 3260976.42708369\n",
            "Iteration 182, loss = 3198750.46605572\n",
            "Iteration 183, loss = 3154905.42807205\n",
            "Iteration 184, loss = 3097676.00389649\n",
            "Iteration 185, loss = 3040441.75431697\n",
            "Iteration 186, loss = 2991773.25829020\n",
            "Iteration 187, loss = 2942911.99768753\n",
            "Iteration 188, loss = 2900129.73878716\n",
            "Iteration 189, loss = 2857607.01821746\n",
            "Iteration 190, loss = 2807271.74935050\n",
            "Iteration 191, loss = 2759671.88124872\n",
            "Iteration 192, loss = 2732123.53489268\n",
            "Iteration 193, loss = 2698051.99312060\n",
            "Iteration 194, loss = 2666660.04264073\n",
            "Iteration 195, loss = 2626866.57447185\n",
            "Iteration 196, loss = 2580681.40335783\n",
            "Iteration 197, loss = 2546887.60577922\n",
            "Iteration 198, loss = 2519675.06645288\n",
            "Iteration 199, loss = 2480877.51306256\n",
            "Iteration 200, loss = 2448283.21215188\n",
            "Iteration 201, loss = 2413255.40152230\n",
            "Iteration 202, loss = 2385769.82255832\n",
            "Iteration 203, loss = 2355378.23676372\n",
            "Iteration 204, loss = 2326306.75231825\n",
            "Iteration 205, loss = 2300251.56131449\n",
            "Iteration 206, loss = 2269912.15376605\n",
            "Iteration 207, loss = 2251689.60247771\n",
            "Iteration 208, loss = 2231927.45780546\n",
            "Iteration 209, loss = 2210471.92555990\n",
            "Iteration 210, loss = 2184860.76436699\n",
            "Iteration 211, loss = 2154731.81940311\n",
            "Iteration 212, loss = 2121160.73668794\n",
            "Iteration 213, loss = 2091455.05849629\n",
            "Iteration 214, loss = 2069429.43949360\n",
            "Iteration 215, loss = 2053388.64526579\n",
            "Iteration 216, loss = 2036622.21958171\n",
            "Iteration 217, loss = 2014594.86107190\n",
            "Iteration 218, loss = 1986596.88705116\n",
            "Iteration 219, loss = 1960948.54212053\n",
            "Iteration 220, loss = 1934488.31039982\n",
            "Iteration 221, loss = 1909416.42771323\n",
            "Iteration 222, loss = 1888729.38085886\n",
            "Iteration 223, loss = 1870191.35603036\n",
            "Iteration 224, loss = 1847454.58524045\n",
            "Iteration 225, loss = 1824173.29855320\n",
            "Iteration 226, loss = 1801963.10932914\n",
            "Iteration 227, loss = 1789602.53505115\n",
            "Iteration 228, loss = 1768221.40315481\n",
            "Iteration 229, loss = 1745480.06394968\n",
            "Iteration 230, loss = 1723045.83759960\n",
            "Iteration 231, loss = 1704838.60609053\n",
            "Iteration 232, loss = 1692749.80670597\n",
            "Iteration 233, loss = 1679274.47896270\n",
            "Iteration 234, loss = 1653920.12897075\n",
            "Iteration 235, loss = 1634665.62050916\n",
            "Iteration 236, loss = 1617888.65734357\n",
            "Iteration 237, loss = 1605630.38518331\n",
            "Iteration 238, loss = 1589961.46786517\n",
            "Iteration 239, loss = 1573378.34211653\n",
            "Iteration 240, loss = 1556902.82961045\n",
            "Iteration 241, loss = 1539871.36866735\n",
            "Iteration 242, loss = 1524936.42354207\n",
            "Iteration 243, loss = 1507802.02274927\n",
            "Iteration 244, loss = 1496142.98950943\n",
            "Iteration 245, loss = 1481263.06095288\n",
            "Iteration 246, loss = 1467987.74623427\n",
            "Iteration 247, loss = 1462942.33744231\n",
            "Iteration 248, loss = 1448692.37891218\n",
            "Iteration 249, loss = 1435361.28903823\n",
            "Iteration 250, loss = 1423948.67203766\n",
            "Iteration 251, loss = 1414239.36725289\n",
            "Iteration 252, loss = 1404326.55007116\n",
            "Iteration 253, loss = 1396061.36264592\n",
            "Iteration 254, loss = 1387702.78195073\n",
            "Iteration 255, loss = 1377692.89387600\n",
            "Iteration 256, loss = 1370869.35150088\n",
            "Iteration 257, loss = 1362469.48970707\n",
            "Iteration 258, loss = 1349898.62030744\n",
            "Iteration 259, loss = 1340861.39461492\n",
            "Iteration 260, loss = 1336529.22354433\n",
            "Iteration 261, loss = 1331389.69282323\n",
            "Iteration 262, loss = 1320834.13144277\n",
            "Iteration 263, loss = 1316420.61741362\n",
            "Iteration 264, loss = 1303646.11976032\n",
            "Iteration 265, loss = 1297540.90870541\n",
            "Iteration 266, loss = 1291791.04733687\n",
            "Iteration 267, loss = 1286232.42274335\n",
            "Iteration 268, loss = 1279667.11928278\n",
            "Iteration 269, loss = 1279166.63596143\n",
            "Iteration 270, loss = 1275277.40469205\n",
            "Iteration 271, loss = 1269775.54654484\n",
            "Iteration 272, loss = 1258769.69542669\n",
            "Iteration 273, loss = 1255692.27070184\n",
            "Iteration 274, loss = 1251309.91459699\n",
            "Iteration 275, loss = 1248270.89068844\n",
            "Iteration 276, loss = 1244473.24039656\n",
            "Iteration 277, loss = 1240162.14866385\n",
            "Iteration 278, loss = 1234593.22488251\n",
            "Iteration 279, loss = 1227504.54066037\n",
            "Iteration 280, loss = 1222361.06831337\n",
            "Iteration 281, loss = 1218630.73822275\n",
            "Iteration 282, loss = 1215663.96770083\n",
            "Iteration 283, loss = 1211815.87779680\n",
            "Iteration 284, loss = 1209224.41176304\n",
            "Iteration 285, loss = 1202689.61579692\n",
            "Iteration 286, loss = 1199320.80568341\n",
            "Iteration 287, loss = 1196568.12238372\n",
            "Iteration 288, loss = 1193226.92922278\n",
            "Iteration 289, loss = 1188740.64892623\n",
            "Iteration 290, loss = 1184688.05596867\n",
            "Iteration 291, loss = 1180705.56000779\n",
            "Iteration 292, loss = 1177267.34147804\n",
            "Iteration 293, loss = 1174501.97203453\n",
            "Iteration 294, loss = 1171291.66012319\n",
            "Iteration 295, loss = 1168181.49963719\n",
            "Iteration 296, loss = 1170023.31914317\n",
            "Iteration 297, loss = 1169896.39942169\n",
            "Iteration 298, loss = 1164565.17314161\n",
            "Iteration 299, loss = 1156728.06125506\n",
            "Iteration 300, loss = 1152873.16808818\n",
            "Iteration 301, loss = 1153916.54793864\n",
            "Iteration 302, loss = 1153240.67524141\n",
            "Iteration 303, loss = 1149840.42514608\n",
            "Iteration 304, loss = 1146091.34551799\n",
            "Iteration 305, loss = 1142922.71056561\n",
            "Iteration 306, loss = 1140496.46519875\n",
            "Iteration 307, loss = 1138167.93668198\n",
            "Iteration 308, loss = 1136364.87622490\n",
            "Iteration 309, loss = 1133917.30146252\n",
            "Iteration 310, loss = 1131855.07395095\n",
            "Iteration 311, loss = 1130339.89929354\n",
            "Iteration 312, loss = 1128076.36251363\n",
            "Iteration 313, loss = 1127657.93370911\n",
            "Iteration 314, loss = 1128574.21358167\n",
            "Iteration 315, loss = 1131217.64692188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 316, loss = 1134394.17086335\n",
            "Iteration 317, loss = 1136111.03841912\n",
            "Iteration 318, loss = 1129139.43161213\n",
            "Iteration 319, loss = 1114875.44842608\n",
            "Iteration 320, loss = 1114448.29699343\n",
            "Iteration 321, loss = 1125826.38657238\n",
            "Iteration 322, loss = 1126742.69085270\n",
            "Iteration 323, loss = 1117432.94667374\n",
            "Iteration 324, loss = 1106641.91399401\n",
            "Iteration 325, loss = 1106396.60760189\n",
            "Iteration 326, loss = 1104354.07985548\n",
            "Iteration 327, loss = 1101203.28045986\n",
            "Iteration 328, loss = 1100464.63007539\n",
            "Iteration 329, loss = 1100735.88590228\n",
            "Iteration 330, loss = 1097921.66345552\n",
            "Iteration 331, loss = 1093058.18987296\n",
            "Iteration 332, loss = 1099040.77419151\n",
            "Iteration 333, loss = 1099693.72244098\n",
            "Iteration 334, loss = 1097568.86886802\n",
            "Iteration 335, loss = 1092070.15983091\n",
            "Iteration 336, loss = 1089133.13081383\n",
            "Iteration 337, loss = 1088858.40337225\n",
            "Iteration 338, loss = 1087394.52424124\n",
            "Iteration 339, loss = 1083987.58039594\n",
            "Iteration 340, loss = 1083060.07401647\n",
            "Iteration 341, loss = 1084112.70496338\n",
            "Iteration 342, loss = 1084370.64050244\n",
            "Iteration 343, loss = 1082999.06051004\n",
            "Iteration 344, loss = 1083268.94104801\n",
            "Iteration 345, loss = 1083155.05382109\n",
            "Iteration 346, loss = 1086363.64226143\n",
            "Iteration 347, loss = 1083932.04755704\n",
            "Iteration 348, loss = 1081422.70132863\n",
            "Iteration 349, loss = 1076890.18817855\n",
            "Iteration 350, loss = 1076327.25954371\n",
            "Iteration 351, loss = 1074891.61616063\n",
            "Iteration 352, loss = 1074796.25494238\n",
            "Iteration 353, loss = 1073097.50293657\n",
            "Iteration 354, loss = 1073795.67675204\n",
            "Iteration 355, loss = 1083855.84637707\n",
            "Iteration 356, loss = 1078806.43970126\n",
            "Iteration 357, loss = 1073585.34974420\n",
            "Iteration 358, loss = 1074531.67041399\n",
            "Iteration 359, loss = 1076794.38468632\n",
            "Iteration 360, loss = 1074878.54873053\n",
            "Iteration 361, loss = 1071365.07672129\n",
            "Iteration 362, loss = 1070402.17645668\n",
            "Iteration 363, loss = 1069667.88542502\n",
            "Iteration 364, loss = 1072037.21100607\n",
            "Iteration 365, loss = 1070811.38389764\n",
            "Iteration 366, loss = 1068221.16732833\n",
            "Iteration 367, loss = 1065452.72797592\n",
            "Iteration 368, loss = 1070626.67013288\n",
            "Iteration 369, loss = 1071647.89673461\n",
            "Iteration 370, loss = 1068897.83603338\n",
            "Iteration 371, loss = 1065623.17022995\n",
            "Iteration 372, loss = 1063799.66684959\n",
            "Iteration 373, loss = 1064125.58383625\n",
            "Iteration 374, loss = 1062780.59771280\n",
            "Iteration 375, loss = 1062449.09092322\n",
            "Iteration 376, loss = 1062594.90488002\n",
            "Iteration 377, loss = 1061471.99616143\n",
            "Iteration 378, loss = 1060517.55574632\n",
            "Iteration 379, loss = 1061287.78104271\n",
            "Iteration 380, loss = 1058639.52606914\n",
            "Iteration 381, loss = 1060373.09089349\n",
            "Iteration 382, loss = 1063748.10250226\n",
            "Iteration 383, loss = 1059739.50790278\n",
            "Iteration 384, loss = 1056049.47664354\n",
            "Iteration 385, loss = 1065705.84094129\n",
            "Iteration 386, loss = 1067098.77583364\n",
            "Iteration 387, loss = 1060439.90014209\n",
            "Iteration 388, loss = 1058892.48808999\n",
            "Iteration 389, loss = 1054090.07604127\n",
            "Iteration 390, loss = 1054079.78885268\n",
            "Iteration 391, loss = 1058910.11602394\n",
            "Iteration 392, loss = 1058301.40507296\n",
            "Iteration 393, loss = 1056013.44708835\n",
            "Iteration 394, loss = 1052538.91792340\n",
            "Iteration 395, loss = 1051935.37912362\n",
            "Iteration 396, loss = 1052593.75320957\n",
            "Iteration 397, loss = 1052705.40963995\n",
            "Iteration 398, loss = 1052775.47906845\n",
            "Iteration 399, loss = 1053317.69339961\n",
            "Iteration 400, loss = 1049820.18366800\n",
            "Iteration 401, loss = 1050129.84581244\n",
            "Iteration 402, loss = 1051893.63428203\n",
            "Iteration 403, loss = 1054133.65344458\n",
            "Iteration 404, loss = 1054356.77371726\n",
            "Iteration 405, loss = 1053318.95127666\n",
            "Iteration 406, loss = 1050483.53444360\n",
            "Iteration 407, loss = 1048630.91208741\n",
            "Iteration 408, loss = 1050602.78193805\n",
            "Iteration 409, loss = 1050030.38465167\n",
            "Iteration 410, loss = 1049535.49433160\n",
            "Iteration 411, loss = 1049422.82677068\n",
            "Iteration 412, loss = 1048277.33020942\n",
            "Iteration 413, loss = 1047813.55082967\n",
            "Iteration 414, loss = 1048088.02812272\n",
            "Iteration 415, loss = 1049527.00591662\n",
            "Iteration 416, loss = 1048233.76224358\n",
            "Iteration 417, loss = 1046237.18455079\n",
            "Iteration 418, loss = 1046286.07847906\n",
            "Iteration 419, loss = 1052296.79851051\n",
            "Iteration 420, loss = 1049778.11479240\n",
            "Iteration 421, loss = 1045468.66805721\n",
            "Iteration 422, loss = 1046543.18642091\n",
            "Iteration 423, loss = 1053770.17530967\n",
            "Iteration 424, loss = 1064885.98487105\n",
            "Iteration 425, loss = 1059780.02980165\n",
            "Iteration 426, loss = 1046511.72291332\n",
            "Iteration 427, loss = 1052650.40621580\n",
            "Iteration 428, loss = 1063612.57558736\n",
            "Iteration 429, loss = 1059869.33935382\n",
            "Iteration 430, loss = 1044328.37870555\n",
            "Iteration 431, loss = 1047853.15709294\n",
            "Iteration 432, loss = 1063009.60676325\n",
            "Iteration 433, loss = 1064690.63881690\n",
            "Iteration 434, loss = 1044924.38915246\n",
            "Iteration 435, loss = 1040684.21604981\n",
            "Iteration 436, loss = 1068480.22750382\n",
            "Iteration 437, loss = 1094346.11932521\n",
            "Iteration 438, loss = 1058899.35244260\n",
            "Iteration 439, loss = 1044658.82037524\n",
            "Iteration 440, loss = 1076415.98855171\n",
            "Iteration 441, loss = 1096690.82935088\n",
            "Iteration 442, loss = 1081511.37098781\n",
            "Iteration 443, loss = 1049255.84739022\n",
            "Iteration 444, loss = 1043289.06371439\n",
            "Iteration 445, loss = 1040374.11549293\n",
            "Iteration 446, loss = 1043313.57746593\n",
            "Iteration 447, loss = 1043295.30269748\n",
            "Iteration 448, loss = 1041057.31532958\n",
            "Iteration 449, loss = 1040382.34163378\n",
            "Iteration 450, loss = 1040970.27197561\n",
            "Iteration 451, loss = 1042786.79755818\n",
            "Iteration 452, loss = 1050470.53622689\n",
            "Iteration 453, loss = 1044724.03298827\n",
            "Iteration 454, loss = 1035420.85216274\n",
            "Iteration 455, loss = 1047554.18082252\n",
            "Iteration 456, loss = 1065556.51143723\n",
            "Iteration 457, loss = 1058645.47829445\n",
            "Iteration 458, loss = 1040061.01303392\n",
            "Iteration 459, loss = 1040405.22755363\n",
            "Iteration 460, loss = 1039894.05472117\n",
            "Iteration 461, loss = 1040506.48179251\n",
            "Iteration 462, loss = 1041057.07723482\n",
            "Iteration 463, loss = 1041410.05635709\n",
            "Iteration 464, loss = 1040327.19680695\n",
            "Iteration 465, loss = 1039581.26215375\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1517547172.27408743\n",
            "Iteration 2, loss = 1027467026.44138038\n",
            "Iteration 3, loss = 1010685419.97111142\n",
            "Iteration 4, loss = 745937016.94085431\n",
            "Iteration 5, loss = 575980807.90779579\n",
            "Iteration 6, loss = 432401402.60832089\n",
            "Iteration 7, loss = 323262471.52481967\n",
            "Iteration 8, loss = 210172277.97304532\n",
            "Iteration 9, loss = 138412336.40323916\n",
            "Iteration 10, loss = 82043096.01702566\n",
            "Iteration 11, loss = 47816837.29190513\n",
            "Iteration 12, loss = 31079365.96293277\n",
            "Iteration 13, loss = 22117280.74521091\n",
            "Iteration 14, loss = 21198779.30074644\n",
            "Iteration 15, loss = 22993400.54457305\n",
            "Iteration 16, loss = 26751050.55514880\n",
            "Iteration 17, loss = 29402307.55219297\n",
            "Iteration 18, loss = 31762320.66405696\n",
            "Iteration 19, loss = 33018335.16226116\n",
            "Iteration 20, loss = 32089747.82446989\n",
            "Iteration 21, loss = 31138613.09699810\n",
            "Iteration 22, loss = 29098928.01158205\n",
            "Iteration 23, loss = 27054889.07755958\n",
            "Iteration 24, loss = 24952408.47812868\n",
            "Iteration 25, loss = 22992263.62773544\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538789171.78859615\n",
            "Iteration 2, loss = 1538628267.13159657\n",
            "Iteration 3, loss = 1538457406.86015725\n",
            "Iteration 4, loss = 1538320068.93778396\n",
            "Iteration 5, loss = 1538231630.65713239\n",
            "Iteration 6, loss = 1538169541.21064568\n",
            "Iteration 7, loss = 1538112509.78282213\n",
            "Iteration 8, loss = 1538055850.29157352\n",
            "Iteration 9, loss = 1537998617.46449804\n",
            "Iteration 10, loss = 1537941319.41424990\n",
            "Iteration 11, loss = 1537883137.63408947\n",
            "Iteration 12, loss = 1537825839.42153835\n",
            "Iteration 13, loss = 1537767042.76192713\n",
            "Iteration 14, loss = 1537709435.20701480\n",
            "Iteration 15, loss = 1537651415.65055823\n",
            "Iteration 16, loss = 1537592926.13487840\n",
            "Iteration 17, loss = 1537534903.54962349\n",
            "Iteration 18, loss = 1537477099.55986714\n",
            "Iteration 19, loss = 1537418873.41592526\n",
            "Iteration 20, loss = 1537361102.98623824\n",
            "Iteration 21, loss = 1537303277.80192423\n",
            "Iteration 22, loss = 1537245704.87395978\n",
            "Iteration 23, loss = 1537188107.27053881\n",
            "Iteration 24, loss = 1537130801.57412243\n",
            "Iteration 25, loss = 1537073821.91636443\n",
            "Iteration 26, loss = 1537016533.25406194\n",
            "Iteration 27, loss = 1536959364.98232055\n",
            "Iteration 28, loss = 1536902639.59359193\n",
            "Iteration 29, loss = 1536845787.10283089\n",
            "Iteration 30, loss = 1536788866.74630713\n",
            "Iteration 31, loss = 1536732268.51462388\n",
            "Iteration 32, loss = 1536675352.02967620\n",
            "Iteration 33, loss = 1536618756.93956518\n",
            "Iteration 34, loss = 1536562366.87986660\n",
            "Iteration 35, loss = 1536505627.77920675\n",
            "Iteration 36, loss = 1536449166.70231223\n",
            "Iteration 37, loss = 1536392899.17775106\n",
            "Iteration 38, loss = 1536335944.44158125\n",
            "Iteration 39, loss = 1536279624.28398252\n",
            "Iteration 40, loss = 1536223243.64706564\n",
            "Iteration 41, loss = 1536166610.07246542\n",
            "Iteration 42, loss = 1536110100.26444316\n",
            "Iteration 43, loss = 1536053963.67580843\n",
            "Iteration 44, loss = 1535997530.75184798\n",
            "Iteration 45, loss = 1535941106.64790487\n",
            "Iteration 46, loss = 1535885064.49210072\n",
            "Iteration 47, loss = 1535828773.39882016\n",
            "Iteration 48, loss = 1535772559.69121647\n",
            "Iteration 49, loss = 1535716380.58018756\n",
            "Iteration 50, loss = 1535660050.50889111\n",
            "Iteration 51, loss = 1535604597.25035095\n",
            "Iteration 52, loss = 1535547681.11803365\n",
            "Iteration 53, loss = 1535492156.10763860\n",
            "Iteration 54, loss = 1535436203.15506053\n",
            "Iteration 55, loss = 1535380418.94494486\n",
            "Iteration 56, loss = 1535324725.40736794\n",
            "Iteration 57, loss = 1535268735.93112946\n",
            "Iteration 58, loss = 1535213185.68645167\n",
            "Iteration 59, loss = 1535157557.87845111\n",
            "Iteration 60, loss = 1535101637.99883938\n",
            "Iteration 61, loss = 1535046160.35169435\n",
            "Iteration 62, loss = 1534990377.79972577\n",
            "Iteration 63, loss = 1534934578.79087496\n",
            "Iteration 64, loss = 1534878899.39102936\n",
            "Iteration 65, loss = 1534823369.78348207\n",
            "Iteration 66, loss = 1534767631.47200060\n",
            "Iteration 67, loss = 1534712518.40975547\n",
            "Iteration 68, loss = 1534656967.76848960\n",
            "Iteration 69, loss = 1534601579.02129817\n",
            "Iteration 70, loss = 1534546509.11014605\n",
            "Iteration 71, loss = 1534490742.84326649\n",
            "Iteration 72, loss = 1534435877.27224946\n",
            "Iteration 73, loss = 1534380454.37525487\n",
            "Iteration 74, loss = 1534324658.65647864\n",
            "Iteration 75, loss = 1534269369.98884630\n",
            "Iteration 76, loss = 1534214151.41901350\n",
            "Iteration 77, loss = 1534158502.92564511\n",
            "Iteration 78, loss = 1534102916.11451459\n",
            "Iteration 79, loss = 1534047680.71917939\n",
            "Iteration 80, loss = 1533992362.06804609\n",
            "Iteration 81, loss = 1533937213.49720454\n",
            "Iteration 82, loss = 1533881436.56114411\n",
            "Iteration 83, loss = 1533826573.61307883\n",
            "Iteration 84, loss = 1533771484.43099737\n",
            "Iteration 85, loss = 1533716165.41530919\n",
            "Iteration 86, loss = 1533661071.34939051\n",
            "Iteration 87, loss = 1533606221.00197673\n",
            "Iteration 88, loss = 1533550869.83027554\n",
            "Iteration 89, loss = 1533495816.76651740\n",
            "Iteration 90, loss = 1533440929.46184444\n",
            "Iteration 91, loss = 1533385848.03627992\n",
            "Iteration 92, loss = 1533330528.64657617\n",
            "Iteration 93, loss = 1533275371.48884010\n",
            "Iteration 94, loss = 1533220582.92548323\n",
            "Iteration 95, loss = 1533165418.02605891\n",
            "Iteration 96, loss = 1533110365.71472621\n",
            "Iteration 97, loss = 1533055124.12856007\n",
            "Iteration 98, loss = 1533000148.03766775\n",
            "Iteration 99, loss = 1532945024.54451776\n",
            "Iteration 100, loss = 1532889809.18312740\n",
            "Iteration 101, loss = 1532834455.91348505\n",
            "Iteration 102, loss = 1532779228.69723654\n",
            "Iteration 103, loss = 1532723808.38580966\n",
            "Iteration 104, loss = 1532668664.63086581\n",
            "Iteration 105, loss = 1532612500.72127104\n",
            "Iteration 106, loss = 1532557622.84371567\n",
            "Iteration 107, loss = 1532502117.42420912\n",
            "Iteration 108, loss = 1532446541.02243304\n",
            "Iteration 109, loss = 1532391103.27170348\n",
            "Iteration 110, loss = 1532335672.21802902\n",
            "Iteration 111, loss = 1532280130.37134910\n",
            "Iteration 112, loss = 1532224850.32724476\n",
            "Iteration 113, loss = 1532169180.54148746\n",
            "Iteration 114, loss = 1532113840.50706911\n",
            "Iteration 115, loss = 1532058533.88677335\n",
            "Iteration 116, loss = 1532003023.96357179\n",
            "Iteration 117, loss = 1531947586.12699437\n",
            "Iteration 118, loss = 1531892217.75458145\n",
            "Iteration 119, loss = 1531836600.04464149\n",
            "Iteration 120, loss = 1531781705.67192674\n",
            "Iteration 121, loss = 1531726054.18241739\n",
            "Iteration 122, loss = 1531670388.10039234\n",
            "Iteration 123, loss = 1531615390.80965734\n",
            "Iteration 124, loss = 1531559716.44255519\n",
            "Iteration 125, loss = 1531504778.65233111\n",
            "Iteration 126, loss = 1531450005.91030312\n",
            "Iteration 127, loss = 1531394276.55416036\n",
            "Iteration 128, loss = 1531339831.35458899\n",
            "Iteration 129, loss = 1531284871.60438275\n",
            "Iteration 130, loss = 1531230109.70114040\n",
            "Iteration 131, loss = 1531175255.76050711\n",
            "Iteration 132, loss = 1531120758.34443617\n",
            "Iteration 133, loss = 1531065598.20649362\n",
            "Iteration 134, loss = 1531011285.45808434\n",
            "Iteration 135, loss = 1530956058.57306886\n",
            "Iteration 136, loss = 1530901170.18664169\n",
            "Iteration 137, loss = 1530846254.99987006\n",
            "Iteration 138, loss = 1530791376.85252833\n",
            "Iteration 139, loss = 1530736111.90167594\n",
            "Iteration 140, loss = 1530681269.73852730\n",
            "Iteration 141, loss = 1530626474.60710073\n",
            "Iteration 142, loss = 1530571036.98252249\n",
            "Iteration 143, loss = 1530516155.29694200\n",
            "Iteration 144, loss = 1530461215.01380849\n",
            "Iteration 145, loss = 1530406498.21584439\n",
            "Iteration 146, loss = 1530351485.61330247\n",
            "Iteration 147, loss = 1530296651.26049542\n",
            "Iteration 148, loss = 1530241434.17365623\n",
            "Iteration 149, loss = 1530186407.64881563\n",
            "Iteration 150, loss = 1530131983.09453940\n",
            "Iteration 151, loss = 1530077171.39649129\n",
            "Iteration 152, loss = 1530021811.36140895\n",
            "Iteration 153, loss = 1529967185.83627915\n",
            "Iteration 154, loss = 1529912346.60597587\n",
            "Iteration 155, loss = 1529857204.01885939\n",
            "Iteration 156, loss = 1529802567.73560452\n",
            "Iteration 157, loss = 1529747667.48818231\n",
            "Iteration 158, loss = 1529692581.02363682\n",
            "Iteration 159, loss = 1529637778.51233411\n",
            "Iteration 160, loss = 1529583209.46564126\n",
            "Iteration 161, loss = 1529528232.14714670\n",
            "Iteration 162, loss = 1529473503.51459599\n",
            "Iteration 163, loss = 1529418585.19855404\n",
            "Iteration 164, loss = 1529363876.94501233\n",
            "Iteration 165, loss = 1529308882.17465711\n",
            "Iteration 166, loss = 1529253967.74913049\n",
            "Iteration 167, loss = 1529199215.93364239\n",
            "Iteration 168, loss = 1529144313.55333948\n",
            "Iteration 169, loss = 1529089331.77153587\n",
            "Iteration 170, loss = 1529034277.06218910\n",
            "Iteration 171, loss = 1528979114.80094886\n",
            "Iteration 172, loss = 1528924397.72998381\n",
            "Iteration 173, loss = 1528869004.39480162\n",
            "Iteration 174, loss = 1528813933.15198779\n",
            "Iteration 175, loss = 1528758865.50880289\n",
            "Iteration 176, loss = 1528703700.73682570\n",
            "Iteration 177, loss = 1528648295.37520623\n",
            "Iteration 178, loss = 1528593534.69002986\n",
            "Iteration 179, loss = 1528538540.34029317\n",
            "Iteration 180, loss = 1528483723.91625571\n",
            "Iteration 181, loss = 1528428796.00276685\n",
            "Iteration 182, loss = 1528374062.99125886\n",
            "Iteration 183, loss = 1528319819.28599524\n",
            "Iteration 184, loss = 1528264541.18506932\n",
            "Iteration 185, loss = 1528210428.18017912\n",
            "Iteration 186, loss = 1528155401.96630120\n",
            "Iteration 187, loss = 1528101047.09697270\n",
            "Iteration 188, loss = 1528046412.81692100\n",
            "Iteration 189, loss = 1527991494.55487823\n",
            "Iteration 190, loss = 1527937072.72392702\n",
            "Iteration 191, loss = 1527881922.38367987\n",
            "Iteration 192, loss = 1527827701.03439260\n",
            "Iteration 193, loss = 1527772736.27972221\n",
            "Iteration 194, loss = 1527717949.44422793\n",
            "Iteration 195, loss = 1527663666.67770720\n",
            "Iteration 196, loss = 1527608609.60216689\n",
            "Iteration 197, loss = 1527554198.33971691\n",
            "Iteration 198, loss = 1527499752.25714326\n",
            "Iteration 199, loss = 1527445240.34677887\n",
            "Iteration 200, loss = 1527390300.31653953\n",
            "Iteration 201, loss = 1527336226.73506165\n",
            "Iteration 202, loss = 1527281486.80641460\n",
            "Iteration 203, loss = 1527226989.16998553\n",
            "Iteration 204, loss = 1527172202.45216537\n",
            "Iteration 205, loss = 1527117532.98928595\n",
            "Iteration 206, loss = 1527063100.78857446\n",
            "Iteration 207, loss = 1527008518.74898791\n",
            "Iteration 208, loss = 1526953893.34529543\n",
            "Iteration 209, loss = 1526899233.31275392\n",
            "Iteration 210, loss = 1526844390.21461892\n",
            "Iteration 211, loss = 1526790109.10777926\n",
            "Iteration 212, loss = 1526735642.38992691\n",
            "Iteration 213, loss = 1526680612.32673216\n",
            "Iteration 214, loss = 1526625979.02218890\n",
            "Iteration 215, loss = 1526571339.68537807\n",
            "Iteration 216, loss = 1526516548.39355206\n",
            "Iteration 217, loss = 1526461847.77605677\n",
            "Iteration 218, loss = 1526406999.26974392\n",
            "Iteration 219, loss = 1526352173.16491294\n",
            "Iteration 220, loss = 1526297729.92584157\n",
            "Iteration 221, loss = 1526242707.41778541\n",
            "Iteration 222, loss = 1526188261.81874347\n",
            "Iteration 223, loss = 1526133366.73854470\n",
            "Iteration 224, loss = 1526079075.22750449\n",
            "Iteration 225, loss = 1526024150.72783184\n",
            "Iteration 226, loss = 1525969443.04506588\n",
            "Iteration 227, loss = 1525914788.15705395\n",
            "Iteration 228, loss = 1525860102.88097763\n",
            "Iteration 229, loss = 1525805432.73485851\n",
            "Iteration 230, loss = 1525750789.23173475\n",
            "Iteration 231, loss = 1525696039.84428453\n",
            "Iteration 232, loss = 1525641447.08470607\n",
            "Iteration 233, loss = 1525586674.59011889\n",
            "Iteration 234, loss = 1525532098.26058125\n",
            "Iteration 235, loss = 1525477560.71547389\n",
            "Iteration 236, loss = 1525422603.97994065\n",
            "Iteration 237, loss = 1525367940.11476564\n",
            "Iteration 238, loss = 1525313494.88232660\n",
            "Iteration 239, loss = 1525258348.33577847\n",
            "Iteration 240, loss = 1525204028.58501148\n",
            "Iteration 241, loss = 1525148959.16032910\n",
            "Iteration 242, loss = 1525094405.40613127\n",
            "Iteration 243, loss = 1525039277.06283092\n",
            "Iteration 244, loss = 1524985046.04059315\n",
            "Iteration 245, loss = 1524929842.74957585\n",
            "Iteration 246, loss = 1524875025.57089567\n",
            "Iteration 247, loss = 1524820507.21616602\n",
            "Iteration 248, loss = 1524765622.53107548\n",
            "Iteration 249, loss = 1524711379.95963788\n",
            "Iteration 250, loss = 1524656045.79219818\n",
            "Iteration 251, loss = 1524601941.30708218\n",
            "Iteration 252, loss = 1524546872.05550861\n",
            "Iteration 253, loss = 1524492444.25532675\n",
            "Iteration 254, loss = 1524437610.18158245\n",
            "Iteration 255, loss = 1524383063.93821096\n",
            "Iteration 256, loss = 1524328310.83111811\n",
            "Iteration 257, loss = 1524273967.83969998\n",
            "Iteration 258, loss = 1524218849.55604005\n",
            "Iteration 259, loss = 1524164114.13100863\n",
            "Iteration 260, loss = 1524109505.79004073\n",
            "Iteration 261, loss = 1524054842.73546481\n",
            "Iteration 262, loss = 1523999641.90977883\n",
            "Iteration 263, loss = 1523944955.17772770\n",
            "Iteration 264, loss = 1523890105.92615080\n",
            "Iteration 265, loss = 1523835187.47174954\n",
            "Iteration 266, loss = 1523780566.51884365\n",
            "Iteration 267, loss = 1523725661.89596605\n",
            "Iteration 268, loss = 1523671006.36724329\n",
            "Iteration 269, loss = 1523616098.90763068\n",
            "Iteration 270, loss = 1523561492.27443218\n",
            "Iteration 271, loss = 1523506473.50644135\n",
            "Iteration 272, loss = 1523451713.23098969\n",
            "Iteration 273, loss = 1523397086.51688075\n",
            "Iteration 274, loss = 1523342052.62321424\n",
            "Iteration 275, loss = 1523287244.34212947\n",
            "Iteration 276, loss = 1523232636.15948415\n",
            "Iteration 277, loss = 1523177622.14706969\n",
            "Iteration 278, loss = 1523123205.20199800\n",
            "Iteration 279, loss = 1523068855.05580878\n",
            "Iteration 280, loss = 1523014244.40800095\n",
            "Iteration 281, loss = 1522959941.42732000\n",
            "Iteration 282, loss = 1522905737.67520833\n",
            "Iteration 283, loss = 1522851651.49572015\n",
            "Iteration 284, loss = 1522797224.44528008\n",
            "Iteration 285, loss = 1522743311.20607519\n",
            "Iteration 286, loss = 1522689094.63944864\n",
            "Iteration 287, loss = 1522634672.47774172\n",
            "Iteration 288, loss = 1522580640.97106791\n",
            "Iteration 289, loss = 1522526541.61018968\n",
            "Iteration 290, loss = 1522472197.84060144\n",
            "Iteration 291, loss = 1522418169.18431258\n",
            "Iteration 292, loss = 1522363946.19502521\n",
            "Iteration 293, loss = 1522309598.03942871\n",
            "Iteration 294, loss = 1522255549.02540660\n",
            "Iteration 295, loss = 1522201730.70522690\n",
            "Iteration 296, loss = 1522147414.61515880\n",
            "Iteration 297, loss = 1522093234.79194188\n",
            "Iteration 298, loss = 1522039272.20720959\n",
            "Iteration 299, loss = 1521984822.64530826\n",
            "Iteration 300, loss = 1521930772.46194768\n",
            "Iteration 301, loss = 1521876524.35865378\n",
            "Iteration 302, loss = 1521822264.46250510\n",
            "Iteration 303, loss = 1521767973.03197742\n",
            "Iteration 304, loss = 1521713605.10500026\n",
            "Iteration 305, loss = 1521659406.41409159\n",
            "Iteration 306, loss = 1521605132.99250078\n",
            "Iteration 307, loss = 1521550623.29596114\n",
            "Iteration 308, loss = 1521496487.96411395\n",
            "Iteration 309, loss = 1521441903.61928892\n",
            "Iteration 310, loss = 1521387739.86065745\n",
            "Iteration 311, loss = 1521333563.67536235\n",
            "Iteration 312, loss = 1521278959.23176575\n",
            "Iteration 313, loss = 1521224771.46514344\n",
            "Iteration 314, loss = 1521170100.29904699\n",
            "Iteration 315, loss = 1521115649.70965028\n",
            "Iteration 316, loss = 1521061145.06927252\n",
            "Iteration 317, loss = 1521006943.77325821\n",
            "Iteration 318, loss = 1520952172.06228423\n",
            "Iteration 319, loss = 1520897498.60804462\n",
            "Iteration 320, loss = 1520843303.59629202\n",
            "Iteration 321, loss = 1520789086.27606606\n",
            "Iteration 322, loss = 1520734079.32104635\n",
            "Iteration 323, loss = 1520680099.29274487\n",
            "Iteration 324, loss = 1520625370.41742110\n",
            "Iteration 325, loss = 1520570932.46179199\n",
            "Iteration 326, loss = 1520516804.90841651\n",
            "Iteration 327, loss = 1520462092.75688910\n",
            "Iteration 328, loss = 1520407777.01735926\n",
            "Iteration 329, loss = 1520352954.12295890\n",
            "Iteration 330, loss = 1520298614.50439262\n",
            "Iteration 331, loss = 1520244225.16496849\n",
            "Iteration 332, loss = 1520189377.98861909\n",
            "Iteration 333, loss = 1520134922.66403556\n",
            "Iteration 334, loss = 1520079805.88093996\n",
            "Iteration 335, loss = 1520025621.06086707\n",
            "Iteration 336, loss = 1519970951.66094160\n",
            "Iteration 337, loss = 1519916391.06527638\n",
            "Iteration 338, loss = 1519861841.41962481\n",
            "Iteration 339, loss = 1519807325.67790961\n",
            "Iteration 340, loss = 1519752771.31902480\n",
            "Iteration 341, loss = 1519698613.22889924\n",
            "Iteration 342, loss = 1519644131.13827491\n",
            "Iteration 343, loss = 1519589484.41665030\n",
            "Iteration 344, loss = 1519535156.42707992\n",
            "Iteration 345, loss = 1519480944.76473045\n",
            "Iteration 346, loss = 1519426008.89570880\n",
            "Iteration 347, loss = 1519371671.18669081\n",
            "Iteration 348, loss = 1519317363.59170723\n",
            "Iteration 349, loss = 1519262730.75320625\n",
            "Iteration 350, loss = 1519208234.11686683\n",
            "Iteration 351, loss = 1519154024.84449720\n",
            "Iteration 352, loss = 1519099549.83021927\n",
            "Iteration 353, loss = 1519045365.04109097\n",
            "Iteration 354, loss = 1518990941.47042108\n",
            "Iteration 355, loss = 1518936626.58738971\n",
            "Iteration 356, loss = 1518882429.55037165\n",
            "Iteration 357, loss = 1518827903.15017319\n",
            "Iteration 358, loss = 1518773306.47323322\n",
            "Iteration 359, loss = 1518718838.43193555\n",
            "Iteration 360, loss = 1518664417.98573017\n",
            "Iteration 361, loss = 1518609424.51850557\n",
            "Iteration 362, loss = 1518554760.75029278\n",
            "Iteration 363, loss = 1518500339.48488522\n",
            "Iteration 364, loss = 1518445413.94872165\n",
            "Iteration 365, loss = 1518390846.59228754\n",
            "Iteration 366, loss = 1518336690.63093162\n",
            "Iteration 367, loss = 1518281780.58194709\n",
            "Iteration 368, loss = 1518227658.24639654\n",
            "Iteration 369, loss = 1518173116.59173560\n",
            "Iteration 370, loss = 1518118775.89018893\n",
            "Iteration 371, loss = 1518064989.54364014\n",
            "Iteration 372, loss = 1518010424.34497190\n",
            "Iteration 373, loss = 1517956316.86286497\n",
            "Iteration 374, loss = 1517902287.20801878\n",
            "Iteration 375, loss = 1517847855.66204238\n",
            "Iteration 376, loss = 1517794064.48362207\n",
            "Iteration 377, loss = 1517739788.81363034\n",
            "Iteration 378, loss = 1517685205.58277202\n",
            "Iteration 379, loss = 1517631211.72520876\n",
            "Iteration 380, loss = 1517576867.90581155\n",
            "Iteration 381, loss = 1517522286.09981823\n",
            "Iteration 382, loss = 1517467800.85764074\n",
            "Iteration 383, loss = 1517413483.43733096\n",
            "Iteration 384, loss = 1517358667.14206386\n",
            "Iteration 385, loss = 1517303877.20824265\n",
            "Iteration 386, loss = 1517249817.37214899\n",
            "Iteration 387, loss = 1517195036.76936412\n",
            "Iteration 388, loss = 1517140601.17271280\n",
            "Iteration 389, loss = 1517085701.07916856\n",
            "Iteration 390, loss = 1517031374.34016824\n",
            "Iteration 391, loss = 1516976878.26240373\n",
            "Iteration 392, loss = 1516922252.31367493\n",
            "Iteration 393, loss = 1516867569.75651050\n",
            "Iteration 394, loss = 1516813061.16810560\n",
            "Iteration 395, loss = 1516758681.44292307\n",
            "Iteration 396, loss = 1516704340.72967315\n",
            "Iteration 397, loss = 1516649587.37951994\n",
            "Iteration 398, loss = 1516595392.00331259\n",
            "Iteration 399, loss = 1516541050.16144872\n",
            "Iteration 400, loss = 1516486531.08661008\n",
            "Iteration 401, loss = 1516432051.40351009\n",
            "Iteration 402, loss = 1516377497.37750316\n",
            "Iteration 403, loss = 1516323139.79183507\n",
            "Iteration 404, loss = 1516268630.19986105\n",
            "Iteration 405, loss = 1516214047.80962825\n",
            "Iteration 406, loss = 1516159517.59423256\n",
            "Iteration 407, loss = 1516104906.03763843\n",
            "Iteration 408, loss = 1516049815.10726309\n",
            "Iteration 409, loss = 1515995381.47505713\n",
            "Iteration 410, loss = 1515940712.90715170\n",
            "Iteration 411, loss = 1515885843.50929832\n",
            "Iteration 412, loss = 1515831122.75117064\n",
            "Iteration 413, loss = 1515776309.01963735\n",
            "Iteration 414, loss = 1515721897.99280214\n",
            "Iteration 415, loss = 1515667201.46721864\n",
            "Iteration 416, loss = 1515612516.04481244\n",
            "Iteration 417, loss = 1515558383.55813026\n",
            "Iteration 418, loss = 1515503856.53219557\n",
            "Iteration 419, loss = 1515449163.47677374\n",
            "Iteration 420, loss = 1515394737.43339038\n",
            "Iteration 421, loss = 1515340409.14135504\n",
            "Iteration 422, loss = 1515285846.90605497\n",
            "Iteration 423, loss = 1515231762.00568008\n",
            "Iteration 424, loss = 1515176951.78453302\n",
            "Iteration 425, loss = 1515122549.67639756\n",
            "Iteration 426, loss = 1515068224.07904220\n",
            "Iteration 427, loss = 1515013681.32938933\n",
            "Iteration 428, loss = 1514959010.29349995\n",
            "Iteration 429, loss = 1514904547.67158341\n",
            "Iteration 430, loss = 1514850383.30650711\n",
            "Iteration 431, loss = 1514796160.89061952\n",
            "Iteration 432, loss = 1514741511.84612584\n",
            "Iteration 433, loss = 1514687331.56020832\n",
            "Iteration 434, loss = 1514633198.09724069\n",
            "Iteration 435, loss = 1514579119.28400159\n",
            "Iteration 436, loss = 1514524685.02471399\n",
            "Iteration 437, loss = 1514471042.68157673\n",
            "Iteration 438, loss = 1514416314.52394271\n",
            "Iteration 439, loss = 1514362551.60728812\n",
            "Iteration 440, loss = 1514308252.40129566\n",
            "Iteration 441, loss = 1514254222.53513718\n",
            "Iteration 442, loss = 1514200022.24487185\n",
            "Iteration 443, loss = 1514145903.63093805\n",
            "Iteration 444, loss = 1514091558.71968842\n",
            "Iteration 445, loss = 1514037307.82505465\n",
            "Iteration 446, loss = 1513982937.32511973\n",
            "Iteration 447, loss = 1513928897.45776892\n",
            "Iteration 448, loss = 1513874456.82597208\n",
            "Iteration 449, loss = 1513819867.73223901\n",
            "Iteration 450, loss = 1513765652.71943140\n",
            "Iteration 451, loss = 1513710911.42726851\n",
            "Iteration 452, loss = 1513656728.18830967\n",
            "Iteration 453, loss = 1513602058.51031017\n",
            "Iteration 454, loss = 1513547659.35660172\n",
            "Iteration 455, loss = 1513492987.94262028\n",
            "Iteration 456, loss = 1513438487.15474391\n",
            "Iteration 457, loss = 1513383442.31064272\n",
            "Iteration 458, loss = 1513329354.51864409\n",
            "Iteration 459, loss = 1513274411.39100575\n",
            "Iteration 460, loss = 1513219692.13240862\n",
            "Iteration 461, loss = 1513164926.05403471\n",
            "Iteration 462, loss = 1513110413.07923675\n",
            "Iteration 463, loss = 1513056042.55579758\n",
            "Iteration 464, loss = 1513001106.07749414\n",
            "Iteration 465, loss = 1512946835.29435992\n",
            "Iteration 466, loss = 1512892388.42307329\n",
            "Iteration 467, loss = 1512838247.41125417\n",
            "Iteration 468, loss = 1512783801.79955482\n",
            "Iteration 469, loss = 1512729513.05404162\n",
            "Iteration 470, loss = 1512675347.95035243\n",
            "Iteration 471, loss = 1512621046.20756459\n",
            "Iteration 472, loss = 1512567047.59251928\n",
            "Iteration 473, loss = 1512513025.35374379\n",
            "Iteration 474, loss = 1512458685.99342918\n",
            "Iteration 475, loss = 1512404973.54591656\n",
            "Iteration 476, loss = 1512350641.18035412\n",
            "Iteration 477, loss = 1512296756.23146105\n",
            "Iteration 478, loss = 1512242545.68095613\n",
            "Iteration 479, loss = 1512188771.15213728\n",
            "Iteration 480, loss = 1512133944.42548013\n",
            "Iteration 481, loss = 1512080240.93266773\n",
            "Iteration 482, loss = 1512025537.72866344\n",
            "Iteration 483, loss = 1511971568.48576450\n",
            "Iteration 484, loss = 1511917099.70446682\n",
            "Iteration 485, loss = 1511862816.02845550\n",
            "Iteration 486, loss = 1511808548.11849904\n",
            "Iteration 487, loss = 1511754370.92518067\n",
            "Iteration 488, loss = 1511700062.54443431\n",
            "Iteration 489, loss = 1511645971.43480086\n",
            "Iteration 490, loss = 1511591873.04646540\n",
            "Iteration 491, loss = 1511538082.10687995\n",
            "Iteration 492, loss = 1511484016.75818944\n",
            "Iteration 493, loss = 1511429931.41229057\n",
            "Iteration 494, loss = 1511375993.96930766\n",
            "Iteration 495, loss = 1511322417.90976143\n",
            "Iteration 496, loss = 1511268150.40927172\n",
            "Iteration 497, loss = 1511214252.89406109\n",
            "Iteration 498, loss = 1511160264.57727504\n",
            "Iteration 499, loss = 1511106358.90424132\n",
            "Iteration 500, loss = 1511052414.03556681\n",
            "Iteration 501, loss = 1510998606.89855790\n",
            "Iteration 502, loss = 1510944136.59455013\n",
            "Iteration 503, loss = 1510890558.37263203\n",
            "Iteration 504, loss = 1510836681.55726647\n",
            "Iteration 505, loss = 1510782698.82463789\n",
            "Iteration 506, loss = 1510728478.90312529\n",
            "Iteration 507, loss = 1510674689.18190646\n",
            "Iteration 508, loss = 1510620795.50813794\n",
            "Iteration 509, loss = 1510566719.81264067\n",
            "Iteration 510, loss = 1510512990.69460154\n",
            "Iteration 511, loss = 1510459008.46328378\n",
            "Iteration 512, loss = 1510405025.98597407\n",
            "Iteration 513, loss = 1510351192.46549273\n",
            "Iteration 514, loss = 1510296926.08723140\n",
            "Iteration 515, loss = 1510242918.12055922\n",
            "Iteration 516, loss = 1510188772.92167616\n",
            "Iteration 517, loss = 1510134243.85721874\n",
            "Iteration 518, loss = 1510079862.33284402\n",
            "Iteration 519, loss = 1510025720.21712852\n",
            "Iteration 520, loss = 1509971235.59788489\n",
            "Iteration 521, loss = 1509916766.41586900\n",
            "Iteration 522, loss = 1509862436.74563313\n",
            "Iteration 523, loss = 1509808400.80370641\n",
            "Iteration 524, loss = 1509753771.08126569\n",
            "Iteration 525, loss = 1509699483.85457134\n",
            "Iteration 526, loss = 1509644946.91991854\n",
            "Iteration 527, loss = 1509590528.16479421\n",
            "Iteration 528, loss = 1509536149.60958624\n",
            "Iteration 529, loss = 1509481504.01408243\n",
            "Iteration 530, loss = 1509427561.22731900\n",
            "Iteration 531, loss = 1509373159.07578373\n",
            "Iteration 532, loss = 1509319039.20939875\n",
            "Iteration 533, loss = 1509265047.39882565\n",
            "Iteration 534, loss = 1509210998.85870552\n",
            "Iteration 535, loss = 1509156707.54807210\n",
            "Iteration 536, loss = 1509102557.97786951\n",
            "Iteration 537, loss = 1509048529.16505265\n",
            "Iteration 538, loss = 1508994135.14145613\n",
            "Iteration 539, loss = 1508939936.53488517\n",
            "Iteration 540, loss = 1508885537.92952585\n",
            "Iteration 541, loss = 1508831758.27667618\n",
            "Iteration 542, loss = 1508777210.94752789\n",
            "Iteration 543, loss = 1508723144.55875921\n",
            "Iteration 544, loss = 1508669491.01439142\n",
            "Iteration 545, loss = 1508615538.95920587\n",
            "Iteration 546, loss = 1508561392.52422380\n",
            "Iteration 547, loss = 1508507876.15762067\n",
            "Iteration 548, loss = 1508453704.60593009\n",
            "Iteration 549, loss = 1508400151.05949688\n",
            "Iteration 550, loss = 1508345871.06320953\n",
            "Iteration 551, loss = 1508291931.70499754\n",
            "Iteration 552, loss = 1508238177.79014707\n",
            "Iteration 553, loss = 1508183913.50953269\n",
            "Iteration 554, loss = 1508130460.64165282\n",
            "Iteration 555, loss = 1508075985.37832379\n",
            "Iteration 556, loss = 1508022286.15681744\n",
            "Iteration 557, loss = 1507968372.61023545\n",
            "Iteration 558, loss = 1507914214.38787103\n",
            "Iteration 559, loss = 1507860287.19569850\n",
            "Iteration 560, loss = 1507806357.57842541\n",
            "Iteration 561, loss = 1507752166.39613867\n",
            "Iteration 562, loss = 1507698215.55979848\n",
            "Iteration 563, loss = 1507644125.45357537\n",
            "Iteration 564, loss = 1507589872.62155104\n",
            "Iteration 565, loss = 1507535641.10930634\n",
            "Iteration 566, loss = 1507481746.60326576\n",
            "Iteration 567, loss = 1507427672.02327347\n",
            "Iteration 568, loss = 1507373431.79901028\n",
            "Iteration 569, loss = 1507319649.10517097\n",
            "Iteration 570, loss = 1507265440.84275150\n",
            "Iteration 571, loss = 1507211659.46304274\n",
            "Iteration 572, loss = 1507157563.60676336\n",
            "Iteration 573, loss = 1507103779.96548843\n",
            "Iteration 574, loss = 1507049668.28839135\n",
            "Iteration 575, loss = 1506995347.27760172\n",
            "Iteration 576, loss = 1506941747.38756585\n",
            "Iteration 577, loss = 1506887414.38813877\n",
            "Iteration 578, loss = 1506833178.27510667\n",
            "Iteration 579, loss = 1506779615.65094328\n",
            "Iteration 580, loss = 1506725434.48983693\n",
            "Iteration 581, loss = 1506671539.92466807\n",
            "Iteration 582, loss = 1506617592.76846385\n",
            "Iteration 583, loss = 1506563892.69623256\n",
            "Iteration 584, loss = 1506509817.75426435\n",
            "Iteration 585, loss = 1506455701.60688639\n",
            "Iteration 586, loss = 1506401969.28179002\n",
            "Iteration 587, loss = 1506347551.26397634\n",
            "Iteration 588, loss = 1506293676.95259953\n",
            "Iteration 589, loss = 1506239219.21273947\n",
            "Iteration 590, loss = 1506185714.65625978\n",
            "Iteration 591, loss = 1506131936.63385582\n",
            "Iteration 592, loss = 1506077539.06807065\n",
            "Iteration 593, loss = 1506024235.76373792\n",
            "Iteration 594, loss = 1505970344.03911829\n",
            "Iteration 595, loss = 1505917029.46498036\n",
            "Iteration 596, loss = 1505863280.62287331\n",
            "Iteration 597, loss = 1505809456.83655906\n",
            "Iteration 598, loss = 1505755402.77616644\n",
            "Iteration 599, loss = 1505702182.48627782\n",
            "Iteration 600, loss = 1505648034.05404234\n",
            "Iteration 601, loss = 1505594006.23758149\n",
            "Iteration 602, loss = 1505540051.63832784\n",
            "Iteration 603, loss = 1505486510.22469234\n",
            "Iteration 604, loss = 1505432266.75171900\n",
            "Iteration 605, loss = 1505378459.12020302\n",
            "Iteration 606, loss = 1505324612.50258613\n",
            "Iteration 607, loss = 1505270599.92450809\n",
            "Iteration 608, loss = 1505216477.86107802\n",
            "Iteration 609, loss = 1505162716.93975115\n",
            "Iteration 610, loss = 1505108672.51105142\n",
            "Iteration 611, loss = 1505054704.21928382\n",
            "Iteration 612, loss = 1505000607.91173339\n",
            "Iteration 613, loss = 1504947035.92211747\n",
            "Iteration 614, loss = 1504892689.03714442\n",
            "Iteration 615, loss = 1504838682.41310477\n",
            "Iteration 616, loss = 1504784820.33488655\n",
            "Iteration 617, loss = 1504731220.72649884\n",
            "Iteration 618, loss = 1504676851.89666247\n",
            "Iteration 619, loss = 1504623221.13447452\n",
            "Iteration 620, loss = 1504569215.18395209\n",
            "Iteration 621, loss = 1504515254.47827983\n",
            "Iteration 622, loss = 1504461208.85159111\n",
            "Iteration 623, loss = 1504407200.34769130\n",
            "Iteration 624, loss = 1504352999.56172585\n",
            "Iteration 625, loss = 1504298795.26556206\n",
            "Iteration 626, loss = 1504244841.44884372\n",
            "Iteration 627, loss = 1504190702.26833773\n",
            "Iteration 628, loss = 1504136940.34794641\n",
            "Iteration 629, loss = 1504082784.66223383\n",
            "Iteration 630, loss = 1504029195.09104824\n",
            "Iteration 631, loss = 1503975297.29572630\n",
            "Iteration 632, loss = 1503921800.04422212\n",
            "Iteration 633, loss = 1503867643.16160846\n",
            "Iteration 634, loss = 1503813966.22115207\n",
            "Iteration 635, loss = 1503759950.50809789\n",
            "Iteration 636, loss = 1503705768.61453795\n",
            "Iteration 637, loss = 1503651933.38306618\n",
            "Iteration 638, loss = 1503597914.34565020\n",
            "Iteration 639, loss = 1503543604.34319615\n",
            "Iteration 640, loss = 1503489615.81904507\n",
            "Iteration 641, loss = 1503435965.24636650\n",
            "Iteration 642, loss = 1503381663.41654778\n",
            "Iteration 643, loss = 1503327771.88550091\n",
            "Iteration 644, loss = 1503273564.58966732\n",
            "Iteration 645, loss = 1503219715.78181529\n",
            "Iteration 646, loss = 1503165622.98853421\n",
            "Iteration 647, loss = 1503111215.31748581\n",
            "Iteration 648, loss = 1503057132.37803650\n",
            "Iteration 649, loss = 1503003171.72241664\n",
            "Iteration 650, loss = 1502949159.39692283\n",
            "Iteration 651, loss = 1502894931.75981760\n",
            "Iteration 652, loss = 1502840897.00462747\n",
            "Iteration 653, loss = 1502787047.39313006\n",
            "Iteration 654, loss = 1502733472.47223806\n",
            "Iteration 655, loss = 1502679756.87393212\n",
            "Iteration 656, loss = 1502625657.57420707\n",
            "Iteration 657, loss = 1502572094.82234979\n",
            "Iteration 658, loss = 1502518630.16337776\n",
            "Iteration 659, loss = 1502464752.94845796\n",
            "Iteration 660, loss = 1502410951.31326199\n",
            "Iteration 661, loss = 1502357364.78347850\n",
            "Iteration 662, loss = 1502303535.59910607\n",
            "Iteration 663, loss = 1502249597.48487115\n",
            "Iteration 664, loss = 1502196346.71588302\n",
            "Iteration 665, loss = 1502142211.01430202\n",
            "Iteration 666, loss = 1502088864.16858554\n",
            "Iteration 667, loss = 1502034978.75957990\n",
            "Iteration 668, loss = 1501981535.09977078\n",
            "Iteration 669, loss = 1501927905.73614907\n",
            "Iteration 670, loss = 1501874222.55158234\n",
            "Iteration 671, loss = 1501820330.70063782\n",
            "Iteration 672, loss = 1501766739.55221295\n",
            "Iteration 673, loss = 1501712816.62997699\n",
            "Iteration 674, loss = 1501658956.35988474\n",
            "Iteration 675, loss = 1501605344.39637685\n",
            "Iteration 676, loss = 1501551344.07676172\n",
            "Iteration 677, loss = 1501497579.42964625\n",
            "Iteration 678, loss = 1501443652.28783441\n",
            "Iteration 679, loss = 1501389997.57605958\n",
            "Iteration 680, loss = 1501336471.62922382\n",
            "Iteration 681, loss = 1501282540.48446012\n",
            "Iteration 682, loss = 1501228805.59218049\n",
            "Iteration 683, loss = 1501175465.96308923\n",
            "Iteration 684, loss = 1501121548.66251445\n",
            "Iteration 685, loss = 1501068225.89227438\n",
            "Iteration 686, loss = 1501014577.19591570\n",
            "Iteration 687, loss = 1500960864.43917298\n",
            "Iteration 688, loss = 1500907043.29688907\n",
            "Iteration 689, loss = 1500853445.92057371\n",
            "Iteration 690, loss = 1500799615.20736933\n",
            "Iteration 691, loss = 1500745790.53594637\n",
            "Iteration 692, loss = 1500692058.06282687\n",
            "Iteration 693, loss = 1500638422.86096144\n",
            "Iteration 694, loss = 1500584390.91204119\n",
            "Iteration 695, loss = 1500530722.63819170\n",
            "Iteration 696, loss = 1500477146.15507627\n",
            "Iteration 697, loss = 1500423534.26743269\n",
            "Iteration 698, loss = 1500369562.36538076\n",
            "Iteration 699, loss = 1500316297.27887988\n",
            "Iteration 700, loss = 1500262695.90275073\n",
            "Iteration 701, loss = 1500209287.89049506\n",
            "Iteration 702, loss = 1500155774.83676624\n",
            "Iteration 703, loss = 1500102419.71186733\n",
            "Iteration 704, loss = 1500048993.80318689\n",
            "Iteration 705, loss = 1499995595.91668630\n",
            "Iteration 706, loss = 1499941497.05117369\n",
            "Iteration 707, loss = 1499888708.51054907\n",
            "Iteration 708, loss = 1499834559.86527085\n",
            "Iteration 709, loss = 1499780943.54764080\n",
            "Iteration 710, loss = 1499727431.01372695\n",
            "Iteration 711, loss = 1499673640.44068480\n",
            "Iteration 712, loss = 1499619799.20835257\n",
            "Iteration 713, loss = 1499566025.86117291\n",
            "Iteration 714, loss = 1499512339.88206816\n",
            "Iteration 715, loss = 1499458838.02503610\n",
            "Iteration 716, loss = 1499404483.99635696\n",
            "Iteration 717, loss = 1499350455.65499139\n",
            "Iteration 718, loss = 1499297295.04152203\n",
            "Iteration 719, loss = 1499242978.34164882\n",
            "Iteration 720, loss = 1499188799.97515893\n",
            "Iteration 721, loss = 1499135065.28818607\n",
            "Iteration 722, loss = 1499080872.59569478\n",
            "Iteration 723, loss = 1499026656.04797792\n",
            "Iteration 724, loss = 1498972273.80109358\n",
            "Iteration 725, loss = 1498918062.61472893\n",
            "Iteration 726, loss = 1498863895.78826332\n",
            "Iteration 727, loss = 1498809419.41563559\n",
            "Iteration 728, loss = 1498755137.15604186\n",
            "Iteration 729, loss = 1498700582.81624961\n",
            "Iteration 730, loss = 1498646608.16283107\n",
            "Iteration 731, loss = 1498592129.38846922\n",
            "Iteration 732, loss = 1498537767.64848137\n",
            "Iteration 733, loss = 1498483592.23409986\n",
            "Iteration 734, loss = 1498429385.78631830\n",
            "Iteration 735, loss = 1498375112.59797287\n",
            "Iteration 736, loss = 1498320973.40498495\n",
            "Iteration 737, loss = 1498266572.86734414\n",
            "Iteration 738, loss = 1498212823.62823939\n",
            "Iteration 739, loss = 1498158793.75802302\n",
            "Iteration 740, loss = 1498104855.03316283\n",
            "Iteration 741, loss = 1498050864.59586191\n",
            "Iteration 742, loss = 1497996909.00873280\n",
            "Iteration 743, loss = 1497943451.76596928\n",
            "Iteration 744, loss = 1497889834.89796472\n",
            "Iteration 745, loss = 1497836304.31699991\n",
            "Iteration 746, loss = 1497782474.53513193\n",
            "Iteration 747, loss = 1497729110.19952846\n",
            "Iteration 748, loss = 1497675970.95554495\n",
            "Iteration 749, loss = 1497622343.12288022\n",
            "Iteration 750, loss = 1497568548.57692838\n",
            "Iteration 751, loss = 1497515334.29850912\n",
            "Iteration 752, loss = 1497462004.33003426\n",
            "Iteration 753, loss = 1497407985.11544466\n",
            "Iteration 754, loss = 1497354849.88165736\n",
            "Iteration 755, loss = 1497301059.13831496\n",
            "Iteration 756, loss = 1497247776.15074658\n",
            "Iteration 757, loss = 1497194174.82673216\n",
            "Iteration 758, loss = 1497140302.65648317\n",
            "Iteration 759, loss = 1497086984.00645661\n",
            "Iteration 760, loss = 1497033293.61521864\n",
            "Iteration 761, loss = 1496979612.34974170\n",
            "Iteration 762, loss = 1496925989.81234479\n",
            "Iteration 763, loss = 1496872259.05266309\n",
            "Iteration 764, loss = 1496818353.08206582\n",
            "Iteration 765, loss = 1496764937.25869823\n",
            "Iteration 766, loss = 1496711151.54622507\n",
            "Iteration 767, loss = 1496657484.47176862\n",
            "Iteration 768, loss = 1496603557.89527893\n",
            "Iteration 769, loss = 1496550081.55546045\n",
            "Iteration 770, loss = 1496496237.09279752\n",
            "Iteration 771, loss = 1496442267.11842084\n",
            "Iteration 772, loss = 1496388703.21936893\n",
            "Iteration 773, loss = 1496334981.02125573\n",
            "Iteration 774, loss = 1496281109.64360023\n",
            "Iteration 775, loss = 1496227341.99761486\n",
            "Iteration 776, loss = 1496173542.47160745\n",
            "Iteration 777, loss = 1496119698.82093167\n",
            "Iteration 778, loss = 1496065781.51019216\n",
            "Iteration 779, loss = 1496011902.92428994\n",
            "Iteration 780, loss = 1495957931.76788521\n",
            "Iteration 781, loss = 1495903882.48186374\n",
            "Iteration 782, loss = 1495850044.51918292\n",
            "Iteration 783, loss = 1495796070.84229755\n",
            "Iteration 784, loss = 1495742421.27445459\n",
            "Iteration 785, loss = 1495688441.13797736\n",
            "Iteration 786, loss = 1495634738.27455282\n",
            "Iteration 787, loss = 1495580752.71668506\n",
            "Iteration 788, loss = 1495527117.81929612\n",
            "Iteration 789, loss = 1495473380.67817616\n",
            "Iteration 790, loss = 1495419459.08805633\n",
            "Iteration 791, loss = 1495365507.93206882\n",
            "Iteration 792, loss = 1495311890.18193436\n",
            "Iteration 793, loss = 1495257846.39371300\n",
            "Iteration 794, loss = 1495204081.45193172\n",
            "Iteration 795, loss = 1495150226.93289495\n",
            "Iteration 796, loss = 1495096498.41259098\n",
            "Iteration 797, loss = 1495042893.69104028\n",
            "Iteration 798, loss = 1494988938.21700835\n",
            "Iteration 799, loss = 1494935056.59877348\n",
            "Iteration 800, loss = 1494881673.24944520\n",
            "Iteration 801, loss = 1494827884.09598541\n",
            "Iteration 802, loss = 1494773890.30379725\n",
            "Iteration 803, loss = 1494720276.80787420\n",
            "Iteration 804, loss = 1494666475.01344204\n",
            "Iteration 805, loss = 1494612820.91377950\n",
            "Iteration 806, loss = 1494559516.24851990\n",
            "Iteration 807, loss = 1494505413.64564538\n",
            "Iteration 808, loss = 1494452147.65550685\n",
            "Iteration 809, loss = 1494398716.67686486\n",
            "Iteration 810, loss = 1494345371.11772728\n",
            "Iteration 811, loss = 1494291821.55239439\n",
            "Iteration 812, loss = 1494238500.23519206\n",
            "Iteration 813, loss = 1494184838.68726468\n",
            "Iteration 814, loss = 1494131381.84883738\n",
            "Iteration 815, loss = 1494077935.36374855\n",
            "Iteration 816, loss = 1494024243.64495111\n",
            "Iteration 817, loss = 1493970425.74079490\n",
            "Iteration 818, loss = 1493916808.40520287\n",
            "Iteration 819, loss = 1493863466.02116871\n",
            "Iteration 820, loss = 1493809460.82749557\n",
            "Iteration 821, loss = 1493755966.72339797\n",
            "Iteration 822, loss = 1493702596.11815381\n",
            "Iteration 823, loss = 1493649274.76438189\n",
            "Iteration 824, loss = 1493595515.57310319\n",
            "Iteration 825, loss = 1493542233.62729120\n",
            "Iteration 826, loss = 1493488483.93890190\n",
            "Iteration 827, loss = 1493434783.64161968\n",
            "Iteration 828, loss = 1493380963.34293842\n",
            "Iteration 829, loss = 1493326642.89687347\n",
            "Iteration 830, loss = 1493273329.14788628\n",
            "Iteration 831, loss = 1493218845.83214521\n",
            "Iteration 832, loss = 1493165188.37745190\n",
            "Iteration 833, loss = 1493111070.20829344\n",
            "Iteration 834, loss = 1493057041.60112286\n",
            "Iteration 835, loss = 1493003544.20379901\n",
            "Iteration 836, loss = 1492949035.17378688\n",
            "Iteration 837, loss = 1492895202.46296453\n",
            "Iteration 838, loss = 1492841476.95261288\n",
            "Iteration 839, loss = 1492787310.34547162\n",
            "Iteration 840, loss = 1492733557.41587353\n",
            "Iteration 841, loss = 1492679550.43804479\n",
            "Iteration 842, loss = 1492625703.35877204\n",
            "Iteration 843, loss = 1492572162.60400486\n",
            "Iteration 844, loss = 1492518428.79333925\n",
            "Iteration 845, loss = 1492464840.31335640\n",
            "Iteration 846, loss = 1492411083.15079927\n",
            "Iteration 847, loss = 1492357310.41855264\n",
            "Iteration 848, loss = 1492303596.78746581\n",
            "Iteration 849, loss = 1492249606.60494280\n",
            "Iteration 850, loss = 1492196276.36305928\n",
            "Iteration 851, loss = 1492142373.40050602\n",
            "Iteration 852, loss = 1492088781.10480857\n",
            "Iteration 853, loss = 1492034970.22939014\n",
            "Iteration 854, loss = 1491981668.92093849\n",
            "Iteration 855, loss = 1491927949.96384478\n",
            "Iteration 856, loss = 1491874649.80689883\n",
            "Iteration 857, loss = 1491821278.22422671\n",
            "Iteration 858, loss = 1491767498.65080285\n",
            "Iteration 859, loss = 1491714591.38951993\n",
            "Iteration 860, loss = 1491661223.70416498\n",
            "Iteration 861, loss = 1491607675.14769220\n",
            "Iteration 862, loss = 1491554465.19320393\n",
            "Iteration 863, loss = 1491501344.23071790\n",
            "Iteration 864, loss = 1491447897.22518587\n",
            "Iteration 865, loss = 1491394600.24214458\n",
            "Iteration 866, loss = 1491341593.03950357\n",
            "Iteration 867, loss = 1491287852.53665805\n",
            "Iteration 868, loss = 1491234877.97590089\n",
            "Iteration 869, loss = 1491181175.98292255\n",
            "Iteration 870, loss = 1491127973.06336355\n",
            "Iteration 871, loss = 1491074561.62743950\n",
            "Iteration 872, loss = 1491021081.57625151\n",
            "Iteration 873, loss = 1490967575.57623458\n",
            "Iteration 874, loss = 1490914191.44441843\n",
            "Iteration 875, loss = 1490860568.70697927\n",
            "Iteration 876, loss = 1490807032.65010619\n",
            "Iteration 877, loss = 1490753652.16383004\n",
            "Iteration 878, loss = 1490699903.29480982\n",
            "Iteration 879, loss = 1490646688.57055330\n",
            "Iteration 880, loss = 1490592769.96216059\n",
            "Iteration 881, loss = 1490539310.51703286\n",
            "Iteration 882, loss = 1490485797.69055223\n",
            "Iteration 883, loss = 1490432393.67009306\n",
            "Iteration 884, loss = 1490378908.42632294\n",
            "Iteration 885, loss = 1490325575.07849979\n",
            "Iteration 886, loss = 1490271667.45836329\n",
            "Iteration 887, loss = 1490218514.00804186\n",
            "Iteration 888, loss = 1490165168.41878033\n",
            "Iteration 889, loss = 1490111357.77721334\n",
            "Iteration 890, loss = 1490058174.15943456\n",
            "Iteration 891, loss = 1490004354.44834876\n",
            "Iteration 892, loss = 1489950866.54968071\n",
            "Iteration 893, loss = 1489896935.84783006\n",
            "Iteration 894, loss = 1489843246.69903779\n",
            "Iteration 895, loss = 1489789944.94069815\n",
            "Iteration 896, loss = 1489735451.84482670\n",
            "Iteration 897, loss = 1489682050.91959071\n",
            "Iteration 898, loss = 1489627813.17879558\n",
            "Iteration 899, loss = 1489574169.10517073\n",
            "Iteration 900, loss = 1489520346.87637568\n",
            "Iteration 901, loss = 1489466716.65565395\n",
            "Iteration 902, loss = 1489412487.76332474\n",
            "Iteration 903, loss = 1489359017.13163543\n",
            "Iteration 904, loss = 1489305225.46433783\n",
            "Iteration 905, loss = 1489251591.28921628\n",
            "Iteration 906, loss = 1489198028.51304913\n",
            "Iteration 907, loss = 1489144579.08087492\n",
            "Iteration 908, loss = 1489090459.23202085\n",
            "Iteration 909, loss = 1489037403.41011786\n",
            "Iteration 910, loss = 1488983903.60135436\n",
            "Iteration 911, loss = 1488930078.62719297\n",
            "Iteration 912, loss = 1488876989.88674378\n",
            "Iteration 913, loss = 1488823284.96878982\n",
            "Iteration 914, loss = 1488770423.09723663\n",
            "Iteration 915, loss = 1488716481.79131532\n",
            "Iteration 916, loss = 1488663144.50743747\n",
            "Iteration 917, loss = 1488609883.28828168\n",
            "Iteration 918, loss = 1488556246.99424267\n",
            "Iteration 919, loss = 1488502582.05204320\n",
            "Iteration 920, loss = 1488449068.59597349\n",
            "Iteration 921, loss = 1488395609.92897391\n",
            "Iteration 922, loss = 1488342146.64488530\n",
            "Iteration 923, loss = 1488288517.12925363\n",
            "Iteration 924, loss = 1488234982.72170901\n",
            "Iteration 925, loss = 1488182032.71753669\n",
            "Iteration 926, loss = 1488128297.71830297\n",
            "Iteration 927, loss = 1488074927.80663729\n",
            "Iteration 928, loss = 1488021716.94063401\n",
            "Iteration 929, loss = 1487968119.24863291\n",
            "Iteration 930, loss = 1487914957.87233448\n",
            "Iteration 931, loss = 1487861119.96486735\n",
            "Iteration 932, loss = 1487807668.95703650\n",
            "Iteration 933, loss = 1487754312.83933306\n",
            "Iteration 934, loss = 1487700461.79930758\n",
            "Iteration 935, loss = 1487647519.13049006\n",
            "Iteration 936, loss = 1487593940.32729292\n",
            "Iteration 937, loss = 1487540527.16152692\n",
            "Iteration 938, loss = 1487487538.40700102\n",
            "Iteration 939, loss = 1487434327.39765573\n",
            "Iteration 940, loss = 1487381008.44917250\n",
            "Iteration 941, loss = 1487327968.16829062\n",
            "Iteration 942, loss = 1487274648.10405946\n",
            "Iteration 943, loss = 1487221292.97547984\n",
            "Iteration 944, loss = 1487167922.91874528\n",
            "Iteration 945, loss = 1487114404.11795545\n",
            "Iteration 946, loss = 1487060751.81491208\n",
            "Iteration 947, loss = 1487007552.90343642\n",
            "Iteration 948, loss = 1486954018.84942818\n",
            "Iteration 949, loss = 1486900590.78796291\n",
            "Iteration 950, loss = 1486847008.20984674\n",
            "Iteration 951, loss = 1486793854.71075034\n",
            "Iteration 952, loss = 1486741050.54056621\n",
            "Iteration 953, loss = 1486687606.51123071\n",
            "Iteration 954, loss = 1486634415.00620222\n",
            "Iteration 955, loss = 1486581534.90326905\n",
            "Iteration 956, loss = 1486528510.30205011\n",
            "Iteration 957, loss = 1486475366.06624746\n",
            "Iteration 958, loss = 1486422185.89564753\n",
            "Iteration 959, loss = 1486369125.82053447\n",
            "Iteration 960, loss = 1486316029.52265859\n",
            "Iteration 961, loss = 1486262795.64101839\n",
            "Iteration 962, loss = 1486209517.47624254\n",
            "Iteration 963, loss = 1486156339.28355026\n",
            "Iteration 964, loss = 1486102903.28618693\n",
            "Iteration 965, loss = 1486049684.93581963\n",
            "Iteration 966, loss = 1485996426.89537024\n",
            "Iteration 967, loss = 1485942884.35441732\n",
            "Iteration 968, loss = 1485889475.00702143\n",
            "Iteration 969, loss = 1485835848.26892424\n",
            "Iteration 970, loss = 1485782408.09746718\n",
            "Iteration 971, loss = 1485729258.59559751\n",
            "Iteration 972, loss = 1485675439.74220157\n",
            "Iteration 973, loss = 1485622067.69708323\n",
            "Iteration 974, loss = 1485568424.12345791\n",
            "Iteration 975, loss = 1485515113.08321428\n",
            "Iteration 976, loss = 1485461705.24486780\n",
            "Iteration 977, loss = 1485407886.08837318\n",
            "Iteration 978, loss = 1485354453.03384995\n",
            "Iteration 979, loss = 1485300875.17754960\n",
            "Iteration 980, loss = 1485247453.86278558\n",
            "Iteration 981, loss = 1485193767.04127645\n",
            "Iteration 982, loss = 1485140166.15661669\n",
            "Iteration 983, loss = 1485086769.71167040\n",
            "Iteration 984, loss = 1485033181.35484052\n",
            "Iteration 985, loss = 1484979571.79143238\n",
            "Iteration 986, loss = 1484926281.65587497\n",
            "Iteration 987, loss = 1484872912.14462996\n",
            "Iteration 988, loss = 1484819186.17918944\n",
            "Iteration 989, loss = 1484765993.91431236\n",
            "Iteration 990, loss = 1484712557.96480322\n",
            "Iteration 991, loss = 1484659238.45324135\n",
            "Iteration 992, loss = 1484606158.31816888\n",
            "Iteration 993, loss = 1484552735.85133839\n",
            "Iteration 994, loss = 1484499511.61560512\n",
            "Iteration 995, loss = 1484446193.98995328\n",
            "Iteration 996, loss = 1484393051.65788150\n",
            "Iteration 997, loss = 1484339805.99839115\n",
            "Iteration 998, loss = 1484286310.45542836\n",
            "Iteration 999, loss = 1484233062.50577092\n",
            "Iteration 1000, loss = 1484179558.24169898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1510867605.62256718\n",
            "Iteration 2, loss = 139704615.32895932\n",
            "Iteration 3, loss = 267409585.57985255\n",
            "Iteration 4, loss = 98644181.39067930\n",
            "Iteration 5, loss = 102220763.88031827\n",
            "Iteration 6, loss = 97590772.97921479\n",
            "Iteration 7, loss = 100322635.53416063\n",
            "Iteration 8, loss = 97998729.32835200\n",
            "Iteration 9, loss = 99259301.83912547\n",
            "Iteration 10, loss = 100172682.77939902\n",
            "Iteration 11, loss = 98247849.12063666\n",
            "Iteration 12, loss = 97963841.20988297\n",
            "Iteration 13, loss = 98297272.52789935\n",
            "Iteration 14, loss = 99578792.94181797\n",
            "Iteration 15, loss = 101461317.98438446\n",
            "Iteration 16, loss = 99146250.60709786\n",
            "Iteration 17, loss = 98470861.35648252\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538774296.71858454\n",
            "Iteration 2, loss = 1538622680.26954794\n",
            "Iteration 3, loss = 1538467488.82182431\n",
            "Iteration 4, loss = 1538338678.80278540\n",
            "Iteration 5, loss = 1538255551.95166397\n",
            "Iteration 6, loss = 1538194410.59074521\n",
            "Iteration 7, loss = 1538136773.20883060\n",
            "Iteration 8, loss = 1538079883.38261271\n",
            "Iteration 9, loss = 1538022136.18452001\n",
            "Iteration 10, loss = 1537964734.94918418\n",
            "Iteration 11, loss = 1537906494.70775938\n",
            "Iteration 12, loss = 1537848550.04005289\n",
            "Iteration 13, loss = 1537790032.02035046\n",
            "Iteration 14, loss = 1537731692.82953572\n",
            "Iteration 15, loss = 1537673843.82877135\n",
            "Iteration 16, loss = 1537615082.28484535\n",
            "Iteration 17, loss = 1537557186.74605584\n",
            "Iteration 18, loss = 1537498866.17319250\n",
            "Iteration 19, loss = 1537441116.43262315\n",
            "Iteration 20, loss = 1537383311.99235535\n",
            "Iteration 21, loss = 1537325321.93578768\n",
            "Iteration 22, loss = 1537267521.80354118\n",
            "Iteration 23, loss = 1537210016.76599050\n",
            "Iteration 24, loss = 1537152543.71852565\n",
            "Iteration 25, loss = 1537095103.92895699\n",
            "Iteration 26, loss = 1537038010.06186295\n",
            "Iteration 27, loss = 1536980802.25904441\n",
            "Iteration 28, loss = 1536923962.28998971\n",
            "Iteration 29, loss = 1536867015.19404364\n",
            "Iteration 30, loss = 1536810812.49201083\n",
            "Iteration 31, loss = 1536754285.96937418\n",
            "Iteration 32, loss = 1536697648.04915667\n",
            "Iteration 33, loss = 1536641341.93450332\n",
            "Iteration 34, loss = 1536585350.47146082\n",
            "Iteration 35, loss = 1536529110.07777047\n",
            "Iteration 36, loss = 1536472304.52420092\n",
            "Iteration 37, loss = 1536416579.95036650\n",
            "Iteration 38, loss = 1536360202.28843236\n",
            "Iteration 39, loss = 1536303578.16270661\n",
            "Iteration 40, loss = 1536247457.31390834\n",
            "Iteration 41, loss = 1536190882.52092624\n",
            "Iteration 42, loss = 1536134811.17467737\n",
            "Iteration 43, loss = 1536078309.99100351\n",
            "Iteration 44, loss = 1536022244.56306362\n",
            "Iteration 45, loss = 1535965694.17917085\n",
            "Iteration 46, loss = 1535909874.98212671\n",
            "Iteration 47, loss = 1535853465.57347655\n",
            "Iteration 48, loss = 1535797544.80079079\n",
            "Iteration 49, loss = 1535741626.62692785\n",
            "Iteration 50, loss = 1535685893.69353604\n",
            "Iteration 51, loss = 1535629702.08674788\n",
            "Iteration 52, loss = 1535574021.57623625\n",
            "Iteration 53, loss = 1535517957.82166553\n",
            "Iteration 54, loss = 1535462199.08725071\n",
            "Iteration 55, loss = 1535406297.86262226\n",
            "Iteration 56, loss = 1535350167.98342824\n",
            "Iteration 57, loss = 1535294161.83900881\n",
            "Iteration 58, loss = 1535238266.85348153\n",
            "Iteration 59, loss = 1535182387.09150958\n",
            "Iteration 60, loss = 1535126372.89517617\n",
            "Iteration 61, loss = 1535070261.27553844\n",
            "Iteration 62, loss = 1535014430.32730746\n",
            "Iteration 63, loss = 1534958778.91517138\n",
            "Iteration 64, loss = 1534903110.42255235\n",
            "Iteration 65, loss = 1534847267.11911130\n",
            "Iteration 66, loss = 1534791675.03310204\n",
            "Iteration 67, loss = 1534735889.39771748\n",
            "Iteration 68, loss = 1534680571.47460103\n",
            "Iteration 69, loss = 1534624799.63516760\n",
            "Iteration 70, loss = 1534569002.99454498\n",
            "Iteration 71, loss = 1534513492.69921374\n",
            "Iteration 72, loss = 1534457686.75319409\n",
            "Iteration 73, loss = 1534401939.85015607\n",
            "Iteration 74, loss = 1534346407.13859010\n",
            "Iteration 75, loss = 1534290773.75518990\n",
            "Iteration 76, loss = 1534234953.45546746\n",
            "Iteration 77, loss = 1534179578.11359358\n",
            "Iteration 78, loss = 1534123762.74299979\n",
            "Iteration 79, loss = 1534068435.91646147\n",
            "Iteration 80, loss = 1534012608.46461177\n",
            "Iteration 81, loss = 1533957076.38305831\n",
            "Iteration 82, loss = 1533901584.92552567\n",
            "Iteration 83, loss = 1533845858.72415018\n",
            "Iteration 84, loss = 1533790702.89663649\n",
            "Iteration 85, loss = 1533735097.27085805\n",
            "Iteration 86, loss = 1533679826.41573977\n",
            "Iteration 87, loss = 1533624505.66356564\n",
            "Iteration 88, loss = 1533569148.66717410\n",
            "Iteration 89, loss = 1533514275.12534451\n",
            "Iteration 90, loss = 1533458522.29579687\n",
            "Iteration 91, loss = 1533403452.52243733\n",
            "Iteration 92, loss = 1533348322.76857829\n",
            "Iteration 93, loss = 1533293291.51320887\n",
            "Iteration 94, loss = 1533237877.09305143\n",
            "Iteration 95, loss = 1533182645.71242666\n",
            "Iteration 96, loss = 1533127878.85944152\n",
            "Iteration 97, loss = 1533072717.82751036\n",
            "Iteration 98, loss = 1533017627.49529314\n",
            "Iteration 99, loss = 1532962779.65425396\n",
            "Iteration 100, loss = 1532908017.71656299\n",
            "Iteration 101, loss = 1532852665.22656298\n",
            "Iteration 102, loss = 1532797863.31877160\n",
            "Iteration 103, loss = 1532742962.90602088\n",
            "Iteration 104, loss = 1532687983.33579302\n",
            "Iteration 105, loss = 1532632654.45020556\n",
            "Iteration 106, loss = 1532577816.54878187\n",
            "Iteration 107, loss = 1532522388.88609171\n",
            "Iteration 108, loss = 1532467271.85629010\n",
            "Iteration 109, loss = 1532412268.54832864\n",
            "Iteration 110, loss = 1532356821.55624270\n",
            "Iteration 111, loss = 1532301370.50996661\n",
            "Iteration 112, loss = 1532246094.06483626\n",
            "Iteration 113, loss = 1532191129.93443608\n",
            "Iteration 114, loss = 1532135559.25046968\n",
            "Iteration 115, loss = 1532080227.06024408\n",
            "Iteration 116, loss = 1532024744.46109080\n",
            "Iteration 117, loss = 1531969752.49416351\n",
            "Iteration 118, loss = 1531914207.79623127\n",
            "Iteration 119, loss = 1531859238.22979593\n",
            "Iteration 120, loss = 1531804497.38223410\n",
            "Iteration 121, loss = 1531749069.67715573\n",
            "Iteration 122, loss = 1531694140.49771476\n",
            "Iteration 123, loss = 1531639330.53073168\n",
            "Iteration 124, loss = 1531584661.45221019\n",
            "Iteration 125, loss = 1531529668.08482623\n",
            "Iteration 126, loss = 1531474727.64278245\n",
            "Iteration 127, loss = 1531419844.23185754\n",
            "Iteration 128, loss = 1531365241.67375469\n",
            "Iteration 129, loss = 1531310400.52006984\n",
            "Iteration 130, loss = 1531255515.49022579\n",
            "Iteration 131, loss = 1531201066.78311682\n",
            "Iteration 132, loss = 1531145932.94664955\n",
            "Iteration 133, loss = 1531091243.61220288\n",
            "Iteration 134, loss = 1531036616.87439752\n",
            "Iteration 135, loss = 1530981784.95290947\n",
            "Iteration 136, loss = 1530926558.32476258\n",
            "Iteration 137, loss = 1530872027.92898965\n",
            "Iteration 138, loss = 1530817163.44690299\n",
            "Iteration 139, loss = 1530761958.61532664\n",
            "Iteration 140, loss = 1530707305.04989862\n",
            "Iteration 141, loss = 1530652470.17553568\n",
            "Iteration 142, loss = 1530597787.08302498\n",
            "Iteration 143, loss = 1530543083.45730281\n",
            "Iteration 144, loss = 1530488091.56358314\n",
            "Iteration 145, loss = 1530433371.58962870\n",
            "Iteration 146, loss = 1530378633.25677848\n",
            "Iteration 147, loss = 1530323570.19893408\n",
            "Iteration 148, loss = 1530268487.56060576\n",
            "Iteration 149, loss = 1530213838.22789598\n",
            "Iteration 150, loss = 1530158574.03939867\n",
            "Iteration 151, loss = 1530103531.35817552\n",
            "Iteration 152, loss = 1530048483.35873747\n",
            "Iteration 153, loss = 1529993516.06965518\n",
            "Iteration 154, loss = 1529938471.25595975\n",
            "Iteration 155, loss = 1529883562.85457611\n",
            "Iteration 156, loss = 1529828301.97888470\n",
            "Iteration 157, loss = 1529773537.69462204\n",
            "Iteration 158, loss = 1529718646.33169127\n",
            "Iteration 159, loss = 1529663412.10609961\n",
            "Iteration 160, loss = 1529608670.21531272\n",
            "Iteration 161, loss = 1529553546.60454965\n",
            "Iteration 162, loss = 1529498884.09909773\n",
            "Iteration 163, loss = 1529443884.93861818\n",
            "Iteration 164, loss = 1529389254.85850453\n",
            "Iteration 165, loss = 1529334159.63928914\n",
            "Iteration 166, loss = 1529279507.67761421\n",
            "Iteration 167, loss = 1529224826.00241804\n",
            "Iteration 168, loss = 1529170067.82087541\n",
            "Iteration 169, loss = 1529115277.92088294\n",
            "Iteration 170, loss = 1529060837.75771236\n",
            "Iteration 171, loss = 1529006192.29141378\n",
            "Iteration 172, loss = 1528951474.49013519\n",
            "Iteration 173, loss = 1528897511.72822165\n",
            "Iteration 174, loss = 1528842649.75975299\n",
            "Iteration 175, loss = 1528788300.41515970\n",
            "Iteration 176, loss = 1528733898.03742146\n",
            "Iteration 177, loss = 1528679427.66864872\n",
            "Iteration 178, loss = 1528624913.62269330\n",
            "Iteration 179, loss = 1528570358.29063034\n",
            "Iteration 180, loss = 1528515619.19271064\n",
            "Iteration 181, loss = 1528460874.98498678\n",
            "Iteration 182, loss = 1528406500.50158262\n",
            "Iteration 183, loss = 1528351720.21355200\n",
            "Iteration 184, loss = 1528296676.60243368\n",
            "Iteration 185, loss = 1528242100.10746312\n",
            "Iteration 186, loss = 1528187117.55035901\n",
            "Iteration 187, loss = 1528132457.98002601\n",
            "Iteration 188, loss = 1528077588.52489686\n",
            "Iteration 189, loss = 1528022576.81133533\n",
            "Iteration 190, loss = 1527967866.58416653\n",
            "Iteration 191, loss = 1527913222.34013462\n",
            "Iteration 192, loss = 1527858488.17674565\n",
            "Iteration 193, loss = 1527803931.27450800\n",
            "Iteration 194, loss = 1527749272.38848066\n",
            "Iteration 195, loss = 1527694897.37756753\n",
            "Iteration 196, loss = 1527640214.59240961\n",
            "Iteration 197, loss = 1527585674.77354002\n",
            "Iteration 198, loss = 1527531090.79476810\n",
            "Iteration 199, loss = 1527476497.63615417\n",
            "Iteration 200, loss = 1527421739.86461735\n",
            "Iteration 201, loss = 1527367155.18152738\n",
            "Iteration 202, loss = 1527312478.94628334\n",
            "Iteration 203, loss = 1527257905.67083478\n",
            "Iteration 204, loss = 1527202943.14503121\n",
            "Iteration 205, loss = 1527148422.44241261\n",
            "Iteration 206, loss = 1527093936.14610648\n",
            "Iteration 207, loss = 1527039104.56636643\n",
            "Iteration 208, loss = 1526984196.62494063\n",
            "Iteration 209, loss = 1526929461.73238063\n",
            "Iteration 210, loss = 1526874586.70791984\n",
            "Iteration 211, loss = 1526820003.80188870\n",
            "Iteration 212, loss = 1526764766.72063804\n",
            "Iteration 213, loss = 1526710416.93564367\n",
            "Iteration 214, loss = 1526655248.95175791\n",
            "Iteration 215, loss = 1526600779.89182949\n",
            "Iteration 216, loss = 1526545677.86994481\n",
            "Iteration 217, loss = 1526491074.63181472\n",
            "Iteration 218, loss = 1526436378.99137449\n",
            "Iteration 219, loss = 1526381466.31680608\n",
            "Iteration 220, loss = 1526326728.22239566\n",
            "Iteration 221, loss = 1526272226.93289876\n",
            "Iteration 222, loss = 1526217572.48567700\n",
            "Iteration 223, loss = 1526163206.56675696\n",
            "Iteration 224, loss = 1526108606.28044510\n",
            "Iteration 225, loss = 1526054075.23507524\n",
            "Iteration 226, loss = 1525999627.22499776\n",
            "Iteration 227, loss = 1525945190.47354078\n",
            "Iteration 228, loss = 1525890706.06954741\n",
            "Iteration 229, loss = 1525835919.77916098\n",
            "Iteration 230, loss = 1525781590.35865951\n",
            "Iteration 231, loss = 1525726703.55020499\n",
            "Iteration 232, loss = 1525672284.14842939\n",
            "Iteration 233, loss = 1525617672.96441722\n",
            "Iteration 234, loss = 1525562971.89875650\n",
            "Iteration 235, loss = 1525508355.94426489\n",
            "Iteration 236, loss = 1525453518.35315204\n",
            "Iteration 237, loss = 1525399347.08629012\n",
            "Iteration 238, loss = 1525344393.21498227\n",
            "Iteration 239, loss = 1525289885.10240531\n",
            "Iteration 240, loss = 1525235443.07571435\n",
            "Iteration 241, loss = 1525180613.60589957\n",
            "Iteration 242, loss = 1525126586.52960730\n",
            "Iteration 243, loss = 1525071884.18865514\n",
            "Iteration 244, loss = 1525017283.29815102\n",
            "Iteration 245, loss = 1524963123.01526093\n",
            "Iteration 246, loss = 1524908501.89844990\n",
            "Iteration 247, loss = 1524853931.37861800\n",
            "Iteration 248, loss = 1524799408.96309996\n",
            "Iteration 249, loss = 1524744783.36636019\n",
            "Iteration 250, loss = 1524690166.13019490\n",
            "Iteration 251, loss = 1524635522.06735659\n",
            "Iteration 252, loss = 1524580186.11047363\n",
            "Iteration 253, loss = 1524526161.39390922\n",
            "Iteration 254, loss = 1524471252.11785579\n",
            "Iteration 255, loss = 1524416457.93778443\n",
            "Iteration 256, loss = 1524362218.04413581\n",
            "Iteration 257, loss = 1524307672.02882314\n",
            "Iteration 258, loss = 1524252786.34829545\n",
            "Iteration 259, loss = 1524198306.82606053\n",
            "Iteration 260, loss = 1524143900.35258865\n",
            "Iteration 261, loss = 1524089090.09889913\n",
            "Iteration 262, loss = 1524034581.22220874\n",
            "Iteration 263, loss = 1523980015.53955245\n",
            "Iteration 264, loss = 1523925297.02125239\n",
            "Iteration 265, loss = 1523870787.91480803\n",
            "Iteration 266, loss = 1523816268.46475554\n",
            "Iteration 267, loss = 1523761849.76447201\n",
            "Iteration 268, loss = 1523707076.74735236\n",
            "Iteration 269, loss = 1523652934.67610216\n",
            "Iteration 270, loss = 1523598584.40073204\n",
            "Iteration 271, loss = 1523544172.00023627\n",
            "Iteration 272, loss = 1523489972.80228305\n",
            "Iteration 273, loss = 1523435844.60335588\n",
            "Iteration 274, loss = 1523381722.98772478\n",
            "Iteration 275, loss = 1523327653.74461722\n",
            "Iteration 276, loss = 1523273367.86601067\n",
            "Iteration 277, loss = 1523219362.17325091\n",
            "Iteration 278, loss = 1523165114.62694025\n",
            "Iteration 279, loss = 1523110704.49059319\n",
            "Iteration 280, loss = 1523056432.16729617\n",
            "Iteration 281, loss = 1523002332.23017216\n",
            "Iteration 282, loss = 1522947707.83271599\n",
            "Iteration 283, loss = 1522893850.75675964\n",
            "Iteration 284, loss = 1522839041.18315053\n",
            "Iteration 285, loss = 1522785072.66778708\n",
            "Iteration 286, loss = 1522730760.38309121\n",
            "Iteration 287, loss = 1522676664.72372460\n",
            "Iteration 288, loss = 1522622065.22944736\n",
            "Iteration 289, loss = 1522567682.82268429\n",
            "Iteration 290, loss = 1522513547.35907412\n",
            "Iteration 291, loss = 1522458879.14501953\n",
            "Iteration 292, loss = 1522404814.15811777\n",
            "Iteration 293, loss = 1522349667.92597818\n",
            "Iteration 294, loss = 1522295098.08277392\n",
            "Iteration 295, loss = 1522240348.98790121\n",
            "Iteration 296, loss = 1522185398.90601921\n",
            "Iteration 297, loss = 1522130630.55001640\n",
            "Iteration 298, loss = 1522075746.71150208\n",
            "Iteration 299, loss = 1522020818.77555060\n",
            "Iteration 300, loss = 1521966171.15807700\n",
            "Iteration 301, loss = 1521911133.28736520\n",
            "Iteration 302, loss = 1521856808.15871668\n",
            "Iteration 303, loss = 1521802396.99985099\n",
            "Iteration 304, loss = 1521747665.78212190\n",
            "Iteration 305, loss = 1521693351.60218358\n",
            "Iteration 306, loss = 1521638927.67431045\n",
            "Iteration 307, loss = 1521584692.79223037\n",
            "Iteration 308, loss = 1521530295.15229487\n",
            "Iteration 309, loss = 1521475966.01139665\n",
            "Iteration 310, loss = 1521421479.44866180\n",
            "Iteration 311, loss = 1521367241.39639235\n",
            "Iteration 312, loss = 1521313041.04778242\n",
            "Iteration 313, loss = 1521258902.44283509\n",
            "Iteration 314, loss = 1521204542.87997723\n",
            "Iteration 315, loss = 1521150420.41435075\n",
            "Iteration 316, loss = 1521096004.25717139\n",
            "Iteration 317, loss = 1521042034.30579901\n",
            "Iteration 318, loss = 1520987701.34110451\n",
            "Iteration 319, loss = 1520933269.22885489\n",
            "Iteration 320, loss = 1520879317.24762511\n",
            "Iteration 321, loss = 1520824909.56794119\n",
            "Iteration 322, loss = 1520770319.73118544\n",
            "Iteration 323, loss = 1520716274.95594430\n",
            "Iteration 324, loss = 1520662069.82824564\n",
            "Iteration 325, loss = 1520607842.43898845\n",
            "Iteration 326, loss = 1520553243.27960420\n",
            "Iteration 327, loss = 1520498995.22572851\n",
            "Iteration 328, loss = 1520444443.97360587\n",
            "Iteration 329, loss = 1520390299.21774697\n",
            "Iteration 330, loss = 1520335543.34369564\n",
            "Iteration 331, loss = 1520281098.01038241\n",
            "Iteration 332, loss = 1520226594.83166122\n",
            "Iteration 333, loss = 1520172003.39333558\n",
            "Iteration 334, loss = 1520117396.22780252\n",
            "Iteration 335, loss = 1520062716.73709750\n",
            "Iteration 336, loss = 1520008261.95349550\n",
            "Iteration 337, loss = 1519953940.25721717\n",
            "Iteration 338, loss = 1519899199.87761736\n",
            "Iteration 339, loss = 1519844686.90786481\n",
            "Iteration 340, loss = 1519790271.66599631\n",
            "Iteration 341, loss = 1519735653.20943046\n",
            "Iteration 342, loss = 1519681472.14025068\n",
            "Iteration 343, loss = 1519627254.66949821\n",
            "Iteration 344, loss = 1519572736.62071490\n",
            "Iteration 345, loss = 1519518340.22212911\n",
            "Iteration 346, loss = 1519464546.65419769\n",
            "Iteration 347, loss = 1519410040.66431618\n",
            "Iteration 348, loss = 1519355986.86428308\n",
            "Iteration 349, loss = 1519302114.13164163\n",
            "Iteration 350, loss = 1519247587.54512072\n",
            "Iteration 351, loss = 1519193884.67559814\n",
            "Iteration 352, loss = 1519139744.87445545\n",
            "Iteration 353, loss = 1519085841.05652666\n",
            "Iteration 354, loss = 1519031611.67300987\n",
            "Iteration 355, loss = 1518977404.00871468\n",
            "Iteration 356, loss = 1518923290.07211185\n",
            "Iteration 357, loss = 1518869186.06200647\n",
            "Iteration 358, loss = 1518814888.96660972\n",
            "Iteration 359, loss = 1518760447.72885656\n",
            "Iteration 360, loss = 1518706394.91967583\n",
            "Iteration 361, loss = 1518651609.74888206\n",
            "Iteration 362, loss = 1518597050.53796148\n",
            "Iteration 363, loss = 1518542946.91103411\n",
            "Iteration 364, loss = 1518488125.25599790\n",
            "Iteration 365, loss = 1518433700.20352101\n",
            "Iteration 366, loss = 1518379210.18959308\n",
            "Iteration 367, loss = 1518324788.38356972\n",
            "Iteration 368, loss = 1518270548.41478896\n",
            "Iteration 369, loss = 1518216435.42049265\n",
            "Iteration 370, loss = 1518162126.18067575\n",
            "Iteration 371, loss = 1518107746.61685252\n",
            "Iteration 372, loss = 1518054100.86750698\n",
            "Iteration 373, loss = 1517999764.65772533\n",
            "Iteration 374, loss = 1517946084.01693511\n",
            "Iteration 375, loss = 1517891307.00245833\n",
            "Iteration 376, loss = 1517837644.43482661\n",
            "Iteration 377, loss = 1517783423.81147456\n",
            "Iteration 378, loss = 1517729140.04508185\n",
            "Iteration 379, loss = 1517675082.51607156\n",
            "Iteration 380, loss = 1517620837.39661241\n",
            "Iteration 381, loss = 1517566522.13338208\n",
            "Iteration 382, loss = 1517512653.61244440\n",
            "Iteration 383, loss = 1517458266.81309676\n",
            "Iteration 384, loss = 1517404009.97379565\n",
            "Iteration 385, loss = 1517349657.29926348\n",
            "Iteration 386, loss = 1517295605.79586363\n",
            "Iteration 387, loss = 1517241445.77123356\n",
            "Iteration 388, loss = 1517186852.02293038\n",
            "Iteration 389, loss = 1517132448.02307415\n",
            "Iteration 390, loss = 1517078343.31443048\n",
            "Iteration 391, loss = 1517024303.98018336\n",
            "Iteration 392, loss = 1516969816.77142763\n",
            "Iteration 393, loss = 1516915555.54509497\n",
            "Iteration 394, loss = 1516861670.10698962\n",
            "Iteration 395, loss = 1516807261.73360825\n",
            "Iteration 396, loss = 1516753113.56162548\n",
            "Iteration 397, loss = 1516699221.54858088\n",
            "Iteration 398, loss = 1516645375.21645689\n",
            "Iteration 399, loss = 1516591129.98815107\n",
            "Iteration 400, loss = 1516537090.61077428\n",
            "Iteration 401, loss = 1516483419.80646777\n",
            "Iteration 402, loss = 1516429791.79386258\n",
            "Iteration 403, loss = 1516375106.14137197\n",
            "Iteration 404, loss = 1516321284.08217645\n",
            "Iteration 405, loss = 1516267282.53412366\n",
            "Iteration 406, loss = 1516213126.41202664\n",
            "Iteration 407, loss = 1516158783.74766397\n",
            "Iteration 408, loss = 1516104341.49209523\n",
            "Iteration 409, loss = 1516049889.88876128\n",
            "Iteration 410, loss = 1515995426.31759620\n",
            "Iteration 411, loss = 1515941425.10241485\n",
            "Iteration 412, loss = 1515886663.37365460\n",
            "Iteration 413, loss = 1515832447.56638765\n",
            "Iteration 414, loss = 1515778067.52981091\n",
            "Iteration 415, loss = 1515723829.14047289\n",
            "Iteration 416, loss = 1515669470.54290247\n",
            "Iteration 417, loss = 1515615666.03131318\n",
            "Iteration 418, loss = 1515561530.07311583\n",
            "Iteration 419, loss = 1515507249.60553718\n",
            "Iteration 420, loss = 1515453610.58426666\n",
            "Iteration 421, loss = 1515399550.54375911\n",
            "Iteration 422, loss = 1515345607.87431455\n",
            "Iteration 423, loss = 1515291658.65699053\n",
            "Iteration 424, loss = 1515237771.57231712\n",
            "Iteration 425, loss = 1515183842.81907988\n",
            "Iteration 426, loss = 1515129632.74971700\n",
            "Iteration 427, loss = 1515075620.75443053\n",
            "Iteration 428, loss = 1515021728.49527740\n",
            "Iteration 429, loss = 1514967742.29143810\n",
            "Iteration 430, loss = 1514913580.77496076\n",
            "Iteration 431, loss = 1514859558.14511037\n",
            "Iteration 432, loss = 1514805590.14419770\n",
            "Iteration 433, loss = 1514751627.39182663\n",
            "Iteration 434, loss = 1514697346.58939624\n",
            "Iteration 435, loss = 1514643694.18607402\n",
            "Iteration 436, loss = 1514589204.80228400\n",
            "Iteration 437, loss = 1514535547.89159727\n",
            "Iteration 438, loss = 1514481444.98528910\n",
            "Iteration 439, loss = 1514427293.93346095\n",
            "Iteration 440, loss = 1514373283.29071689\n",
            "Iteration 441, loss = 1514319287.21637869\n",
            "Iteration 442, loss = 1514265137.89919114\n",
            "Iteration 443, loss = 1514211316.13726521\n",
            "Iteration 444, loss = 1514156976.21244645\n",
            "Iteration 445, loss = 1514102662.16893244\n",
            "Iteration 446, loss = 1514048807.24630022\n",
            "Iteration 447, loss = 1513994715.68290257\n",
            "Iteration 448, loss = 1513940537.48045492\n",
            "Iteration 449, loss = 1513886135.14382505\n",
            "Iteration 450, loss = 1513832144.22297525\n",
            "Iteration 451, loss = 1513777492.03129625\n",
            "Iteration 452, loss = 1513723512.32955360\n",
            "Iteration 453, loss = 1513668922.89917231\n",
            "Iteration 454, loss = 1513614651.80053377\n",
            "Iteration 455, loss = 1513560198.74148893\n",
            "Iteration 456, loss = 1513505498.43622494\n",
            "Iteration 457, loss = 1513451245.92510891\n",
            "Iteration 458, loss = 1513397049.85547447\n",
            "Iteration 459, loss = 1513342166.34348130\n",
            "Iteration 460, loss = 1513288384.74928713\n",
            "Iteration 461, loss = 1513233771.16454792\n",
            "Iteration 462, loss = 1513179458.91404104\n",
            "Iteration 463, loss = 1513125412.80712199\n",
            "Iteration 464, loss = 1513070678.85966444\n",
            "Iteration 465, loss = 1513016728.52488565\n",
            "Iteration 466, loss = 1512962521.20541978\n",
            "Iteration 467, loss = 1512908035.99900842\n",
            "Iteration 468, loss = 1512853961.16492152\n",
            "Iteration 469, loss = 1512799699.51213360\n",
            "Iteration 470, loss = 1512745528.26146960\n",
            "Iteration 471, loss = 1512691421.25291061\n",
            "Iteration 472, loss = 1512637574.56151152\n",
            "Iteration 473, loss = 1512583154.27272725\n",
            "Iteration 474, loss = 1512529151.49260426\n",
            "Iteration 475, loss = 1512475037.41372776\n",
            "Iteration 476, loss = 1512420993.52662086\n",
            "Iteration 477, loss = 1512366518.90122199\n",
            "Iteration 478, loss = 1512312439.20232296\n",
            "Iteration 479, loss = 1512258198.38325024\n",
            "Iteration 480, loss = 1512203642.78131294\n",
            "Iteration 481, loss = 1512149698.94064212\n",
            "Iteration 482, loss = 1512095306.61869669\n",
            "Iteration 483, loss = 1512040970.83656073\n",
            "Iteration 484, loss = 1511986839.77940774\n",
            "Iteration 485, loss = 1511932524.79405141\n",
            "Iteration 486, loss = 1511878509.80304980\n",
            "Iteration 487, loss = 1511824022.17887044\n",
            "Iteration 488, loss = 1511770078.30529571\n",
            "Iteration 489, loss = 1511715490.80327487\n",
            "Iteration 490, loss = 1511661191.67333388\n",
            "Iteration 491, loss = 1511606985.46298075\n",
            "Iteration 492, loss = 1511552841.46283960\n",
            "Iteration 493, loss = 1511498226.43020463\n",
            "Iteration 494, loss = 1511444091.19822359\n",
            "Iteration 495, loss = 1511389706.93013978\n",
            "Iteration 496, loss = 1511335361.79142761\n",
            "Iteration 497, loss = 1511281025.20408440\n",
            "Iteration 498, loss = 1511226781.01994634\n",
            "Iteration 499, loss = 1511172084.68639851\n",
            "Iteration 500, loss = 1511118387.38640213\n",
            "Iteration 501, loss = 1511063965.54577637\n",
            "Iteration 502, loss = 1511009791.80824113\n",
            "Iteration 503, loss = 1510955374.03303504\n",
            "Iteration 504, loss = 1510901375.73468614\n",
            "Iteration 505, loss = 1510847113.53042841\n",
            "Iteration 506, loss = 1510792991.20896101\n",
            "Iteration 507, loss = 1510738474.04951644\n",
            "Iteration 508, loss = 1510684214.69667578\n",
            "Iteration 509, loss = 1510630394.24440408\n",
            "Iteration 510, loss = 1510575937.90749049\n",
            "Iteration 511, loss = 1510521602.75294781\n",
            "Iteration 512, loss = 1510467830.00918245\n",
            "Iteration 513, loss = 1510413724.54317856\n",
            "Iteration 514, loss = 1510359780.98503828\n",
            "Iteration 515, loss = 1510305870.65573597\n",
            "Iteration 516, loss = 1510251357.64440227\n",
            "Iteration 517, loss = 1510197473.55959463\n",
            "Iteration 518, loss = 1510143409.82100463\n",
            "Iteration 519, loss = 1510089424.10236359\n",
            "Iteration 520, loss = 1510035340.02240229\n",
            "Iteration 521, loss = 1509981103.01375175\n",
            "Iteration 522, loss = 1509926952.33833718\n",
            "Iteration 523, loss = 1509873078.78164148\n",
            "Iteration 524, loss = 1509818694.49544454\n",
            "Iteration 525, loss = 1509764646.20078516\n",
            "Iteration 526, loss = 1509710596.92898512\n",
            "Iteration 527, loss = 1509656568.34333563\n",
            "Iteration 528, loss = 1509602254.42677450\n",
            "Iteration 529, loss = 1509548111.72220349\n",
            "Iteration 530, loss = 1509494453.44926000\n",
            "Iteration 531, loss = 1509440032.36239123\n",
            "Iteration 532, loss = 1509386320.22834015\n",
            "Iteration 533, loss = 1509331951.35156536\n",
            "Iteration 534, loss = 1509278048.31116295\n",
            "Iteration 535, loss = 1509224222.44927907\n",
            "Iteration 536, loss = 1509170360.26760793\n",
            "Iteration 537, loss = 1509116211.43906546\n",
            "Iteration 538, loss = 1509062593.04028511\n",
            "Iteration 539, loss = 1509008793.45273066\n",
            "Iteration 540, loss = 1508954441.37105346\n",
            "Iteration 541, loss = 1508900629.84098959\n",
            "Iteration 542, loss = 1508846951.77480674\n",
            "Iteration 543, loss = 1508792463.99851131\n",
            "Iteration 544, loss = 1508738825.74678111\n",
            "Iteration 545, loss = 1508684518.82416177\n",
            "Iteration 546, loss = 1508630625.93771744\n",
            "Iteration 547, loss = 1508576746.43832254\n",
            "Iteration 548, loss = 1508522839.25314856\n",
            "Iteration 549, loss = 1508468825.41173816\n",
            "Iteration 550, loss = 1508415221.14989305\n",
            "Iteration 551, loss = 1508360973.91109920\n",
            "Iteration 552, loss = 1508307371.98208046\n",
            "Iteration 553, loss = 1508253123.25172853\n",
            "Iteration 554, loss = 1508199398.65064025\n",
            "Iteration 555, loss = 1508145241.57397103\n",
            "Iteration 556, loss = 1508091029.53348494\n",
            "Iteration 557, loss = 1508036704.98368144\n",
            "Iteration 558, loss = 1507982439.40287948\n",
            "Iteration 559, loss = 1507928250.34976578\n",
            "Iteration 560, loss = 1507873911.69148469\n",
            "Iteration 561, loss = 1507819691.25361133\n",
            "Iteration 562, loss = 1507765613.85130191\n",
            "Iteration 563, loss = 1507711086.43619776\n",
            "Iteration 564, loss = 1507656867.72820401\n",
            "Iteration 565, loss = 1507602969.75873947\n",
            "Iteration 566, loss = 1507548877.74372506\n",
            "Iteration 567, loss = 1507494547.77622843\n",
            "Iteration 568, loss = 1507440612.39558578\n",
            "Iteration 569, loss = 1507386491.04902744\n",
            "Iteration 570, loss = 1507332563.15877342\n",
            "Iteration 571, loss = 1507278485.83539104\n",
            "Iteration 572, loss = 1507224281.99715686\n",
            "Iteration 573, loss = 1507170502.00311208\n",
            "Iteration 574, loss = 1507116415.83312845\n",
            "Iteration 575, loss = 1507062393.77610993\n",
            "Iteration 576, loss = 1507008344.50049806\n",
            "Iteration 577, loss = 1506954586.89429045\n",
            "Iteration 578, loss = 1506900325.82906437\n",
            "Iteration 579, loss = 1506846424.45102692\n",
            "Iteration 580, loss = 1506792420.81195092\n",
            "Iteration 581, loss = 1506738739.48073649\n",
            "Iteration 582, loss = 1506684866.72813368\n",
            "Iteration 583, loss = 1506630756.68486500\n",
            "Iteration 584, loss = 1506577245.14009929\n",
            "Iteration 585, loss = 1506523778.02055025\n",
            "Iteration 586, loss = 1506470006.28622580\n",
            "Iteration 587, loss = 1506416423.29001713\n",
            "Iteration 588, loss = 1506362632.07403183\n",
            "Iteration 589, loss = 1506308868.63475299\n",
            "Iteration 590, loss = 1506255047.88742304\n",
            "Iteration 591, loss = 1506201048.31136203\n",
            "Iteration 592, loss = 1506147381.17979574\n",
            "Iteration 593, loss = 1506093454.46285343\n",
            "Iteration 594, loss = 1506039754.20206308\n",
            "Iteration 595, loss = 1505985668.00863433\n",
            "Iteration 596, loss = 1505932245.59763527\n",
            "Iteration 597, loss = 1505878591.07652926\n",
            "Iteration 598, loss = 1505824968.14840579\n",
            "Iteration 599, loss = 1505771131.90282559\n",
            "Iteration 600, loss = 1505717298.45582747\n",
            "Iteration 601, loss = 1505663670.15180540\n",
            "Iteration 602, loss = 1505610016.79422212\n",
            "Iteration 603, loss = 1505556339.01905417\n",
            "Iteration 604, loss = 1505502518.92508626\n",
            "Iteration 605, loss = 1505448962.29245090\n",
            "Iteration 606, loss = 1505395108.05472732\n",
            "Iteration 607, loss = 1505341878.15375209\n",
            "Iteration 608, loss = 1505287631.44455791\n",
            "Iteration 609, loss = 1505234178.08436370\n",
            "Iteration 610, loss = 1505180635.45016193\n",
            "Iteration 611, loss = 1505126634.03665304\n",
            "Iteration 612, loss = 1505072658.45285606\n",
            "Iteration 613, loss = 1505018914.50294566\n",
            "Iteration 614, loss = 1504965093.12903738\n",
            "Iteration 615, loss = 1504911408.50110507\n",
            "Iteration 616, loss = 1504857317.85911345\n",
            "Iteration 617, loss = 1504803768.31021953\n",
            "Iteration 618, loss = 1504750000.75682044\n",
            "Iteration 619, loss = 1504696233.00200772\n",
            "Iteration 620, loss = 1504642687.69926214\n",
            "Iteration 621, loss = 1504588820.22209811\n",
            "Iteration 622, loss = 1504535224.05073953\n",
            "Iteration 623, loss = 1504481559.31538653\n",
            "Iteration 624, loss = 1504427569.96886730\n",
            "Iteration 625, loss = 1504373945.41718006\n",
            "Iteration 626, loss = 1504319745.47689724\n",
            "Iteration 627, loss = 1504266103.71231437\n",
            "Iteration 628, loss = 1504212307.10985613\n",
            "Iteration 629, loss = 1504158494.69471169\n",
            "Iteration 630, loss = 1504104665.37090015\n",
            "Iteration 631, loss = 1504050704.25897980\n",
            "Iteration 632, loss = 1503997213.58426929\n",
            "Iteration 633, loss = 1503943464.96577096\n",
            "Iteration 634, loss = 1503889911.77478886\n",
            "Iteration 635, loss = 1503836443.10260725\n",
            "Iteration 636, loss = 1503782680.12822247\n",
            "Iteration 637, loss = 1503729304.79658699\n",
            "Iteration 638, loss = 1503675794.23327112\n",
            "Iteration 639, loss = 1503622585.25980377\n",
            "Iteration 640, loss = 1503568714.13712454\n",
            "Iteration 641, loss = 1503515214.34063649\n",
            "Iteration 642, loss = 1503461326.37366724\n",
            "Iteration 643, loss = 1503407629.25369453\n",
            "Iteration 644, loss = 1503353799.29581594\n",
            "Iteration 645, loss = 1503299859.57614875\n",
            "Iteration 646, loss = 1503245637.90517187\n",
            "Iteration 647, loss = 1503191441.19770622\n",
            "Iteration 648, loss = 1503137770.32375073\n",
            "Iteration 649, loss = 1503083530.32273984\n",
            "Iteration 650, loss = 1503029260.93214321\n",
            "Iteration 651, loss = 1502975237.27887750\n",
            "Iteration 652, loss = 1502921207.48701096\n",
            "Iteration 653, loss = 1502867255.51905012\n",
            "Iteration 654, loss = 1502813231.21401930\n",
            "Iteration 655, loss = 1502758941.24582219\n",
            "Iteration 656, loss = 1502705200.20670509\n",
            "Iteration 657, loss = 1502650893.01024222\n",
            "Iteration 658, loss = 1502596833.71171641\n",
            "Iteration 659, loss = 1502542745.82692862\n",
            "Iteration 660, loss = 1502488598.80155158\n",
            "Iteration 661, loss = 1502434452.37374401\n",
            "Iteration 662, loss = 1502380446.89235187\n",
            "Iteration 663, loss = 1502326354.05493617\n",
            "Iteration 664, loss = 1502272296.62604141\n",
            "Iteration 665, loss = 1502218404.78433442\n",
            "Iteration 666, loss = 1502164439.52316570\n",
            "Iteration 667, loss = 1502110189.12487841\n",
            "Iteration 668, loss = 1502056808.95834661\n",
            "Iteration 669, loss = 1502002557.19290328\n",
            "Iteration 670, loss = 1501948794.75874615\n",
            "Iteration 671, loss = 1501894952.88519168\n",
            "Iteration 672, loss = 1501841121.44324493\n",
            "Iteration 673, loss = 1501787427.73969412\n",
            "Iteration 674, loss = 1501733433.15691590\n",
            "Iteration 675, loss = 1501679985.47605920\n",
            "Iteration 676, loss = 1501625966.36709952\n",
            "Iteration 677, loss = 1501572096.58412576\n",
            "Iteration 678, loss = 1501518404.88170171\n",
            "Iteration 679, loss = 1501464442.34981227\n",
            "Iteration 680, loss = 1501410212.14448023\n",
            "Iteration 681, loss = 1501356221.96049929\n",
            "Iteration 682, loss = 1501302078.24902630\n",
            "Iteration 683, loss = 1501247930.54954720\n",
            "Iteration 684, loss = 1501193747.79035020\n",
            "Iteration 685, loss = 1501139784.32675838\n",
            "Iteration 686, loss = 1501085924.15383482\n",
            "Iteration 687, loss = 1501031547.42864823\n",
            "Iteration 688, loss = 1500977761.73905110\n",
            "Iteration 689, loss = 1500923810.91527390\n",
            "Iteration 690, loss = 1500869814.39483595\n",
            "Iteration 691, loss = 1500816142.28074026\n",
            "Iteration 692, loss = 1500762090.84383416\n",
            "Iteration 693, loss = 1500708164.11035490\n",
            "Iteration 694, loss = 1500654484.36656022\n",
            "Iteration 695, loss = 1500600693.88657236\n",
            "Iteration 696, loss = 1500546610.15732145\n",
            "Iteration 697, loss = 1500492759.54173517\n",
            "Iteration 698, loss = 1500439280.21227622\n",
            "Iteration 699, loss = 1500385247.40266442\n",
            "Iteration 700, loss = 1500331321.66717982\n",
            "Iteration 701, loss = 1500277731.46161222\n",
            "Iteration 702, loss = 1500223834.78429246\n",
            "Iteration 703, loss = 1500170009.00909352\n",
            "Iteration 704, loss = 1500116740.79910088\n",
            "Iteration 705, loss = 1500062610.53665447\n",
            "Iteration 706, loss = 1500008692.72626233\n",
            "Iteration 707, loss = 1499955195.02670670\n",
            "Iteration 708, loss = 1499901428.77654266\n",
            "Iteration 709, loss = 1499847555.73704934\n",
            "Iteration 710, loss = 1499793617.91512275\n",
            "Iteration 711, loss = 1499739823.96645641\n",
            "Iteration 712, loss = 1499686044.32947946\n",
            "Iteration 713, loss = 1499632234.77289629\n",
            "Iteration 714, loss = 1499578506.43843842\n",
            "Iteration 715, loss = 1499524685.47297764\n",
            "Iteration 716, loss = 1499471086.18976831\n",
            "Iteration 717, loss = 1499417356.70434976\n",
            "Iteration 718, loss = 1499363902.46699858\n",
            "Iteration 719, loss = 1499309993.34197330\n",
            "Iteration 720, loss = 1499256386.31460309\n",
            "Iteration 721, loss = 1499202546.91691089\n",
            "Iteration 722, loss = 1499148787.68519735\n",
            "Iteration 723, loss = 1499094964.13864946\n",
            "Iteration 724, loss = 1499041024.87956238\n",
            "Iteration 725, loss = 1498986950.93984842\n",
            "Iteration 726, loss = 1498933266.93269467\n",
            "Iteration 727, loss = 1498879005.96178007\n",
            "Iteration 728, loss = 1498824974.73562145\n",
            "Iteration 729, loss = 1498771109.96295214\n",
            "Iteration 730, loss = 1498716935.45062757\n",
            "Iteration 731, loss = 1498662871.41578889\n",
            "Iteration 732, loss = 1498609043.64364266\n",
            "Iteration 733, loss = 1498555098.23023248\n",
            "Iteration 734, loss = 1498501278.33922315\n",
            "Iteration 735, loss = 1498447368.36479926\n",
            "Iteration 736, loss = 1498393757.30361915\n",
            "Iteration 737, loss = 1498340011.61293483\n",
            "Iteration 738, loss = 1498286673.51040101\n",
            "Iteration 739, loss = 1498232655.01803637\n",
            "Iteration 740, loss = 1498179213.97322106\n",
            "Iteration 741, loss = 1498125264.67987132\n",
            "Iteration 742, loss = 1498071434.60009480\n",
            "Iteration 743, loss = 1498018040.28291798\n",
            "Iteration 744, loss = 1497963872.82984042\n",
            "Iteration 745, loss = 1497910447.44553494\n",
            "Iteration 746, loss = 1497856569.42569947\n",
            "Iteration 747, loss = 1497802909.80499101\n",
            "Iteration 748, loss = 1497749327.19784951\n",
            "Iteration 749, loss = 1497695647.44671035\n",
            "Iteration 750, loss = 1497642060.19398761\n",
            "Iteration 751, loss = 1497588579.84303117\n",
            "Iteration 752, loss = 1497534574.73437452\n",
            "Iteration 753, loss = 1497481496.71509385\n",
            "Iteration 754, loss = 1497427395.34889293\n",
            "Iteration 755, loss = 1497373799.43254542\n",
            "Iteration 756, loss = 1497320001.74849105\n",
            "Iteration 757, loss = 1497266359.13270950\n",
            "Iteration 758, loss = 1497212823.60841799\n",
            "Iteration 759, loss = 1497158632.71551228\n",
            "Iteration 760, loss = 1497105158.31975961\n",
            "Iteration 761, loss = 1497051238.82638693\n",
            "Iteration 762, loss = 1496997773.29753637\n",
            "Iteration 763, loss = 1496943774.09096026\n",
            "Iteration 764, loss = 1496889837.72580433\n",
            "Iteration 765, loss = 1496836309.47253561\n",
            "Iteration 766, loss = 1496782148.75321078\n",
            "Iteration 767, loss = 1496728518.78067493\n",
            "Iteration 768, loss = 1496674801.86472607\n",
            "Iteration 769, loss = 1496620685.58024096\n",
            "Iteration 770, loss = 1496567297.90807581\n",
            "Iteration 771, loss = 1496513286.54894018\n",
            "Iteration 772, loss = 1496459922.47920609\n",
            "Iteration 773, loss = 1496405943.20632243\n",
            "Iteration 774, loss = 1496352328.08494473\n",
            "Iteration 775, loss = 1496298686.40531135\n",
            "Iteration 776, loss = 1496244784.81124187\n",
            "Iteration 777, loss = 1496191091.71188736\n",
            "Iteration 778, loss = 1496137471.04627204\n",
            "Iteration 779, loss = 1496083622.68441463\n",
            "Iteration 780, loss = 1496029793.01529670\n",
            "Iteration 781, loss = 1495975934.15680790\n",
            "Iteration 782, loss = 1495922278.44723225\n",
            "Iteration 783, loss = 1495868895.11274171\n",
            "Iteration 784, loss = 1495814930.53139758\n",
            "Iteration 785, loss = 1495761001.71199799\n",
            "Iteration 786, loss = 1495707348.10398960\n",
            "Iteration 787, loss = 1495653569.29430223\n",
            "Iteration 788, loss = 1495599878.21918082\n",
            "Iteration 789, loss = 1495546222.25319147\n",
            "Iteration 790, loss = 1495491928.99521255\n",
            "Iteration 791, loss = 1495437995.64223981\n",
            "Iteration 792, loss = 1495384270.96452856\n",
            "Iteration 793, loss = 1495330278.16936493\n",
            "Iteration 794, loss = 1495276061.69771028\n",
            "Iteration 795, loss = 1495222271.12341738\n",
            "Iteration 796, loss = 1495168325.51051545\n",
            "Iteration 797, loss = 1495114303.55853558\n",
            "Iteration 798, loss = 1495060484.19681931\n",
            "Iteration 799, loss = 1495006648.22172546\n",
            "Iteration 800, loss = 1494953060.29659534\n",
            "Iteration 801, loss = 1494899054.21313834\n",
            "Iteration 802, loss = 1494845652.46396017\n",
            "Iteration 803, loss = 1494791837.08848166\n",
            "Iteration 804, loss = 1494738369.21583319\n",
            "Iteration 805, loss = 1494684285.08923745\n",
            "Iteration 806, loss = 1494631014.47173572\n",
            "Iteration 807, loss = 1494577067.87950850\n",
            "Iteration 808, loss = 1494523448.97589350\n",
            "Iteration 809, loss = 1494469603.91461158\n",
            "Iteration 810, loss = 1494415919.03144407\n",
            "Iteration 811, loss = 1494361987.31042123\n",
            "Iteration 812, loss = 1494308307.50153375\n",
            "Iteration 813, loss = 1494253977.02213502\n",
            "Iteration 814, loss = 1494200771.28756237\n",
            "Iteration 815, loss = 1494146722.65786338\n",
            "Iteration 816, loss = 1494092905.92616296\n",
            "Iteration 817, loss = 1494039146.04530478\n",
            "Iteration 818, loss = 1493985241.86316252\n",
            "Iteration 819, loss = 1493932021.37325358\n",
            "Iteration 820, loss = 1493878135.01937795\n",
            "Iteration 821, loss = 1493824461.39091206\n",
            "Iteration 822, loss = 1493770683.32229042\n",
            "Iteration 823, loss = 1493717309.36389685\n",
            "Iteration 824, loss = 1493663340.83074307\n",
            "Iteration 825, loss = 1493610069.53487945\n",
            "Iteration 826, loss = 1493555864.89567018\n",
            "Iteration 827, loss = 1493502406.09823442\n",
            "Iteration 828, loss = 1493448821.04228306\n",
            "Iteration 829, loss = 1493394927.81924772\n",
            "Iteration 830, loss = 1493341399.07010221\n",
            "Iteration 831, loss = 1493287756.15504885\n",
            "Iteration 832, loss = 1493233627.76628637\n",
            "Iteration 833, loss = 1493179912.42751026\n",
            "Iteration 834, loss = 1493125702.63008976\n",
            "Iteration 835, loss = 1493072058.63224053\n",
            "Iteration 836, loss = 1493017948.42982554\n",
            "Iteration 837, loss = 1492964322.60806513\n",
            "Iteration 838, loss = 1492910101.23331237\n",
            "Iteration 839, loss = 1492856599.42349219\n",
            "Iteration 840, loss = 1492802961.61781049\n",
            "Iteration 841, loss = 1492749184.29308701\n",
            "Iteration 842, loss = 1492695493.45768833\n",
            "Iteration 843, loss = 1492641712.73181534\n",
            "Iteration 844, loss = 1492588201.60362792\n",
            "Iteration 845, loss = 1492534540.92339540\n",
            "Iteration 846, loss = 1492480841.54332423\n",
            "Iteration 847, loss = 1492426993.83820701\n",
            "Iteration 848, loss = 1492373659.14641142\n",
            "Iteration 849, loss = 1492320049.77880263\n",
            "Iteration 850, loss = 1492266525.20962405\n",
            "Iteration 851, loss = 1492213135.42564702\n",
            "Iteration 852, loss = 1492159493.46458888\n",
            "Iteration 853, loss = 1492106124.18116975\n",
            "Iteration 854, loss = 1492052589.62811017\n",
            "Iteration 855, loss = 1491999227.96003962\n",
            "Iteration 856, loss = 1491945722.29472899\n",
            "Iteration 857, loss = 1491891926.27742100\n",
            "Iteration 858, loss = 1491838276.55883312\n",
            "Iteration 859, loss = 1491785136.26717830\n",
            "Iteration 860, loss = 1491731430.90874100\n",
            "Iteration 861, loss = 1491677752.92691731\n",
            "Iteration 862, loss = 1491624087.98571467\n",
            "Iteration 863, loss = 1491570786.00155950\n",
            "Iteration 864, loss = 1491517069.05937600\n",
            "Iteration 865, loss = 1491463573.09234738\n",
            "Iteration 866, loss = 1491409920.76487112\n",
            "Iteration 867, loss = 1491356676.00583029\n",
            "Iteration 868, loss = 1491303141.11114478\n",
            "Iteration 869, loss = 1491249355.61713171\n",
            "Iteration 870, loss = 1491195767.66731358\n",
            "Iteration 871, loss = 1491142342.12309217\n",
            "Iteration 872, loss = 1491088660.89957333\n",
            "Iteration 873, loss = 1491034869.62701583\n",
            "Iteration 874, loss = 1490981545.85439348\n",
            "Iteration 875, loss = 1490928063.52727103\n",
            "Iteration 876, loss = 1490874314.61804461\n",
            "Iteration 877, loss = 1490820992.11720157\n",
            "Iteration 878, loss = 1490767136.77859187\n",
            "Iteration 879, loss = 1490713978.19066143\n",
            "Iteration 880, loss = 1490660256.96194601\n",
            "Iteration 881, loss = 1490606613.28861809\n",
            "Iteration 882, loss = 1490553090.40069127\n",
            "Iteration 883, loss = 1490499676.14844823\n",
            "Iteration 884, loss = 1490446054.02045417\n",
            "Iteration 885, loss = 1490392398.80988026\n",
            "Iteration 886, loss = 1490339088.62495518\n",
            "Iteration 887, loss = 1490285545.50910163\n",
            "Iteration 888, loss = 1490232240.56896329\n",
            "Iteration 889, loss = 1490178495.99676919\n",
            "Iteration 890, loss = 1490124896.14456511\n",
            "Iteration 891, loss = 1490071506.37833595\n",
            "Iteration 892, loss = 1490017988.53254604\n",
            "Iteration 893, loss = 1489964386.58998871\n",
            "Iteration 894, loss = 1489910608.05588341\n",
            "Iteration 895, loss = 1489857187.27881694\n",
            "Iteration 896, loss = 1489803420.07160521\n",
            "Iteration 897, loss = 1489750144.19631124\n",
            "Iteration 898, loss = 1489696270.72409797\n",
            "Iteration 899, loss = 1489642568.73413682\n",
            "Iteration 900, loss = 1489588940.77105904\n",
            "Iteration 901, loss = 1489535518.55987239\n",
            "Iteration 902, loss = 1489481910.28048468\n",
            "Iteration 903, loss = 1489428383.33442211\n",
            "Iteration 904, loss = 1489374650.22349620\n",
            "Iteration 905, loss = 1489321212.88227129\n",
            "Iteration 906, loss = 1489267652.36898184\n",
            "Iteration 907, loss = 1489214332.52823472\n",
            "Iteration 908, loss = 1489160201.56566167\n",
            "Iteration 909, loss = 1489107195.01168203\n",
            "Iteration 910, loss = 1489053489.43974972\n",
            "Iteration 911, loss = 1489000071.45215869\n",
            "Iteration 912, loss = 1488946316.93681169\n",
            "Iteration 913, loss = 1488893330.36057138\n",
            "Iteration 914, loss = 1488839670.64377880\n",
            "Iteration 915, loss = 1488786319.29295087\n",
            "Iteration 916, loss = 1488732918.10769153\n",
            "Iteration 917, loss = 1488679530.80294824\n",
            "Iteration 918, loss = 1488626374.78156972\n",
            "Iteration 919, loss = 1488572688.07039618\n",
            "Iteration 920, loss = 1488519137.21758699\n",
            "Iteration 921, loss = 1488465840.62420416\n",
            "Iteration 922, loss = 1488412737.31826639\n",
            "Iteration 923, loss = 1488359145.55562210\n",
            "Iteration 924, loss = 1488305798.93470430\n",
            "Iteration 925, loss = 1488252533.74118137\n",
            "Iteration 926, loss = 1488199285.56078768\n",
            "Iteration 927, loss = 1488145744.72521520\n",
            "Iteration 928, loss = 1488092423.59788990\n",
            "Iteration 929, loss = 1488038753.02035403\n",
            "Iteration 930, loss = 1487985246.39640856\n",
            "Iteration 931, loss = 1487931829.28598166\n",
            "Iteration 932, loss = 1487877990.25255179\n",
            "Iteration 933, loss = 1487824882.52917242\n",
            "Iteration 934, loss = 1487771226.59373474\n",
            "Iteration 935, loss = 1487717820.39815164\n",
            "Iteration 936, loss = 1487664638.56625938\n",
            "Iteration 937, loss = 1487611358.77137947\n",
            "Iteration 938, loss = 1487558128.23461485\n",
            "Iteration 939, loss = 1487504758.36659336\n",
            "Iteration 940, loss = 1487450957.20977926\n",
            "Iteration 941, loss = 1487397747.81634974\n",
            "Iteration 942, loss = 1487343864.77743888\n",
            "Iteration 943, loss = 1487290323.11153412\n",
            "Iteration 944, loss = 1487236153.76921964\n",
            "Iteration 945, loss = 1487182751.96041846\n",
            "Iteration 946, loss = 1487128966.21830392\n",
            "Iteration 947, loss = 1487074932.17522979\n",
            "Iteration 948, loss = 1487021544.75563073\n",
            "Iteration 949, loss = 1486968153.91701984\n",
            "Iteration 950, loss = 1486914426.14937973\n",
            "Iteration 951, loss = 1486860950.83212924\n",
            "Iteration 952, loss = 1486807445.76818991\n",
            "Iteration 953, loss = 1486754051.18966413\n",
            "Iteration 954, loss = 1486700853.37952638\n",
            "Iteration 955, loss = 1486647107.87884545\n",
            "Iteration 956, loss = 1486593846.83421040\n",
            "Iteration 957, loss = 1486540379.62447214\n",
            "Iteration 958, loss = 1486487075.88481045\n",
            "Iteration 959, loss = 1486433670.39654779\n",
            "Iteration 960, loss = 1486380207.85801125\n",
            "Iteration 961, loss = 1486326952.29989481\n",
            "Iteration 962, loss = 1486273510.81831813\n",
            "Iteration 963, loss = 1486219923.43772459\n",
            "Iteration 964, loss = 1486166687.63179803\n",
            "Iteration 965, loss = 1486112818.25044966\n",
            "Iteration 966, loss = 1486059299.28521156\n",
            "Iteration 967, loss = 1486005666.21801567\n",
            "Iteration 968, loss = 1485952348.44494128\n",
            "Iteration 969, loss = 1485898715.41556835\n",
            "Iteration 970, loss = 1485845099.34083700\n",
            "Iteration 971, loss = 1485792108.63221240\n",
            "Iteration 972, loss = 1485738582.61393785\n",
            "Iteration 973, loss = 1485685461.37575388\n",
            "Iteration 974, loss = 1485632033.44138455\n",
            "Iteration 975, loss = 1485578810.94376588\n",
            "Iteration 976, loss = 1485525605.00467443\n",
            "Iteration 977, loss = 1485472005.50781989\n",
            "Iteration 978, loss = 1485418315.52552438\n",
            "Iteration 979, loss = 1485365170.21570802\n",
            "Iteration 980, loss = 1485311267.49239993\n",
            "Iteration 981, loss = 1485257761.25608087\n",
            "Iteration 982, loss = 1485203745.39228296\n",
            "Iteration 983, loss = 1485150116.03219175\n",
            "Iteration 984, loss = 1485096515.14076281\n",
            "Iteration 985, loss = 1485042704.48358870\n",
            "Iteration 986, loss = 1484988810.65802526\n",
            "Iteration 987, loss = 1484935339.44981313\n",
            "Iteration 988, loss = 1484881597.89743257\n",
            "Iteration 989, loss = 1484828095.13096690\n",
            "Iteration 990, loss = 1484774476.66106844\n",
            "Iteration 991, loss = 1484720881.06809521\n",
            "Iteration 992, loss = 1484667254.20720673\n",
            "Iteration 993, loss = 1484613499.88590145\n",
            "Iteration 994, loss = 1484559934.07994294\n",
            "Iteration 995, loss = 1484506702.42726469\n",
            "Iteration 996, loss = 1484453014.21656442\n",
            "Iteration 997, loss = 1484399316.61778808\n",
            "Iteration 998, loss = 1484346386.88135505\n",
            "Iteration 999, loss = 1484293325.21825051\n",
            "Iteration 1000, loss = 1484239799.78272891\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1549520198.29646945\n",
            "Iteration 2, loss = 147614385.12045237\n",
            "Iteration 3, loss = 271114505.64353400\n",
            "Iteration 4, loss = 53186594.13741039\n",
            "Iteration 5, loss = 46006078.94978302\n",
            "Iteration 6, loss = 38239600.80902726\n",
            "Iteration 7, loss = 43380229.89845406\n",
            "Iteration 8, loss = 51326132.74972475\n",
            "Iteration 9, loss = 56154752.28322192\n",
            "Iteration 10, loss = 58625641.92063551\n",
            "Iteration 11, loss = 58833052.02196957\n",
            "Iteration 12, loss = 57936425.10172083\n",
            "Iteration 13, loss = 57942934.68298436\n",
            "Iteration 14, loss = 57351931.04159845\n",
            "Iteration 15, loss = 58111961.41476436\n",
            "Iteration 16, loss = 59301906.60511400\n",
            "Iteration 17, loss = 60180309.17162088\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538779828.42344832\n",
            "Iteration 2, loss = 1538647718.29991293\n",
            "Iteration 3, loss = 1538510013.73038554\n",
            "Iteration 4, loss = 1538374994.57089829\n",
            "Iteration 5, loss = 1538271663.05324841\n",
            "Iteration 6, loss = 1538203957.06158662\n",
            "Iteration 7, loss = 1538145780.94079304\n",
            "Iteration 8, loss = 1538089034.81040335\n",
            "Iteration 9, loss = 1538032085.57141066\n",
            "Iteration 10, loss = 1537974008.25274873\n",
            "Iteration 11, loss = 1537916185.73059797\n",
            "Iteration 12, loss = 1537857298.89292026\n",
            "Iteration 13, loss = 1537798531.08418918\n",
            "Iteration 14, loss = 1537739871.41073012\n",
            "Iteration 15, loss = 1537681039.39866519\n",
            "Iteration 16, loss = 1537622418.14547896\n",
            "Iteration 17, loss = 1537563592.98086452\n",
            "Iteration 18, loss = 1537504932.76913643\n",
            "Iteration 19, loss = 1537446336.49261856\n",
            "Iteration 20, loss = 1537387959.77176189\n",
            "Iteration 21, loss = 1537329670.39324737\n",
            "Iteration 22, loss = 1537271349.42181611\n",
            "Iteration 23, loss = 1537213287.79816031\n",
            "Iteration 24, loss = 1537155333.36032224\n",
            "Iteration 25, loss = 1537097475.14252877\n",
            "Iteration 26, loss = 1537040308.06338406\n",
            "Iteration 27, loss = 1536982161.93892050\n",
            "Iteration 28, loss = 1536924998.08146000\n",
            "Iteration 29, loss = 1536867739.68090749\n",
            "Iteration 30, loss = 1536810630.21617675\n",
            "Iteration 31, loss = 1536753143.04871035\n",
            "Iteration 32, loss = 1536696054.62526584\n",
            "Iteration 33, loss = 1536638731.68994737\n",
            "Iteration 34, loss = 1536581830.08309054\n",
            "Iteration 35, loss = 1536524610.73061347\n",
            "Iteration 36, loss = 1536467518.25876474\n",
            "Iteration 37, loss = 1536410420.40193844\n",
            "Iteration 38, loss = 1536353900.39095712\n",
            "Iteration 39, loss = 1536296726.85272050\n",
            "Iteration 40, loss = 1536240357.84859324\n",
            "Iteration 41, loss = 1536184109.09976482\n",
            "Iteration 42, loss = 1536127360.51668525\n",
            "Iteration 43, loss = 1536071001.96902919\n",
            "Iteration 44, loss = 1536014794.46353602\n",
            "Iteration 45, loss = 1535958893.99609613\n",
            "Iteration 46, loss = 1535902048.87838149\n",
            "Iteration 47, loss = 1535846057.55606842\n",
            "Iteration 48, loss = 1535789678.12648892\n",
            "Iteration 49, loss = 1535733428.26701260\n",
            "Iteration 50, loss = 1535677317.52917576\n",
            "Iteration 51, loss = 1535620675.74104214\n",
            "Iteration 52, loss = 1535564722.38253570\n",
            "Iteration 53, loss = 1535508671.60493636\n",
            "Iteration 54, loss = 1535452539.93230987\n",
            "Iteration 55, loss = 1535396533.12261057\n",
            "Iteration 56, loss = 1535340390.56078029\n",
            "Iteration 57, loss = 1535284598.88638067\n",
            "Iteration 58, loss = 1535228856.18773389\n",
            "Iteration 59, loss = 1535172852.99310255\n",
            "Iteration 60, loss = 1535116972.74324918\n",
            "Iteration 61, loss = 1535061393.78798866\n",
            "Iteration 62, loss = 1535005705.11277556\n",
            "Iteration 63, loss = 1534949804.25002789\n",
            "Iteration 64, loss = 1534894131.37236071\n",
            "Iteration 65, loss = 1534838123.96911740\n",
            "Iteration 66, loss = 1534783101.44416451\n",
            "Iteration 67, loss = 1534727210.15296054\n",
            "Iteration 68, loss = 1534671594.00635076\n",
            "Iteration 69, loss = 1534616179.95665812\n",
            "Iteration 70, loss = 1534560939.64268064\n",
            "Iteration 71, loss = 1534505386.03661871\n",
            "Iteration 72, loss = 1534450106.55711174\n",
            "Iteration 73, loss = 1534394697.28351164\n",
            "Iteration 74, loss = 1534339226.94206023\n",
            "Iteration 75, loss = 1534283614.96772289\n",
            "Iteration 76, loss = 1534227974.77132583\n",
            "Iteration 77, loss = 1534172159.54269099\n",
            "Iteration 78, loss = 1534116678.39674616\n",
            "Iteration 79, loss = 1534060899.52859998\n",
            "Iteration 80, loss = 1534005113.34185147\n",
            "Iteration 81, loss = 1533949527.08275437\n",
            "Iteration 82, loss = 1533893921.87689567\n",
            "Iteration 83, loss = 1533838300.98400712\n",
            "Iteration 84, loss = 1533782852.68073273\n",
            "Iteration 85, loss = 1533727394.47283626\n",
            "Iteration 86, loss = 1533671814.72642946\n",
            "Iteration 87, loss = 1533616097.78187513\n",
            "Iteration 88, loss = 1533561152.13409591\n",
            "Iteration 89, loss = 1533505315.26931739\n",
            "Iteration 90, loss = 1533449960.23731256\n",
            "Iteration 91, loss = 1533394747.95022893\n",
            "Iteration 92, loss = 1533339670.41457605\n",
            "Iteration 93, loss = 1533284265.22027707\n",
            "Iteration 94, loss = 1533229164.96344376\n",
            "Iteration 95, loss = 1533173988.51895523\n",
            "Iteration 96, loss = 1533118925.00233221\n",
            "Iteration 97, loss = 1533063755.29629779\n",
            "Iteration 98, loss = 1533008363.12714815\n",
            "Iteration 99, loss = 1532953528.84121227\n",
            "Iteration 100, loss = 1532898089.72534919\n",
            "Iteration 101, loss = 1532842916.48630619\n",
            "Iteration 102, loss = 1532787523.02326679\n",
            "Iteration 103, loss = 1532732552.15542722\n",
            "Iteration 104, loss = 1532677193.32201505\n",
            "Iteration 105, loss = 1532622020.77633882\n",
            "Iteration 106, loss = 1532566757.08743882\n",
            "Iteration 107, loss = 1532511821.43940330\n",
            "Iteration 108, loss = 1532456276.53410196\n",
            "Iteration 109, loss = 1532401433.99194479\n",
            "Iteration 110, loss = 1532345917.03603339\n",
            "Iteration 111, loss = 1532291039.13426614\n",
            "Iteration 112, loss = 1532235399.81109238\n",
            "Iteration 113, loss = 1532179954.65964127\n",
            "Iteration 114, loss = 1532124711.83702207\n",
            "Iteration 115, loss = 1532068829.86292148\n",
            "Iteration 116, loss = 1532013682.86770391\n",
            "Iteration 117, loss = 1531957951.29838109\n",
            "Iteration 118, loss = 1531902585.66783071\n",
            "Iteration 119, loss = 1531847046.49206471\n",
            "Iteration 120, loss = 1531791781.22074413\n",
            "Iteration 121, loss = 1531736424.14817882\n",
            "Iteration 122, loss = 1531681254.87044740\n",
            "Iteration 123, loss = 1531625844.85430789\n",
            "Iteration 124, loss = 1531570786.72483921\n",
            "Iteration 125, loss = 1531515267.61063862\n",
            "Iteration 126, loss = 1531460212.93678617\n",
            "Iteration 127, loss = 1531404591.49462652\n",
            "Iteration 128, loss = 1531349110.27761793\n",
            "Iteration 129, loss = 1531293922.07157516\n",
            "Iteration 130, loss = 1531238601.67430902\n",
            "Iteration 131, loss = 1531183192.55677676\n",
            "Iteration 132, loss = 1531128002.16443872\n",
            "Iteration 133, loss = 1531072694.70209432\n",
            "Iteration 134, loss = 1531017573.04604197\n",
            "Iteration 135, loss = 1530962575.51856017\n",
            "Iteration 136, loss = 1530907241.10908508\n",
            "Iteration 137, loss = 1530852368.20611763\n",
            "Iteration 138, loss = 1530797123.24476600\n",
            "Iteration 139, loss = 1530742256.81438994\n",
            "Iteration 140, loss = 1530687090.18820715\n",
            "Iteration 141, loss = 1530632073.13452649\n",
            "Iteration 142, loss = 1530577035.62290740\n",
            "Iteration 143, loss = 1530522014.11704421\n",
            "Iteration 144, loss = 1530466922.08941126\n",
            "Iteration 145, loss = 1530411548.36306334\n",
            "Iteration 146, loss = 1530356591.28516293\n",
            "Iteration 147, loss = 1530301658.07610965\n",
            "Iteration 148, loss = 1530246336.49931526\n",
            "Iteration 149, loss = 1530191162.93807578\n",
            "Iteration 150, loss = 1530136306.53894615\n",
            "Iteration 151, loss = 1530081244.11393976\n",
            "Iteration 152, loss = 1530026353.01402831\n",
            "Iteration 153, loss = 1529971161.84087563\n",
            "Iteration 154, loss = 1529916467.90798211\n",
            "Iteration 155, loss = 1529861587.25404811\n",
            "Iteration 156, loss = 1529806019.81563401\n",
            "Iteration 157, loss = 1529751674.99627423\n",
            "Iteration 158, loss = 1529696458.17848325\n",
            "Iteration 159, loss = 1529641471.09247828\n",
            "Iteration 160, loss = 1529586861.19946718\n",
            "Iteration 161, loss = 1529531578.62735820\n",
            "Iteration 162, loss = 1529477065.10124445\n",
            "Iteration 163, loss = 1529421844.69738770\n",
            "Iteration 164, loss = 1529367181.28505278\n",
            "Iteration 165, loss = 1529312010.25828385\n",
            "Iteration 166, loss = 1529257157.76869559\n",
            "Iteration 167, loss = 1529202229.80579638\n",
            "Iteration 168, loss = 1529147635.90947580\n",
            "Iteration 169, loss = 1529092989.54300117\n",
            "Iteration 170, loss = 1529038087.15729237\n",
            "Iteration 171, loss = 1528983506.72954607\n",
            "Iteration 172, loss = 1528928701.61205196\n",
            "Iteration 173, loss = 1528874172.67437291\n",
            "Iteration 174, loss = 1528819527.11619306\n",
            "Iteration 175, loss = 1528764602.99310136\n",
            "Iteration 176, loss = 1528709733.85327411\n",
            "Iteration 177, loss = 1528654949.25977159\n",
            "Iteration 178, loss = 1528600537.17244005\n",
            "Iteration 179, loss = 1528545636.98824000\n",
            "Iteration 180, loss = 1528490996.96894813\n",
            "Iteration 181, loss = 1528436350.29931951\n",
            "Iteration 182, loss = 1528381775.33806562\n",
            "Iteration 183, loss = 1528327184.92146850\n",
            "Iteration 184, loss = 1528272244.42429185\n",
            "Iteration 185, loss = 1528217745.44899702\n",
            "Iteration 186, loss = 1528163311.18571234\n",
            "Iteration 187, loss = 1528108186.89775467\n",
            "Iteration 188, loss = 1528053714.98558021\n",
            "Iteration 189, loss = 1527999035.65082097\n",
            "Iteration 190, loss = 1527944328.18035746\n",
            "Iteration 191, loss = 1527889875.54480314\n",
            "Iteration 192, loss = 1527834908.64988637\n",
            "Iteration 193, loss = 1527779918.45834494\n",
            "Iteration 194, loss = 1527724865.06900144\n",
            "Iteration 195, loss = 1527670229.64162993\n",
            "Iteration 196, loss = 1527614841.14653301\n",
            "Iteration 197, loss = 1527559803.77952433\n",
            "Iteration 198, loss = 1527505008.68431258\n",
            "Iteration 199, loss = 1527449820.19778347\n",
            "Iteration 200, loss = 1527395326.18024778\n",
            "Iteration 201, loss = 1527340270.01600075\n",
            "Iteration 202, loss = 1527285831.54206872\n",
            "Iteration 203, loss = 1527231176.74217916\n",
            "Iteration 204, loss = 1527176144.99090266\n",
            "Iteration 205, loss = 1527121976.90039968\n",
            "Iteration 206, loss = 1527067204.02830005\n",
            "Iteration 207, loss = 1527012687.35076308\n",
            "Iteration 208, loss = 1526958326.02023602\n",
            "Iteration 209, loss = 1526903766.51298285\n",
            "Iteration 210, loss = 1526849443.76665688\n",
            "Iteration 211, loss = 1526794483.08617020\n",
            "Iteration 212, loss = 1526740565.05683327\n",
            "Iteration 213, loss = 1526685585.88845110\n",
            "Iteration 214, loss = 1526631048.85185552\n",
            "Iteration 215, loss = 1526576208.29150677\n",
            "Iteration 216, loss = 1526521467.59563303\n",
            "Iteration 217, loss = 1526466500.06735849\n",
            "Iteration 218, loss = 1526411997.93463469\n",
            "Iteration 219, loss = 1526356820.34250927\n",
            "Iteration 220, loss = 1526302097.79209876\n",
            "Iteration 221, loss = 1526247146.61549306\n",
            "Iteration 222, loss = 1526192119.20249271\n",
            "Iteration 223, loss = 1526137501.01620555\n",
            "Iteration 224, loss = 1526082683.02717638\n",
            "Iteration 225, loss = 1526027593.88182473\n",
            "Iteration 226, loss = 1525972978.31159210\n",
            "Iteration 227, loss = 1525918277.85629892\n",
            "Iteration 228, loss = 1525863483.21079969\n",
            "Iteration 229, loss = 1525809041.51756263\n",
            "Iteration 230, loss = 1525754760.12535930\n",
            "Iteration 231, loss = 1525700017.32392788\n",
            "Iteration 232, loss = 1525645695.59921741\n",
            "Iteration 233, loss = 1525591429.10855699\n",
            "Iteration 234, loss = 1525537173.65524864\n",
            "Iteration 235, loss = 1525482851.09250116\n",
            "Iteration 236, loss = 1525428381.58680320\n",
            "Iteration 237, loss = 1525373535.46841216\n",
            "Iteration 238, loss = 1525319303.51394486\n",
            "Iteration 239, loss = 1525264804.33514619\n",
            "Iteration 240, loss = 1525210089.80757809\n",
            "Iteration 241, loss = 1525155407.85630846\n",
            "Iteration 242, loss = 1525100877.84704733\n",
            "Iteration 243, loss = 1525045936.76951456\n",
            "Iteration 244, loss = 1524991526.35751534\n",
            "Iteration 245, loss = 1524936689.42016029\n",
            "Iteration 246, loss = 1524882033.74432659\n",
            "Iteration 247, loss = 1524827504.63735986\n",
            "Iteration 248, loss = 1524772737.70400429\n",
            "Iteration 249, loss = 1524718282.91579056\n",
            "Iteration 250, loss = 1524663956.53707981\n",
            "Iteration 251, loss = 1524609294.87286687\n",
            "Iteration 252, loss = 1524554840.62137532\n",
            "Iteration 253, loss = 1524500236.90224791\n",
            "Iteration 254, loss = 1524445675.36087441\n",
            "Iteration 255, loss = 1524391057.98909044\n",
            "Iteration 256, loss = 1524336315.53949642\n",
            "Iteration 257, loss = 1524281750.33464789\n",
            "Iteration 258, loss = 1524226756.90937996\n",
            "Iteration 259, loss = 1524172390.18118739\n",
            "Iteration 260, loss = 1524117510.11512160\n",
            "Iteration 261, loss = 1524063065.59368753\n",
            "Iteration 262, loss = 1524008707.06751800\n",
            "Iteration 263, loss = 1523953915.04906678\n",
            "Iteration 264, loss = 1523899336.30127239\n",
            "Iteration 265, loss = 1523845075.80338502\n",
            "Iteration 266, loss = 1523790547.63399744\n",
            "Iteration 267, loss = 1523735504.64476466\n",
            "Iteration 268, loss = 1523681188.57367396\n",
            "Iteration 269, loss = 1523626254.54720092\n",
            "Iteration 270, loss = 1523571572.50160336\n",
            "Iteration 271, loss = 1523516767.39747453\n",
            "Iteration 272, loss = 1523461998.48457932\n",
            "Iteration 273, loss = 1523407258.25971842\n",
            "Iteration 274, loss = 1523352642.18838024\n",
            "Iteration 275, loss = 1523297708.66310835\n",
            "Iteration 276, loss = 1523242997.46803665\n",
            "Iteration 277, loss = 1523188697.13312149\n",
            "Iteration 278, loss = 1523133957.33825541\n",
            "Iteration 279, loss = 1523079435.01155639\n",
            "Iteration 280, loss = 1523024852.78125596\n",
            "Iteration 281, loss = 1522970302.22727156\n",
            "Iteration 282, loss = 1522916041.89100242\n",
            "Iteration 283, loss = 1522861277.68532014\n",
            "Iteration 284, loss = 1522807125.62121677\n",
            "Iteration 285, loss = 1522752276.40970778\n",
            "Iteration 286, loss = 1522697949.19437146\n",
            "Iteration 287, loss = 1522643690.31568527\n",
            "Iteration 288, loss = 1522589150.66962385\n",
            "Iteration 289, loss = 1522534463.37789035\n",
            "Iteration 290, loss = 1522480003.62228680\n",
            "Iteration 291, loss = 1522425774.47141695\n",
            "Iteration 292, loss = 1522371217.93643856\n",
            "Iteration 293, loss = 1522316296.15422630\n",
            "Iteration 294, loss = 1522262149.55207491\n",
            "Iteration 295, loss = 1522207255.38107967\n",
            "Iteration 296, loss = 1522152666.62799525\n",
            "Iteration 297, loss = 1522097943.46135163\n",
            "Iteration 298, loss = 1522043229.02825356\n",
            "Iteration 299, loss = 1521988728.23722553\n",
            "Iteration 300, loss = 1521933983.00768280\n",
            "Iteration 301, loss = 1521879043.12572503\n",
            "Iteration 302, loss = 1521824682.63970566\n",
            "Iteration 303, loss = 1521770086.96045017\n",
            "Iteration 304, loss = 1521715719.44596839\n",
            "Iteration 305, loss = 1521661353.21913314\n",
            "Iteration 306, loss = 1521606864.91072607\n",
            "Iteration 307, loss = 1521552259.28738999\n",
            "Iteration 308, loss = 1521498458.96105814\n",
            "Iteration 309, loss = 1521444005.59656048\n",
            "Iteration 310, loss = 1521389866.88369179\n",
            "Iteration 311, loss = 1521335285.52740693\n",
            "Iteration 312, loss = 1521281396.88649940\n",
            "Iteration 313, loss = 1521226808.24771643\n",
            "Iteration 314, loss = 1521172570.67818475\n",
            "Iteration 315, loss = 1521118533.11801434\n",
            "Iteration 316, loss = 1521063708.93022275\n",
            "Iteration 317, loss = 1521009913.21118212\n",
            "Iteration 318, loss = 1520954886.90407753\n",
            "Iteration 319, loss = 1520900866.76523638\n",
            "Iteration 320, loss = 1520846351.91828299\n",
            "Iteration 321, loss = 1520792105.10596037\n",
            "Iteration 322, loss = 1520737702.32325578\n",
            "Iteration 323, loss = 1520683487.74025941\n",
            "Iteration 324, loss = 1520629377.38349819\n",
            "Iteration 325, loss = 1520575476.54076719\n",
            "Iteration 326, loss = 1520521127.04846454\n",
            "Iteration 327, loss = 1520466891.23021412\n",
            "Iteration 328, loss = 1520413058.21411872\n",
            "Iteration 329, loss = 1520358428.88138080\n",
            "Iteration 330, loss = 1520304436.51572633\n",
            "Iteration 331, loss = 1520249869.71570969\n",
            "Iteration 332, loss = 1520195687.17820454\n",
            "Iteration 333, loss = 1520140903.11397696\n",
            "Iteration 334, loss = 1520086399.47856045\n",
            "Iteration 335, loss = 1520031847.09181428\n",
            "Iteration 336, loss = 1519977181.86576748\n",
            "Iteration 337, loss = 1519922465.06711054\n",
            "Iteration 338, loss = 1519867612.66399336\n",
            "Iteration 339, loss = 1519813423.71919727\n",
            "Iteration 340, loss = 1519758088.67798424\n",
            "Iteration 341, loss = 1519703580.63328338\n",
            "Iteration 342, loss = 1519649272.29824853\n",
            "Iteration 343, loss = 1519594351.39454460\n",
            "Iteration 344, loss = 1519540067.19378591\n",
            "Iteration 345, loss = 1519485427.92101526\n",
            "Iteration 346, loss = 1519431144.76760912\n",
            "Iteration 347, loss = 1519377092.11618829\n",
            "Iteration 348, loss = 1519322621.33946037\n",
            "Iteration 349, loss = 1519268486.90431309\n",
            "Iteration 350, loss = 1519214129.27189612\n",
            "Iteration 351, loss = 1519160378.20505524\n",
            "Iteration 352, loss = 1519105892.87872601\n",
            "Iteration 353, loss = 1519051968.29060459\n",
            "Iteration 354, loss = 1518997561.40086031\n",
            "Iteration 355, loss = 1518943333.55966997\n",
            "Iteration 356, loss = 1518889118.77484655\n",
            "Iteration 357, loss = 1518834803.02207041\n",
            "Iteration 358, loss = 1518780329.77937222\n",
            "Iteration 359, loss = 1518725777.46072602\n",
            "Iteration 360, loss = 1518671650.82687306\n",
            "Iteration 361, loss = 1518617158.96899152\n",
            "Iteration 362, loss = 1518562713.93399000\n",
            "Iteration 363, loss = 1518508353.49213314\n",
            "Iteration 364, loss = 1518453783.82497740\n",
            "Iteration 365, loss = 1518399804.93556762\n",
            "Iteration 366, loss = 1518345183.59742999\n",
            "Iteration 367, loss = 1518291040.70430255\n",
            "Iteration 368, loss = 1518236726.77546287\n",
            "Iteration 369, loss = 1518182514.54471684\n",
            "Iteration 370, loss = 1518128264.15925932\n",
            "Iteration 371, loss = 1518074013.19169378\n",
            "Iteration 372, loss = 1518019892.95534801\n",
            "Iteration 373, loss = 1517965737.21258020\n",
            "Iteration 374, loss = 1517911187.79806566\n",
            "Iteration 375, loss = 1517857138.45984650\n",
            "Iteration 376, loss = 1517802609.29418755\n",
            "Iteration 377, loss = 1517748368.66923428\n",
            "Iteration 378, loss = 1517693663.95153952\n",
            "Iteration 379, loss = 1517639531.45637393\n",
            "Iteration 380, loss = 1517585286.62596273\n",
            "Iteration 381, loss = 1517530576.77223730\n",
            "Iteration 382, loss = 1517476144.35993719\n",
            "Iteration 383, loss = 1517421884.96666980\n",
            "Iteration 384, loss = 1517367354.24796867\n",
            "Iteration 385, loss = 1517312992.83068943\n",
            "Iteration 386, loss = 1517258613.39746761\n",
            "Iteration 387, loss = 1517203725.61138344\n",
            "Iteration 388, loss = 1517149810.73604679\n",
            "Iteration 389, loss = 1517095236.19734693\n",
            "Iteration 390, loss = 1517040725.88006377\n",
            "Iteration 391, loss = 1516986348.07105064\n",
            "Iteration 392, loss = 1516932062.16400480\n",
            "Iteration 393, loss = 1516877480.35041618\n",
            "Iteration 394, loss = 1516823572.03062677\n",
            "Iteration 395, loss = 1516768930.39085650\n",
            "Iteration 396, loss = 1516714626.82346940\n",
            "Iteration 397, loss = 1516660989.22506404\n",
            "Iteration 398, loss = 1516606355.05771732\n",
            "Iteration 399, loss = 1516552548.20916057\n",
            "Iteration 400, loss = 1516498489.29040432\n",
            "Iteration 401, loss = 1516444877.41348124\n",
            "Iteration 402, loss = 1516390466.49638796\n",
            "Iteration 403, loss = 1516336701.64686871\n",
            "Iteration 404, loss = 1516282647.51221180\n",
            "Iteration 405, loss = 1516228883.52124262\n",
            "Iteration 406, loss = 1516174496.04979634\n",
            "Iteration 407, loss = 1516120521.63298321\n",
            "Iteration 408, loss = 1516066532.08386898\n",
            "Iteration 409, loss = 1516011868.65054059\n",
            "Iteration 410, loss = 1515957433.84684420\n",
            "Iteration 411, loss = 1515903210.98944473\n",
            "Iteration 412, loss = 1515848752.92704868\n",
            "Iteration 413, loss = 1515794340.62315226\n",
            "Iteration 414, loss = 1515739704.25661397\n",
            "Iteration 415, loss = 1515685686.70093060\n",
            "Iteration 416, loss = 1515630923.57749176\n",
            "Iteration 417, loss = 1515576843.52236271\n",
            "Iteration 418, loss = 1515522464.13390183\n",
            "Iteration 419, loss = 1515468254.52116585\n",
            "Iteration 420, loss = 1515414015.86925793\n",
            "Iteration 421, loss = 1515359822.25640559\n",
            "Iteration 422, loss = 1515305973.52507210\n",
            "Iteration 423, loss = 1515251831.06990957\n",
            "Iteration 424, loss = 1515197733.74654984\n",
            "Iteration 425, loss = 1515143848.21705246\n",
            "Iteration 426, loss = 1515089961.73227048\n",
            "Iteration 427, loss = 1515035473.08787751\n",
            "Iteration 428, loss = 1514981845.25566721\n",
            "Iteration 429, loss = 1514927326.13864732\n",
            "Iteration 430, loss = 1514873485.52140617\n",
            "Iteration 431, loss = 1514819290.49013972\n",
            "Iteration 432, loss = 1514765199.60261345\n",
            "Iteration 433, loss = 1514710874.32963848\n",
            "Iteration 434, loss = 1514656646.59164739\n",
            "Iteration 435, loss = 1514602358.88927007\n",
            "Iteration 436, loss = 1514547959.73306441\n",
            "Iteration 437, loss = 1514493347.52085900\n",
            "Iteration 438, loss = 1514438881.02928138\n",
            "Iteration 439, loss = 1514384153.82995605\n",
            "Iteration 440, loss = 1514330014.37308335\n",
            "Iteration 441, loss = 1514275244.24453235\n",
            "Iteration 442, loss = 1514221160.13070178\n",
            "Iteration 443, loss = 1514166071.89779830\n",
            "Iteration 444, loss = 1514112246.04810262\n",
            "Iteration 445, loss = 1514057286.60437894\n",
            "Iteration 446, loss = 1514002783.12383080\n",
            "Iteration 447, loss = 1513948332.16223359\n",
            "Iteration 448, loss = 1513893681.07388854\n",
            "Iteration 449, loss = 1513839452.61708045\n",
            "Iteration 450, loss = 1513784668.81970024\n",
            "Iteration 451, loss = 1513730215.91583991\n",
            "Iteration 452, loss = 1513675881.72291040\n",
            "Iteration 453, loss = 1513621387.58453488\n",
            "Iteration 454, loss = 1513567062.06958437\n",
            "Iteration 455, loss = 1513512178.99341273\n",
            "Iteration 456, loss = 1513458301.76058722\n",
            "Iteration 457, loss = 1513403617.55303502\n",
            "Iteration 458, loss = 1513349242.87264991\n",
            "Iteration 459, loss = 1513295077.02229881\n",
            "Iteration 460, loss = 1513240541.86500525\n",
            "Iteration 461, loss = 1513186482.40644121\n",
            "Iteration 462, loss = 1513131944.57651997\n",
            "Iteration 463, loss = 1513077954.81192708\n",
            "Iteration 464, loss = 1513023756.61144924\n",
            "Iteration 465, loss = 1512969570.96107244\n",
            "Iteration 466, loss = 1512915776.04179764\n",
            "Iteration 467, loss = 1512861415.96871543\n",
            "Iteration 468, loss = 1512807176.90105748\n",
            "Iteration 469, loss = 1512753623.53195381\n",
            "Iteration 470, loss = 1512699077.83053184\n",
            "Iteration 471, loss = 1512645073.92906857\n",
            "Iteration 472, loss = 1512590813.98555040\n",
            "Iteration 473, loss = 1512536833.09634662\n",
            "Iteration 474, loss = 1512482840.23939061\n",
            "Iteration 475, loss = 1512428683.49612737\n",
            "Iteration 476, loss = 1512374501.19829845\n",
            "Iteration 477, loss = 1512320255.90049267\n",
            "Iteration 478, loss = 1512266338.80511665\n",
            "Iteration 479, loss = 1512211866.49990654\n",
            "Iteration 480, loss = 1512157557.85843992\n",
            "Iteration 481, loss = 1512102962.81239152\n",
            "Iteration 482, loss = 1512048949.67182612\n",
            "Iteration 483, loss = 1511994536.62379456\n",
            "Iteration 484, loss = 1511940053.59642577\n",
            "Iteration 485, loss = 1511886059.34549499\n",
            "Iteration 486, loss = 1511831922.26306891\n",
            "Iteration 487, loss = 1511777812.66268039\n",
            "Iteration 488, loss = 1511723719.76912308\n",
            "Iteration 489, loss = 1511669500.26864266\n",
            "Iteration 490, loss = 1511615553.25383425\n",
            "Iteration 491, loss = 1511561384.10556865\n",
            "Iteration 492, loss = 1511507238.71649289\n",
            "Iteration 493, loss = 1511452754.83286810\n",
            "Iteration 494, loss = 1511398479.53299499\n",
            "Iteration 495, loss = 1511344079.53088427\n",
            "Iteration 496, loss = 1511289850.94735312\n",
            "Iteration 497, loss = 1511235758.08488607\n",
            "Iteration 498, loss = 1511181237.45115042\n",
            "Iteration 499, loss = 1511127417.43810701\n",
            "Iteration 500, loss = 1511073041.67267561\n",
            "Iteration 501, loss = 1511019431.85313487\n",
            "Iteration 502, loss = 1510964929.07187128\n",
            "Iteration 503, loss = 1510911028.83841085\n",
            "Iteration 504, loss = 1510856675.44030523\n",
            "Iteration 505, loss = 1510802688.42476845\n",
            "Iteration 506, loss = 1510748578.85908508\n",
            "Iteration 507, loss = 1510694216.55640078\n",
            "Iteration 508, loss = 1510639813.09765434\n",
            "Iteration 509, loss = 1510585750.84299755\n",
            "Iteration 510, loss = 1510531948.16290307\n",
            "Iteration 511, loss = 1510477245.73562789\n",
            "Iteration 512, loss = 1510423149.01019311\n",
            "Iteration 513, loss = 1510369131.28769159\n",
            "Iteration 514, loss = 1510314595.96948695\n",
            "Iteration 515, loss = 1510260835.57643485\n",
            "Iteration 516, loss = 1510206302.76178908\n",
            "Iteration 517, loss = 1510152353.20751524\n",
            "Iteration 518, loss = 1510098278.99182153\n",
            "Iteration 519, loss = 1510043660.98842382\n",
            "Iteration 520, loss = 1509990096.17047620\n",
            "Iteration 521, loss = 1509935938.44344497\n",
            "Iteration 522, loss = 1509882014.06251216\n",
            "Iteration 523, loss = 1509827880.48936343\n",
            "Iteration 524, loss = 1509774129.90902376\n",
            "Iteration 525, loss = 1509720451.01091576\n",
            "Iteration 526, loss = 1509666224.92364097\n",
            "Iteration 527, loss = 1509612731.60909629\n",
            "Iteration 528, loss = 1509558151.67312288\n",
            "Iteration 529, loss = 1509504465.88757467\n",
            "Iteration 530, loss = 1509450324.99669552\n",
            "Iteration 531, loss = 1509396213.66543388\n",
            "Iteration 532, loss = 1509342029.16669154\n",
            "Iteration 533, loss = 1509287829.84519982\n",
            "Iteration 534, loss = 1509233545.51737142\n",
            "Iteration 535, loss = 1509179429.76882100\n",
            "Iteration 536, loss = 1509124941.21428776\n",
            "Iteration 537, loss = 1509070877.51002359\n",
            "Iteration 538, loss = 1509016593.13460898\n",
            "Iteration 539, loss = 1508962634.71906233\n",
            "Iteration 540, loss = 1508908304.14651775\n",
            "Iteration 541, loss = 1508854446.14510059\n",
            "Iteration 542, loss = 1508800419.64794064\n",
            "Iteration 543, loss = 1508746907.92043257\n",
            "Iteration 544, loss = 1508692958.25435734\n",
            "Iteration 545, loss = 1508638855.98319793\n",
            "Iteration 546, loss = 1508585167.27183032\n",
            "Iteration 547, loss = 1508531308.76903486\n",
            "Iteration 548, loss = 1508477271.54623032\n",
            "Iteration 549, loss = 1508423465.16409898\n",
            "Iteration 550, loss = 1508369929.93349338\n",
            "Iteration 551, loss = 1508315962.97906733\n",
            "Iteration 552, loss = 1508262047.10635614\n",
            "Iteration 553, loss = 1508208404.82647610\n",
            "Iteration 554, loss = 1508154661.31065869\n",
            "Iteration 555, loss = 1508100584.12305951\n",
            "Iteration 556, loss = 1508046952.12343717\n",
            "Iteration 557, loss = 1507992877.50760579\n",
            "Iteration 558, loss = 1507938833.74631691\n",
            "Iteration 559, loss = 1507884866.39604878\n",
            "Iteration 560, loss = 1507830675.26608968\n",
            "Iteration 561, loss = 1507776333.73333168\n",
            "Iteration 562, loss = 1507722386.81260920\n",
            "Iteration 563, loss = 1507668093.14445734\n",
            "Iteration 564, loss = 1507613990.24417043\n",
            "Iteration 565, loss = 1507559887.64323401\n",
            "Iteration 566, loss = 1507505840.11198807\n",
            "Iteration 567, loss = 1507451686.92428398\n",
            "Iteration 568, loss = 1507397963.17752790\n",
            "Iteration 569, loss = 1507343761.54348588\n",
            "Iteration 570, loss = 1507289800.30445266\n",
            "Iteration 571, loss = 1507235723.85113692\n",
            "Iteration 572, loss = 1507181620.20099330\n",
            "Iteration 573, loss = 1507127400.96302319\n",
            "Iteration 574, loss = 1507073555.41417551\n",
            "Iteration 575, loss = 1507019360.17964625\n",
            "Iteration 576, loss = 1506965461.13374090\n",
            "Iteration 577, loss = 1506911816.75361562\n",
            "Iteration 578, loss = 1506857752.93208122\n",
            "Iteration 579, loss = 1506803791.06729484\n",
            "Iteration 580, loss = 1506749504.16976237\n",
            "Iteration 581, loss = 1506695640.34622741\n",
            "Iteration 582, loss = 1506641397.08101296\n",
            "Iteration 583, loss = 1506587193.51571703\n",
            "Iteration 584, loss = 1506532731.99798369\n",
            "Iteration 585, loss = 1506478579.73647666\n",
            "Iteration 586, loss = 1506423927.79973507\n",
            "Iteration 587, loss = 1506370011.92419314\n",
            "Iteration 588, loss = 1506316059.47475672\n",
            "Iteration 589, loss = 1506261706.63891554\n",
            "Iteration 590, loss = 1506207812.88208413\n",
            "Iteration 591, loss = 1506154018.96800399\n",
            "Iteration 592, loss = 1506099820.71090293\n",
            "Iteration 593, loss = 1506046256.84785557\n",
            "Iteration 594, loss = 1505992001.44098663\n",
            "Iteration 595, loss = 1505938274.66492057\n",
            "Iteration 596, loss = 1505884274.58515406\n",
            "Iteration 597, loss = 1505830338.18839884\n",
            "Iteration 598, loss = 1505776641.98674273\n",
            "Iteration 599, loss = 1505722642.07212949\n",
            "Iteration 600, loss = 1505668773.42722321\n",
            "Iteration 601, loss = 1505614830.99643302\n",
            "Iteration 602, loss = 1505561025.33010674\n",
            "Iteration 603, loss = 1505507213.40491796\n",
            "Iteration 604, loss = 1505453050.11180663\n",
            "Iteration 605, loss = 1505398957.06764150\n",
            "Iteration 606, loss = 1505344976.33133411\n",
            "Iteration 607, loss = 1505290874.67119145\n",
            "Iteration 608, loss = 1505236801.83987927\n",
            "Iteration 609, loss = 1505182687.04810119\n",
            "Iteration 610, loss = 1505128592.18053603\n",
            "Iteration 611, loss = 1505074844.74900150\n",
            "Iteration 612, loss = 1505020622.53745103\n",
            "Iteration 613, loss = 1504966765.56706023\n",
            "Iteration 614, loss = 1504912661.20217991\n",
            "Iteration 615, loss = 1504859006.30842996\n",
            "Iteration 616, loss = 1504805102.22884059\n",
            "Iteration 617, loss = 1504751180.30704427\n",
            "Iteration 618, loss = 1504697425.60510635\n",
            "Iteration 619, loss = 1504643446.34945059\n",
            "Iteration 620, loss = 1504589686.86983609\n",
            "Iteration 621, loss = 1504536060.62103438\n",
            "Iteration 622, loss = 1504482024.19863534\n",
            "Iteration 623, loss = 1504428202.51780534\n",
            "Iteration 624, loss = 1504374164.49470901\n",
            "Iteration 625, loss = 1504320599.63740897\n",
            "Iteration 626, loss = 1504266744.37846923\n",
            "Iteration 627, loss = 1504212860.39220691\n",
            "Iteration 628, loss = 1504159162.80407882\n",
            "Iteration 629, loss = 1504104884.36107326\n",
            "Iteration 630, loss = 1504051467.44308138\n",
            "Iteration 631, loss = 1503997694.26963472\n",
            "Iteration 632, loss = 1503943921.77823853\n",
            "Iteration 633, loss = 1503890207.22679901\n",
            "Iteration 634, loss = 1503836484.82005405\n",
            "Iteration 635, loss = 1503782969.64518237\n",
            "Iteration 636, loss = 1503729408.59715509\n",
            "Iteration 637, loss = 1503675968.97088146\n",
            "Iteration 638, loss = 1503622019.54594827\n",
            "Iteration 639, loss = 1503568228.57153130\n",
            "Iteration 640, loss = 1503514723.88960814\n",
            "Iteration 641, loss = 1503460884.34357214\n",
            "Iteration 642, loss = 1503406917.64905667\n",
            "Iteration 643, loss = 1503353196.79993701\n",
            "Iteration 644, loss = 1503299444.39782906\n",
            "Iteration 645, loss = 1503245236.65556550\n",
            "Iteration 646, loss = 1503191562.01668334\n",
            "Iteration 647, loss = 1503137602.28662014\n",
            "Iteration 648, loss = 1503083774.48678136\n",
            "Iteration 649, loss = 1503029846.73361301\n",
            "Iteration 650, loss = 1502975545.07668066\n",
            "Iteration 651, loss = 1502921753.05452514\n",
            "Iteration 652, loss = 1502867792.95745492\n",
            "Iteration 653, loss = 1502813917.08226800\n",
            "Iteration 654, loss = 1502759868.28927159\n",
            "Iteration 655, loss = 1502705687.78145218\n",
            "Iteration 656, loss = 1502651726.76005459\n",
            "Iteration 657, loss = 1502597579.92779803\n",
            "Iteration 658, loss = 1502543773.91326070\n",
            "Iteration 659, loss = 1502489669.65518355\n",
            "Iteration 660, loss = 1502435941.60685778\n",
            "Iteration 661, loss = 1502381710.45597386\n",
            "Iteration 662, loss = 1502328118.24613881\n",
            "Iteration 663, loss = 1502274385.60450459\n",
            "Iteration 664, loss = 1502220546.71276546\n",
            "Iteration 665, loss = 1502166631.74208212\n",
            "Iteration 666, loss = 1502112975.74711037\n",
            "Iteration 667, loss = 1502059075.89362764\n",
            "Iteration 668, loss = 1502005218.97699642\n",
            "Iteration 669, loss = 1501951177.37582660\n",
            "Iteration 670, loss = 1501897400.97177958\n",
            "Iteration 671, loss = 1501843330.58139563\n",
            "Iteration 672, loss = 1501789715.71626520\n",
            "Iteration 673, loss = 1501735292.74637771\n",
            "Iteration 674, loss = 1501681386.15084052\n",
            "Iteration 675, loss = 1501627728.72469640\n",
            "Iteration 676, loss = 1501573694.32628465\n",
            "Iteration 677, loss = 1501519795.31149769\n",
            "Iteration 678, loss = 1501465908.82420611\n",
            "Iteration 679, loss = 1501411975.47374964\n",
            "Iteration 680, loss = 1501358055.99730396\n",
            "Iteration 681, loss = 1501304435.85626197\n",
            "Iteration 682, loss = 1501250497.96517158\n",
            "Iteration 683, loss = 1501196751.10603237\n",
            "Iteration 684, loss = 1501142711.68934369\n",
            "Iteration 685, loss = 1501089031.41761780\n",
            "Iteration 686, loss = 1501035290.17979860\n",
            "Iteration 687, loss = 1500981345.58779979\n",
            "Iteration 688, loss = 1500927715.87650871\n",
            "Iteration 689, loss = 1500873547.68210125\n",
            "Iteration 690, loss = 1500820090.84572387\n",
            "Iteration 691, loss = 1500766003.27891922\n",
            "Iteration 692, loss = 1500711992.76928067\n",
            "Iteration 693, loss = 1500658641.78046513\n",
            "Iteration 694, loss = 1500604409.21728897\n",
            "Iteration 695, loss = 1500550784.05371976\n",
            "Iteration 696, loss = 1500496582.00413036\n",
            "Iteration 697, loss = 1500442649.42800212\n",
            "Iteration 698, loss = 1500388857.13040972\n",
            "Iteration 699, loss = 1500335020.36777639\n",
            "Iteration 700, loss = 1500280706.75640917\n",
            "Iteration 701, loss = 1500226821.63522220\n",
            "Iteration 702, loss = 1500172900.28545570\n",
            "Iteration 703, loss = 1500119166.86986876\n",
            "Iteration 704, loss = 1500065334.33648896\n",
            "Iteration 705, loss = 1500011422.44255209\n",
            "Iteration 706, loss = 1499957725.05899549\n",
            "Iteration 707, loss = 1499903623.57952714\n",
            "Iteration 708, loss = 1499850129.91827297\n",
            "Iteration 709, loss = 1499796338.42550135\n",
            "Iteration 710, loss = 1499742015.57705259\n",
            "Iteration 711, loss = 1499688259.56568050\n",
            "Iteration 712, loss = 1499634491.36782026\n",
            "Iteration 713, loss = 1499580666.12835598\n",
            "Iteration 714, loss = 1499526052.91633630\n",
            "Iteration 715, loss = 1499472397.48943877\n",
            "Iteration 716, loss = 1499418156.00783110\n",
            "Iteration 717, loss = 1499363902.73902249\n",
            "Iteration 718, loss = 1499309798.58277345\n",
            "Iteration 719, loss = 1499255936.66727138\n",
            "Iteration 720, loss = 1499201805.54633498\n",
            "Iteration 721, loss = 1499148145.58540750\n",
            "Iteration 722, loss = 1499093962.05089116\n",
            "Iteration 723, loss = 1499040330.36359525\n",
            "Iteration 724, loss = 1498986601.53671980\n",
            "Iteration 725, loss = 1498932488.18073249\n",
            "Iteration 726, loss = 1498878512.33198476\n",
            "Iteration 727, loss = 1498824923.38770700\n",
            "Iteration 728, loss = 1498770734.57045960\n",
            "Iteration 729, loss = 1498716753.49200773\n",
            "Iteration 730, loss = 1498662685.78571320\n",
            "Iteration 731, loss = 1498608931.93736053\n",
            "Iteration 732, loss = 1498555112.27923393\n",
            "Iteration 733, loss = 1498501146.80568385\n",
            "Iteration 734, loss = 1498447252.11139655\n",
            "Iteration 735, loss = 1498393721.87740660\n",
            "Iteration 736, loss = 1498339753.52231526\n",
            "Iteration 737, loss = 1498286069.56471038\n",
            "Iteration 738, loss = 1498232504.04084611\n",
            "Iteration 739, loss = 1498178461.21143866\n",
            "Iteration 740, loss = 1498124722.81323528\n",
            "Iteration 741, loss = 1498070949.31416464\n",
            "Iteration 742, loss = 1498016947.49969172\n",
            "Iteration 743, loss = 1497963152.04505754\n",
            "Iteration 744, loss = 1497908957.76828384\n",
            "Iteration 745, loss = 1497855290.39586926\n",
            "Iteration 746, loss = 1497801074.60389233\n",
            "Iteration 747, loss = 1497747544.96112728\n",
            "Iteration 748, loss = 1497693465.70134735\n",
            "Iteration 749, loss = 1497639929.35373807\n",
            "Iteration 750, loss = 1497586249.81611896\n",
            "Iteration 751, loss = 1497532096.29716563\n",
            "Iteration 752, loss = 1497479327.30611396\n",
            "Iteration 753, loss = 1497424876.89939332\n",
            "Iteration 754, loss = 1497371829.31491423\n",
            "Iteration 755, loss = 1497318045.65026617\n",
            "Iteration 756, loss = 1497264240.87590575\n",
            "Iteration 757, loss = 1497210619.73806691\n",
            "Iteration 758, loss = 1497156853.10207820\n",
            "Iteration 759, loss = 1497103064.35499477\n",
            "Iteration 760, loss = 1497049270.49750900\n",
            "Iteration 761, loss = 1496995378.08833814\n",
            "Iteration 762, loss = 1496941449.82608080\n",
            "Iteration 763, loss = 1496887688.90076256\n",
            "Iteration 764, loss = 1496833822.19712687\n",
            "Iteration 765, loss = 1496780227.37049055\n",
            "Iteration 766, loss = 1496726433.07683778\n",
            "Iteration 767, loss = 1496672815.23213840\n",
            "Iteration 768, loss = 1496619176.71571398\n",
            "Iteration 769, loss = 1496565422.76722741\n",
            "Iteration 770, loss = 1496511926.79765964\n",
            "Iteration 771, loss = 1496457939.67055893\n",
            "Iteration 772, loss = 1496404407.79719353\n",
            "Iteration 773, loss = 1496350511.50427532\n",
            "Iteration 774, loss = 1496296970.26160431\n",
            "Iteration 775, loss = 1496243052.76229620\n",
            "Iteration 776, loss = 1496189538.91829538\n",
            "Iteration 777, loss = 1496135964.72241783\n",
            "Iteration 778, loss = 1496081961.14548993\n",
            "Iteration 779, loss = 1496028497.07947206\n",
            "Iteration 780, loss = 1495974549.38613319\n",
            "Iteration 781, loss = 1495920787.53324676\n",
            "Iteration 782, loss = 1495866820.80732250\n",
            "Iteration 783, loss = 1495812570.64324665\n",
            "Iteration 784, loss = 1495758913.95713234\n",
            "Iteration 785, loss = 1495704694.66352630\n",
            "Iteration 786, loss = 1495650841.11971259\n",
            "Iteration 787, loss = 1495596791.47004437\n",
            "Iteration 788, loss = 1495542560.10157084\n",
            "Iteration 789, loss = 1495488700.69436169\n",
            "Iteration 790, loss = 1495434681.11050987\n",
            "Iteration 791, loss = 1495380724.59748030\n",
            "Iteration 792, loss = 1495326557.44276237\n",
            "Iteration 793, loss = 1495272596.17772889\n",
            "Iteration 794, loss = 1495218289.21840572\n",
            "Iteration 795, loss = 1495164639.36343813\n",
            "Iteration 796, loss = 1495110387.51690888\n",
            "Iteration 797, loss = 1495056637.03922677\n",
            "Iteration 798, loss = 1495002443.97956610\n",
            "Iteration 799, loss = 1494948739.85709023\n",
            "Iteration 800, loss = 1494895150.46026969\n",
            "Iteration 801, loss = 1494841139.19258523\n",
            "Iteration 802, loss = 1494787840.57786775\n",
            "Iteration 803, loss = 1494733967.84909725\n",
            "Iteration 804, loss = 1494680553.21934366\n",
            "Iteration 805, loss = 1494626796.29114795\n",
            "Iteration 806, loss = 1494573537.30998325\n",
            "Iteration 807, loss = 1494519731.95477676\n",
            "Iteration 808, loss = 1494466039.50533772\n",
            "Iteration 809, loss = 1494412539.76883030\n",
            "Iteration 810, loss = 1494359287.63528800\n",
            "Iteration 811, loss = 1494305306.43559361\n",
            "Iteration 812, loss = 1494251932.41322088\n",
            "Iteration 813, loss = 1494198571.33398676\n",
            "Iteration 814, loss = 1494144861.13876128\n",
            "Iteration 815, loss = 1494091499.74073672\n",
            "Iteration 816, loss = 1494037889.15332127\n",
            "Iteration 817, loss = 1493984125.23820877\n",
            "Iteration 818, loss = 1493930763.50148058\n",
            "Iteration 819, loss = 1493877378.22916079\n",
            "Iteration 820, loss = 1493823806.64572453\n",
            "Iteration 821, loss = 1493770341.05090761\n",
            "Iteration 822, loss = 1493716804.95038438\n",
            "Iteration 823, loss = 1493663423.12397099\n",
            "Iteration 824, loss = 1493609964.72094679\n",
            "Iteration 825, loss = 1493556296.76790929\n",
            "Iteration 826, loss = 1493502904.62164474\n",
            "Iteration 827, loss = 1493449310.45141315\n",
            "Iteration 828, loss = 1493395310.79653978\n",
            "Iteration 829, loss = 1493341884.31395793\n",
            "Iteration 830, loss = 1493288536.34857321\n",
            "Iteration 831, loss = 1493234880.29409170\n",
            "Iteration 832, loss = 1493181385.10613036\n",
            "Iteration 833, loss = 1493128028.02567220\n",
            "Iteration 834, loss = 1493074552.29999113\n",
            "Iteration 835, loss = 1493021188.20347714\n",
            "Iteration 836, loss = 1492967509.90261984\n",
            "Iteration 837, loss = 1492914104.03641009\n",
            "Iteration 838, loss = 1492860770.12925005\n",
            "Iteration 839, loss = 1492807487.65140605\n",
            "Iteration 840, loss = 1492754331.64449763\n",
            "Iteration 841, loss = 1492700509.68867588\n",
            "Iteration 842, loss = 1492647781.62285995\n",
            "Iteration 843, loss = 1492594382.60950279\n",
            "Iteration 844, loss = 1492541331.04277420\n",
            "Iteration 845, loss = 1492488040.35521293\n",
            "Iteration 846, loss = 1492434572.27072859\n",
            "Iteration 847, loss = 1492381150.52063870\n",
            "Iteration 848, loss = 1492327985.53881598\n",
            "Iteration 849, loss = 1492274576.34470415\n",
            "Iteration 850, loss = 1492221092.58377361\n",
            "Iteration 851, loss = 1492167722.93764830\n",
            "Iteration 852, loss = 1492114390.71428728\n",
            "Iteration 853, loss = 1492060740.92801785\n",
            "Iteration 854, loss = 1492007739.99997902\n",
            "Iteration 855, loss = 1491954006.19624901\n",
            "Iteration 856, loss = 1491900687.56292009\n",
            "Iteration 857, loss = 1491847369.57451439\n",
            "Iteration 858, loss = 1491793872.34409642\n",
            "Iteration 859, loss = 1491740399.92408514\n",
            "Iteration 860, loss = 1491686989.19111133\n",
            "Iteration 861, loss = 1491633444.22193766\n",
            "Iteration 862, loss = 1491579908.27348042\n",
            "Iteration 863, loss = 1491526204.24025202\n",
            "Iteration 864, loss = 1491472858.67442703\n",
            "Iteration 865, loss = 1491418948.12924862\n",
            "Iteration 866, loss = 1491365438.51133156\n",
            "Iteration 867, loss = 1491311667.94235897\n",
            "Iteration 868, loss = 1491257966.64754820\n",
            "Iteration 869, loss = 1491204095.14557624\n",
            "Iteration 870, loss = 1491150521.26663280\n",
            "Iteration 871, loss = 1491096460.30463147\n",
            "Iteration 872, loss = 1491042994.53290844\n",
            "Iteration 873, loss = 1490989146.54390001\n",
            "Iteration 874, loss = 1490935246.84892225\n",
            "Iteration 875, loss = 1490881952.64246440\n",
            "Iteration 876, loss = 1490827718.29441118\n",
            "Iteration 877, loss = 1490774177.40840054\n",
            "Iteration 878, loss = 1490720711.61110401\n",
            "Iteration 879, loss = 1490667070.57314277\n",
            "Iteration 880, loss = 1490613184.12750149\n",
            "Iteration 881, loss = 1490559679.63325429\n",
            "Iteration 882, loss = 1490506202.38148475\n",
            "Iteration 883, loss = 1490452528.19832683\n",
            "Iteration 884, loss = 1490399088.89721704\n",
            "Iteration 885, loss = 1490345352.44151139\n",
            "Iteration 886, loss = 1490292046.38336706\n",
            "Iteration 887, loss = 1490238354.11921334\n",
            "Iteration 888, loss = 1490184730.83904195\n",
            "Iteration 889, loss = 1490131363.76909995\n",
            "Iteration 890, loss = 1490078016.54950070\n",
            "Iteration 891, loss = 1490024280.25756598\n",
            "Iteration 892, loss = 1489970618.52261066\n",
            "Iteration 893, loss = 1489917339.81186843\n",
            "Iteration 894, loss = 1489863562.25824642\n",
            "Iteration 895, loss = 1489810092.20880461\n",
            "Iteration 896, loss = 1489756364.96786785\n",
            "Iteration 897, loss = 1489702532.47887707\n",
            "Iteration 898, loss = 1489648954.08893657\n",
            "Iteration 899, loss = 1489595488.44257975\n",
            "Iteration 900, loss = 1489541343.30587840\n",
            "Iteration 901, loss = 1489488019.14040828\n",
            "Iteration 902, loss = 1489434001.24286151\n",
            "Iteration 903, loss = 1489380904.66052890\n",
            "Iteration 904, loss = 1489327188.98498797\n",
            "Iteration 905, loss = 1489273310.92465448\n",
            "Iteration 906, loss = 1489220240.56656027\n",
            "Iteration 907, loss = 1489166828.47144866\n",
            "Iteration 908, loss = 1489113401.90049911\n",
            "Iteration 909, loss = 1489059965.15256691\n",
            "Iteration 910, loss = 1489006681.27271318\n",
            "Iteration 911, loss = 1488953215.71811795\n",
            "Iteration 912, loss = 1488900082.45819616\n",
            "Iteration 913, loss = 1488846699.11068845\n",
            "Iteration 914, loss = 1488793326.03534794\n",
            "Iteration 915, loss = 1488740088.71078324\n",
            "Iteration 916, loss = 1488686781.25318146\n",
            "Iteration 917, loss = 1488633207.51557946\n",
            "Iteration 918, loss = 1488580388.97084904\n",
            "Iteration 919, loss = 1488526636.37269378\n",
            "Iteration 920, loss = 1488473208.56514692\n",
            "Iteration 921, loss = 1488419562.20657063\n",
            "Iteration 922, loss = 1488366285.73592997\n",
            "Iteration 923, loss = 1488312477.68520832\n",
            "Iteration 924, loss = 1488258824.45381570\n",
            "Iteration 925, loss = 1488205035.15424609\n",
            "Iteration 926, loss = 1488151618.35602498\n",
            "Iteration 927, loss = 1488097589.25430417\n",
            "Iteration 928, loss = 1488043893.59085655\n",
            "Iteration 929, loss = 1487990415.31270909\n",
            "Iteration 930, loss = 1487936350.06653118\n",
            "Iteration 931, loss = 1487882663.01776767\n",
            "Iteration 932, loss = 1487828913.71078634\n",
            "Iteration 933, loss = 1487775417.34863114\n",
            "Iteration 934, loss = 1487721780.94507408\n",
            "Iteration 935, loss = 1487668148.63164186\n",
            "Iteration 936, loss = 1487614516.88760400\n",
            "Iteration 937, loss = 1487561152.24363542\n",
            "Iteration 938, loss = 1487507449.08070421\n",
            "Iteration 939, loss = 1487454183.16534781\n",
            "Iteration 940, loss = 1487400612.31829977\n",
            "Iteration 941, loss = 1487347095.04764771\n",
            "Iteration 942, loss = 1487293900.38580489\n",
            "Iteration 943, loss = 1487240298.00572205\n",
            "Iteration 944, loss = 1487187230.07139659\n",
            "Iteration 945, loss = 1487133404.44251251\n",
            "Iteration 946, loss = 1487079864.36938810\n",
            "Iteration 947, loss = 1487026557.91305518\n",
            "Iteration 948, loss = 1486972731.79722524\n",
            "Iteration 949, loss = 1486918719.79125500\n",
            "Iteration 950, loss = 1486865307.58304834\n",
            "Iteration 951, loss = 1486811337.53647566\n",
            "Iteration 952, loss = 1486757664.19670820\n",
            "Iteration 953, loss = 1486704127.66060853\n",
            "Iteration 954, loss = 1486650504.04453588\n",
            "Iteration 955, loss = 1486596958.52634621\n",
            "Iteration 956, loss = 1486543536.93695784\n",
            "Iteration 957, loss = 1486490421.07238364\n",
            "Iteration 958, loss = 1486437151.98227859\n",
            "Iteration 959, loss = 1486383687.45321536\n",
            "Iteration 960, loss = 1486330521.97579074\n",
            "Iteration 961, loss = 1486277275.91945052\n",
            "Iteration 962, loss = 1486224161.72260070\n",
            "Iteration 963, loss = 1486170899.68468356\n",
            "Iteration 964, loss = 1486117668.36613035\n",
            "Iteration 965, loss = 1486064866.68451357\n",
            "Iteration 966, loss = 1486011297.01640248\n",
            "Iteration 967, loss = 1485958439.43937993\n",
            "Iteration 968, loss = 1485905598.12131786\n",
            "Iteration 969, loss = 1485852155.02505255\n",
            "Iteration 970, loss = 1485799348.89385223\n",
            "Iteration 971, loss = 1485746115.49326015\n",
            "Iteration 972, loss = 1485692953.95626640\n",
            "Iteration 973, loss = 1485639731.32226896\n",
            "Iteration 974, loss = 1485586960.88706899\n",
            "Iteration 975, loss = 1485533596.49129605\n",
            "Iteration 976, loss = 1485480499.20192719\n",
            "Iteration 977, loss = 1485427412.20491266\n",
            "Iteration 978, loss = 1485374256.10901022\n",
            "Iteration 979, loss = 1485321163.30555439\n",
            "Iteration 980, loss = 1485268243.90590596\n",
            "Iteration 981, loss = 1485214791.97895646\n",
            "Iteration 982, loss = 1485162001.86113453\n",
            "Iteration 983, loss = 1485108303.10966349\n",
            "Iteration 984, loss = 1485055292.30650043\n",
            "Iteration 985, loss = 1485002067.04984975\n",
            "Iteration 986, loss = 1484948456.61669493\n",
            "Iteration 987, loss = 1484895189.52476048\n",
            "Iteration 988, loss = 1484841901.02775407\n",
            "Iteration 989, loss = 1484788395.12613225\n",
            "Iteration 990, loss = 1484735108.49405622\n",
            "Iteration 991, loss = 1484681948.69350863\n",
            "Iteration 992, loss = 1484628986.08012748\n",
            "Iteration 993, loss = 1484575535.02364898\n",
            "Iteration 994, loss = 1484522359.68696451\n",
            "Iteration 995, loss = 1484469511.88208151\n",
            "Iteration 996, loss = 1484416182.75250602\n",
            "Iteration 997, loss = 1484362485.78035617\n",
            "Iteration 998, loss = 1484309449.30350995\n",
            "Iteration 999, loss = 1484255641.03596640\n",
            "Iteration 1000, loss = 1484202360.35034990\n",
            "Iteration 1, loss = 1403841721.44166136\n",
            "Iteration 2, loss = 173547332.85466465\n",
            "Iteration 3, loss = 294559006.23760372\n",
            "Iteration 4, loss = 231523496.11712798\n",
            "Iteration 5, loss = 98779913.86263590\n",
            "Iteration 6, loss = 116318544.69049074\n",
            "Iteration 7, loss = 109111584.02907294\n",
            "Iteration 8, loss = 95553913.43572749\n",
            "Iteration 9, loss = 98609670.98628342\n",
            "Iteration 10, loss = 97221959.87539478\n",
            "Iteration 11, loss = 95829354.13238038\n",
            "Iteration 12, loss = 96706259.13847649\n",
            "Iteration 13, loss = 95598138.57085519\n",
            "Iteration 14, loss = 96745577.17829287\n",
            "Iteration 15, loss = 96698657.05351773\n",
            "Iteration 16, loss = 95674998.80692758\n",
            "Iteration 17, loss = 95827974.40799764\n",
            "Iteration 18, loss = 95990504.59531996\n",
            "Iteration 19, loss = 96149641.39814712\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538807803.47312212\n",
            "Iteration 2, loss = 1538739175.09501600\n",
            "Iteration 3, loss = 1538672839.40930438\n",
            "Iteration 4, loss = 1538616235.81949401\n",
            "Iteration 5, loss = 1538571912.33241916\n",
            "Iteration 6, loss = 1538534917.54274821\n",
            "Iteration 7, loss = 1538500871.42747259\n",
            "Iteration 8, loss = 1538467163.29092312\n",
            "Iteration 9, loss = 1538433271.37919545\n",
            "Iteration 10, loss = 1538399213.13773704\n",
            "Iteration 11, loss = 1538364301.17901969\n",
            "Iteration 12, loss = 1538328256.42277479\n",
            "Iteration 13, loss = 1538290320.50730705\n",
            "Iteration 14, loss = 1538251086.58981991\n",
            "Iteration 15, loss = 1538211111.07824755\n",
            "Iteration 16, loss = 1538172511.94493389\n",
            "Iteration 17, loss = 1538134805.42653275\n",
            "Iteration 18, loss = 1538097057.69496179\n",
            "Iteration 19, loss = 1538059570.46041298\n",
            "Iteration 20, loss = 1538021479.56966543\n",
            "Iteration 21, loss = 1537983413.56830096\n",
            "Iteration 22, loss = 1537943825.77656460\n",
            "Iteration 23, loss = 1537903699.30377030\n",
            "Iteration 24, loss = 1537864438.11866736\n",
            "Iteration 25, loss = 1537825304.82996273\n",
            "Iteration 26, loss = 1537786651.84230614\n",
            "Iteration 27, loss = 1537747927.99501801\n",
            "Iteration 28, loss = 1537709219.69157314\n",
            "Iteration 29, loss = 1537670741.32141852\n",
            "Iteration 30, loss = 1537632147.20167232\n",
            "Iteration 31, loss = 1537593624.92970610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 32, loss = 1537554801.80658960\n",
            "Iteration 33, loss = 1537514789.48671985\n",
            "Iteration 34, loss = 1537472452.69881678\n",
            "Iteration 35, loss = 1537428766.17587066\n",
            "Iteration 36, loss = 1537386319.62120008\n",
            "Iteration 37, loss = 1537344602.57641888\n",
            "Iteration 38, loss = 1537303289.11727071\n",
            "Iteration 39, loss = 1537261512.91157937\n",
            "Iteration 40, loss = 1537220047.35535383\n",
            "Iteration 41, loss = 1537178478.98212075\n",
            "Iteration 42, loss = 1537137023.75851941\n",
            "Iteration 43, loss = 1537095597.73669386\n",
            "Iteration 44, loss = 1537054398.04537868\n",
            "Iteration 45, loss = 1537013053.17861319\n",
            "Iteration 46, loss = 1536971899.75491238\n",
            "Iteration 47, loss = 1536930995.78159618\n",
            "Iteration 48, loss = 1536890104.67261124\n",
            "Iteration 49, loss = 1536849026.70171738\n",
            "Iteration 50, loss = 1536807846.92836070\n",
            "Iteration 51, loss = 1536765622.03110814\n",
            "Iteration 52, loss = 1536721757.42195535\n",
            "Iteration 53, loss = 1536678483.11737609\n",
            "Iteration 54, loss = 1536635839.73629069\n",
            "Iteration 55, loss = 1536593062.77352357\n",
            "Iteration 56, loss = 1536550693.07348108\n",
            "Iteration 57, loss = 1536508297.04245806\n",
            "Iteration 58, loss = 1536465748.33761120\n",
            "Iteration 59, loss = 1536423626.31009793\n",
            "Iteration 60, loss = 1536381203.79972577\n",
            "Iteration 61, loss = 1536338666.47948456\n",
            "Iteration 62, loss = 1536296902.67059231\n",
            "Iteration 63, loss = 1536254758.14322758\n",
            "Iteration 64, loss = 1536212423.30807328\n",
            "Iteration 65, loss = 1536170652.47302747\n",
            "Iteration 66, loss = 1536128781.13254356\n",
            "Iteration 67, loss = 1536086915.34795642\n",
            "Iteration 68, loss = 1536045233.09309626\n",
            "Iteration 69, loss = 1536003689.08805776\n",
            "Iteration 70, loss = 1535961930.43099570\n",
            "Iteration 71, loss = 1535920604.84817863\n",
            "Iteration 72, loss = 1535878862.83479691\n",
            "Iteration 73, loss = 1535837568.97010064\n",
            "Iteration 74, loss = 1535795696.63935614\n",
            "Iteration 75, loss = 1535751658.19044995\n",
            "Iteration 76, loss = 1535706795.00150228\n",
            "Iteration 77, loss = 1535662952.98935556\n",
            "Iteration 78, loss = 1535619210.05115175\n",
            "Iteration 79, loss = 1535575676.51480842\n",
            "Iteration 80, loss = 1535532202.72829247\n",
            "Iteration 81, loss = 1535488405.89109778\n",
            "Iteration 82, loss = 1535443451.42994142\n",
            "Iteration 83, loss = 1535396181.22364616\n",
            "Iteration 84, loss = 1535349444.35504651\n",
            "Iteration 85, loss = 1535303341.34789038\n",
            "Iteration 86, loss = 1535256982.34978294\n",
            "Iteration 87, loss = 1535211239.89038801\n",
            "Iteration 88, loss = 1535164333.71888900\n",
            "Iteration 89, loss = 1535118001.81962872\n",
            "Iteration 90, loss = 1535068983.38042808\n",
            "Iteration 91, loss = 1535019682.05351424\n",
            "Iteration 92, loss = 1534971257.02272606\n",
            "Iteration 93, loss = 1534923526.84227920\n",
            "Iteration 94, loss = 1534874866.09481382\n",
            "Iteration 95, loss = 1534827061.39891171\n",
            "Iteration 96, loss = 1534778961.52950335\n",
            "Iteration 97, loss = 1534730783.26855969\n",
            "Iteration 98, loss = 1534683187.95958900\n",
            "Iteration 99, loss = 1534635342.50243950\n",
            "Iteration 100, loss = 1534587687.00111365\n",
            "Iteration 101, loss = 1534540341.13655472\n",
            "Iteration 102, loss = 1534492887.34961081\n",
            "Iteration 103, loss = 1534445754.65695858\n",
            "Iteration 104, loss = 1534398849.69278574\n",
            "Iteration 105, loss = 1534351672.05258584\n",
            "Iteration 106, loss = 1534305173.48373365\n",
            "Iteration 107, loss = 1534258383.01441360\n",
            "Iteration 108, loss = 1534211551.63231421\n",
            "Iteration 109, loss = 1534165238.27083278\n",
            "Iteration 110, loss = 1534119118.18098307\n",
            "Iteration 111, loss = 1534072500.13047147\n",
            "Iteration 112, loss = 1534026320.40355086\n",
            "Iteration 113, loss = 1533980759.87895060\n",
            "Iteration 114, loss = 1533934733.83675671\n",
            "Iteration 115, loss = 1533888996.94012785\n",
            "Iteration 116, loss = 1533843345.85793781\n",
            "Iteration 117, loss = 1533797847.04116845\n",
            "Iteration 118, loss = 1533752540.52807379\n",
            "Iteration 119, loss = 1533706253.43805790\n",
            "Iteration 120, loss = 1533658006.63317585\n",
            "Iteration 121, loss = 1533609077.08197427\n",
            "Iteration 122, loss = 1533561031.29941058\n",
            "Iteration 123, loss = 1533512668.52625012\n",
            "Iteration 124, loss = 1533464804.68363667\n",
            "Iteration 125, loss = 1533416417.55905271\n",
            "Iteration 126, loss = 1533368516.26036143\n",
            "Iteration 127, loss = 1533319833.41269088\n",
            "Iteration 128, loss = 1533271811.13899612\n",
            "Iteration 129, loss = 1533223406.83188581\n",
            "Iteration 130, loss = 1533175549.31676149\n",
            "Iteration 131, loss = 1533127392.83387065\n",
            "Iteration 132, loss = 1533079532.15809250\n",
            "Iteration 133, loss = 1533031750.06051970\n",
            "Iteration 134, loss = 1532983613.46396852\n",
            "Iteration 135, loss = 1532936518.52218080\n",
            "Iteration 136, loss = 1532887423.12570357\n",
            "Iteration 137, loss = 1532836098.37985420\n",
            "Iteration 138, loss = 1532785332.26525688\n",
            "Iteration 139, loss = 1532735239.09622645\n",
            "Iteration 140, loss = 1532685084.46138787\n",
            "Iteration 141, loss = 1532634638.17928767\n",
            "Iteration 142, loss = 1532584708.07686949\n",
            "Iteration 143, loss = 1532534821.72791934\n",
            "Iteration 144, loss = 1532484419.22456503\n",
            "Iteration 145, loss = 1532434659.93869996\n",
            "Iteration 146, loss = 1532384904.99465251\n",
            "Iteration 147, loss = 1532335118.30374312\n",
            "Iteration 148, loss = 1532285384.98168063\n",
            "Iteration 149, loss = 1532236126.94098496\n",
            "Iteration 150, loss = 1532186495.50437784\n",
            "Iteration 151, loss = 1532137252.31124520\n",
            "Iteration 152, loss = 1532088331.80929995\n",
            "Iteration 153, loss = 1532039282.98958325\n",
            "Iteration 154, loss = 1531990141.32327390\n",
            "Iteration 155, loss = 1531941699.30519724\n",
            "Iteration 156, loss = 1531892782.34371543\n",
            "Iteration 157, loss = 1531844273.12266850\n",
            "Iteration 158, loss = 1531795621.88361263\n",
            "Iteration 159, loss = 1531747234.04952264\n",
            "Iteration 160, loss = 1531698741.79776978\n",
            "Iteration 161, loss = 1531650198.09144759\n",
            "Iteration 162, loss = 1531602136.67849946\n",
            "Iteration 163, loss = 1531553645.41474390\n",
            "Iteration 164, loss = 1531505737.04729533\n",
            "Iteration 165, loss = 1531457282.16491365\n",
            "Iteration 166, loss = 1531409456.52295184\n",
            "Iteration 167, loss = 1531361211.65818787\n",
            "Iteration 168, loss = 1531313450.95627165\n",
            "Iteration 169, loss = 1531265537.54401612\n",
            "Iteration 170, loss = 1531217726.60725880\n",
            "Iteration 171, loss = 1531170078.26286983\n",
            "Iteration 172, loss = 1531122496.45965481\n",
            "Iteration 173, loss = 1531074889.79467416\n",
            "Iteration 174, loss = 1531027598.05054832\n",
            "Iteration 175, loss = 1530979937.31613183\n",
            "Iteration 176, loss = 1530932813.47483754\n",
            "Iteration 177, loss = 1530885750.74591064\n",
            "Iteration 178, loss = 1530838038.98421526\n",
            "Iteration 179, loss = 1530790606.89614654\n",
            "Iteration 180, loss = 1530741113.53117776\n",
            "Iteration 181, loss = 1530689235.17738128\n",
            "Iteration 182, loss = 1530638319.88055348\n",
            "Iteration 183, loss = 1530587721.59662414\n",
            "Iteration 184, loss = 1530537061.73184323\n",
            "Iteration 185, loss = 1530485777.44412303\n",
            "Iteration 186, loss = 1530434651.19157052\n",
            "Iteration 187, loss = 1530383630.91525698\n",
            "Iteration 188, loss = 1530332483.11676335\n",
            "Iteration 189, loss = 1530281144.98052406\n",
            "Iteration 190, loss = 1530230316.76460552\n",
            "Iteration 191, loss = 1530179121.41316986\n",
            "Iteration 192, loss = 1530128723.81908488\n",
            "Iteration 193, loss = 1530077771.28754711\n",
            "Iteration 194, loss = 1530027432.34827495\n",
            "Iteration 195, loss = 1529977096.87025476\n",
            "Iteration 196, loss = 1529926531.65281653\n",
            "Iteration 197, loss = 1529876789.78400564\n",
            "Iteration 198, loss = 1529826915.72674489\n",
            "Iteration 199, loss = 1529776650.89353490\n",
            "Iteration 200, loss = 1529727079.59896064\n",
            "Iteration 201, loss = 1529677478.24818301\n",
            "Iteration 202, loss = 1529627803.26254463\n",
            "Iteration 203, loss = 1529578342.41601777\n",
            "Iteration 204, loss = 1529528804.01317334\n",
            "Iteration 205, loss = 1529479461.97981358\n",
            "Iteration 206, loss = 1529429867.67534447\n",
            "Iteration 207, loss = 1529380551.31080461\n",
            "Iteration 208, loss = 1529331203.95061946\n",
            "Iteration 209, loss = 1529282185.68037438\n",
            "Iteration 210, loss = 1529232924.85755992\n",
            "Iteration 211, loss = 1529183460.73835707\n",
            "Iteration 212, loss = 1529132297.72295022\n",
            "Iteration 213, loss = 1529078252.03162670\n",
            "Iteration 214, loss = 1529025662.36546111\n",
            "Iteration 215, loss = 1528973291.08144236\n",
            "Iteration 216, loss = 1528920351.61930490\n",
            "Iteration 217, loss = 1528865720.19468904\n",
            "Iteration 218, loss = 1528807306.68281698\n",
            "Iteration 219, loss = 1528750447.97278714\n",
            "Iteration 220, loss = 1528694406.85497522\n",
            "Iteration 221, loss = 1528637578.66017771\n",
            "Iteration 222, loss = 1528580805.91284227\n",
            "Iteration 223, loss = 1528524341.76094794\n",
            "Iteration 224, loss = 1528467595.93129349\n",
            "Iteration 225, loss = 1528411392.94462085\n",
            "Iteration 226, loss = 1528355017.79211068\n",
            "Iteration 227, loss = 1528298793.34625554\n",
            "Iteration 228, loss = 1528243401.64719152\n",
            "Iteration 229, loss = 1528187286.65345812\n",
            "Iteration 230, loss = 1528132458.17868900\n",
            "Iteration 231, loss = 1528077037.19835210\n",
            "Iteration 232, loss = 1528022174.14584565\n",
            "Iteration 233, loss = 1527967366.03089833\n",
            "Iteration 234, loss = 1527912715.46254086\n",
            "Iteration 235, loss = 1527858194.04537058\n",
            "Iteration 236, loss = 1527803915.55947042\n",
            "Iteration 237, loss = 1527749706.07768989\n",
            "Iteration 238, loss = 1527695493.94525433\n",
            "Iteration 239, loss = 1527641810.75235581\n",
            "Iteration 240, loss = 1527587746.43688035\n",
            "Iteration 241, loss = 1527534179.85342026\n",
            "Iteration 242, loss = 1527480755.16958332\n",
            "Iteration 243, loss = 1527427518.79446292\n",
            "Iteration 244, loss = 1527374403.35991287\n",
            "Iteration 245, loss = 1527321613.17745376\n",
            "Iteration 246, loss = 1527268543.15080190\n",
            "Iteration 247, loss = 1527216130.22850990\n",
            "Iteration 248, loss = 1527163609.21183157\n",
            "Iteration 249, loss = 1527110920.81811357\n",
            "Iteration 250, loss = 1527058732.98372841\n",
            "Iteration 251, loss = 1527006303.32587862\n",
            "Iteration 252, loss = 1526954382.09935212\n",
            "Iteration 253, loss = 1526901748.83170629\n",
            "Iteration 254, loss = 1526849746.05846930\n",
            "Iteration 255, loss = 1526797663.65338731\n",
            "Iteration 256, loss = 1526745211.38929558\n",
            "Iteration 257, loss = 1526693430.64415336\n",
            "Iteration 258, loss = 1526640602.54670143\n",
            "Iteration 259, loss = 1526586151.99294591\n",
            "Iteration 260, loss = 1526527412.55376363\n",
            "Iteration 261, loss = 1526472007.23718500\n",
            "Iteration 262, loss = 1526416047.57826829\n",
            "Iteration 263, loss = 1526359926.40418983\n",
            "Iteration 264, loss = 1526303814.55214858\n",
            "Iteration 265, loss = 1526247418.07064223\n",
            "Iteration 266, loss = 1526191813.60939479\n",
            "Iteration 267, loss = 1526135795.49709654\n",
            "Iteration 268, loss = 1526079727.32664156\n",
            "Iteration 269, loss = 1526023998.71012187\n",
            "Iteration 270, loss = 1525968855.61504412\n",
            "Iteration 271, loss = 1525913265.41107297\n",
            "Iteration 272, loss = 1525857933.67324877\n",
            "Iteration 273, loss = 1525802630.85593557\n",
            "Iteration 274, loss = 1525748023.66421914\n",
            "Iteration 275, loss = 1525692811.15149117\n",
            "Iteration 276, loss = 1525637956.11324096\n",
            "Iteration 277, loss = 1525583437.84539866\n",
            "Iteration 278, loss = 1525528616.45810294\n",
            "Iteration 279, loss = 1525474057.55349398\n",
            "Iteration 280, loss = 1525419457.64158130\n",
            "Iteration 281, loss = 1525364968.95527267\n",
            "Iteration 282, loss = 1525310204.98059416\n",
            "Iteration 283, loss = 1525253883.65941024\n",
            "Iteration 284, loss = 1525194110.18443227\n",
            "Iteration 285, loss = 1525135777.77106380\n",
            "Iteration 286, loss = 1525077652.26357555\n",
            "Iteration 287, loss = 1525019169.25710082\n",
            "Iteration 288, loss = 1524961235.15296197\n",
            "Iteration 289, loss = 1524902383.38520741\n",
            "Iteration 290, loss = 1524844420.23995543\n",
            "Iteration 291, loss = 1524786027.38544273\n",
            "Iteration 292, loss = 1524728003.40516114\n",
            "Iteration 293, loss = 1524670015.41698551\n",
            "Iteration 294, loss = 1524612197.55616689\n",
            "Iteration 295, loss = 1524554514.80730796\n",
            "Iteration 296, loss = 1524497046.12638664\n",
            "Iteration 297, loss = 1524439969.66829705\n",
            "Iteration 298, loss = 1524382769.52454567\n",
            "Iteration 299, loss = 1524325861.78720951\n",
            "Iteration 300, loss = 1524269378.05488873\n",
            "Iteration 301, loss = 1524212241.32646394\n",
            "Iteration 302, loss = 1524156001.85432839\n",
            "Iteration 303, loss = 1524099757.10667229\n",
            "Iteration 304, loss = 1524042872.96464372\n",
            "Iteration 305, loss = 1523983459.17099047\n",
            "Iteration 306, loss = 1523921285.23630095\n",
            "Iteration 307, loss = 1523860898.07831335\n",
            "Iteration 308, loss = 1523800915.87226367\n",
            "Iteration 309, loss = 1523741102.94692779\n",
            "Iteration 310, loss = 1523680865.19823980\n",
            "Iteration 311, loss = 1523620591.27938128\n",
            "Iteration 312, loss = 1523561047.19076777\n",
            "Iteration 313, loss = 1523500908.51264429\n",
            "Iteration 314, loss = 1523441548.93622899\n",
            "Iteration 315, loss = 1523381637.57014704\n",
            "Iteration 316, loss = 1523322388.74374676\n",
            "Iteration 317, loss = 1523262796.02871776\n",
            "Iteration 318, loss = 1523204011.00272894\n",
            "Iteration 319, loss = 1523144477.14236760\n",
            "Iteration 320, loss = 1523085916.62859631\n",
            "Iteration 321, loss = 1523027342.25338340\n",
            "Iteration 322, loss = 1522968424.67422271\n",
            "Iteration 323, loss = 1522910658.57845235\n",
            "Iteration 324, loss = 1522852455.96969891\n",
            "Iteration 325, loss = 1522794547.08096766\n",
            "Iteration 326, loss = 1522736897.53246284\n",
            "Iteration 327, loss = 1522679097.36150718\n",
            "Iteration 328, loss = 1522621657.56132674\n",
            "Iteration 329, loss = 1522564701.42691422\n",
            "Iteration 330, loss = 1522506890.92147613\n",
            "Iteration 331, loss = 1522448805.19111395\n",
            "Iteration 332, loss = 1522385607.60396290\n",
            "Iteration 333, loss = 1522323515.04485440\n",
            "Iteration 334, loss = 1522260780.56549287\n",
            "Iteration 335, loss = 1522193755.66074920\n",
            "Iteration 336, loss = 1522126995.40108562\n",
            "Iteration 337, loss = 1522060503.44807792\n",
            "Iteration 338, loss = 1521995227.69408894\n",
            "Iteration 339, loss = 1521928805.34385085\n",
            "Iteration 340, loss = 1521862541.09431744\n",
            "Iteration 341, loss = 1521796918.41207194\n",
            "Iteration 342, loss = 1521731052.08644986\n",
            "Iteration 343, loss = 1521665758.74003983\n",
            "Iteration 344, loss = 1521600759.97904778\n",
            "Iteration 345, loss = 1521535538.92939997\n",
            "Iteration 346, loss = 1521470617.81658411\n",
            "Iteration 347, loss = 1521406002.92753005\n",
            "Iteration 348, loss = 1521341656.46490479\n",
            "Iteration 349, loss = 1521277391.99706531\n",
            "Iteration 350, loss = 1521213111.77214336\n",
            "Iteration 351, loss = 1521149116.06869698\n",
            "Iteration 352, loss = 1521085619.31487131\n",
            "Iteration 353, loss = 1521021566.68127203\n",
            "Iteration 354, loss = 1520958472.74470568\n",
            "Iteration 355, loss = 1520895138.28713250\n",
            "Iteration 356, loss = 1520832105.23647928\n",
            "Iteration 357, loss = 1520769276.98200631\n",
            "Iteration 358, loss = 1520706995.51635504\n",
            "Iteration 359, loss = 1520644334.64317679\n",
            "Iteration 360, loss = 1520582340.38689113\n",
            "Iteration 361, loss = 1520520572.94244146\n",
            "Iteration 362, loss = 1520458934.89374018\n",
            "Iteration 363, loss = 1520397062.28211951\n",
            "Iteration 364, loss = 1520335677.41744113\n",
            "Iteration 365, loss = 1520274409.70878243\n",
            "Iteration 366, loss = 1520213183.08221960\n",
            "Iteration 367, loss = 1520152077.64592433\n",
            "Iteration 368, loss = 1520091233.13200259\n",
            "Iteration 369, loss = 1520030043.05719852\n",
            "Iteration 370, loss = 1519969498.66404009\n",
            "Iteration 371, loss = 1519909027.65661716\n",
            "Iteration 372, loss = 1519847822.41654992\n",
            "Iteration 373, loss = 1519787388.93838859\n",
            "Iteration 374, loss = 1519726579.65615034\n",
            "Iteration 375, loss = 1519661626.51790714\n",
            "Iteration 376, loss = 1519595520.71013689\n",
            "Iteration 377, loss = 1519530624.64564872\n",
            "Iteration 378, loss = 1519466016.60286784\n",
            "Iteration 379, loss = 1519401192.15300536\n",
            "Iteration 380, loss = 1519336303.64381051\n",
            "Iteration 381, loss = 1519271697.15465307\n",
            "Iteration 382, loss = 1519206403.97284603\n",
            "Iteration 383, loss = 1519142188.94441390\n",
            "Iteration 384, loss = 1519077527.93194389\n",
            "Iteration 385, loss = 1519013124.08518028\n",
            "Iteration 386, loss = 1518949119.47611713\n",
            "Iteration 387, loss = 1518884705.28002381\n",
            "Iteration 388, loss = 1518821241.84335828\n",
            "Iteration 389, loss = 1518757253.93782234\n",
            "Iteration 390, loss = 1518693859.15975523\n",
            "Iteration 391, loss = 1518630614.43964648\n",
            "Iteration 392, loss = 1518567638.29307842\n",
            "Iteration 393, loss = 1518504748.21340132\n",
            "Iteration 394, loss = 1518442341.47587705\n",
            "Iteration 395, loss = 1518379721.73511243\n",
            "Iteration 396, loss = 1518317543.75161195\n",
            "Iteration 397, loss = 1518255740.89134932\n",
            "Iteration 398, loss = 1518193840.98383951\n",
            "Iteration 399, loss = 1518132150.65463853\n",
            "Iteration 400, loss = 1518070994.22761273\n",
            "Iteration 401, loss = 1518009262.45900607\n",
            "Iteration 402, loss = 1517947963.83681536\n",
            "Iteration 403, loss = 1517887177.58837795\n",
            "Iteration 404, loss = 1517825958.31293082\n",
            "Iteration 405, loss = 1517765178.99048090\n",
            "Iteration 406, loss = 1517704259.60425091\n",
            "Iteration 407, loss = 1517643583.98860621\n",
            "Iteration 408, loss = 1517582477.69313979\n",
            "Iteration 409, loss = 1517522247.15832806\n",
            "Iteration 410, loss = 1517461093.03299093\n",
            "Iteration 411, loss = 1517400433.21870899\n",
            "Iteration 412, loss = 1517340129.02607322\n",
            "Iteration 413, loss = 1517279108.02562261\n",
            "Iteration 414, loss = 1517218264.05098748\n",
            "Iteration 415, loss = 1517158268.94932461\n",
            "Iteration 416, loss = 1517097732.41843319\n",
            "Iteration 417, loss = 1517037407.42229176\n",
            "Iteration 418, loss = 1516977224.74589539\n",
            "Iteration 419, loss = 1516917181.81282735\n",
            "Iteration 420, loss = 1516857774.66926861\n",
            "Iteration 421, loss = 1516797790.87059617\n",
            "Iteration 422, loss = 1516738057.56633139\n",
            "Iteration 423, loss = 1516678891.61963415\n",
            "Iteration 424, loss = 1516619011.11843753\n",
            "Iteration 425, loss = 1516559469.32865429\n",
            "Iteration 426, loss = 1516500634.60434818\n",
            "Iteration 427, loss = 1516440688.81736851\n",
            "Iteration 428, loss = 1516381820.00857711\n",
            "Iteration 429, loss = 1516321996.92576146\n",
            "Iteration 430, loss = 1516262782.87848806\n",
            "Iteration 431, loss = 1516203408.48310614\n",
            "Iteration 432, loss = 1516144519.92580032\n",
            "Iteration 433, loss = 1516084854.12765837\n",
            "Iteration 434, loss = 1516025578.23384595\n",
            "Iteration 435, loss = 1515966639.99552631\n",
            "Iteration 436, loss = 1515907386.29943180\n",
            "Iteration 437, loss = 1515848622.43080354\n",
            "Iteration 438, loss = 1515789543.36945248\n",
            "Iteration 439, loss = 1515730258.83663964\n",
            "Iteration 440, loss = 1515671993.28328133\n",
            "Iteration 441, loss = 1515612924.36661077\n",
            "Iteration 442, loss = 1515554178.25270057\n",
            "Iteration 443, loss = 1515495340.43922687\n",
            "Iteration 444, loss = 1515436795.05433321\n",
            "Iteration 445, loss = 1515377889.92835546\n",
            "Iteration 446, loss = 1515319460.02461791\n",
            "Iteration 447, loss = 1515260209.23942113\n",
            "Iteration 448, loss = 1515201499.84469581\n",
            "Iteration 449, loss = 1515142887.08381414\n",
            "Iteration 450, loss = 1515083950.74616170\n",
            "Iteration 451, loss = 1515025508.75929976\n",
            "Iteration 452, loss = 1514967003.69857907\n",
            "Iteration 453, loss = 1514908386.43369102\n",
            "Iteration 454, loss = 1514850109.80253911\n",
            "Iteration 455, loss = 1514791903.65878510\n",
            "Iteration 456, loss = 1514733968.52603292\n",
            "Iteration 457, loss = 1514675661.69576812\n",
            "Iteration 458, loss = 1514617629.46740150\n",
            "Iteration 459, loss = 1514559237.14005232\n",
            "Iteration 460, loss = 1514501374.33417296\n",
            "Iteration 461, loss = 1514443022.26940799\n",
            "Iteration 462, loss = 1514384620.02629447\n",
            "Iteration 463, loss = 1514326826.70554543\n",
            "Iteration 464, loss = 1514268610.04292107\n",
            "Iteration 465, loss = 1514210631.20155215\n",
            "Iteration 466, loss = 1514152495.28511548\n",
            "Iteration 467, loss = 1514094653.46390724\n",
            "Iteration 468, loss = 1514036984.83743978\n",
            "Iteration 469, loss = 1513979398.34824038\n",
            "Iteration 470, loss = 1513921587.84761214\n",
            "Iteration 471, loss = 1513864219.26210213\n",
            "Iteration 472, loss = 1513806481.94358253\n",
            "Iteration 473, loss = 1513748578.36629581\n",
            "Iteration 474, loss = 1513690554.16486502\n",
            "Iteration 475, loss = 1513630444.52755833\n",
            "Iteration 476, loss = 1513566255.69495535\n",
            "Iteration 477, loss = 1513503533.52950191\n",
            "Iteration 478, loss = 1513440675.33409762\n",
            "Iteration 479, loss = 1513377498.65713787\n",
            "Iteration 480, loss = 1513314344.68566632\n",
            "Iteration 481, loss = 1513250971.18132401\n",
            "Iteration 482, loss = 1513188160.11090064\n",
            "Iteration 483, loss = 1513124877.88009620\n",
            "Iteration 484, loss = 1513062346.10035872\n",
            "Iteration 485, loss = 1512999478.18488145\n",
            "Iteration 486, loss = 1512937150.67788124\n",
            "Iteration 487, loss = 1512875073.17458463\n",
            "Iteration 488, loss = 1512812703.07808852\n",
            "Iteration 489, loss = 1512750946.98358989\n",
            "Iteration 490, loss = 1512688841.79994178\n",
            "Iteration 491, loss = 1512627319.59758711\n",
            "Iteration 492, loss = 1512565538.87070441\n",
            "Iteration 493, loss = 1512504045.55218458\n",
            "Iteration 494, loss = 1512442753.35653353\n",
            "Iteration 495, loss = 1512381057.32118988\n",
            "Iteration 496, loss = 1512319974.86639667\n",
            "Iteration 497, loss = 1512258913.97968245\n",
            "Iteration 498, loss = 1512197519.66113830\n",
            "Iteration 499, loss = 1512136171.52666378\n",
            "Iteration 500, loss = 1512075372.33500695\n",
            "Iteration 501, loss = 1512014016.37551141\n",
            "Iteration 502, loss = 1511952948.92521596\n",
            "Iteration 503, loss = 1511891960.19684744\n",
            "Iteration 504, loss = 1511830775.99837232\n",
            "Iteration 505, loss = 1511770220.78996420\n",
            "Iteration 506, loss = 1511709681.01230907\n",
            "Iteration 507, loss = 1511648618.22838306\n",
            "Iteration 508, loss = 1511589114.76550794\n",
            "Iteration 509, loss = 1511528096.87478209\n",
            "Iteration 510, loss = 1511468364.83458638\n",
            "Iteration 511, loss = 1511408474.38590503\n",
            "Iteration 512, loss = 1511348105.57476854\n",
            "Iteration 513, loss = 1511288169.44945812\n",
            "Iteration 514, loss = 1511228165.75004005\n",
            "Iteration 515, loss = 1511168187.11833668\n",
            "Iteration 516, loss = 1511108019.75938535\n",
            "Iteration 517, loss = 1511047838.05504036\n",
            "Iteration 518, loss = 1510988322.36365128\n",
            "Iteration 519, loss = 1510928054.94555020\n",
            "Iteration 520, loss = 1510868057.01238346\n",
            "Iteration 521, loss = 1510808379.70153570\n",
            "Iteration 522, loss = 1510748564.56173062\n",
            "Iteration 523, loss = 1510689167.36948705\n",
            "Iteration 524, loss = 1510629400.13079453\n",
            "Iteration 525, loss = 1510569938.08052802\n",
            "Iteration 526, loss = 1510510323.95062089\n",
            "Iteration 527, loss = 1510451311.60558510\n",
            "Iteration 528, loss = 1510391510.71557999\n",
            "Iteration 529, loss = 1510332563.79198122\n",
            "Iteration 530, loss = 1510273192.60728431\n",
            "Iteration 531, loss = 1510213492.85423946\n",
            "Iteration 532, loss = 1510154539.64928126\n",
            "Iteration 533, loss = 1510095194.54331851\n",
            "Iteration 534, loss = 1510035766.20649815\n",
            "Iteration 535, loss = 1509976605.37304020\n",
            "Iteration 536, loss = 1509917366.79770041\n",
            "Iteration 537, loss = 1509858124.95440221\n",
            "Iteration 538, loss = 1509799340.81216741\n",
            "Iteration 539, loss = 1509740255.70410848\n",
            "Iteration 540, loss = 1509681258.37710357\n",
            "Iteration 541, loss = 1509622436.05583096\n",
            "Iteration 542, loss = 1509563801.53567863\n",
            "Iteration 543, loss = 1509504677.52620196\n",
            "Iteration 544, loss = 1509445828.86093068\n",
            "Iteration 545, loss = 1509386970.48414016\n",
            "Iteration 546, loss = 1509328517.91736603\n",
            "Iteration 547, loss = 1509269740.50142908\n",
            "Iteration 548, loss = 1509210882.38445568\n",
            "Iteration 549, loss = 1509152403.43598199\n",
            "Iteration 550, loss = 1509093874.42114735\n",
            "Iteration 551, loss = 1509035315.68037701\n",
            "Iteration 552, loss = 1508976755.48395824\n",
            "Iteration 553, loss = 1508918120.37896562\n",
            "Iteration 554, loss = 1508859824.83346105\n",
            "Iteration 555, loss = 1508800754.07330394\n",
            "Iteration 556, loss = 1508742797.74384737\n",
            "Iteration 557, loss = 1508684224.61649132\n",
            "Iteration 558, loss = 1508625874.33062458\n",
            "Iteration 559, loss = 1508567490.97471356\n",
            "Iteration 560, loss = 1508509607.15086508\n",
            "Iteration 561, loss = 1508451135.31170154\n",
            "Iteration 562, loss = 1508393047.58499336\n",
            "Iteration 563, loss = 1508335060.31952190\n",
            "Iteration 564, loss = 1508276800.44598985\n",
            "Iteration 565, loss = 1508219195.64261508\n",
            "Iteration 566, loss = 1508160426.73430800\n",
            "Iteration 567, loss = 1508102601.40379691\n",
            "Iteration 568, loss = 1508044284.44816780\n",
            "Iteration 569, loss = 1507985960.85014272\n",
            "Iteration 570, loss = 1507927905.06950426\n",
            "Iteration 571, loss = 1507869811.20037127\n",
            "Iteration 572, loss = 1507811597.83240056\n",
            "Iteration 573, loss = 1507753714.23538661\n",
            "Iteration 574, loss = 1507695754.84015775\n",
            "Iteration 575, loss = 1507637720.97989631\n",
            "Iteration 576, loss = 1507580302.35164952\n",
            "Iteration 577, loss = 1507522187.07281685\n",
            "Iteration 578, loss = 1507464391.29005194\n",
            "Iteration 579, loss = 1507406812.95701075\n",
            "Iteration 580, loss = 1507348775.12400937\n",
            "Iteration 581, loss = 1507290976.01835918\n",
            "Iteration 582, loss = 1507233145.02267551\n",
            "Iteration 583, loss = 1507175336.80431104\n",
            "Iteration 584, loss = 1507117048.23153830\n",
            "Iteration 585, loss = 1507059491.65682244\n",
            "Iteration 586, loss = 1507001286.57041860\n",
            "Iteration 587, loss = 1506943652.83920860\n",
            "Iteration 588, loss = 1506885589.39176822\n",
            "Iteration 589, loss = 1506827483.71108484\n",
            "Iteration 590, loss = 1506769592.39910388\n",
            "Iteration 591, loss = 1506711682.13486409\n",
            "Iteration 592, loss = 1506653608.38534665\n",
            "Iteration 593, loss = 1506596413.78937364\n",
            "Iteration 594, loss = 1506538277.36950564\n",
            "Iteration 595, loss = 1506480466.02131605\n",
            "Iteration 596, loss = 1506423489.28389764\n",
            "Iteration 597, loss = 1506365933.67192316\n",
            "Iteration 598, loss = 1506308523.34046221\n",
            "Iteration 599, loss = 1506251399.59556699\n",
            "Iteration 600, loss = 1506193813.20096850\n",
            "Iteration 601, loss = 1506136644.88199043\n",
            "Iteration 602, loss = 1506079420.86635709\n",
            "Iteration 603, loss = 1506021825.13610601\n",
            "Iteration 604, loss = 1505964943.95547271\n",
            "Iteration 605, loss = 1505907454.42404604\n",
            "Iteration 606, loss = 1505850386.62819004\n",
            "Iteration 607, loss = 1505793094.89456129\n",
            "Iteration 608, loss = 1505736200.82342982\n",
            "Iteration 609, loss = 1505679001.02150512\n",
            "Iteration 610, loss = 1505622096.58961320\n",
            "Iteration 611, loss = 1505565504.42667818\n",
            "Iteration 612, loss = 1505508136.10324430\n",
            "Iteration 613, loss = 1505451592.64488053\n",
            "Iteration 614, loss = 1505394806.18341041\n",
            "Iteration 615, loss = 1505337696.96904182\n",
            "Iteration 616, loss = 1505281191.15580630\n",
            "Iteration 617, loss = 1505224299.13719106\n",
            "Iteration 618, loss = 1505167518.10659003\n",
            "Iteration 619, loss = 1505110737.84224725\n",
            "Iteration 620, loss = 1505053963.40121007\n",
            "Iteration 621, loss = 1504997244.74897528\n",
            "Iteration 622, loss = 1504940469.27939367\n",
            "Iteration 623, loss = 1504883556.92657137\n",
            "Iteration 624, loss = 1504827129.92005181\n",
            "Iteration 625, loss = 1504770409.59034848\n",
            "Iteration 626, loss = 1504714120.22794580\n",
            "Iteration 627, loss = 1504656809.67516184\n",
            "Iteration 628, loss = 1504600577.60765433\n",
            "Iteration 629, loss = 1504543670.25305772\n",
            "Iteration 630, loss = 1504487213.91885281\n",
            "Iteration 631, loss = 1504430388.41179156\n",
            "Iteration 632, loss = 1504373688.54095411\n",
            "Iteration 633, loss = 1504317352.01816058\n",
            "Iteration 634, loss = 1504260295.52536106\n",
            "Iteration 635, loss = 1504203947.97284794\n",
            "Iteration 636, loss = 1504147404.05020261\n",
            "Iteration 637, loss = 1504091102.53379202\n",
            "Iteration 638, loss = 1504034301.74844503\n",
            "Iteration 639, loss = 1503977956.77897882\n",
            "Iteration 640, loss = 1503920970.29473233\n",
            "Iteration 641, loss = 1503864922.27171111\n",
            "Iteration 642, loss = 1503808070.80440044\n",
            "Iteration 643, loss = 1503751706.40710187\n",
            "Iteration 644, loss = 1503694980.78934383\n",
            "Iteration 645, loss = 1503638602.69439888\n",
            "Iteration 646, loss = 1503582216.16042519\n",
            "Iteration 647, loss = 1503525694.54525733\n",
            "Iteration 648, loss = 1503469045.23813868\n",
            "Iteration 649, loss = 1503412728.97015953\n",
            "Iteration 650, loss = 1503356262.58026338\n",
            "Iteration 651, loss = 1503299466.34855652\n",
            "Iteration 652, loss = 1503242948.54815602\n",
            "Iteration 653, loss = 1503186231.03871727\n",
            "Iteration 654, loss = 1503129451.36378908\n",
            "Iteration 655, loss = 1503072901.86358261\n",
            "Iteration 656, loss = 1503016217.95985842\n",
            "Iteration 657, loss = 1502959096.90827703\n",
            "Iteration 658, loss = 1502902543.48452687\n",
            "Iteration 659, loss = 1502845929.56672382\n",
            "Iteration 660, loss = 1502788923.16770649\n",
            "Iteration 661, loss = 1502731838.35256171\n",
            "Iteration 662, loss = 1502675529.35031700\n",
            "Iteration 663, loss = 1502618730.85749197\n",
            "Iteration 664, loss = 1502561955.67903352\n",
            "Iteration 665, loss = 1502505531.16773176\n",
            "Iteration 666, loss = 1502448762.49136376\n",
            "Iteration 667, loss = 1502392819.96347308\n",
            "Iteration 668, loss = 1502335894.61846709\n",
            "Iteration 669, loss = 1502279540.08342385\n",
            "Iteration 670, loss = 1502223457.94427276\n",
            "Iteration 671, loss = 1502166729.52559686\n",
            "Iteration 672, loss = 1502111103.52337575\n",
            "Iteration 673, loss = 1502054404.59488916\n",
            "Iteration 674, loss = 1501998227.17304420\n",
            "Iteration 675, loss = 1501942039.30462837\n",
            "Iteration 676, loss = 1501885962.86582208\n",
            "Iteration 677, loss = 1501829594.51350093\n",
            "Iteration 678, loss = 1501774153.66112280\n",
            "Iteration 679, loss = 1501717805.85775828\n",
            "Iteration 680, loss = 1501661969.27790403\n",
            "Iteration 681, loss = 1501606101.16588616\n",
            "Iteration 682, loss = 1501550052.81701231\n",
            "Iteration 683, loss = 1501494313.30193424\n",
            "Iteration 684, loss = 1501438401.31874919\n",
            "Iteration 685, loss = 1501381787.97472119\n",
            "Iteration 686, loss = 1501326268.22471118\n",
            "Iteration 687, loss = 1501269909.21652174\n",
            "Iteration 688, loss = 1501213866.81493306\n",
            "Iteration 689, loss = 1501157542.05825615\n",
            "Iteration 690, loss = 1501101397.15619040\n",
            "Iteration 691, loss = 1501045363.56186676\n",
            "Iteration 692, loss = 1500989244.50337839\n",
            "Iteration 693, loss = 1500932926.74150181\n",
            "Iteration 694, loss = 1500877079.69793797\n",
            "Iteration 695, loss = 1500821090.41956091\n",
            "Iteration 696, loss = 1500764880.04416990\n",
            "Iteration 697, loss = 1500709200.09366727\n",
            "Iteration 698, loss = 1500652660.30455399\n",
            "Iteration 699, loss = 1500596976.48136163\n",
            "Iteration 700, loss = 1500540995.25250316\n",
            "Iteration 701, loss = 1500484701.57980156\n",
            "Iteration 702, loss = 1500428663.48195791\n",
            "Iteration 703, loss = 1500372551.55764699\n",
            "Iteration 704, loss = 1500316703.39712548\n",
            "Iteration 705, loss = 1500260396.36490393\n",
            "Iteration 706, loss = 1500204859.05460143\n",
            "Iteration 707, loss = 1500148654.52441716\n",
            "Iteration 708, loss = 1500092964.74031186\n",
            "Iteration 709, loss = 1500037019.54944730\n",
            "Iteration 710, loss = 1499981062.98661995\n",
            "Iteration 711, loss = 1499924918.85374045\n",
            "Iteration 712, loss = 1499869420.39840150\n",
            "Iteration 713, loss = 1499813321.41957712\n",
            "Iteration 714, loss = 1499757225.81409526\n",
            "Iteration 715, loss = 1499701471.70892143\n",
            "Iteration 716, loss = 1499645628.88583350\n",
            "Iteration 717, loss = 1499589819.71776962\n",
            "Iteration 718, loss = 1499533541.31575155\n",
            "Iteration 719, loss = 1499477809.23091054\n",
            "Iteration 720, loss = 1499421643.86486697\n",
            "Iteration 721, loss = 1499365824.34001064\n",
            "Iteration 722, loss = 1499309993.39155650\n",
            "Iteration 723, loss = 1499253753.27244091\n",
            "Iteration 724, loss = 1499198040.86476660\n",
            "Iteration 725, loss = 1499142399.36132336\n",
            "Iteration 726, loss = 1499086605.90330744\n",
            "Iteration 727, loss = 1499030906.26646495\n",
            "Iteration 728, loss = 1498975374.54728365\n",
            "Iteration 729, loss = 1498919462.67404151\n",
            "Iteration 730, loss = 1498863786.46734142\n",
            "Iteration 731, loss = 1498808108.74299073\n",
            "Iteration 732, loss = 1498752273.66034389\n",
            "Iteration 733, loss = 1498696333.35499978\n",
            "Iteration 734, loss = 1498640683.24373221\n",
            "Iteration 735, loss = 1498584626.63172555\n",
            "Iteration 736, loss = 1498528778.18494081\n",
            "Iteration 737, loss = 1498473192.02039051\n",
            "Iteration 738, loss = 1498417450.51688480\n",
            "Iteration 739, loss = 1498361690.12824154\n",
            "Iteration 740, loss = 1498306342.24425960\n",
            "Iteration 741, loss = 1498250729.87178779\n",
            "Iteration 742, loss = 1498195427.26677895\n",
            "Iteration 743, loss = 1498140062.28838968\n",
            "Iteration 744, loss = 1498084799.34726477\n",
            "Iteration 745, loss = 1498029257.89244676\n",
            "Iteration 746, loss = 1497974201.93336463\n",
            "Iteration 747, loss = 1497918457.67824125\n",
            "Iteration 748, loss = 1497863138.62440062\n",
            "Iteration 749, loss = 1497807317.84801221\n",
            "Iteration 750, loss = 1497752114.03777695\n",
            "Iteration 751, loss = 1497696707.44901633\n",
            "Iteration 752, loss = 1497641157.24170780\n",
            "Iteration 753, loss = 1497585502.75243783\n",
            "Iteration 754, loss = 1497530237.38723254\n",
            "Iteration 755, loss = 1497474555.49089432\n",
            "Iteration 756, loss = 1497419365.34152269\n",
            "Iteration 757, loss = 1497363609.52190995\n",
            "Iteration 758, loss = 1497308208.98464894\n",
            "Iteration 759, loss = 1497252851.39014101\n",
            "Iteration 760, loss = 1497197538.99217725\n",
            "Iteration 761, loss = 1497142093.85940957\n",
            "Iteration 762, loss = 1497086958.51447940\n",
            "Iteration 763, loss = 1497032003.61996889\n",
            "Iteration 764, loss = 1496976910.54896522\n",
            "Iteration 765, loss = 1496921403.71148539\n",
            "Iteration 766, loss = 1496866312.95064521\n",
            "Iteration 767, loss = 1496811281.08138084\n",
            "Iteration 768, loss = 1496756032.59600997\n",
            "Iteration 769, loss = 1496700552.83753014\n",
            "Iteration 770, loss = 1496644911.66216946\n",
            "Iteration 771, loss = 1496589936.57356358\n",
            "Iteration 772, loss = 1496534414.41108990\n",
            "Iteration 773, loss = 1496478988.71507478\n",
            "Iteration 774, loss = 1496423610.84153676\n",
            "Iteration 775, loss = 1496368060.67286301\n",
            "Iteration 776, loss = 1496312690.58812070\n",
            "Iteration 777, loss = 1496257755.81130552\n",
            "Iteration 778, loss = 1496202051.21719289\n",
            "Iteration 779, loss = 1496146895.60923815\n",
            "Iteration 780, loss = 1496091615.38800216\n",
            "Iteration 781, loss = 1496036257.29282331\n",
            "Iteration 782, loss = 1495980886.87077618\n",
            "Iteration 783, loss = 1495925788.64633751\n",
            "Iteration 784, loss = 1495870519.02404499\n",
            "Iteration 785, loss = 1495815132.60713100\n",
            "Iteration 786, loss = 1495759984.34163594\n",
            "Iteration 787, loss = 1495704531.54178381\n",
            "Iteration 788, loss = 1495649318.72178435\n",
            "Iteration 789, loss = 1495594073.27186346\n",
            "Iteration 790, loss = 1495538577.37511301\n",
            "Iteration 791, loss = 1495483386.42275190\n",
            "Iteration 792, loss = 1495428175.11138368\n",
            "Iteration 793, loss = 1495372630.02726603\n",
            "Iteration 794, loss = 1495317347.71601868\n",
            "Iteration 795, loss = 1495262547.77662110\n",
            "Iteration 796, loss = 1495206979.40307713\n",
            "Iteration 797, loss = 1495151709.67585945\n",
            "Iteration 798, loss = 1495096741.85250282\n",
            "Iteration 799, loss = 1495041151.35260510\n",
            "Iteration 800, loss = 1494986195.44166970\n",
            "Iteration 801, loss = 1494930937.45470166\n",
            "Iteration 802, loss = 1494875702.67468429\n",
            "Iteration 803, loss = 1494820519.51192093\n",
            "Iteration 804, loss = 1494764739.94384670\n",
            "Iteration 805, loss = 1494710006.95719862\n",
            "Iteration 806, loss = 1494654567.26768994\n",
            "Iteration 807, loss = 1494599291.75407362\n",
            "Iteration 808, loss = 1494543952.75000596\n",
            "Iteration 809, loss = 1494488752.02116346\n",
            "Iteration 810, loss = 1494433358.94883442\n",
            "Iteration 811, loss = 1494378058.52405620\n",
            "Iteration 812, loss = 1494322200.00811052\n",
            "Iteration 813, loss = 1494266775.01400375\n",
            "Iteration 814, loss = 1494211332.81492639\n",
            "Iteration 815, loss = 1494155592.36811662\n",
            "Iteration 816, loss = 1494099844.51064563\n",
            "Iteration 817, loss = 1494044402.18329835\n",
            "Iteration 818, loss = 1493988939.11551356\n",
            "Iteration 819, loss = 1493933244.96584082\n",
            "Iteration 820, loss = 1493877743.76092815\n",
            "Iteration 821, loss = 1493822231.99115181\n",
            "Iteration 822, loss = 1493766482.34951973\n",
            "Iteration 823, loss = 1493711261.45867729\n",
            "Iteration 824, loss = 1493655529.31164408\n",
            "Iteration 825, loss = 1493599696.59117293\n",
            "Iteration 826, loss = 1493544228.91988063\n",
            "Iteration 827, loss = 1493488798.63969398\n",
            "Iteration 828, loss = 1493433346.59733105\n",
            "Iteration 829, loss = 1493378015.16891289\n",
            "Iteration 830, loss = 1493322540.27683997\n",
            "Iteration 831, loss = 1493267498.80741525\n",
            "Iteration 832, loss = 1493212492.89430404\n",
            "Iteration 833, loss = 1493156974.68260169\n",
            "Iteration 834, loss = 1493102137.20975709\n",
            "Iteration 835, loss = 1493047148.66941071\n",
            "Iteration 836, loss = 1492991799.90730810\n",
            "Iteration 837, loss = 1492936836.51250076\n",
            "Iteration 838, loss = 1492881582.29215217\n",
            "Iteration 839, loss = 1492826481.68763423\n",
            "Iteration 840, loss = 1492771118.76601505\n",
            "Iteration 841, loss = 1492716034.66047645\n",
            "Iteration 842, loss = 1492661137.57881212\n",
            "Iteration 843, loss = 1492605759.73207951\n",
            "Iteration 844, loss = 1492550673.49249792\n",
            "Iteration 845, loss = 1492495298.30766249\n",
            "Iteration 846, loss = 1492440544.27094221\n",
            "Iteration 847, loss = 1492384955.11943817\n",
            "Iteration 848, loss = 1492329827.22606683\n",
            "Iteration 849, loss = 1492274723.93237209\n",
            "Iteration 850, loss = 1492219591.80219007\n",
            "Iteration 851, loss = 1492164530.71359444\n",
            "Iteration 852, loss = 1492109523.37608695\n",
            "Iteration 853, loss = 1492054469.45851016\n",
            "Iteration 854, loss = 1491999816.30350494\n",
            "Iteration 855, loss = 1491944750.20632434\n",
            "Iteration 856, loss = 1491889974.42067719\n",
            "Iteration 857, loss = 1491835275.12470078\n",
            "Iteration 858, loss = 1491780493.70843768\n",
            "Iteration 859, loss = 1491725661.78253245\n",
            "Iteration 860, loss = 1491670924.31437135\n",
            "Iteration 861, loss = 1491616224.10799408\n",
            "Iteration 862, loss = 1491561556.17542624\n",
            "Iteration 863, loss = 1491506896.07403517\n",
            "Iteration 864, loss = 1491452197.80978131\n",
            "Iteration 865, loss = 1491397300.87988234\n",
            "Iteration 866, loss = 1491342857.23262930\n",
            "Iteration 867, loss = 1491287917.86616087\n",
            "Iteration 868, loss = 1491233479.15144134\n",
            "Iteration 869, loss = 1491178659.94139600\n",
            "Iteration 870, loss = 1491123777.76127052\n",
            "Iteration 871, loss = 1491068975.18185973\n",
            "Iteration 872, loss = 1491014355.56625152\n",
            "Iteration 873, loss = 1490959185.86185169\n",
            "Iteration 874, loss = 1490904413.81304336\n",
            "Iteration 875, loss = 1490849412.46930099\n",
            "Iteration 876, loss = 1490794621.80258894\n",
            "Iteration 877, loss = 1490739452.80280256\n",
            "Iteration 878, loss = 1490684505.66896749\n",
            "Iteration 879, loss = 1490629503.38560796\n",
            "Iteration 880, loss = 1490575014.14302683\n",
            "Iteration 881, loss = 1490519543.32319546\n",
            "Iteration 882, loss = 1490465359.28797340\n",
            "Iteration 883, loss = 1490410268.76614332\n",
            "Iteration 884, loss = 1490355434.90198970\n",
            "Iteration 885, loss = 1490300519.11885977\n",
            "Iteration 886, loss = 1490245446.00941730\n",
            "Iteration 887, loss = 1490190998.84481621\n",
            "Iteration 888, loss = 1490135815.13230824\n",
            "Iteration 889, loss = 1490081080.78995991\n",
            "Iteration 890, loss = 1490026319.79341745\n",
            "Iteration 891, loss = 1489971709.28738832\n",
            "Iteration 892, loss = 1489917353.27651191\n",
            "Iteration 893, loss = 1489862443.16162443\n",
            "Iteration 894, loss = 1489808096.20737648\n",
            "Iteration 895, loss = 1489753802.74273872\n",
            "Iteration 896, loss = 1489699165.40805984\n",
            "Iteration 897, loss = 1489644573.89950061\n",
            "Iteration 898, loss = 1489590046.65980721\n",
            "Iteration 899, loss = 1489535727.13056755\n",
            "Iteration 900, loss = 1489480909.70112872\n",
            "Iteration 901, loss = 1489426447.44111109\n",
            "Iteration 902, loss = 1489371821.24075866\n",
            "Iteration 903, loss = 1489317526.69639850\n",
            "Iteration 904, loss = 1489262869.40849829\n",
            "Iteration 905, loss = 1489208278.37996936\n",
            "Iteration 906, loss = 1489153698.43041849\n",
            "Iteration 907, loss = 1489099156.08257771\n",
            "Iteration 908, loss = 1489044717.96740961\n",
            "Iteration 909, loss = 1488990011.97962475\n",
            "Iteration 910, loss = 1488935526.59865808\n",
            "Iteration 911, loss = 1488880665.18443799\n",
            "Iteration 912, loss = 1488826376.64108157\n",
            "Iteration 913, loss = 1488771741.41355515\n",
            "Iteration 914, loss = 1488717257.18462396\n",
            "Iteration 915, loss = 1488662660.37411904\n",
            "Iteration 916, loss = 1488607942.95401311\n",
            "Iteration 917, loss = 1488553390.67708945\n",
            "Iteration 918, loss = 1488498676.99125171\n",
            "Iteration 919, loss = 1488444119.53008652\n",
            "Iteration 920, loss = 1488389108.41309595\n",
            "Iteration 921, loss = 1488334802.20672655\n",
            "Iteration 922, loss = 1488280132.65181375\n",
            "Iteration 923, loss = 1488225046.70166135\n",
            "Iteration 924, loss = 1488170746.61689281\n",
            "Iteration 925, loss = 1488116319.58078766\n",
            "Iteration 926, loss = 1488061404.81943607\n",
            "Iteration 927, loss = 1488006729.34052110\n",
            "Iteration 928, loss = 1487952104.37124705\n",
            "Iteration 929, loss = 1487897334.48692918\n",
            "Iteration 930, loss = 1487842987.82574034\n",
            "Iteration 931, loss = 1487788132.26903892\n",
            "Iteration 932, loss = 1487733297.72239065\n",
            "Iteration 933, loss = 1487679172.63621044\n",
            "Iteration 934, loss = 1487624219.00070047\n",
            "Iteration 935, loss = 1487569755.63571215\n",
            "Iteration 936, loss = 1487515334.13707256\n",
            "Iteration 937, loss = 1487460515.78703547\n",
            "Iteration 938, loss = 1487406295.88574028\n",
            "Iteration 939, loss = 1487351254.70495605\n",
            "Iteration 940, loss = 1487297074.30577540\n",
            "Iteration 941, loss = 1487242598.90573144\n",
            "Iteration 942, loss = 1487188108.34889793\n",
            "Iteration 943, loss = 1487133642.75518036\n",
            "Iteration 944, loss = 1487078991.56415868\n",
            "Iteration 945, loss = 1487024754.30305052\n",
            "Iteration 946, loss = 1486970199.95330119\n",
            "Iteration 947, loss = 1486915503.16664839\n",
            "Iteration 948, loss = 1486860940.46456933\n",
            "Iteration 949, loss = 1486806984.41082883\n",
            "Iteration 950, loss = 1486752020.27109432\n",
            "Iteration 951, loss = 1486697511.57976985\n",
            "Iteration 952, loss = 1486643334.16476130\n",
            "Iteration 953, loss = 1486589140.01256800\n",
            "Iteration 954, loss = 1486534500.63020539\n",
            "Iteration 955, loss = 1486480218.43884969\n",
            "Iteration 956, loss = 1486425790.48913121\n",
            "Iteration 957, loss = 1486371523.16491246\n",
            "Iteration 958, loss = 1486316958.34405899\n",
            "Iteration 959, loss = 1486262585.98459005\n",
            "Iteration 960, loss = 1486208402.78795695\n",
            "Iteration 961, loss = 1486153755.71214986\n",
            "Iteration 962, loss = 1486099532.37551427\n",
            "Iteration 963, loss = 1486044941.24492908\n",
            "Iteration 964, loss = 1485990503.25950336\n",
            "Iteration 965, loss = 1485936274.89273643\n",
            "Iteration 966, loss = 1485881403.33206916\n",
            "Iteration 967, loss = 1485827017.25930166\n",
            "Iteration 968, loss = 1485772562.90830898\n",
            "Iteration 969, loss = 1485718130.24518704\n",
            "Iteration 970, loss = 1485663530.11432672\n",
            "Iteration 971, loss = 1485609142.28988004\n",
            "Iteration 972, loss = 1485554661.53639746\n",
            "Iteration 973, loss = 1485500194.18823600\n",
            "Iteration 974, loss = 1485445755.00843477\n",
            "Iteration 975, loss = 1485391176.59670973\n",
            "Iteration 976, loss = 1485336931.16500640\n",
            "Iteration 977, loss = 1485282664.21088076\n",
            "Iteration 978, loss = 1485227889.71493864\n",
            "Iteration 979, loss = 1485173620.55879879\n",
            "Iteration 980, loss = 1485118903.29414582\n",
            "Iteration 981, loss = 1485064913.82252836\n",
            "Iteration 982, loss = 1485010586.99306369\n",
            "Iteration 983, loss = 1484956167.87567329\n",
            "Iteration 984, loss = 1484901726.72764087\n",
            "Iteration 985, loss = 1484847400.17662430\n",
            "Iteration 986, loss = 1484792966.94056535\n",
            "Iteration 987, loss = 1484738666.12337685\n",
            "Iteration 988, loss = 1484684160.67064190\n",
            "Iteration 989, loss = 1484629584.83415437\n",
            "Iteration 990, loss = 1484575626.38484716\n",
            "Iteration 991, loss = 1484521116.21831679\n",
            "Iteration 992, loss = 1484466752.91900301\n",
            "Iteration 993, loss = 1484412730.42495060\n",
            "Iteration 994, loss = 1484358634.31952500\n",
            "Iteration 995, loss = 1484304266.88405085\n",
            "Iteration 996, loss = 1484250236.81578827\n",
            "Iteration 997, loss = 1484195888.56915951\n",
            "Iteration 998, loss = 1484141769.24302030\n",
            "Iteration 999, loss = 1484087455.88098860\n",
            "Iteration 1000, loss = 1484033475.54433608\n",
            "Iteration 1, loss = 1370646032.66676259\n",
            "Iteration 2, loss = 118335788.20770612\n",
            "Iteration 3, loss = 347632033.84094787\n",
            "Iteration 4, loss = 139001089.20273408\n",
            "Iteration 5, loss = 112562912.44785753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 6, loss = 121246466.58808777\n",
            "Iteration 7, loss = 95039928.06609374\n",
            "Iteration 8, loss = 104131360.08154003\n",
            "Iteration 9, loss = 97300087.03777242\n",
            "Iteration 10, loss = 97209169.42298026\n",
            "Iteration 11, loss = 96049045.66745925\n",
            "Iteration 12, loss = 96301935.99970256\n",
            "Iteration 13, loss = 95725466.22506957\n",
            "Iteration 14, loss = 95713486.65548320\n",
            "Iteration 15, loss = 96539980.65607223\n",
            "Iteration 16, loss = 98486682.50732394\n",
            "Iteration 17, loss = 96148091.75138484\n",
            "Iteration 18, loss = 95973277.75521567\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538807691.62633944\n",
            "Iteration 2, loss = 1538740359.87983656\n",
            "Iteration 3, loss = 1538672900.75454807\n",
            "Iteration 4, loss = 1538610404.07492113\n",
            "Iteration 5, loss = 1538557732.73679781\n",
            "Iteration 6, loss = 1538513159.17384791\n",
            "Iteration 7, loss = 1538472209.51454401\n",
            "Iteration 8, loss = 1538432249.84022307\n",
            "Iteration 9, loss = 1538393576.92935777\n",
            "Iteration 10, loss = 1538354502.87636566\n",
            "Iteration 11, loss = 1538315335.37932348\n",
            "Iteration 12, loss = 1538276592.57275939\n",
            "Iteration 13, loss = 1538237229.63800001\n",
            "Iteration 14, loss = 1538198296.56638598\n",
            "Iteration 15, loss = 1538157951.01455569\n",
            "Iteration 16, loss = 1538115516.97731590\n",
            "Iteration 17, loss = 1538071623.40028358\n",
            "Iteration 18, loss = 1538026866.52817893\n",
            "Iteration 19, loss = 1537981654.09873700\n",
            "Iteration 20, loss = 1537936257.93412757\n",
            "Iteration 21, loss = 1537891725.07854009\n",
            "Iteration 22, loss = 1537847303.91702199\n",
            "Iteration 23, loss = 1537803547.18307233\n",
            "Iteration 24, loss = 1537759002.57220387\n",
            "Iteration 25, loss = 1537713310.96914911\n",
            "Iteration 26, loss = 1537667266.25395036\n",
            "Iteration 27, loss = 1537621545.13256884\n",
            "Iteration 28, loss = 1537576143.46472883\n",
            "Iteration 29, loss = 1537531024.03925276\n",
            "Iteration 30, loss = 1537486279.03036380\n",
            "Iteration 31, loss = 1537441158.08917952\n",
            "Iteration 32, loss = 1537396249.53338432\n",
            "Iteration 33, loss = 1537351920.12346864\n",
            "Iteration 34, loss = 1537307307.19434166\n",
            "Iteration 35, loss = 1537262824.94150162\n",
            "Iteration 36, loss = 1537218522.13030028\n",
            "Iteration 37, loss = 1537174499.98691249\n",
            "Iteration 38, loss = 1537130305.41753101\n",
            "Iteration 39, loss = 1537086484.76341081\n",
            "Iteration 40, loss = 1537042619.87231016\n",
            "Iteration 41, loss = 1536999190.12788582\n",
            "Iteration 42, loss = 1536955243.19417882\n",
            "Iteration 43, loss = 1536911647.80629635\n",
            "Iteration 44, loss = 1536868053.19342375\n",
            "Iteration 45, loss = 1536823546.51972318\n",
            "Iteration 46, loss = 1536777519.98145843\n",
            "Iteration 47, loss = 1536731635.27549291\n",
            "Iteration 48, loss = 1536686205.28242755\n",
            "Iteration 49, loss = 1536640933.74272823\n",
            "Iteration 50, loss = 1536595416.04512954\n",
            "Iteration 51, loss = 1536549086.88435888\n",
            "Iteration 52, loss = 1536500927.87625742\n",
            "Iteration 53, loss = 1536449443.99666119\n",
            "Iteration 54, loss = 1536398815.01625037\n",
            "Iteration 55, loss = 1536349313.95666552\n",
            "Iteration 56, loss = 1536299596.17050838\n",
            "Iteration 57, loss = 1536250014.98735237\n",
            "Iteration 58, loss = 1536200411.52442956\n",
            "Iteration 59, loss = 1536150973.14084101\n",
            "Iteration 60, loss = 1536101223.66015720\n",
            "Iteration 61, loss = 1536052019.31218004\n",
            "Iteration 62, loss = 1536002429.88791752\n",
            "Iteration 63, loss = 1535953316.92212677\n",
            "Iteration 64, loss = 1535904114.84276605\n",
            "Iteration 65, loss = 1535855090.24482727\n",
            "Iteration 66, loss = 1535806458.06204724\n",
            "Iteration 67, loss = 1535757734.72683692\n",
            "Iteration 68, loss = 1535709126.88226342\n",
            "Iteration 69, loss = 1535660824.27388501\n",
            "Iteration 70, loss = 1535612491.32556677\n",
            "Iteration 71, loss = 1535564326.83505821\n",
            "Iteration 72, loss = 1535516388.76481557\n",
            "Iteration 73, loss = 1535468220.99630904\n",
            "Iteration 74, loss = 1535420648.67554188\n",
            "Iteration 75, loss = 1535372609.26090813\n",
            "Iteration 76, loss = 1535324997.70105147\n",
            "Iteration 77, loss = 1535277580.71616101\n",
            "Iteration 78, loss = 1535230008.96216702\n",
            "Iteration 79, loss = 1535182855.28777790\n",
            "Iteration 80, loss = 1535135514.45011377\n",
            "Iteration 81, loss = 1535088676.84942842\n",
            "Iteration 82, loss = 1535041510.20987749\n",
            "Iteration 83, loss = 1534994592.14061952\n",
            "Iteration 84, loss = 1534947977.17136049\n",
            "Iteration 85, loss = 1534901021.13883710\n",
            "Iteration 86, loss = 1534854258.76093698\n",
            "Iteration 87, loss = 1534807609.14934516\n",
            "Iteration 88, loss = 1534761126.00305128\n",
            "Iteration 89, loss = 1534714221.81545401\n",
            "Iteration 90, loss = 1534667862.39398551\n",
            "Iteration 91, loss = 1534621166.71065259\n",
            "Iteration 92, loss = 1534574677.08120775\n",
            "Iteration 93, loss = 1534528083.23902035\n",
            "Iteration 94, loss = 1534481988.11768365\n",
            "Iteration 95, loss = 1534435290.61826468\n",
            "Iteration 96, loss = 1534388996.21347189\n",
            "Iteration 97, loss = 1534342890.18174815\n",
            "Iteration 98, loss = 1534296794.25703549\n",
            "Iteration 99, loss = 1534250398.48822832\n",
            "Iteration 100, loss = 1534204305.13779640\n",
            "Iteration 101, loss = 1534156860.99974608\n",
            "Iteration 102, loss = 1534107881.58983994\n",
            "Iteration 103, loss = 1534058057.33276844\n",
            "Iteration 104, loss = 1534009502.31232500\n",
            "Iteration 105, loss = 1533960030.33584166\n",
            "Iteration 106, loss = 1533911182.52723527\n",
            "Iteration 107, loss = 1533862243.42514515\n",
            "Iteration 108, loss = 1533812948.33559513\n",
            "Iteration 109, loss = 1533763528.45265150\n",
            "Iteration 110, loss = 1533714947.23201227\n",
            "Iteration 111, loss = 1533665826.19283581\n",
            "Iteration 112, loss = 1533617130.96157789\n",
            "Iteration 113, loss = 1533568120.00281596\n",
            "Iteration 114, loss = 1533519520.99497342\n",
            "Iteration 115, loss = 1533471061.80624294\n",
            "Iteration 116, loss = 1533422530.97453165\n",
            "Iteration 117, loss = 1533373880.91985607\n",
            "Iteration 118, loss = 1533325640.63700032\n",
            "Iteration 119, loss = 1533277416.55139613\n",
            "Iteration 120, loss = 1533229296.15587854\n",
            "Iteration 121, loss = 1533181220.80478859\n",
            "Iteration 122, loss = 1533133298.97147870\n",
            "Iteration 123, loss = 1533085752.19932985\n",
            "Iteration 124, loss = 1533037700.26771784\n",
            "Iteration 125, loss = 1532990591.03548741\n",
            "Iteration 126, loss = 1532942663.91858053\n",
            "Iteration 127, loss = 1532895783.49104404\n",
            "Iteration 128, loss = 1532848175.83864522\n",
            "Iteration 129, loss = 1532800843.57919621\n",
            "Iteration 130, loss = 1532753372.63794208\n",
            "Iteration 131, loss = 1532706193.99451923\n",
            "Iteration 132, loss = 1532658771.51619864\n",
            "Iteration 133, loss = 1532611353.83540940\n",
            "Iteration 134, loss = 1532564116.71827698\n",
            "Iteration 135, loss = 1532516892.65871811\n",
            "Iteration 136, loss = 1532469583.07415128\n",
            "Iteration 137, loss = 1532422374.11434984\n",
            "Iteration 138, loss = 1532375441.11005402\n",
            "Iteration 139, loss = 1532328430.75285888\n",
            "Iteration 140, loss = 1532281045.13623500\n",
            "Iteration 141, loss = 1532234649.12267327\n",
            "Iteration 142, loss = 1532187136.59018731\n",
            "Iteration 143, loss = 1532140299.24691200\n",
            "Iteration 144, loss = 1532093413.30674672\n",
            "Iteration 145, loss = 1532046361.58874607\n",
            "Iteration 146, loss = 1531999455.93253231\n",
            "Iteration 147, loss = 1531952567.28187823\n",
            "Iteration 148, loss = 1531905810.07593942\n",
            "Iteration 149, loss = 1531858799.33204293\n",
            "Iteration 150, loss = 1531812293.82166624\n",
            "Iteration 151, loss = 1531765678.67682743\n",
            "Iteration 152, loss = 1531718940.18035769\n",
            "Iteration 153, loss = 1531672361.30592585\n",
            "Iteration 154, loss = 1531625444.51517034\n",
            "Iteration 155, loss = 1531579316.00548244\n",
            "Iteration 156, loss = 1531532422.10163379\n",
            "Iteration 157, loss = 1531485736.59618115\n",
            "Iteration 158, loss = 1531438881.45620084\n",
            "Iteration 159, loss = 1531392254.46575499\n",
            "Iteration 160, loss = 1531345201.78195310\n",
            "Iteration 161, loss = 1531298266.11571622\n",
            "Iteration 162, loss = 1531251246.49925041\n",
            "Iteration 163, loss = 1531204363.99502683\n",
            "Iteration 164, loss = 1531157656.11497378\n",
            "Iteration 165, loss = 1531110649.69513392\n",
            "Iteration 166, loss = 1531064005.54089117\n",
            "Iteration 167, loss = 1531016989.25678754\n",
            "Iteration 168, loss = 1530970498.23529983\n",
            "Iteration 169, loss = 1530923390.24022651\n",
            "Iteration 170, loss = 1530874610.76923704\n",
            "Iteration 171, loss = 1530824160.58355570\n",
            "Iteration 172, loss = 1530774670.89589667\n",
            "Iteration 173, loss = 1530725056.98963857\n",
            "Iteration 174, loss = 1530674971.22146630\n",
            "Iteration 175, loss = 1530625245.39065671\n",
            "Iteration 176, loss = 1530575272.50272846\n",
            "Iteration 177, loss = 1530525485.54454184\n",
            "Iteration 178, loss = 1530475232.13949156\n",
            "Iteration 179, loss = 1530425620.61756468\n",
            "Iteration 180, loss = 1530375961.73144484\n",
            "Iteration 181, loss = 1530325940.29883242\n",
            "Iteration 182, loss = 1530276584.68238616\n",
            "Iteration 183, loss = 1530226951.48992395\n",
            "Iteration 184, loss = 1530177420.84178758\n",
            "Iteration 185, loss = 1530128431.91221571\n",
            "Iteration 186, loss = 1530078889.09530449\n",
            "Iteration 187, loss = 1530029647.04896355\n",
            "Iteration 188, loss = 1529980963.73268151\n",
            "Iteration 189, loss = 1529931881.66948700\n",
            "Iteration 190, loss = 1529882831.86184907\n",
            "Iteration 191, loss = 1529834039.62817812\n",
            "Iteration 192, loss = 1529785261.57539034\n",
            "Iteration 193, loss = 1529736292.23925400\n",
            "Iteration 194, loss = 1529687736.53445673\n",
            "Iteration 195, loss = 1529638807.72402740\n",
            "Iteration 196, loss = 1529589877.59300160\n",
            "Iteration 197, loss = 1529541372.43028426\n",
            "Iteration 198, loss = 1529492780.07632279\n",
            "Iteration 199, loss = 1529444061.46627522\n",
            "Iteration 200, loss = 1529395599.46263957\n",
            "Iteration 201, loss = 1529347030.31919909\n",
            "Iteration 202, loss = 1529298799.56571484\n",
            "Iteration 203, loss = 1529250218.71141529\n",
            "Iteration 204, loss = 1529201777.49067593\n",
            "Iteration 205, loss = 1529153285.97023392\n",
            "Iteration 206, loss = 1529104770.95151901\n",
            "Iteration 207, loss = 1529056353.39490438\n",
            "Iteration 208, loss = 1529007668.23035550\n",
            "Iteration 209, loss = 1528959417.19944143\n",
            "Iteration 210, loss = 1528911232.66397142\n",
            "Iteration 211, loss = 1528862425.18556380\n",
            "Iteration 212, loss = 1528814179.71008587\n",
            "Iteration 213, loss = 1528766060.30752754\n",
            "Iteration 214, loss = 1528718229.04538631\n",
            "Iteration 215, loss = 1528670059.04271221\n",
            "Iteration 216, loss = 1528621752.64859366\n",
            "Iteration 217, loss = 1528574078.60004115\n",
            "Iteration 218, loss = 1528525769.10020900\n",
            "Iteration 219, loss = 1528478286.55648017\n",
            "Iteration 220, loss = 1528430338.65943027\n",
            "Iteration 221, loss = 1528382197.74897408\n",
            "Iteration 222, loss = 1528334441.76156163\n",
            "Iteration 223, loss = 1528286750.08300567\n",
            "Iteration 224, loss = 1528238613.48374677\n",
            "Iteration 225, loss = 1528191119.21663642\n",
            "Iteration 226, loss = 1528143366.01484323\n",
            "Iteration 227, loss = 1528095470.65272808\n",
            "Iteration 228, loss = 1528047920.45345902\n",
            "Iteration 229, loss = 1527999835.19764471\n",
            "Iteration 230, loss = 1527952404.95727062\n",
            "Iteration 231, loss = 1527904382.52736974\n",
            "Iteration 232, loss = 1527856814.23797107\n",
            "Iteration 233, loss = 1527809021.58592248\n",
            "Iteration 234, loss = 1527761329.94013476\n",
            "Iteration 235, loss = 1527713270.93506289\n",
            "Iteration 236, loss = 1527664543.81092596\n",
            "Iteration 237, loss = 1527612993.03069735\n",
            "Iteration 238, loss = 1527561452.48158383\n",
            "Iteration 239, loss = 1527510111.71557260\n",
            "Iteration 240, loss = 1527458580.18562031\n",
            "Iteration 241, loss = 1527407223.96579742\n",
            "Iteration 242, loss = 1527355511.22549057\n",
            "Iteration 243, loss = 1527303731.27538681\n",
            "Iteration 244, loss = 1527252529.62176538\n",
            "Iteration 245, loss = 1527200826.64870191\n",
            "Iteration 246, loss = 1527149658.13485479\n",
            "Iteration 247, loss = 1527098330.39147592\n",
            "Iteration 248, loss = 1527046970.90409112\n",
            "Iteration 249, loss = 1526995951.31950474\n",
            "Iteration 250, loss = 1526944806.84239221\n",
            "Iteration 251, loss = 1526893720.49556017\n",
            "Iteration 252, loss = 1526842716.22778058\n",
            "Iteration 253, loss = 1526791864.46290135\n",
            "Iteration 254, loss = 1526740860.52310753\n",
            "Iteration 255, loss = 1526690297.49089170\n",
            "Iteration 256, loss = 1526639806.83784366\n",
            "Iteration 257, loss = 1526589117.25594354\n",
            "Iteration 258, loss = 1526538714.63664579\n",
            "Iteration 259, loss = 1526488403.94796848\n",
            "Iteration 260, loss = 1526438173.10272884\n",
            "Iteration 261, loss = 1526387541.98365951\n",
            "Iteration 262, loss = 1526337818.41727567\n",
            "Iteration 263, loss = 1526287308.85525751\n",
            "Iteration 264, loss = 1526237158.10141635\n",
            "Iteration 265, loss = 1526186863.04905510\n",
            "Iteration 266, loss = 1526136814.72720551\n",
            "Iteration 267, loss = 1526086440.45662451\n",
            "Iteration 268, loss = 1526036597.54089451\n",
            "Iteration 269, loss = 1525986204.01444626\n",
            "Iteration 270, loss = 1525936213.45030499\n",
            "Iteration 271, loss = 1525886448.50047421\n",
            "Iteration 272, loss = 1525836271.77369547\n",
            "Iteration 273, loss = 1525786460.91472912\n",
            "Iteration 274, loss = 1525736643.61531782\n",
            "Iteration 275, loss = 1525686776.85667157\n",
            "Iteration 276, loss = 1525637034.10591006\n",
            "Iteration 277, loss = 1525587261.67045093\n",
            "Iteration 278, loss = 1525537861.00276089\n",
            "Iteration 279, loss = 1525488032.51133394\n",
            "Iteration 280, loss = 1525438536.76738143\n",
            "Iteration 281, loss = 1525389256.81321931\n",
            "Iteration 282, loss = 1525339737.35580206\n",
            "Iteration 283, loss = 1525290628.11361265\n",
            "Iteration 284, loss = 1525241167.87855792\n",
            "Iteration 285, loss = 1525192137.82187629\n",
            "Iteration 286, loss = 1525142618.28044415\n",
            "Iteration 287, loss = 1525093311.67588663\n",
            "Iteration 288, loss = 1525044371.36736035\n",
            "Iteration 289, loss = 1524994160.28322840\n",
            "Iteration 290, loss = 1524942826.79515767\n",
            "Iteration 291, loss = 1524887557.95016170\n",
            "Iteration 292, loss = 1524834357.17212057\n",
            "Iteration 293, loss = 1524780507.74054003\n",
            "Iteration 294, loss = 1524727099.60194802\n",
            "Iteration 295, loss = 1524672977.65758491\n",
            "Iteration 296, loss = 1524619101.23792958\n",
            "Iteration 297, loss = 1524565688.17023277\n",
            "Iteration 298, loss = 1524511673.43008637\n",
            "Iteration 299, loss = 1524458527.72808290\n",
            "Iteration 300, loss = 1524404984.09873247\n",
            "Iteration 301, loss = 1524351675.96723509\n",
            "Iteration 302, loss = 1524298392.00213504\n",
            "Iteration 303, loss = 1524245384.32907724\n",
            "Iteration 304, loss = 1524191906.06923652\n",
            "Iteration 305, loss = 1524139135.33539581\n",
            "Iteration 306, loss = 1524086203.49439788\n",
            "Iteration 307, loss = 1524033624.67884207\n",
            "Iteration 308, loss = 1523980898.26733947\n",
            "Iteration 309, loss = 1523928536.90729094\n",
            "Iteration 310, loss = 1523876339.71163344\n",
            "Iteration 311, loss = 1523824321.52487469\n",
            "Iteration 312, loss = 1523772191.10902524\n",
            "Iteration 313, loss = 1523720114.86818862\n",
            "Iteration 314, loss = 1523668277.36311626\n",
            "Iteration 315, loss = 1523616020.62537622\n",
            "Iteration 316, loss = 1523564357.29742837\n",
            "Iteration 317, loss = 1523512210.14073205\n",
            "Iteration 318, loss = 1523460650.30820656\n",
            "Iteration 319, loss = 1523408472.44435692\n",
            "Iteration 320, loss = 1523356525.10258842\n",
            "Iteration 321, loss = 1523304523.71664619\n",
            "Iteration 322, loss = 1523252736.58069038\n",
            "Iteration 323, loss = 1523200880.61031890\n",
            "Iteration 324, loss = 1523148995.35874963\n",
            "Iteration 325, loss = 1523096905.21007586\n",
            "Iteration 326, loss = 1523045422.08018899\n",
            "Iteration 327, loss = 1522993696.22737241\n",
            "Iteration 328, loss = 1522941913.71294165\n",
            "Iteration 329, loss = 1522890685.25786018\n",
            "Iteration 330, loss = 1522838986.51497626\n",
            "Iteration 331, loss = 1522787483.76552081\n",
            "Iteration 332, loss = 1522736311.68125272\n",
            "Iteration 333, loss = 1522684990.81992888\n",
            "Iteration 334, loss = 1522633674.87747622\n",
            "Iteration 335, loss = 1522582528.37762713\n",
            "Iteration 336, loss = 1522531853.03779221\n",
            "Iteration 337, loss = 1522481096.29528570\n",
            "Iteration 338, loss = 1522429964.91146517\n",
            "Iteration 339, loss = 1522379537.23945451\n",
            "Iteration 340, loss = 1522329112.65594411\n",
            "Iteration 341, loss = 1522278492.52098536\n",
            "Iteration 342, loss = 1522227898.17357183\n",
            "Iteration 343, loss = 1522177527.80089784\n",
            "Iteration 344, loss = 1522126857.68810678\n",
            "Iteration 345, loss = 1522076204.41139507\n",
            "Iteration 346, loss = 1522025700.93176460\n",
            "Iteration 347, loss = 1521975077.91088891\n",
            "Iteration 348, loss = 1521924474.33670402\n",
            "Iteration 349, loss = 1521873861.65147018\n",
            "Iteration 350, loss = 1521823441.65154815\n",
            "Iteration 351, loss = 1521772680.54377460\n",
            "Iteration 352, loss = 1521722308.22521210\n",
            "Iteration 353, loss = 1521671871.17652869\n",
            "Iteration 354, loss = 1521621211.96387196\n",
            "Iteration 355, loss = 1521571171.17845273\n",
            "Iteration 356, loss = 1521520688.56680226\n",
            "Iteration 357, loss = 1521470522.72600961\n",
            "Iteration 358, loss = 1521419707.80679297\n",
            "Iteration 359, loss = 1521369954.56306863\n",
            "Iteration 360, loss = 1521319641.47952485\n",
            "Iteration 361, loss = 1521269163.59230757\n",
            "Iteration 362, loss = 1521219241.09606433\n",
            "Iteration 363, loss = 1521168756.03106999\n",
            "Iteration 364, loss = 1521118630.53810000\n",
            "Iteration 365, loss = 1521068773.74973512\n",
            "Iteration 366, loss = 1521018202.95378995\n",
            "Iteration 367, loss = 1520968103.98476243\n",
            "Iteration 368, loss = 1520918118.42307448\n",
            "Iteration 369, loss = 1520867644.36991310\n",
            "Iteration 370, loss = 1520815815.60343599\n",
            "Iteration 371, loss = 1520759538.85914326\n",
            "Iteration 372, loss = 1520705112.30821276\n",
            "Iteration 373, loss = 1520650211.48752403\n",
            "Iteration 374, loss = 1520595555.02295709\n",
            "Iteration 375, loss = 1520540491.73247242\n",
            "Iteration 376, loss = 1520485508.88699985\n",
            "Iteration 377, loss = 1520430332.50667524\n",
            "Iteration 378, loss = 1520375615.10154152\n",
            "Iteration 379, loss = 1520320550.83862472\n",
            "Iteration 380, loss = 1520265748.14749503\n",
            "Iteration 381, loss = 1520210785.65017056\n",
            "Iteration 382, loss = 1520156282.97507024\n",
            "Iteration 383, loss = 1520101594.36818051\n",
            "Iteration 384, loss = 1520046566.28292823\n",
            "Iteration 385, loss = 1519992517.10266137\n",
            "Iteration 386, loss = 1519937792.56265402\n",
            "Iteration 387, loss = 1519883655.02393556\n",
            "Iteration 388, loss = 1519829388.83082652\n",
            "Iteration 389, loss = 1519775143.16091442\n",
            "Iteration 390, loss = 1519721638.86088753\n",
            "Iteration 391, loss = 1519667568.12070036\n",
            "Iteration 392, loss = 1519613998.76340580\n",
            "Iteration 393, loss = 1519560576.08806467\n",
            "Iteration 394, loss = 1519506872.99076319\n",
            "Iteration 395, loss = 1519453173.18436265\n",
            "Iteration 396, loss = 1519399313.21146512\n",
            "Iteration 397, loss = 1519341488.61676836\n",
            "Iteration 398, loss = 1519281904.86665630\n",
            "Iteration 399, loss = 1519224004.22628570\n",
            "Iteration 400, loss = 1519165701.03807807\n",
            "Iteration 401, loss = 1519107324.44308233\n",
            "Iteration 402, loss = 1519049004.31294608\n",
            "Iteration 403, loss = 1518990588.40271664\n",
            "Iteration 404, loss = 1518932235.40935063\n",
            "Iteration 405, loss = 1518874096.57675958\n",
            "Iteration 406, loss = 1518816283.50092912\n",
            "Iteration 407, loss = 1518758135.18729830\n",
            "Iteration 408, loss = 1518700073.65638447\n",
            "Iteration 409, loss = 1518642886.61596727\n",
            "Iteration 410, loss = 1518584661.28201437\n",
            "Iteration 411, loss = 1518527095.37255168\n",
            "Iteration 412, loss = 1518470147.90015769\n",
            "Iteration 413, loss = 1518412651.45711398\n",
            "Iteration 414, loss = 1518355984.62348294\n",
            "Iteration 415, loss = 1518298664.20819378\n",
            "Iteration 416, loss = 1518242485.81708312\n",
            "Iteration 417, loss = 1518185946.42388725\n",
            "Iteration 418, loss = 1518130000.71802592\n",
            "Iteration 419, loss = 1518074013.10947275\n",
            "Iteration 420, loss = 1518017933.54074240\n",
            "Iteration 421, loss = 1517962479.42736435\n",
            "Iteration 422, loss = 1517906828.00038719\n",
            "Iteration 423, loss = 1517851516.51212907\n",
            "Iteration 424, loss = 1517795408.08980131\n",
            "Iteration 425, loss = 1517735961.96784115\n",
            "Iteration 426, loss = 1517674772.96968675\n",
            "Iteration 427, loss = 1517615131.68255854\n",
            "Iteration 428, loss = 1517555433.82265830\n",
            "Iteration 429, loss = 1517494926.31905699\n",
            "Iteration 430, loss = 1517434639.44622874\n",
            "Iteration 431, loss = 1517374470.97768974\n",
            "Iteration 432, loss = 1517314165.65546703\n",
            "Iteration 433, loss = 1517254071.70232153\n",
            "Iteration 434, loss = 1517193989.68853736\n",
            "Iteration 435, loss = 1517133931.20226145\n",
            "Iteration 436, loss = 1517074470.77743220\n",
            "Iteration 437, loss = 1517014932.98657584\n",
            "Iteration 438, loss = 1516955437.64211321\n",
            "Iteration 439, loss = 1516895799.23631668\n",
            "Iteration 440, loss = 1516837217.86385322\n",
            "Iteration 441, loss = 1516778026.23810077\n",
            "Iteration 442, loss = 1516719267.82500911\n",
            "Iteration 443, loss = 1516660495.70734215\n",
            "Iteration 444, loss = 1516601958.74634957\n",
            "Iteration 445, loss = 1516543346.98876071\n",
            "Iteration 446, loss = 1516485321.46948624\n",
            "Iteration 447, loss = 1516426764.32117271\n",
            "Iteration 448, loss = 1516368891.35706139\n",
            "Iteration 449, loss = 1516310824.41411352\n",
            "Iteration 450, loss = 1516253029.24046946\n",
            "Iteration 451, loss = 1516195201.60015702\n",
            "Iteration 452, loss = 1516138010.77315092\n",
            "Iteration 453, loss = 1516080355.03390288\n",
            "Iteration 454, loss = 1516022984.28722215\n",
            "Iteration 455, loss = 1515966070.15102720\n",
            "Iteration 456, loss = 1515908899.09603620\n",
            "Iteration 457, loss = 1515852120.17261195\n",
            "Iteration 458, loss = 1515795499.43063855\n",
            "Iteration 459, loss = 1515738789.51551700\n",
            "Iteration 460, loss = 1515682086.92275167\n",
            "Iteration 461, loss = 1515625771.86992717\n",
            "Iteration 462, loss = 1515569415.56121540\n",
            "Iteration 463, loss = 1515512974.22129965\n",
            "Iteration 464, loss = 1515456469.46890330\n",
            "Iteration 465, loss = 1515399923.43093014\n",
            "Iteration 466, loss = 1515344249.47959280\n",
            "Iteration 467, loss = 1515287967.41254115\n",
            "Iteration 468, loss = 1515231858.28658414\n",
            "Iteration 469, loss = 1515175860.74826193\n",
            "Iteration 470, loss = 1515119973.56875491\n",
            "Iteration 471, loss = 1515064384.91656256\n",
            "Iteration 472, loss = 1515008566.01233196\n",
            "Iteration 473, loss = 1514952582.93462253\n",
            "Iteration 474, loss = 1514896868.19526339\n",
            "Iteration 475, loss = 1514841509.22632623\n",
            "Iteration 476, loss = 1514785530.39188051\n",
            "Iteration 477, loss = 1514730129.73930478\n",
            "Iteration 478, loss = 1514674448.66982603\n",
            "Iteration 479, loss = 1514619035.02521586\n",
            "Iteration 480, loss = 1514563430.12773561\n",
            "Iteration 481, loss = 1514508066.09903121\n",
            "Iteration 482, loss = 1514452708.28827929\n",
            "Iteration 483, loss = 1514397220.81048179\n",
            "Iteration 484, loss = 1514342081.18203902\n",
            "Iteration 485, loss = 1514286443.41254568\n",
            "Iteration 486, loss = 1514231090.02310538\n",
            "Iteration 487, loss = 1514175502.76367760\n",
            "Iteration 488, loss = 1514120224.74497390\n",
            "Iteration 489, loss = 1514064636.13209271\n",
            "Iteration 490, loss = 1514009085.20199442\n",
            "Iteration 491, loss = 1513953894.97212076\n",
            "Iteration 492, loss = 1513898557.90400743\n",
            "Iteration 493, loss = 1513843010.85452485\n",
            "Iteration 494, loss = 1513788035.53579807\n",
            "Iteration 495, loss = 1513732805.61114383\n",
            "Iteration 496, loss = 1513677961.64343214\n",
            "Iteration 497, loss = 1513622795.30818176\n",
            "Iteration 498, loss = 1513567892.15588403\n",
            "Iteration 499, loss = 1513513204.83723688\n",
            "Iteration 500, loss = 1513458197.54114461\n",
            "Iteration 501, loss = 1513403647.04259968\n",
            "Iteration 502, loss = 1513348760.64984035\n",
            "Iteration 503, loss = 1513294316.80283785\n",
            "Iteration 504, loss = 1513239557.45934391\n",
            "Iteration 505, loss = 1513185539.39654469\n",
            "Iteration 506, loss = 1513131076.27547526\n",
            "Iteration 507, loss = 1513076644.94760513\n",
            "Iteration 508, loss = 1513022819.70412660\n",
            "Iteration 509, loss = 1512968629.65116262\n",
            "Iteration 510, loss = 1512914376.65970469\n",
            "Iteration 511, loss = 1512860816.73638272\n",
            "Iteration 512, loss = 1512806604.18911767\n",
            "Iteration 513, loss = 1512752511.24135375\n",
            "Iteration 514, loss = 1512698658.71252155\n",
            "Iteration 515, loss = 1512644417.57904696\n",
            "Iteration 516, loss = 1512590604.35918140\n",
            "Iteration 517, loss = 1512536437.39624166\n",
            "Iteration 518, loss = 1512482324.62308073\n",
            "Iteration 519, loss = 1512428297.70233226\n",
            "Iteration 520, loss = 1512374079.44644070\n",
            "Iteration 521, loss = 1512320150.58448863\n",
            "Iteration 522, loss = 1512266100.98611856\n",
            "Iteration 523, loss = 1512211789.96664691\n",
            "Iteration 524, loss = 1512158100.43405223\n",
            "Iteration 525, loss = 1512103889.91732669\n",
            "Iteration 526, loss = 1512049974.50468087\n",
            "Iteration 527, loss = 1511995487.06064034\n",
            "Iteration 528, loss = 1511941348.63755822\n",
            "Iteration 529, loss = 1511887263.93707585\n",
            "Iteration 530, loss = 1511832859.80185795\n",
            "Iteration 531, loss = 1511778697.18577647\n",
            "Iteration 532, loss = 1511724754.83231616\n",
            "Iteration 533, loss = 1511670525.44941878\n",
            "Iteration 534, loss = 1511616376.69627309\n",
            "Iteration 535, loss = 1511562714.11363101\n",
            "Iteration 536, loss = 1511508560.39156342\n",
            "Iteration 537, loss = 1511454984.07024240\n",
            "Iteration 538, loss = 1511401222.97825074\n",
            "Iteration 539, loss = 1511347561.46349621\n",
            "Iteration 540, loss = 1511294102.90886784\n",
            "Iteration 541, loss = 1511240000.65752196\n",
            "Iteration 542, loss = 1511187015.24813342\n",
            "Iteration 543, loss = 1511133222.79542041\n",
            "Iteration 544, loss = 1511079332.27883220\n",
            "Iteration 545, loss = 1511026200.47366929\n",
            "Iteration 546, loss = 1510972407.00645280\n",
            "Iteration 547, loss = 1510918592.72214794\n",
            "Iteration 548, loss = 1510864915.56087375\n",
            "Iteration 549, loss = 1510811394.05735707\n",
            "Iteration 550, loss = 1510757615.84863472\n",
            "Iteration 551, loss = 1510703942.57991171\n",
            "Iteration 552, loss = 1510650269.77612758\n",
            "Iteration 553, loss = 1510596451.29120421\n",
            "Iteration 554, loss = 1510543034.17627645\n",
            "Iteration 555, loss = 1510489131.70552301\n",
            "Iteration 556, loss = 1510435726.48685575\n",
            "Iteration 557, loss = 1510382049.03137302\n",
            "Iteration 558, loss = 1510328476.99563670\n",
            "Iteration 559, loss = 1510274917.49559283\n",
            "Iteration 560, loss = 1510221293.17443538\n",
            "Iteration 561, loss = 1510167629.27493095\n",
            "Iteration 562, loss = 1510114247.49480867\n",
            "Iteration 563, loss = 1510060276.56415725\n",
            "Iteration 564, loss = 1510006383.29106784\n",
            "Iteration 565, loss = 1509948252.02831006\n",
            "Iteration 566, loss = 1509887427.14000940\n",
            "Iteration 567, loss = 1509829042.73800993\n",
            "Iteration 568, loss = 1509769676.32244825\n",
            "Iteration 569, loss = 1509710749.42379999\n",
            "Iteration 570, loss = 1509651507.50968719\n",
            "Iteration 571, loss = 1509592341.95380831\n",
            "Iteration 572, loss = 1509532687.05288720\n",
            "Iteration 573, loss = 1509474128.35346174\n",
            "Iteration 574, loss = 1509415312.10916495\n",
            "Iteration 575, loss = 1509356410.03106403\n",
            "Iteration 576, loss = 1509298328.44249892\n",
            "Iteration 577, loss = 1509239680.68934393\n",
            "Iteration 578, loss = 1509181717.99977088\n",
            "Iteration 579, loss = 1509123445.74006271\n",
            "Iteration 580, loss = 1509065993.82178140\n",
            "Iteration 581, loss = 1509007951.34817600\n",
            "Iteration 582, loss = 1508950235.67243314\n",
            "Iteration 583, loss = 1508892218.96129680\n",
            "Iteration 584, loss = 1508834750.34313774\n",
            "Iteration 585, loss = 1508777085.02884102\n",
            "Iteration 586, loss = 1508719590.13975143\n",
            "Iteration 587, loss = 1508662585.51064706\n",
            "Iteration 588, loss = 1508604939.47205257\n",
            "Iteration 589, loss = 1508548025.95413399\n",
            "Iteration 590, loss = 1508491100.63433933\n",
            "Iteration 591, loss = 1508434242.51634145\n",
            "Iteration 592, loss = 1508377623.36515427\n",
            "Iteration 593, loss = 1508320492.30650163\n",
            "Iteration 594, loss = 1508263957.36381769\n",
            "Iteration 595, loss = 1508207079.69416928\n",
            "Iteration 596, loss = 1508150520.39395380\n",
            "Iteration 597, loss = 1508093139.98029900\n",
            "Iteration 598, loss = 1508036505.42861390\n",
            "Iteration 599, loss = 1507979542.70162868\n",
            "Iteration 600, loss = 1507922693.65846133\n",
            "Iteration 601, loss = 1507865682.18868351\n",
            "Iteration 602, loss = 1507809127.12551761\n",
            "Iteration 603, loss = 1507752367.87276316\n",
            "Iteration 604, loss = 1507695914.03765488\n",
            "Iteration 605, loss = 1507639157.23523641\n",
            "Iteration 606, loss = 1507582836.93770385\n",
            "Iteration 607, loss = 1507526474.48734593\n",
            "Iteration 608, loss = 1507470607.18597150\n",
            "Iteration 609, loss = 1507414158.65709043\n",
            "Iteration 610, loss = 1507357825.52462101\n",
            "Iteration 611, loss = 1507302128.71171141\n",
            "Iteration 612, loss = 1507246079.50130916\n",
            "Iteration 613, loss = 1507189907.73125863\n",
            "Iteration 614, loss = 1507134158.43777251\n",
            "Iteration 615, loss = 1507078256.96447206\n",
            "Iteration 616, loss = 1507022260.97719264\n",
            "Iteration 617, loss = 1506966742.43206525\n",
            "Iteration 618, loss = 1506911177.09703922\n",
            "Iteration 619, loss = 1506855589.40013433\n",
            "Iteration 620, loss = 1506800368.26391912\n",
            "Iteration 621, loss = 1506745103.28650618\n",
            "Iteration 622, loss = 1506690205.50086331\n",
            "Iteration 623, loss = 1506634797.90686226\n",
            "Iteration 624, loss = 1506579621.56432319\n",
            "Iteration 625, loss = 1506524521.47849321\n",
            "Iteration 626, loss = 1506469409.14603615\n",
            "Iteration 627, loss = 1506414184.30700159\n",
            "Iteration 628, loss = 1506359050.48035598\n",
            "Iteration 629, loss = 1506303548.31350327\n",
            "Iteration 630, loss = 1506248465.20014882\n",
            "Iteration 631, loss = 1506193298.69992447\n",
            "Iteration 632, loss = 1506138101.16487098\n",
            "Iteration 633, loss = 1506082948.05163550\n",
            "Iteration 634, loss = 1506027927.46838903\n",
            "Iteration 635, loss = 1505972822.21526837\n",
            "Iteration 636, loss = 1505917728.34171295\n",
            "Iteration 637, loss = 1505862891.71854687\n",
            "Iteration 638, loss = 1505807721.18753314\n",
            "Iteration 639, loss = 1505752758.44555378\n",
            "Iteration 640, loss = 1505697904.83736277\n",
            "Iteration 641, loss = 1505642416.43995023\n",
            "Iteration 642, loss = 1505587768.07300591\n",
            "Iteration 643, loss = 1505532713.97453928\n",
            "Iteration 644, loss = 1505477134.08253264\n",
            "Iteration 645, loss = 1505422415.09561920\n",
            "Iteration 646, loss = 1505367388.01255941\n",
            "Iteration 647, loss = 1505310786.14136457\n",
            "Iteration 648, loss = 1505248177.49603391\n",
            "Iteration 649, loss = 1505187662.10048485\n",
            "Iteration 650, loss = 1505126950.82251954\n",
            "Iteration 651, loss = 1505066657.06708097\n",
            "Iteration 652, loss = 1505005430.14574623\n",
            "Iteration 653, loss = 1504944383.13909316\n",
            "Iteration 654, loss = 1504883824.76958728\n",
            "Iteration 655, loss = 1504822989.14714241\n",
            "Iteration 656, loss = 1504762233.39056015\n",
            "Iteration 657, loss = 1504701417.79329348\n",
            "Iteration 658, loss = 1504641213.31970930\n",
            "Iteration 659, loss = 1504580728.10913277\n",
            "Iteration 660, loss = 1504520661.92629886\n",
            "Iteration 661, loss = 1504460498.19113684\n",
            "Iteration 662, loss = 1504400058.75932789\n",
            "Iteration 663, loss = 1504340452.50128627\n",
            "Iteration 664, loss = 1504281189.60087395\n",
            "Iteration 665, loss = 1504221381.13622975\n",
            "Iteration 666, loss = 1504162181.27131748\n",
            "Iteration 667, loss = 1504103220.39686036\n",
            "Iteration 668, loss = 1504044103.76997423\n",
            "Iteration 669, loss = 1503985374.49498868\n",
            "Iteration 670, loss = 1503926685.77084589\n",
            "Iteration 671, loss = 1503868142.17613077\n",
            "Iteration 672, loss = 1503809475.55734944\n",
            "Iteration 673, loss = 1503750455.89105797\n",
            "Iteration 674, loss = 1503692736.96623802\n",
            "Iteration 675, loss = 1503633864.96057558\n",
            "Iteration 676, loss = 1503575869.95831156\n",
            "Iteration 677, loss = 1503517863.02329803\n",
            "Iteration 678, loss = 1503459653.04208207\n",
            "Iteration 679, loss = 1503402058.66911030\n",
            "Iteration 680, loss = 1503344290.91440082\n",
            "Iteration 681, loss = 1503286905.58687997\n",
            "Iteration 682, loss = 1503229282.99513960\n",
            "Iteration 683, loss = 1503171811.55715609\n",
            "Iteration 684, loss = 1503114472.35012650\n",
            "Iteration 685, loss = 1503056867.66677523\n",
            "Iteration 686, loss = 1502999481.15596533\n",
            "Iteration 687, loss = 1502942070.85852051\n",
            "Iteration 688, loss = 1502884553.16284847\n",
            "Iteration 689, loss = 1502826951.95665574\n",
            "Iteration 690, loss = 1502769834.66612744\n",
            "Iteration 691, loss = 1502712177.28507566\n",
            "Iteration 692, loss = 1502654934.64515591\n",
            "Iteration 693, loss = 1502597507.41615295\n",
            "Iteration 694, loss = 1502540138.19487000\n",
            "Iteration 695, loss = 1502482964.48783636\n",
            "Iteration 696, loss = 1502425819.70566392\n",
            "Iteration 697, loss = 1502368466.20247340\n",
            "Iteration 698, loss = 1502311603.96862054\n",
            "Iteration 699, loss = 1502254650.56943655\n",
            "Iteration 700, loss = 1502197237.24187207\n",
            "Iteration 701, loss = 1502140530.98108172\n",
            "Iteration 702, loss = 1502083939.79834247\n",
            "Iteration 703, loss = 1502026834.44072199\n",
            "Iteration 704, loss = 1501970173.18495393\n",
            "Iteration 705, loss = 1501913697.98865867\n",
            "Iteration 706, loss = 1501856552.29426098\n",
            "Iteration 707, loss = 1501799997.99163580\n",
            "Iteration 708, loss = 1501743461.01055932\n",
            "Iteration 709, loss = 1501686575.24378610\n",
            "Iteration 710, loss = 1501630283.12267876\n",
            "Iteration 711, loss = 1501573377.11849117\n",
            "Iteration 712, loss = 1501516882.50421405\n",
            "Iteration 713, loss = 1501460646.95133924\n",
            "Iteration 714, loss = 1501404320.91324520\n",
            "Iteration 715, loss = 1501347443.37835860\n",
            "Iteration 716, loss = 1501291547.29818368\n",
            "Iteration 717, loss = 1501234936.61823797\n",
            "Iteration 718, loss = 1501178649.10600400\n",
            "Iteration 719, loss = 1501122386.53859901\n",
            "Iteration 720, loss = 1501066337.52628207\n",
            "Iteration 721, loss = 1501009837.73749042\n",
            "Iteration 722, loss = 1500954067.75284481\n",
            "Iteration 723, loss = 1500897684.34525561\n",
            "Iteration 724, loss = 1500841879.09200501\n",
            "Iteration 725, loss = 1500786033.68496299\n",
            "Iteration 726, loss = 1500729864.59759808\n",
            "Iteration 727, loss = 1500673885.83018565\n",
            "Iteration 728, loss = 1500618328.95217156\n",
            "Iteration 729, loss = 1500562206.73264408\n",
            "Iteration 730, loss = 1500506262.68469119\n",
            "Iteration 731, loss = 1500450291.77573729\n",
            "Iteration 732, loss = 1500394693.78364420\n",
            "Iteration 733, loss = 1500338664.06416035\n",
            "Iteration 734, loss = 1500282923.30780387\n",
            "Iteration 735, loss = 1500226882.40861583\n",
            "Iteration 736, loss = 1500171189.67967343\n",
            "Iteration 737, loss = 1500115314.09899330\n",
            "Iteration 738, loss = 1500059357.71924305\n",
            "Iteration 739, loss = 1500003530.53048825\n",
            "Iteration 740, loss = 1499947542.28545189\n",
            "Iteration 741, loss = 1499892009.20416260\n",
            "Iteration 742, loss = 1499835731.87279296\n",
            "Iteration 743, loss = 1499780340.72234011\n",
            "Iteration 744, loss = 1499724669.03265309\n",
            "Iteration 745, loss = 1499668877.01440549\n",
            "Iteration 746, loss = 1499613340.23623776\n",
            "Iteration 747, loss = 1499558044.18793607\n",
            "Iteration 748, loss = 1499502064.80935740\n",
            "Iteration 749, loss = 1499446629.09194422\n",
            "Iteration 750, loss = 1499391246.91345024\n",
            "Iteration 751, loss = 1499335808.38279343\n",
            "Iteration 752, loss = 1499279977.22951627\n",
            "Iteration 753, loss = 1499224377.74899530\n",
            "Iteration 754, loss = 1499169266.17587137\n",
            "Iteration 755, loss = 1499113714.49173522\n",
            "Iteration 756, loss = 1499058363.58167291\n",
            "Iteration 757, loss = 1499002980.19136262\n",
            "Iteration 758, loss = 1498947943.66292238\n",
            "Iteration 759, loss = 1498893008.50043273\n",
            "Iteration 760, loss = 1498837593.57021904\n",
            "Iteration 761, loss = 1498782552.15474200\n",
            "Iteration 762, loss = 1498727694.22371435\n",
            "Iteration 763, loss = 1498672528.08880830\n",
            "Iteration 764, loss = 1498617452.17936420\n",
            "Iteration 765, loss = 1498562314.12954617\n",
            "Iteration 766, loss = 1498507269.04381847\n",
            "Iteration 767, loss = 1498451923.19824457\n",
            "Iteration 768, loss = 1498397233.43209887\n",
            "Iteration 769, loss = 1498341626.34980726\n",
            "Iteration 770, loss = 1498286502.29574966\n",
            "Iteration 771, loss = 1498230994.91232133\n",
            "Iteration 772, loss = 1498175757.34194708\n",
            "Iteration 773, loss = 1498120458.92706060\n",
            "Iteration 774, loss = 1498065162.67330360\n",
            "Iteration 775, loss = 1498009702.28491998\n",
            "Iteration 776, loss = 1497954306.93513489\n",
            "Iteration 777, loss = 1497899260.03365898\n",
            "Iteration 778, loss = 1497843786.38814521\n",
            "Iteration 779, loss = 1497788474.35906267\n",
            "Iteration 780, loss = 1497733033.51557112\n",
            "Iteration 781, loss = 1497677963.00935960\n",
            "Iteration 782, loss = 1497622326.47069788\n",
            "Iteration 783, loss = 1497566943.40147781\n",
            "Iteration 784, loss = 1497511647.39660096\n",
            "Iteration 785, loss = 1497456439.00594759\n",
            "Iteration 786, loss = 1497401054.37673140\n",
            "Iteration 787, loss = 1497346077.15142918\n",
            "Iteration 788, loss = 1497291032.61876750\n",
            "Iteration 789, loss = 1497236242.17655206\n",
            "Iteration 790, loss = 1497181480.46876526\n",
            "Iteration 791, loss = 1497126700.60189342\n",
            "Iteration 792, loss = 1497072314.46765471\n",
            "Iteration 793, loss = 1497017841.72241902\n",
            "Iteration 794, loss = 1496963311.48019719\n",
            "Iteration 795, loss = 1496909058.28303695\n",
            "Iteration 796, loss = 1496854771.30467629\n",
            "Iteration 797, loss = 1496799935.53392816\n",
            "Iteration 798, loss = 1496745582.30544949\n",
            "Iteration 799, loss = 1496690855.81982756\n",
            "Iteration 800, loss = 1496636016.16244292\n",
            "Iteration 801, loss = 1496581491.19637990\n",
            "Iteration 802, loss = 1496526554.37957811\n",
            "Iteration 803, loss = 1496471694.42195916\n",
            "Iteration 804, loss = 1496416872.62738991\n",
            "Iteration 805, loss = 1496362147.09544539\n",
            "Iteration 806, loss = 1496307248.53117085\n",
            "Iteration 807, loss = 1496252378.27618074\n",
            "Iteration 808, loss = 1496197407.63602090\n",
            "Iteration 809, loss = 1496142670.44610262\n",
            "Iteration 810, loss = 1496088009.71597648\n",
            "Iteration 811, loss = 1496032942.24381471\n",
            "Iteration 812, loss = 1495978359.81859398\n",
            "Iteration 813, loss = 1495924054.97919035\n",
            "Iteration 814, loss = 1495869039.48882294\n",
            "Iteration 815, loss = 1495814019.44512153\n",
            "Iteration 816, loss = 1495754004.68899059\n",
            "Iteration 817, loss = 1495692792.62637925\n",
            "Iteration 818, loss = 1495632572.54387712\n",
            "Iteration 819, loss = 1495571928.38347697\n",
            "Iteration 820, loss = 1495511273.19849896\n",
            "Iteration 821, loss = 1495450077.33987093\n",
            "Iteration 822, loss = 1495389374.49675632\n",
            "Iteration 823, loss = 1495328301.14123201\n",
            "Iteration 824, loss = 1495267837.15543485\n",
            "Iteration 825, loss = 1495207060.03042340\n",
            "Iteration 826, loss = 1495146578.96085143\n",
            "Iteration 827, loss = 1495086006.84789658\n",
            "Iteration 828, loss = 1495025731.32859039\n",
            "Iteration 829, loss = 1494965557.11854982\n",
            "Iteration 830, loss = 1494905198.45235920\n",
            "Iteration 831, loss = 1494845304.71548605\n",
            "Iteration 832, loss = 1494785180.69884229\n",
            "Iteration 833, loss = 1494725282.49538517\n",
            "Iteration 834, loss = 1494665759.03757381\n",
            "Iteration 835, loss = 1494606051.16597915\n",
            "Iteration 836, loss = 1494546442.39249039\n",
            "Iteration 837, loss = 1494487004.39513993\n",
            "Iteration 838, loss = 1494427948.51260543\n",
            "Iteration 839, loss = 1494368542.69063592\n",
            "Iteration 840, loss = 1494309773.45945621\n",
            "Iteration 841, loss = 1494250753.71988463\n",
            "Iteration 842, loss = 1494191450.51600099\n",
            "Iteration 843, loss = 1494133247.12314129\n",
            "Iteration 844, loss = 1494074567.07287216\n",
            "Iteration 845, loss = 1494015659.73393631\n",
            "Iteration 846, loss = 1493957213.88027620\n",
            "Iteration 847, loss = 1493898729.90649438\n",
            "Iteration 848, loss = 1493840209.32998037\n",
            "Iteration 849, loss = 1493781827.31827211\n",
            "Iteration 850, loss = 1493723548.89767790\n",
            "Iteration 851, loss = 1493665404.38376784\n",
            "Iteration 852, loss = 1493607504.75464177\n",
            "Iteration 853, loss = 1493549268.64484358\n",
            "Iteration 854, loss = 1493491488.37634683\n",
            "Iteration 855, loss = 1493433939.92173028\n",
            "Iteration 856, loss = 1493376168.76594019\n",
            "Iteration 857, loss = 1493318507.64331222\n",
            "Iteration 858, loss = 1493260388.46768975\n",
            "Iteration 859, loss = 1493202923.06865454\n",
            "Iteration 860, loss = 1493145042.67474389\n",
            "Iteration 861, loss = 1493087266.63625574\n",
            "Iteration 862, loss = 1493029355.79947925\n",
            "Iteration 863, loss = 1492971728.00870705\n",
            "Iteration 864, loss = 1492913818.34011459\n",
            "Iteration 865, loss = 1492855661.59143209\n",
            "Iteration 866, loss = 1492798508.08682013\n",
            "Iteration 867, loss = 1492740536.34911442\n",
            "Iteration 868, loss = 1492683239.41697741\n",
            "Iteration 869, loss = 1492625418.01805758\n",
            "Iteration 870, loss = 1492568437.97820544\n",
            "Iteration 871, loss = 1492510975.03261065\n",
            "Iteration 872, loss = 1492453637.03048754\n",
            "Iteration 873, loss = 1492396689.86714101\n",
            "Iteration 874, loss = 1492339710.76779199\n",
            "Iteration 875, loss = 1492282862.90985560\n",
            "Iteration 876, loss = 1492225817.08185816\n",
            "Iteration 877, loss = 1492168844.83600092\n",
            "Iteration 878, loss = 1492112591.81639338\n",
            "Iteration 879, loss = 1492055604.34811234\n",
            "Iteration 880, loss = 1491999125.87119293\n",
            "Iteration 881, loss = 1491942655.95189667\n",
            "Iteration 882, loss = 1491885707.67382002\n",
            "Iteration 883, loss = 1491829198.22529697\n",
            "Iteration 884, loss = 1491772888.38626790\n",
            "Iteration 885, loss = 1491716007.30863285\n",
            "Iteration 886, loss = 1491659474.67312384\n",
            "Iteration 887, loss = 1491602505.48702455\n",
            "Iteration 888, loss = 1491545888.39850521\n",
            "Iteration 889, loss = 1491489238.45824742\n",
            "Iteration 890, loss = 1491432464.61171174\n",
            "Iteration 891, loss = 1491375702.25631595\n",
            "Iteration 892, loss = 1491318846.59134960\n",
            "Iteration 893, loss = 1491262296.51267385\n",
            "Iteration 894, loss = 1491205540.36827612\n",
            "Iteration 895, loss = 1491149095.52521157\n",
            "Iteration 896, loss = 1491092188.89371824\n",
            "Iteration 897, loss = 1491035599.69778824\n",
            "Iteration 898, loss = 1490979099.50973201\n",
            "Iteration 899, loss = 1490922381.99957395\n",
            "Iteration 900, loss = 1490865791.62684679\n",
            "Iteration 901, loss = 1490808917.13644862\n",
            "Iteration 902, loss = 1490752524.42916036\n",
            "Iteration 903, loss = 1490695860.84363270\n",
            "Iteration 904, loss = 1490639098.55952263\n",
            "Iteration 905, loss = 1490582746.18436933\n",
            "Iteration 906, loss = 1490525557.38313198\n",
            "Iteration 907, loss = 1490469340.17467093\n",
            "Iteration 908, loss = 1490412840.73251486\n",
            "Iteration 909, loss = 1490356047.41884112\n",
            "Iteration 910, loss = 1490299890.18304706\n",
            "Iteration 911, loss = 1490243252.45679426\n",
            "Iteration 912, loss = 1490186692.66418004\n",
            "Iteration 913, loss = 1490130250.52817774\n",
            "Iteration 914, loss = 1490073958.71356559\n",
            "Iteration 915, loss = 1490017486.80325603\n",
            "Iteration 916, loss = 1489961067.84368515\n",
            "Iteration 917, loss = 1489904774.33026290\n",
            "Iteration 918, loss = 1489848559.07989240\n",
            "Iteration 919, loss = 1489792005.89815640\n",
            "Iteration 920, loss = 1489736101.45228481\n",
            "Iteration 921, loss = 1489679933.46771169\n",
            "Iteration 922, loss = 1489623817.05929375\n",
            "Iteration 923, loss = 1489567346.14053226\n",
            "Iteration 924, loss = 1489511744.16373968\n",
            "Iteration 925, loss = 1489455110.88303375\n",
            "Iteration 926, loss = 1489398942.46908188\n",
            "Iteration 927, loss = 1489343299.99617100\n",
            "Iteration 928, loss = 1489286410.43891501\n",
            "Iteration 929, loss = 1489230541.00776172\n",
            "Iteration 930, loss = 1489174446.92699957\n",
            "Iteration 931, loss = 1489117974.87523627\n",
            "Iteration 932, loss = 1489061860.66556668\n",
            "Iteration 933, loss = 1489005683.23206067\n",
            "Iteration 934, loss = 1488949644.47242665\n",
            "Iteration 935, loss = 1488893155.84052181\n",
            "Iteration 936, loss = 1488837058.80604672\n",
            "Iteration 937, loss = 1488781233.44752455\n",
            "Iteration 938, loss = 1488724568.27137566\n",
            "Iteration 939, loss = 1488668772.86916018\n",
            "Iteration 940, loss = 1488612568.98950934\n",
            "Iteration 941, loss = 1488556795.79859996\n",
            "Iteration 942, loss = 1488500325.77878928\n",
            "Iteration 943, loss = 1488444854.08630967\n",
            "Iteration 944, loss = 1488388773.63905549\n",
            "Iteration 945, loss = 1488332434.84331083\n",
            "Iteration 946, loss = 1488276798.28234792\n",
            "Iteration 947, loss = 1488220744.43378711\n",
            "Iteration 948, loss = 1488164932.52490926\n",
            "Iteration 949, loss = 1488108842.79893064\n",
            "Iteration 950, loss = 1488052590.86764669\n",
            "Iteration 951, loss = 1487996508.23891449\n",
            "Iteration 952, loss = 1487940622.55158138\n",
            "Iteration 953, loss = 1487884318.77318406\n",
            "Iteration 954, loss = 1487828424.87028480\n",
            "Iteration 955, loss = 1487772079.53921151\n",
            "Iteration 956, loss = 1487716112.80783486\n",
            "Iteration 957, loss = 1487660064.32254601\n",
            "Iteration 958, loss = 1487604511.71523809\n",
            "Iteration 959, loss = 1487548514.72418737\n",
            "Iteration 960, loss = 1487492693.01377416\n",
            "Iteration 961, loss = 1487437404.20974326\n",
            "Iteration 962, loss = 1487381551.40791225\n",
            "Iteration 963, loss = 1487325760.38131499\n",
            "Iteration 964, loss = 1487270854.30822492\n",
            "Iteration 965, loss = 1487214659.82630587\n",
            "Iteration 966, loss = 1487159305.04542422\n",
            "Iteration 967, loss = 1487103916.05288363\n",
            "Iteration 968, loss = 1487048015.82561016\n",
            "Iteration 969, loss = 1486992788.07293963\n",
            "Iteration 970, loss = 1486937165.19337034\n",
            "Iteration 971, loss = 1486881698.37772155\n",
            "Iteration 972, loss = 1486826299.28698921\n",
            "Iteration 973, loss = 1486770974.95495963\n",
            "Iteration 974, loss = 1486715084.53180051\n",
            "Iteration 975, loss = 1486659944.10934687\n",
            "Iteration 976, loss = 1486604432.08179212\n",
            "Iteration 977, loss = 1486548995.79824281\n",
            "Iteration 978, loss = 1486493289.71447611\n",
            "Iteration 979, loss = 1486438152.37000918\n",
            "Iteration 980, loss = 1486382699.14721608\n",
            "Iteration 981, loss = 1486326890.66459703\n",
            "Iteration 982, loss = 1486271832.14853096\n",
            "Iteration 983, loss = 1486216065.08169031\n",
            "Iteration 984, loss = 1486160670.61023831\n",
            "Iteration 985, loss = 1486105011.95451713\n",
            "Iteration 986, loss = 1486049554.03066540\n",
            "Iteration 987, loss = 1485993959.18861747\n",
            "Iteration 988, loss = 1485938177.04040861\n",
            "Iteration 989, loss = 1485882831.35478973\n",
            "Iteration 990, loss = 1485827744.66260552\n",
            "Iteration 991, loss = 1485771879.51633596\n",
            "Iteration 992, loss = 1485716620.13598585\n",
            "Iteration 993, loss = 1485661304.12625360\n",
            "Iteration 994, loss = 1485605593.68903232\n",
            "Iteration 995, loss = 1485550176.51895523\n",
            "Iteration 996, loss = 1485494674.74089622\n",
            "Iteration 997, loss = 1485439149.75618148\n",
            "Iteration 998, loss = 1485383372.34749842\n",
            "Iteration 999, loss = 1485327884.86268950\n",
            "Iteration 1000, loss = 1485272388.76045799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:545: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 1381810906.63407159\n",
            "Iteration 2, loss = 158420881.98993313\n",
            "Iteration 3, loss = 340488183.20215708\n",
            "Iteration 4, loss = 224009969.70918116\n",
            "Iteration 5, loss = 179535415.84570125\n",
            "Iteration 6, loss = 212980521.67373016\n",
            "Iteration 7, loss = 218553307.53169701\n",
            "Iteration 8, loss = 237982381.84157589\n",
            "Iteration 9, loss = 254017672.78538030\n",
            "Iteration 10, loss = 265007691.30392390\n",
            "Iteration 11, loss = 275747822.89975119\n",
            "Iteration 12, loss = 283754670.97095942\n",
            "Iteration 13, loss = 291115054.55295187\n",
            "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 1538812153.03450418\n",
            "Iteration 2, loss = 1538744582.66195893\n",
            "Iteration 3, loss = 1538678927.69131899\n",
            "Iteration 4, loss = 1538618188.37514615\n",
            "Iteration 5, loss = 1538567599.36787891\n",
            "Iteration 6, loss = 1538525334.78795338\n",
            "Iteration 7, loss = 1538486435.43180585\n",
            "Iteration 8, loss = 1538448907.82629967\n",
            "Iteration 9, loss = 1538411209.92970347\n",
            "Iteration 10, loss = 1538373937.01113367\n",
            "Iteration 11, loss = 1538337048.27839518\n",
            "Iteration 12, loss = 1538300718.40501118\n",
            "Iteration 13, loss = 1538264566.87876940\n",
            "Iteration 14, loss = 1538228721.16431642\n",
            "Iteration 15, loss = 1538192745.02637863\n",
            "Iteration 16, loss = 1538156861.71623206\n",
            "Iteration 17, loss = 1538121126.72915292\n",
            "Iteration 18, loss = 1538085163.24679613\n",
            "Iteration 19, loss = 1538049447.07123351\n",
            "Iteration 20, loss = 1538013533.76631117\n",
            "Iteration 21, loss = 1537976612.12466049\n",
            "Iteration 22, loss = 1537938597.07184124\n",
            "Iteration 23, loss = 1537898381.34716487\n",
            "Iteration 24, loss = 1537858380.94689512\n",
            "Iteration 25, loss = 1537818636.65550685\n",
            "Iteration 26, loss = 1537778668.30487251\n",
            "Iteration 27, loss = 1537738181.71729875\n",
            "Iteration 28, loss = 1537697151.56323290\n",
            "Iteration 29, loss = 1537657154.46135545\n",
            "Iteration 30, loss = 1537616548.53087687\n",
            "Iteration 31, loss = 1537576384.23955870\n",
            "Iteration 32, loss = 1537534241.10578942\n",
            "Iteration 33, loss = 1537491616.03543663\n",
            "Iteration 34, loss = 1537449285.38114476\n",
            "Iteration 35, loss = 1537407579.98918414\n",
            "Iteration 36, loss = 1537365772.04148984\n",
            "Iteration 37, loss = 1537322980.34701133\n",
            "Iteration 38, loss = 1537279035.30832911\n",
            "Iteration 39, loss = 1537234473.99756312\n",
            "Iteration 40, loss = 1537190746.78974342\n",
            "Iteration 41, loss = 1537147026.69523215\n",
            "Iteration 42, loss = 1537102373.34160280\n",
            "Iteration 43, loss = 1537055200.30289626\n",
            "Iteration 44, loss = 1537007308.22225809\n",
            "Iteration 45, loss = 1536959265.50022364\n",
            "Iteration 46, loss = 1536911509.88853383\n",
            "Iteration 47, loss = 1536865136.95011234\n",
            "Iteration 48, loss = 1536818005.53145814\n",
            "Iteration 49, loss = 1536771434.27337432\n",
            "Iteration 50, loss = 1536724670.39269257\n",
            "Iteration 51, loss = 1536678338.73102307\n",
            "Iteration 52, loss = 1536631646.14318419\n",
            "Iteration 53, loss = 1536585075.15528560\n",
            "Iteration 54, loss = 1536538905.75201702\n",
            "Iteration 55, loss = 1536492597.39619589\n",
            "Iteration 56, loss = 1536446656.71348786\n",
            "Iteration 57, loss = 1536400885.43506789\n",
            "Iteration 58, loss = 1536354980.44438124\n",
            "Iteration 59, loss = 1536309752.58655667\n",
            "Iteration 60, loss = 1536264201.77284288\n",
            "Iteration 61, loss = 1536219109.65845370\n",
            "Iteration 62, loss = 1536174179.42852831\n",
            "Iteration 63, loss = 1536129159.31276202\n",
            "Iteration 64, loss = 1536084439.53236771\n",
            "Iteration 65, loss = 1536039897.48900533\n",
            "Iteration 66, loss = 1535995325.87101746\n",
            "Iteration 67, loss = 1535950733.47512579\n",
            "Iteration 68, loss = 1535906546.71337104\n",
            "Iteration 69, loss = 1535862490.70333123\n",
            "Iteration 70, loss = 1535818261.00610280\n",
            "Iteration 71, loss = 1535774570.17155838\n",
            "Iteration 72, loss = 1535730798.56007648\n",
            "Iteration 73, loss = 1535686835.05838609\n",
            "Iteration 74, loss = 1535643148.64160800\n",
            "Iteration 75, loss = 1535599583.36895323\n",
            "Iteration 76, loss = 1535556125.64417601\n",
            "Iteration 77, loss = 1535512318.82994843\n",
            "Iteration 78, loss = 1535468989.57917976\n",
            "Iteration 79, loss = 1535425373.94441581\n",
            "Iteration 80, loss = 1535382206.22194386\n",
            "Iteration 81, loss = 1535339059.32009959\n",
            "Iteration 82, loss = 1535295763.41929078\n",
            "Iteration 83, loss = 1535252774.21152735\n",
            "Iteration 84, loss = 1535209817.43369293\n",
            "Iteration 85, loss = 1535166520.99860597\n",
            "Iteration 86, loss = 1535123873.09518909\n",
            "Iteration 87, loss = 1535080663.28583360\n",
            "Iteration 88, loss = 1535038008.01649809\n",
            "Iteration 89, loss = 1534994953.28444004\n",
            "Iteration 90, loss = 1534952010.78098249\n",
            "Iteration 91, loss = 1534908435.33378696\n",
            "Iteration 92, loss = 1534863596.47774816\n",
            "Iteration 93, loss = 1534817200.51090670\n",
            "Iteration 94, loss = 1534771364.89849806\n",
            "Iteration 95, loss = 1534726263.17218351\n",
            "Iteration 96, loss = 1534680476.68800139\n",
            "Iteration 97, loss = 1534635141.15036154\n",
            "Iteration 98, loss = 1534589233.33737087\n",
            "Iteration 99, loss = 1534543295.79762459\n",
            "Iteration 100, loss = 1534495463.50863695\n",
            "Iteration 101, loss = 1534446052.17332816\n",
            "Iteration 102, loss = 1534397562.35818052\n",
            "Iteration 103, loss = 1534349357.79828382\n",
            "Iteration 104, loss = 1534300945.32617998\n",
            "Iteration 105, loss = 1534252538.75645375\n",
            "Iteration 106, loss = 1534204222.96981215\n",
            "Iteration 107, loss = 1534155921.86065841\n",
            "Iteration 108, loss = 1534107838.50200319\n",
            "Iteration 109, loss = 1534059637.40644193\n",
            "Iteration 110, loss = 1534011787.28473186\n",
            "Iteration 111, loss = 1533964185.24044061\n",
            "Iteration 112, loss = 1533916323.97318649\n",
            "Iteration 113, loss = 1533868835.04639983\n",
            "Iteration 114, loss = 1533821126.14985299\n",
            "Iteration 115, loss = 1533773822.41248322\n",
            "Iteration 116, loss = 1533726485.16499519\n",
            "Iteration 117, loss = 1533679435.02601790\n",
            "Iteration 118, loss = 1533632385.79727578\n",
            "Iteration 119, loss = 1533585449.09339356\n",
            "Iteration 120, loss = 1533538716.81181788\n",
            "Iteration 121, loss = 1533492030.82434392\n",
            "Iteration 122, loss = 1533445321.55056739\n",
            "Iteration 123, loss = 1533398967.97459245\n",
            "Iteration 124, loss = 1533352292.61580920\n",
            "Iteration 125, loss = 1533305694.12441826\n",
            "Iteration 126, loss = 1533259294.06916904\n",
            "Iteration 127, loss = 1533212899.13053250\n",
            "Iteration 128, loss = 1533166413.93212509\n",
            "Iteration 129, loss = 1533119960.50273395\n",
            "Iteration 130, loss = 1533073897.88390923\n",
            "Iteration 131, loss = 1533027305.61350417\n",
            "Iteration 132, loss = 1532981437.73538399\n",
            "Iteration 133, loss = 1532935292.00432110\n",
            "Iteration 134, loss = 1532889317.82192707\n",
            "Iteration 135, loss = 1532843459.50275016\n",
            "Iteration 136, loss = 1532797951.41316271\n",
            "Iteration 137, loss = 1532752206.30836248\n",
            "Iteration 138, loss = 1532706578.71290779\n",
            "Iteration 139, loss = 1532660912.41694689\n",
            "Iteration 140, loss = 1532615786.26386786\n",
            "Iteration 141, loss = 1532570190.16043210\n",
            "Iteration 142, loss = 1532524736.47533154\n",
            "Iteration 143, loss = 1532479415.50556278\n",
            "Iteration 144, loss = 1532433868.71363330\n",
            "Iteration 145, loss = 1532388625.26604748\n",
            "Iteration 146, loss = 1532343435.74782300\n",
            "Iteration 147, loss = 1532298231.73455954\n",
            "Iteration 148, loss = 1532253020.00730777\n",
            "Iteration 149, loss = 1532208071.28848720\n",
            "Iteration 150, loss = 1532162822.90691090\n",
            "Iteration 151, loss = 1532117654.04423404\n",
            "Iteration 152, loss = 1532072850.89632392\n",
            "Iteration 153, loss = 1532027622.09239960\n",
            "Iteration 154, loss = 1531982497.73282552\n",
            "Iteration 155, loss = 1531937414.85709357\n",
            "Iteration 156, loss = 1531892139.50165820\n",
            "Iteration 157, loss = 1531847181.79269099\n",
            "Iteration 158, loss = 1531801923.21221852\n",
            "Iteration 159, loss = 1531757265.36155653\n",
            "Iteration 160, loss = 1531711969.23667240\n",
            "Iteration 161, loss = 1531667252.04018021\n",
            "Iteration 162, loss = 1531622476.05088449\n",
            "Iteration 163, loss = 1531577790.23868370\n",
            "Iteration 164, loss = 1531532990.92973924\n",
            "Iteration 165, loss = 1531488295.47680664\n",
            "Iteration 166, loss = 1531443462.00088930\n",
            "Iteration 167, loss = 1531398700.66379476\n",
            "Iteration 168, loss = 1531353964.59222460\n",
            "Iteration 169, loss = 1531309104.73986912\n",
            "Iteration 170, loss = 1531264315.71689606\n",
            "Iteration 171, loss = 1531219294.88906455\n",
            "Iteration 172, loss = 1531174883.57350349\n",
            "Iteration 173, loss = 1531130023.49780917\n",
            "Iteration 174, loss = 1531085467.83457184\n",
            "Iteration 175, loss = 1531040803.26182866\n",
            "Iteration 176, loss = 1530996047.87972260\n",
            "Iteration 177, loss = 1530951801.59176278\n",
            "Iteration 178, loss = 1530907181.09678459\n",
            "Iteration 179, loss = 1530862386.68110394\n",
            "Iteration 180, loss = 1530818171.43265462\n",
            "Iteration 181, loss = 1530773507.11099005\n",
            "Iteration 182, loss = 1530728576.03288794\n",
            "Iteration 183, loss = 1530684333.08356023\n",
            "Iteration 184, loss = 1530639417.75242257\n",
            "Iteration 185, loss = 1530594881.24873352\n",
            "Iteration 186, loss = 1530550333.59073567\n",
            "Iteration 187, loss = 1530505489.97406411\n",
            "Iteration 188, loss = 1530460853.36695409\n",
            "Iteration 189, loss = 1530415801.73148775\n",
            "Iteration 190, loss = 1530368323.71554232\n",
            "Iteration 191, loss = 1530319208.03249121\n",
            "Iteration 192, loss = 1530270915.89833069\n",
            "Iteration 193, loss = 1530222792.62824678\n",
            "Iteration 194, loss = 1530173968.46051049\n",
            "Iteration 195, loss = 1530125822.22415376\n",
            "Iteration 196, loss = 1530077248.74473405\n",
            "Iteration 197, loss = 1530028578.84506416\n",
            "Iteration 198, loss = 1529980122.32144952\n",
            "Iteration 199, loss = 1529932020.30778265\n",
            "Iteration 200, loss = 1529883750.95292425\n",
            "Iteration 201, loss = 1529835701.00103641\n",
            "Iteration 202, loss = 1529787862.92209959\n",
            "Iteration 203, loss = 1529740142.87940097\n",
            "Iteration 204, loss = 1529692414.47235847\n",
            "Iteration 205, loss = 1529644786.96781778\n",
            "Iteration 206, loss = 1529596984.07050848\n",
            "Iteration 207, loss = 1529549759.67988253\n",
            "Iteration 208, loss = 1529502322.47026920\n",
            "Iteration 209, loss = 1529454832.79421425\n",
            "Iteration 210, loss = 1529407641.26515031\n",
            "Iteration 211, loss = 1529360254.63576269\n",
            "Iteration 212, loss = 1529313729.19403958\n",
            "Iteration 213, loss = 1529266440.15209317\n",
            "Iteration 214, loss = 1529219675.13931966\n",
            "Iteration 215, loss = 1529172857.27132106\n",
            "Iteration 216, loss = 1529126281.51315904\n",
            "Iteration 217, loss = 1529079499.77292848\n",
            "Iteration 218, loss = 1529032829.71457791\n",
            "Iteration 219, loss = 1528985844.34184122\n",
            "Iteration 220, loss = 1528939404.41838551\n",
            "Iteration 221, loss = 1528892843.72464466\n",
            "Iteration 222, loss = 1528846070.62686324\n",
            "Iteration 223, loss = 1528799657.56299472\n",
            "Iteration 224, loss = 1528753074.21873045\n",
            "Iteration 225, loss = 1528706803.52423096\n",
            "Iteration 226, loss = 1528660607.13140488\n",
            "Iteration 227, loss = 1528614370.40999866\n",
            "Iteration 228, loss = 1528568188.79824710\n",
            "Iteration 229, loss = 1528522004.84440660\n",
            "Iteration 230, loss = 1528475887.65626884\n",
            "Iteration 231, loss = 1528429825.02289772\n",
            "Iteration 232, loss = 1528383800.08989525\n",
            "Iteration 233, loss = 1528337531.69338155\n",
            "Iteration 234, loss = 1528291384.43903136\n",
            "Iteration 235, loss = 1528245264.93088961\n",
            "Iteration 236, loss = 1528199230.23033237\n",
            "Iteration 237, loss = 1528152864.60566664\n",
            "Iteration 238, loss = 1528106886.98610282\n",
            "Iteration 239, loss = 1528060647.07800007\n",
            "Iteration 240, loss = 1528014538.49345207\n",
            "Iteration 241, loss = 1527968461.31323743\n",
            "Iteration 242, loss = 1527922434.30419898\n",
            "Iteration 243, loss = 1527876599.87214661\n",
            "Iteration 244, loss = 1527830638.51556206\n",
            "Iteration 245, loss = 1527784583.97368979\n",
            "Iteration 246, loss = 1527738902.68338466\n",
            "Iteration 247, loss = 1527692843.20762753\n",
            "Iteration 248, loss = 1527646982.17694521\n",
            "Iteration 249, loss = 1527601261.41277313\n",
            "Iteration 250, loss = 1527555570.79141402\n",
            "Iteration 251, loss = 1527509752.23706555\n",
            "Iteration 252, loss = 1527464134.72450089\n",
            "Iteration 253, loss = 1527418285.70619726\n",
            "Iteration 254, loss = 1527372967.60698223\n",
            "Iteration 255, loss = 1527327466.57698870\n",
            "Iteration 256, loss = 1527281659.95123959\n",
            "Iteration 257, loss = 1527236071.58977294\n",
            "Iteration 258, loss = 1527190746.92405653\n",
            "Iteration 259, loss = 1527145081.64722419\n",
            "Iteration 260, loss = 1527099231.86589241\n",
            "Iteration 261, loss = 1527053955.31416774\n",
            "Iteration 262, loss = 1527008229.25341153\n",
            "Iteration 263, loss = 1526962838.60081458\n",
            "Iteration 264, loss = 1526917280.77773666\n",
            "Iteration 265, loss = 1526871658.55270720\n",
            "Iteration 266, loss = 1526826292.54601121\n",
            "Iteration 267, loss = 1526780632.94801903\n",
            "Iteration 268, loss = 1526735197.22171688\n",
            "Iteration 269, loss = 1526689417.61090970\n",
            "Iteration 270, loss = 1526644188.47170448\n",
            "Iteration 271, loss = 1526598388.43088341\n",
            "Iteration 272, loss = 1526553121.31085324\n",
            "Iteration 273, loss = 1526507725.18819141\n",
            "Iteration 274, loss = 1526462372.59250093\n",
            "Iteration 275, loss = 1526417256.71907759\n",
            "Iteration 276, loss = 1526372151.74334264\n",
            "Iteration 277, loss = 1526327131.33893251\n",
            "Iteration 278, loss = 1526281984.00754309\n",
            "Iteration 279, loss = 1526237018.44609356\n",
            "Iteration 280, loss = 1526192054.12541699\n",
            "Iteration 281, loss = 1526147051.08243728\n",
            "Iteration 282, loss = 1526101792.55037522\n",
            "Iteration 283, loss = 1526055880.20378065\n",
            "Iteration 284, loss = 1526007286.81422353\n",
            "Iteration 285, loss = 1525955497.20306110\n",
            "Iteration 286, loss = 1525901825.52188230\n",
            "Iteration 287, loss = 1525847327.56150079\n",
            "Iteration 288, loss = 1525793467.85831809\n",
            "Iteration 289, loss = 1525739360.63975453\n",
            "Iteration 290, loss = 1525684550.17644405\n",
            "Iteration 291, loss = 1525630071.09340072\n",
            "Iteration 292, loss = 1525575733.11789656\n",
            "Iteration 293, loss = 1525521075.25979877\n",
            "Iteration 294, loss = 1525466464.22039199\n",
            "Iteration 295, loss = 1525412983.38596034\n",
            "Iteration 296, loss = 1525358703.39555478\n",
            "Iteration 297, loss = 1525304964.57483554\n",
            "Iteration 298, loss = 1525251705.07975841\n",
            "Iteration 299, loss = 1525198204.63898063\n",
            "Iteration 300, loss = 1525145315.44320583\n",
            "Iteration 301, loss = 1525091291.77278519\n",
            "Iteration 302, loss = 1525034040.29602575\n",
            "Iteration 303, loss = 1524977436.22582960\n",
            "Iteration 304, loss = 1524921218.42841005\n",
            "Iteration 305, loss = 1524864479.85630274\n",
            "Iteration 306, loss = 1524808493.16884875\n",
            "Iteration 307, loss = 1524751544.76920891\n",
            "Iteration 308, loss = 1524695484.79476619\n",
            "Iteration 309, loss = 1524638898.75106907\n",
            "Iteration 310, loss = 1524583437.28464890\n",
            "Iteration 311, loss = 1524527003.07253599\n",
            "Iteration 312, loss = 1524471376.33425498\n",
            "Iteration 313, loss = 1524416141.63019872\n",
            "Iteration 314, loss = 1524361039.98640299\n",
            "Iteration 315, loss = 1524305774.32237220\n",
            "Iteration 316, loss = 1524251032.43215227\n",
            "Iteration 317, loss = 1524196540.63090539\n",
            "Iteration 318, loss = 1524142287.65698743\n",
            "Iteration 319, loss = 1524088049.57727742\n",
            "Iteration 320, loss = 1524033695.69928527\n",
            "Iteration 321, loss = 1523980236.39014363\n",
            "Iteration 322, loss = 1523925923.27712584\n",
            "Iteration 323, loss = 1523872239.31710219\n",
            "Iteration 324, loss = 1523818388.71562195\n",
            "Iteration 325, loss = 1523764502.39626122\n",
            "Iteration 326, loss = 1523710927.41181421\n",
            "Iteration 327, loss = 1523657294.43393993\n",
            "Iteration 328, loss = 1523604124.24810696\n",
            "Iteration 329, loss = 1523550467.36980319\n",
            "Iteration 330, loss = 1523497772.69414425\n",
            "Iteration 331, loss = 1523444826.91334009\n",
            "Iteration 332, loss = 1523391825.67621303\n",
            "Iteration 333, loss = 1523339373.72058845\n",
            "Iteration 334, loss = 1523286866.86127806\n",
            "Iteration 335, loss = 1523234349.76143003\n",
            "Iteration 336, loss = 1523181912.73090053\n",
            "Iteration 337, loss = 1523129683.44690323\n",
            "Iteration 338, loss = 1523077679.91550207\n",
            "Iteration 339, loss = 1523025604.42865705\n",
            "Iteration 340, loss = 1522973318.10362220\n",
            "Iteration 341, loss = 1522921702.87234211\n",
            "Iteration 342, loss = 1522869516.98846483\n",
            "Iteration 343, loss = 1522818056.25523114\n",
            "Iteration 344, loss = 1522766265.42842937\n",
            "Iteration 345, loss = 1522714538.31501722\n",
            "Iteration 346, loss = 1522663003.10701847\n",
            "Iteration 347, loss = 1522611562.17780209\n",
            "Iteration 348, loss = 1522560229.94921422\n",
            "Iteration 349, loss = 1522508756.67018890\n",
            "Iteration 350, loss = 1522457580.27304053\n",
            "Iteration 351, loss = 1522406182.69304180\n",
            "Iteration 352, loss = 1522354870.99445176\n",
            "Iteration 353, loss = 1522303626.53662896\n",
            "Iteration 354, loss = 1522252484.81705046\n",
            "Iteration 355, loss = 1522201011.71079731\n",
            "Iteration 356, loss = 1522150191.15641880\n",
            "Iteration 357, loss = 1522099206.39678741\n",
            "Iteration 358, loss = 1522048171.71091986\n",
            "Iteration 359, loss = 1521997322.73899698\n",
            "Iteration 360, loss = 1521946252.69386172\n",
            "Iteration 361, loss = 1521896072.86809349\n",
            "Iteration 362, loss = 1521844725.39976287\n",
            "Iteration 363, loss = 1521794314.87877178\n",
            "Iteration 364, loss = 1521743248.83767247\n",
            "Iteration 365, loss = 1521692660.40673542\n",
            "Iteration 366, loss = 1521641968.05314708\n",
            "Iteration 367, loss = 1521591048.60020995\n",
            "Iteration 368, loss = 1521540570.10071850\n",
            "Iteration 369, loss = 1521489577.82482505\n",
            "Iteration 370, loss = 1521439140.25449753\n",
            "Iteration 371, loss = 1521388533.42204189\n",
            "Iteration 372, loss = 1521337666.74408865\n",
            "Iteration 373, loss = 1521287323.68762541\n",
            "Iteration 374, loss = 1521236521.30116653\n",
            "Iteration 375, loss = 1521186017.57590628\n",
            "Iteration 376, loss = 1521135497.94058394\n",
            "Iteration 377, loss = 1521084760.05074644\n",
            "Iteration 378, loss = 1521034066.01315331\n",
            "Iteration 379, loss = 1520983709.10396647\n",
            "Iteration 380, loss = 1520933252.67644453\n",
            "Iteration 381, loss = 1520882374.14362407\n",
            "Iteration 382, loss = 1520831960.22591376\n",
            "Iteration 383, loss = 1520781503.25574303\n",
            "Iteration 384, loss = 1520730902.66923118\n",
            "Iteration 385, loss = 1520680080.94075155\n",
            "Iteration 386, loss = 1520629634.29529786\n",
            "Iteration 387, loss = 1520579044.02818203\n",
            "Iteration 388, loss = 1520528418.76833701\n",
            "Iteration 389, loss = 1520477642.88828087\n",
            "Iteration 390, loss = 1520427269.59407926\n",
            "Iteration 391, loss = 1520376796.26197958\n",
            "Iteration 392, loss = 1520326335.86379433\n",
            "Iteration 393, loss = 1520276076.40021014\n",
            "Iteration 394, loss = 1520225638.69651699\n",
            "Iteration 395, loss = 1520175303.74479914\n",
            "Iteration 396, loss = 1520125159.14986491\n",
            "Iteration 397, loss = 1520075017.47735405\n",
            "Iteration 398, loss = 1520025119.83316684\n",
            "Iteration 399, loss = 1519974614.22498488\n",
            "Iteration 400, loss = 1519925065.10591102\n",
            "Iteration 401, loss = 1519874959.80827212\n",
            "Iteration 402, loss = 1519825193.34750223\n",
            "Iteration 403, loss = 1519775360.15318799\n",
            "Iteration 404, loss = 1519725979.85096908\n",
            "Iteration 405, loss = 1519676234.95454860\n",
            "Iteration 406, loss = 1519626384.20835757\n",
            "Iteration 407, loss = 1519577305.81247497\n",
            "Iteration 408, loss = 1519527556.90799546\n",
            "Iteration 409, loss = 1519477988.50648451\n",
            "Iteration 410, loss = 1519429064.76879239\n",
            "Iteration 411, loss = 1519379493.17344189\n",
            "Iteration 412, loss = 1519330442.40670562\n",
            "Iteration 413, loss = 1519281017.26907206\n",
            "Iteration 414, loss = 1519232127.59683418\n",
            "Iteration 415, loss = 1519182985.33573675\n",
            "Iteration 416, loss = 1519133676.00113630\n",
            "Iteration 417, loss = 1519084873.79668355\n",
            "Iteration 418, loss = 1519035526.24698019\n",
            "Iteration 419, loss = 1518986772.83871770\n",
            "Iteration 420, loss = 1518936980.28845143\n",
            "Iteration 421, loss = 1518888193.47282600\n",
            "Iteration 422, loss = 1518838892.82291055\n",
            "Iteration 423, loss = 1518789842.07480574\n",
            "Iteration 424, loss = 1518740588.73533773\n",
            "Iteration 425, loss = 1518691627.63853645\n",
            "Iteration 426, loss = 1518642361.92881417\n",
            "Iteration 427, loss = 1518593252.20089316\n",
            "Iteration 428, loss = 1518544494.22451687\n",
            "Iteration 429, loss = 1518495382.86219311\n",
            "Iteration 430, loss = 1518446369.52010512\n",
            "Iteration 431, loss = 1518397422.41489530\n",
            "Iteration 432, loss = 1518348429.60995078\n",
            "Iteration 433, loss = 1518299411.35143757\n",
            "Iteration 434, loss = 1518250304.29393864\n",
            "Iteration 435, loss = 1518201261.98399162\n",
            "Iteration 436, loss = 1518151918.35898709\n",
            "Iteration 437, loss = 1518102643.62197495\n",
            "Iteration 438, loss = 1518053562.28249359\n",
            "Iteration 439, loss = 1518004314.79496121\n",
            "Iteration 440, loss = 1517955015.36202097\n",
            "Iteration 441, loss = 1517905964.65902877\n",
            "Iteration 442, loss = 1517856978.42810893\n",
            "Iteration 443, loss = 1517807899.92436600\n",
            "Iteration 444, loss = 1517758699.22075748\n",
            "Iteration 445, loss = 1517710033.75448060\n",
            "Iteration 446, loss = 1517660754.51663089\n",
            "Iteration 447, loss = 1517612026.47185969\n",
            "Iteration 448, loss = 1517562752.99090791\n",
            "Iteration 449, loss = 1517513606.87196302\n",
            "Iteration 450, loss = 1517464769.12597060\n",
            "Iteration 451, loss = 1517415763.08038974\n",
            "Iteration 452, loss = 1517366365.72347164\n",
            "Iteration 453, loss = 1517317405.07916856\n",
            "Iteration 454, loss = 1517268190.15550613\n",
            "Iteration 455, loss = 1517219029.62986755\n",
            "Iteration 456, loss = 1517169952.42550635\n",
            "Iteration 457, loss = 1517120745.48231244\n",
            "Iteration 458, loss = 1517071705.16089225\n",
            "Iteration 459, loss = 1517022696.26508975\n",
            "Iteration 460, loss = 1516973493.43666291\n",
            "Iteration 461, loss = 1516924559.65997243\n",
            "Iteration 462, loss = 1516875805.02268577\n",
            "Iteration 463, loss = 1516826785.41823387\n",
            "Iteration 464, loss = 1516777889.36891890\n",
            "Iteration 465, loss = 1516728984.77912140\n",
            "Iteration 466, loss = 1516679872.50093961\n",
            "Iteration 467, loss = 1516631390.27451062\n",
            "Iteration 468, loss = 1516582478.94800758\n",
            "Iteration 469, loss = 1516533497.05240011\n",
            "Iteration 470, loss = 1516484941.36007714\n",
            "Iteration 471, loss = 1516436216.89873981\n",
            "Iteration 472, loss = 1516387626.97873712\n",
            "Iteration 473, loss = 1516338834.30775070\n",
            "Iteration 474, loss = 1516290392.01602197\n",
            "Iteration 475, loss = 1516241508.65297914\n",
            "Iteration 476, loss = 1516192641.21455526\n",
            "Iteration 477, loss = 1516144320.04227138\n",
            "Iteration 478, loss = 1516095559.08635259\n",
            "Iteration 479, loss = 1516046621.72414684\n",
            "Iteration 480, loss = 1515998107.21625948\n",
            "Iteration 481, loss = 1515949601.60401440\n",
            "Iteration 482, loss = 1515901138.65244555\n",
            "Iteration 483, loss = 1515852430.47041845\n",
            "Iteration 484, loss = 1515804098.23580599\n",
            "Iteration 485, loss = 1515755364.97461033\n",
            "Iteration 486, loss = 1515707061.08553123\n",
            "Iteration 487, loss = 1515658639.66835570\n",
            "Iteration 488, loss = 1515610105.59327769\n",
            "Iteration 489, loss = 1515561600.77753901\n",
            "Iteration 490, loss = 1515513146.05817938\n",
            "Iteration 491, loss = 1515464735.81049490\n",
            "Iteration 492, loss = 1515416255.38611674\n",
            "Iteration 493, loss = 1515367948.65324044\n",
            "Iteration 494, loss = 1515319218.75752664\n",
            "Iteration 495, loss = 1515270783.32177639\n",
            "Iteration 496, loss = 1515222144.86805463\n",
            "Iteration 497, loss = 1515173821.49177742\n",
            "Iteration 498, loss = 1515124842.36303282\n",
            "Iteration 499, loss = 1515076350.89474678\n",
            "Iteration 500, loss = 1515028020.23670912\n",
            "Iteration 501, loss = 1514979093.59145951\n",
            "Iteration 502, loss = 1514930772.78616714\n",
            "Iteration 503, loss = 1514882629.31959343\n",
            "Iteration 504, loss = 1514834106.56211233\n",
            "Iteration 505, loss = 1514785343.56363416\n",
            "Iteration 506, loss = 1514735451.52978230\n",
            "Iteration 507, loss = 1514681292.04920459\n",
            "Iteration 508, loss = 1514628039.58863759\n",
            "Iteration 509, loss = 1514574412.66106772\n",
            "Iteration 510, loss = 1514520514.49635768\n",
            "Iteration 511, loss = 1514466718.56911802\n",
            "Iteration 512, loss = 1514412134.73047447\n",
            "Iteration 513, loss = 1514358434.73310280\n",
            "Iteration 514, loss = 1514304116.35178566\n",
            "Iteration 515, loss = 1514250260.34016156\n",
            "Iteration 516, loss = 1514196383.11292720\n",
            "Iteration 517, loss = 1514142812.81400323\n",
            "Iteration 518, loss = 1514089265.49460316\n",
            "Iteration 519, loss = 1514035791.35427427\n",
            "Iteration 520, loss = 1513982928.45259356\n",
            "Iteration 521, loss = 1513929782.80089450\n",
            "Iteration 522, loss = 1513876723.21150827\n",
            "Iteration 523, loss = 1513824104.89701128\n",
            "Iteration 524, loss = 1513771326.98993015\n",
            "Iteration 525, loss = 1513718885.20135260\n",
            "Iteration 526, loss = 1513666163.43809509\n",
            "Iteration 527, loss = 1513614187.31024456\n",
            "Iteration 528, loss = 1513561752.09784937\n",
            "Iteration 529, loss = 1513510057.45085049\n",
            "Iteration 530, loss = 1513457824.94539237\n",
            "Iteration 531, loss = 1513406223.05557013\n",
            "Iteration 532, loss = 1513354241.40866375\n",
            "Iteration 533, loss = 1513302962.56952071\n",
            "Iteration 534, loss = 1513251095.97149420\n",
            "Iteration 535, loss = 1513199825.62619901\n",
            "Iteration 536, loss = 1513148027.88891649\n",
            "Iteration 537, loss = 1513096921.58810997\n",
            "Iteration 538, loss = 1513045481.54342532\n",
            "Iteration 539, loss = 1512993831.71190643\n",
            "Iteration 540, loss = 1512942632.45267820\n",
            "Iteration 541, loss = 1512891049.69453931\n",
            "Iteration 542, loss = 1512839459.40119886\n",
            "Iteration 543, loss = 1512788081.15854168\n",
            "Iteration 544, loss = 1512736402.81484127\n",
            "Iteration 545, loss = 1512684931.44593596\n",
            "Iteration 546, loss = 1512633623.59591317\n",
            "Iteration 547, loss = 1512581941.95963025\n",
            "Iteration 548, loss = 1512530506.61122155\n",
            "Iteration 549, loss = 1512479282.42388725\n",
            "Iteration 550, loss = 1512428040.67551398\n",
            "Iteration 551, loss = 1512376650.33156967\n",
            "Iteration 552, loss = 1512325383.29792070\n",
            "Iteration 553, loss = 1512274469.31422496\n",
            "Iteration 554, loss = 1512223231.62915087\n",
            "Iteration 555, loss = 1512172298.53523993\n",
            "Iteration 556, loss = 1512121384.82297039\n",
            "Iteration 557, loss = 1512070391.08662367\n",
            "Iteration 558, loss = 1512019658.43527365\n",
            "Iteration 559, loss = 1511968947.95571280\n",
            "Iteration 560, loss = 1511918379.51305556\n",
            "Iteration 561, loss = 1511867610.53389311\n",
            "Iteration 562, loss = 1511816993.60699129\n",
            "Iteration 563, loss = 1511766587.59302711\n",
            "Iteration 564, loss = 1511716276.42842603\n",
            "Iteration 565, loss = 1511665467.71141005\n",
            "Iteration 566, loss = 1511614975.31412840\n",
            "Iteration 567, loss = 1511564775.56596661\n",
            "Iteration 568, loss = 1511514377.41724801\n",
            "Iteration 569, loss = 1511464102.61727810\n",
            "Iteration 570, loss = 1511413642.43287539\n",
            "Iteration 571, loss = 1511363549.33468032\n",
            "Iteration 572, loss = 1511313534.73621416\n",
            "Iteration 573, loss = 1511263463.11082292\n",
            "Iteration 574, loss = 1511213257.33007741\n",
            "Iteration 575, loss = 1511163163.50035071\n",
            "Iteration 576, loss = 1511112858.52544427\n",
            "Iteration 577, loss = 1511062586.03258157\n",
            "Iteration 578, loss = 1511012273.34101343\n",
            "Iteration 579, loss = 1510961956.03254557\n",
            "Iteration 580, loss = 1510911632.12553644\n",
            "Iteration 581, loss = 1510860937.47139502\n",
            "Iteration 582, loss = 1510810840.73226571\n",
            "Iteration 583, loss = 1510760050.78530836\n",
            "Iteration 584, loss = 1510710230.19871759\n",
            "Iteration 585, loss = 1510659721.07725143\n",
            "Iteration 586, loss = 1510609583.69017339\n",
            "Iteration 587, loss = 1510559155.52855325\n",
            "Iteration 588, loss = 1510509405.99725509\n",
            "Iteration 589, loss = 1510459148.53354669\n",
            "Iteration 590, loss = 1510408879.05047131\n",
            "Iteration 591, loss = 1510359197.86907721\n",
            "Iteration 592, loss = 1510308616.29686546\n",
            "Iteration 593, loss = 1510258583.35261941\n",
            "Iteration 594, loss = 1510208532.27444100\n",
            "Iteration 595, loss = 1510158474.83107257\n",
            "Iteration 596, loss = 1510108348.63047814\n",
            "Iteration 597, loss = 1510058208.80351114\n",
            "Iteration 598, loss = 1510008374.52233791\n",
            "Iteration 599, loss = 1509958378.78036833\n",
            "Iteration 600, loss = 1509908562.57165718\n",
            "Iteration 601, loss = 1509858841.96149898\n",
            "Iteration 602, loss = 1509809014.38293743\n",
            "Iteration 603, loss = 1509759493.31825423\n",
            "Iteration 604, loss = 1509709719.60182023\n",
            "Iteration 605, loss = 1509660022.21248055\n",
            "Iteration 606, loss = 1509610438.60730386\n",
            "Iteration 607, loss = 1509560767.90933442\n",
            "Iteration 608, loss = 1509511010.35996199\n",
            "Iteration 609, loss = 1509461042.27852273\n",
            "Iteration 610, loss = 1509411340.73799086\n",
            "Iteration 611, loss = 1509361544.78150129\n",
            "Iteration 612, loss = 1509311613.85894012\n",
            "Iteration 613, loss = 1509261859.67754126\n",
            "Iteration 614, loss = 1509212023.13983965\n",
            "Iteration 615, loss = 1509162262.69642758\n",
            "Iteration 616, loss = 1509112479.46357942\n",
            "Iteration 617, loss = 1509062731.70583200\n",
            "Iteration 618, loss = 1509012893.87907934\n",
            "Iteration 619, loss = 1508963323.25171638\n",
            "Iteration 620, loss = 1508913487.41699576\n",
            "Iteration 621, loss = 1508863482.50860023\n",
            "Iteration 622, loss = 1508813740.00759339\n",
            "Iteration 623, loss = 1508763908.83739996\n",
            "Iteration 624, loss = 1508713691.23297286\n",
            "Iteration 625, loss = 1508664119.41403127\n",
            "Iteration 626, loss = 1508614048.60535693\n",
            "Iteration 627, loss = 1508564223.18253827\n",
            "Iteration 628, loss = 1508514306.82608247\n",
            "Iteration 629, loss = 1508464795.50349283\n",
            "Iteration 630, loss = 1508415255.12345457\n",
            "Iteration 631, loss = 1508365315.39328361\n",
            "Iteration 632, loss = 1508316046.19180512\n",
            "Iteration 633, loss = 1508266434.22819066\n",
            "Iteration 634, loss = 1508217057.96111894\n",
            "Iteration 635, loss = 1508167061.38519645\n",
            "Iteration 636, loss = 1508117503.44249606\n",
            "Iteration 637, loss = 1508067995.85673285\n",
            "Iteration 638, loss = 1508018360.03079772\n",
            "Iteration 639, loss = 1507968301.99277544\n",
            "Iteration 640, loss = 1507918868.40687919\n",
            "Iteration 641, loss = 1507869158.02561879\n",
            "Iteration 642, loss = 1507819456.58607125\n",
            "Iteration 643, loss = 1507769769.89971852\n",
            "Iteration 644, loss = 1507720525.94646239\n",
            "Iteration 645, loss = 1507670474.75276208\n",
            "Iteration 646, loss = 1507621172.53621149\n",
            "Iteration 647, loss = 1507571409.65252948\n",
            "Iteration 648, loss = 1507521906.84563184\n",
            "Iteration 649, loss = 1507472172.27700472\n",
            "Iteration 650, loss = 1507422834.44417715\n",
            "Iteration 651, loss = 1507373323.18851638\n",
            "Iteration 652, loss = 1507323841.67097425\n",
            "Iteration 653, loss = 1507274821.21729112\n",
            "Iteration 654, loss = 1507225409.38514709\n",
            "Iteration 655, loss = 1507176100.22453666\n",
            "Iteration 656, loss = 1507127412.14584422\n",
            "Iteration 657, loss = 1507078189.52520466\n",
            "Iteration 658, loss = 1507029353.31767058\n",
            "Iteration 659, loss = 1506980303.65296364\n",
            "Iteration 660, loss = 1506931255.42001748\n",
            "Iteration 661, loss = 1506882263.90654588\n",
            "Iteration 662, loss = 1506833608.97135735\n",
            "Iteration 663, loss = 1506784037.63515973\n",
            "Iteration 664, loss = 1506735520.18146968\n",
            "Iteration 665, loss = 1506686053.58572769\n",
            "Iteration 666, loss = 1506636716.57617712\n",
            "Iteration 667, loss = 1506587931.53239584\n",
            "Iteration 668, loss = 1506538739.70704579\n",
            "Iteration 669, loss = 1506489307.36489010\n",
            "Iteration 670, loss = 1506439731.82940984\n",
            "Iteration 671, loss = 1506391240.38117981\n",
            "Iteration 672, loss = 1506341444.66486382\n",
            "Iteration 673, loss = 1506292375.56112194\n",
            "Iteration 674, loss = 1506242838.19389009\n",
            "Iteration 675, loss = 1506193944.86036325\n",
            "Iteration 676, loss = 1506144406.14652276\n",
            "Iteration 677, loss = 1506095548.11509466\n",
            "Iteration 678, loss = 1506045904.05373859\n",
            "Iteration 679, loss = 1505996897.30077410\n",
            "Iteration 680, loss = 1505947529.79678369\n",
            "Iteration 681, loss = 1505898333.65460038\n",
            "Iteration 682, loss = 1505849288.96479511\n",
            "Iteration 683, loss = 1505800070.60574460\n",
            "Iteration 684, loss = 1505751244.19848943\n",
            "Iteration 685, loss = 1505702037.21736526\n",
            "Iteration 686, loss = 1505653184.11959434\n",
            "Iteration 687, loss = 1505604164.13714695\n",
            "Iteration 688, loss = 1505555110.41656709\n",
            "Iteration 689, loss = 1505506309.64780664\n",
            "Iteration 690, loss = 1505456968.94213176\n",
            "Iteration 691, loss = 1505408144.42323756\n",
            "Iteration 692, loss = 1505359104.68818688\n",
            "Iteration 693, loss = 1505309859.77473998\n",
            "Iteration 694, loss = 1505260998.12009239\n",
            "Iteration 695, loss = 1505211781.80762649\n",
            "Iteration 696, loss = 1505162971.65609264\n",
            "Iteration 697, loss = 1505114577.43807054\n",
            "Iteration 698, loss = 1505065326.79046249\n",
            "Iteration 699, loss = 1505016718.55287862\n",
            "Iteration 700, loss = 1504967934.94712901\n",
            "Iteration 701, loss = 1504919237.62595797\n",
            "Iteration 702, loss = 1504870876.14356923\n",
            "Iteration 703, loss = 1504821845.95007801\n",
            "Iteration 704, loss = 1504773052.03810549\n",
            "Iteration 705, loss = 1504724298.95926523\n",
            "Iteration 706, loss = 1504675411.82303476\n",
            "Iteration 707, loss = 1504626758.44955969\n",
            "Iteration 708, loss = 1504578168.33434892\n",
            "Iteration 709, loss = 1504529149.52247024\n",
            "Iteration 710, loss = 1504480590.04908609\n",
            "Iteration 711, loss = 1504431942.35530686\n",
            "Iteration 712, loss = 1504383280.40542126\n",
            "Iteration 713, loss = 1504334478.08020854\n",
            "Iteration 714, loss = 1504285981.40776205\n",
            "Iteration 715, loss = 1504237197.08763552\n",
            "Iteration 716, loss = 1504188449.43924832\n",
            "Iteration 717, loss = 1504139895.23353553\n",
            "Iteration 718, loss = 1504091029.63180733\n",
            "Iteration 719, loss = 1504042136.97850561\n",
            "Iteration 720, loss = 1503993445.37700725\n",
            "Iteration 721, loss = 1503944565.04544783\n",
            "Iteration 722, loss = 1503895932.37831044\n",
            "Iteration 723, loss = 1503847259.44619489\n",
            "Iteration 724, loss = 1503798691.71648288\n",
            "Iteration 725, loss = 1503750038.55637717\n",
            "Iteration 726, loss = 1503701502.54008436\n",
            "Iteration 727, loss = 1503653067.01994348\n",
            "Iteration 728, loss = 1503604255.91473961\n",
            "Iteration 729, loss = 1503555439.28656912\n",
            "Iteration 730, loss = 1503506974.75203586\n",
            "Iteration 731, loss = 1503457757.40715361\n",
            "Iteration 732, loss = 1503408926.58750844\n",
            "Iteration 733, loss = 1503360141.13360190\n",
            "Iteration 734, loss = 1503310969.77956009\n",
            "Iteration 735, loss = 1503262469.07249808\n",
            "Iteration 736, loss = 1503213257.51659703\n",
            "Iteration 737, loss = 1503164502.45078373\n",
            "Iteration 738, loss = 1503116016.84875894\n",
            "Iteration 739, loss = 1503067146.68752766\n",
            "Iteration 740, loss = 1503018531.40313411\n",
            "Iteration 741, loss = 1502969760.93937182\n",
            "Iteration 742, loss = 1502921115.22113132\n",
            "Iteration 743, loss = 1502871820.43627691\n",
            "Iteration 744, loss = 1502817336.39699554\n",
            "Iteration 745, loss = 1502762109.37268543\n",
            "Iteration 746, loss = 1502704680.42901278\n",
            "Iteration 747, loss = 1502642524.38388491\n",
            "Iteration 748, loss = 1502582515.09556317\n",
            "Iteration 749, loss = 1502522178.06526923\n",
            "Iteration 750, loss = 1502460955.67947555\n",
            "Iteration 751, loss = 1502399856.24428725\n",
            "Iteration 752, loss = 1502338176.63028097\n",
            "Iteration 753, loss = 1502277474.94667959\n",
            "Iteration 754, loss = 1502216253.43968678\n",
            "Iteration 755, loss = 1502155485.23940611\n",
            "Iteration 756, loss = 1502094780.08556986\n",
            "Iteration 757, loss = 1502034522.15186667\n",
            "Iteration 758, loss = 1501974683.31098652\n",
            "Iteration 759, loss = 1501914439.13259935\n",
            "Iteration 760, loss = 1501855441.11539221\n",
            "Iteration 761, loss = 1501796365.89917135\n",
            "Iteration 762, loss = 1501737500.78598905\n",
            "Iteration 763, loss = 1501678883.05408764\n",
            "Iteration 764, loss = 1501620550.30565286\n",
            "Iteration 765, loss = 1501562724.94673800\n",
            "Iteration 766, loss = 1501505276.09442329\n",
            "Iteration 767, loss = 1501447532.23483658\n",
            "Iteration 768, loss = 1501390389.81980634\n",
            "Iteration 769, loss = 1501333481.82666802\n",
            "Iteration 770, loss = 1501276799.17560196\n",
            "Iteration 771, loss = 1501219768.07552290\n",
            "Iteration 772, loss = 1501164033.67282772\n",
            "Iteration 773, loss = 1501107181.01289964\n",
            "Iteration 774, loss = 1501051409.76333523\n",
            "Iteration 775, loss = 1500995301.65219975\n",
            "Iteration 776, loss = 1500939342.76156902\n",
            "Iteration 777, loss = 1500883652.24047756\n",
            "Iteration 778, loss = 1500828031.32413292\n",
            "Iteration 779, loss = 1500772430.54169226\n",
            "Iteration 780, loss = 1500716517.07802153\n",
            "Iteration 781, loss = 1500661562.04236960\n",
            "Iteration 782, loss = 1500606130.10562873\n",
            "Iteration 783, loss = 1500550907.41194987\n",
            "Iteration 784, loss = 1500495591.84968710\n",
            "Iteration 785, loss = 1500440909.71225238\n",
            "Iteration 786, loss = 1500386111.07317972\n",
            "Iteration 787, loss = 1500330888.03374743\n",
            "Iteration 788, loss = 1500276402.87174296\n",
            "Iteration 789, loss = 1500221814.61359930\n",
            "Iteration 790, loss = 1500167183.90013766\n",
            "Iteration 791, loss = 1500112646.48035622\n",
            "Iteration 792, loss = 1500058412.54101086\n",
            "Iteration 793, loss = 1500003911.41028881\n",
            "Iteration 794, loss = 1499949814.53919864\n",
            "Iteration 795, loss = 1499895799.02108240\n",
            "Iteration 796, loss = 1499841673.97775316\n",
            "Iteration 797, loss = 1499787428.93071604\n",
            "Iteration 798, loss = 1499733533.40412354\n",
            "Iteration 799, loss = 1499679382.20062590\n",
            "Iteration 800, loss = 1499625228.75511217\n",
            "Iteration 801, loss = 1499570783.19827700\n",
            "Iteration 802, loss = 1499517105.69793344\n",
            "Iteration 803, loss = 1499462633.53188992\n",
            "Iteration 804, loss = 1499408323.39600658\n",
            "Iteration 805, loss = 1499354383.36557770\n",
            "Iteration 806, loss = 1499298549.44745040\n",
            "Iteration 807, loss = 1499238033.34196663\n",
            "Iteration 808, loss = 1499178226.48820496\n",
            "Iteration 809, loss = 1499118673.69915533\n",
            "Iteration 810, loss = 1499059209.05555534\n",
            "Iteration 811, loss = 1498999045.42136431\n",
            "Iteration 812, loss = 1498939394.17145681\n",
            "Iteration 813, loss = 1498878991.73499894\n",
            "Iteration 814, loss = 1498819100.28127146\n",
            "Iteration 815, loss = 1498759836.21563625\n",
            "Iteration 816, loss = 1498699909.68130612\n",
            "Iteration 817, loss = 1498640026.57428050\n",
            "Iteration 818, loss = 1498581307.70370102\n",
            "Iteration 819, loss = 1498521977.14024305\n",
            "Iteration 820, loss = 1498463024.00178576\n",
            "Iteration 821, loss = 1498404318.18031907\n",
            "Iteration 822, loss = 1498345490.34738708\n",
            "Iteration 823, loss = 1498287183.41177583\n",
            "Iteration 824, loss = 1498228480.72322726\n",
            "Iteration 825, loss = 1498170632.68820381\n",
            "Iteration 826, loss = 1498111946.75205660\n",
            "Iteration 827, loss = 1498054290.20667195\n",
            "Iteration 828, loss = 1497996417.39078116\n",
            "Iteration 829, loss = 1497938403.26545477\n",
            "Iteration 830, loss = 1497881063.31775713\n",
            "Iteration 831, loss = 1497823443.51398087\n",
            "Iteration 832, loss = 1497766321.47554421\n",
            "Iteration 833, loss = 1497709193.58987975\n",
            "Iteration 834, loss = 1497651979.80069613\n",
            "Iteration 835, loss = 1497595393.45332170\n",
            "Iteration 836, loss = 1497538538.57961965\n",
            "Iteration 837, loss = 1497481622.25778818\n",
            "Iteration 838, loss = 1497425431.08558297\n",
            "Iteration 839, loss = 1497368789.92815208\n",
            "Iteration 840, loss = 1497312495.02839017\n",
            "Iteration 841, loss = 1497255756.17310023\n",
            "Iteration 842, loss = 1497199445.75039005\n",
            "Iteration 843, loss = 1497143237.40557599\n",
            "Iteration 844, loss = 1497086991.67466497\n",
            "Iteration 845, loss = 1497030425.45937872\n",
            "Iteration 846, loss = 1496974404.38267612\n",
            "Iteration 847, loss = 1496918366.38911939\n",
            "Iteration 848, loss = 1496862477.44158578\n",
            "Iteration 849, loss = 1496806173.44003582\n",
            "Iteration 850, loss = 1496750303.98644805\n",
            "Iteration 851, loss = 1496692945.76371813\n",
            "Iteration 852, loss = 1496629186.52617860\n",
            "Iteration 853, loss = 1496567529.59538770\n",
            "Iteration 854, loss = 1496506420.01040983\n",
            "Iteration 855, loss = 1496444492.74159527\n",
            "Iteration 856, loss = 1496382694.50176024\n",
            "Iteration 857, loss = 1496320093.62943912\n",
            "Iteration 858, loss = 1496258238.17315841\n",
            "Iteration 859, loss = 1496196105.46367002\n",
            "Iteration 860, loss = 1496134308.88890195\n",
            "Iteration 861, loss = 1496072668.74605584\n",
            "Iteration 862, loss = 1496010725.85758424\n",
            "Iteration 863, loss = 1495949799.16531277\n",
            "Iteration 864, loss = 1495888572.99215841\n",
            "Iteration 865, loss = 1495825812.06412482\n",
            "Iteration 866, loss = 1495757487.10002661\n",
            "Iteration 867, loss = 1495691625.32440782\n",
            "Iteration 868, loss = 1495625325.35652828\n",
            "Iteration 869, loss = 1495559245.80473423\n",
            "Iteration 870, loss = 1495493005.43996763\n",
            "Iteration 871, loss = 1495427135.70996261\n",
            "Iteration 872, loss = 1495360537.22549582\n",
            "Iteration 873, loss = 1495294774.70767736\n",
            "Iteration 874, loss = 1495229381.35139513\n",
            "Iteration 875, loss = 1495163583.49188304\n",
            "Iteration 876, loss = 1495098739.11525011\n",
            "Iteration 877, loss = 1495033369.26095343\n",
            "Iteration 878, loss = 1494968624.73711419\n",
            "Iteration 879, loss = 1494904175.47782850\n",
            "Iteration 880, loss = 1494839696.77719092\n",
            "Iteration 881, loss = 1494775612.84752631\n",
            "Iteration 882, loss = 1494711397.98236537\n",
            "Iteration 883, loss = 1494647871.84884667\n",
            "Iteration 884, loss = 1494583783.90313220\n",
            "Iteration 885, loss = 1494521370.28360558\n",
            "Iteration 886, loss = 1494457512.31277299\n",
            "Iteration 887, loss = 1494395006.49268007\n",
            "Iteration 888, loss = 1494332223.38513970\n",
            "Iteration 889, loss = 1494269677.99469399\n",
            "Iteration 890, loss = 1494207175.55680346\n",
            "Iteration 891, loss = 1494145069.50496364\n",
            "Iteration 892, loss = 1494082438.49520183\n",
            "Iteration 893, loss = 1494020299.18909240\n",
            "Iteration 894, loss = 1493958452.09118891\n",
            "Iteration 895, loss = 1493896146.28096032\n",
            "Iteration 896, loss = 1493834066.94524336\n",
            "Iteration 897, loss = 1493772282.71325898\n",
            "Iteration 898, loss = 1493710848.35488081\n",
            "Iteration 899, loss = 1493649324.17940187\n",
            "Iteration 900, loss = 1493587763.26621151\n",
            "Iteration 901, loss = 1493526936.19794941\n",
            "Iteration 902, loss = 1493465939.65668559\n",
            "Iteration 903, loss = 1493405253.95482278\n",
            "Iteration 904, loss = 1493344513.88368964\n",
            "Iteration 905, loss = 1493283687.73324037\n",
            "Iteration 906, loss = 1493223380.02552772\n",
            "Iteration 907, loss = 1493162904.99088287\n",
            "Iteration 908, loss = 1493102324.14026070\n",
            "Iteration 909, loss = 1493041983.84444022\n",
            "Iteration 910, loss = 1492981517.24210715\n",
            "Iteration 911, loss = 1492921390.79829955\n",
            "Iteration 912, loss = 1492860965.55359221\n",
            "Iteration 913, loss = 1492801226.25103259\n",
            "Iteration 914, loss = 1492740624.74307108\n",
            "Iteration 915, loss = 1492680680.18503690\n",
            "Iteration 916, loss = 1492621184.10528827\n",
            "Iteration 917, loss = 1492561096.59739065\n",
            "Iteration 918, loss = 1492501545.82558680\n",
            "Iteration 919, loss = 1492441982.48734903\n",
            "Iteration 920, loss = 1492382693.89953208\n",
            "Iteration 921, loss = 1492323364.22313571\n",
            "Iteration 922, loss = 1492264338.52942061\n",
            "Iteration 923, loss = 1492205286.02610970\n",
            "Iteration 924, loss = 1492146309.71060729\n",
            "Iteration 925, loss = 1492087223.06229472\n",
            "Iteration 926, loss = 1492028308.74096322\n",
            "Iteration 927, loss = 1491969895.24915338\n",
            "Iteration 928, loss = 1491911014.81522298\n",
            "Iteration 929, loss = 1491852439.43674803\n",
            "Iteration 930, loss = 1491793546.51839042\n",
            "Iteration 931, loss = 1491734904.31102371\n",
            "Iteration 932, loss = 1491676452.35245204\n",
            "Iteration 933, loss = 1491617773.09500074\n",
            "Iteration 934, loss = 1491558880.33253050\n",
            "Iteration 935, loss = 1491500120.72614121\n",
            "Iteration 936, loss = 1491441784.62045121\n",
            "Iteration 937, loss = 1491383318.47231650\n",
            "Iteration 938, loss = 1491324591.93471551\n",
            "Iteration 939, loss = 1491266453.44850183\n",
            "Iteration 940, loss = 1491207897.93888974\n",
            "Iteration 941, loss = 1491149791.77566147\n",
            "Iteration 942, loss = 1491091579.25943971\n",
            "Iteration 943, loss = 1491032956.91387630\n",
            "Iteration 944, loss = 1490974600.19726038\n",
            "Iteration 945, loss = 1490916486.38389468\n",
            "Iteration 946, loss = 1490858301.63378620\n",
            "Iteration 947, loss = 1490799994.38008332\n",
            "Iteration 948, loss = 1490741946.84225011\n",
            "Iteration 949, loss = 1490684172.64225578\n",
            "Iteration 950, loss = 1490626140.41282320\n",
            "Iteration 951, loss = 1490568626.10782456\n",
            "Iteration 952, loss = 1490510974.82897401\n",
            "Iteration 953, loss = 1490453397.35906172\n",
            "Iteration 954, loss = 1490395885.19854760\n",
            "Iteration 955, loss = 1490338166.13056898\n",
            "Iteration 956, loss = 1490280500.18946218\n",
            "Iteration 957, loss = 1490223136.63488507\n",
            "Iteration 958, loss = 1490165107.50941944\n",
            "Iteration 959, loss = 1490107750.86175227\n",
            "Iteration 960, loss = 1490049961.90385032\n",
            "Iteration 961, loss = 1489992494.96385789\n",
            "Iteration 962, loss = 1489935203.75376630\n",
            "Iteration 963, loss = 1489877448.83047843\n",
            "Iteration 964, loss = 1489820104.72284389\n",
            "Iteration 965, loss = 1489762183.49568033\n",
            "Iteration 966, loss = 1489698594.05102396\n",
            "Iteration 967, loss = 1489634092.85349035\n",
            "Iteration 968, loss = 1489571764.09976506\n",
            "Iteration 969, loss = 1489508094.15974808\n",
            "Iteration 970, loss = 1489444594.02564836\n",
            "Iteration 971, loss = 1489381268.49144053\n",
            "Iteration 972, loss = 1489317225.00916719\n",
            "Iteration 973, loss = 1489253771.54370260\n",
            "Iteration 974, loss = 1489190020.71866465\n",
            "Iteration 975, loss = 1489126493.82862782\n",
            "Iteration 976, loss = 1489063098.25981855\n",
            "Iteration 977, loss = 1489000061.09855247\n",
            "Iteration 978, loss = 1488936524.30323434\n",
            "Iteration 979, loss = 1488873733.34382248\n",
            "Iteration 980, loss = 1488811324.01382017\n",
            "Iteration 981, loss = 1488748301.44735909\n",
            "Iteration 982, loss = 1488686185.97392273\n",
            "Iteration 983, loss = 1488624183.08556581\n",
            "Iteration 984, loss = 1488561984.57201552\n",
            "Iteration 985, loss = 1488500091.93189120\n",
            "Iteration 986, loss = 1488437890.80877542\n",
            "Iteration 987, loss = 1488376826.93935704\n",
            "Iteration 988, loss = 1488314943.43430090\n",
            "Iteration 989, loss = 1488253435.96708965\n",
            "Iteration 990, loss = 1488192473.54269981\n",
            "Iteration 991, loss = 1488131075.30719399\n",
            "Iteration 992, loss = 1488070187.60696864\n",
            "Iteration 993, loss = 1488009286.21650648\n",
            "Iteration 994, loss = 1487948413.30115628\n",
            "Iteration 995, loss = 1487887864.06818533\n",
            "Iteration 996, loss = 1487827409.36823392\n",
            "Iteration 997, loss = 1487766709.25644708\n",
            "Iteration 998, loss = 1487706074.40669680\n",
            "Iteration 999, loss = 1487646273.30790067\n",
            "Iteration 1000, loss = 1487585896.10685134\n",
            "Métricas do MLP Regressor:\n",
            "                                             MSE         R²\n",
            "(50,)        relu     0.0001 lbfgs  2.844882e+06   0.983743\n",
            "                             adam   3.778547e+08  -1.159233\n",
            "                      0.0010 lbfgs  2.609253e+06   0.985090\n",
            "                             adam   7.832097e+08  -3.475616\n",
            "                      0.0100 lbfgs  2.839273e+06   0.983775\n",
            "...                                          ...        ...\n",
            "(50, 50, 50) logistic 0.0010 sgd    1.969231e+08  -0.125308\n",
            "                             adam   2.718800e+09 -14.536461\n",
            "                      0.0100 lbfgs  5.072444e+07   0.710137\n",
            "                             sgd    1.812059e+08  -0.035493\n",
            "                             adam   2.723219e+09 -14.561713\n",
            "\n",
            "[123 rows x 2 columns]\n",
            "\n",
            "Melhores Parâmetros:\n",
            "((100, 100), 'relu', np.float64(0.001), 'adam')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "hidden_layer_sizes = [(50,), (100,), (100, 50), (100, 100), (50, 50, 50)]\n",
        "activation = ['relu', 'tanh', 'logistic']\n",
        "alpha = [0.0001, 0.001, 0.01]\n",
        "solver = ['lbfgs', 'sgd', 'adam']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "nn_metrics = {}\n",
        "\n",
        "for layers in hidden_layer_sizes:\n",
        "    for act in activation:\n",
        "        for alpha_val in alpha:\n",
        "            for solver_method in solver:\n",
        "                try:\n",
        "                    nn_model = MLPRegressor(\n",
        "                        hidden_layer_sizes=layers,\n",
        "                        activation=act,\n",
        "                        alpha=alpha_val,\n",
        "                        solver=solver_method,\n",
        "                        max_iter=1000,\n",
        "                        verbose=True,\n",
        "                        learning_rate_init=0.01\n",
        "                    )\n",
        "                    nn_model.fit(X_train_scaled, y_train)\n",
        "                    y_pred = nn_model.predict(X_test_scaled)\n",
        "                    nn_metrics[(layers, act, alpha_val, solver_method)] = {\n",
        "                        'MSE': mean_squared_error(y_test, y_pred),\n",
        "                        'R²': r2_score(y_test, y_pred)\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error with parameters {layers}, {act}, {alpha_val}, {solver_method}: {e}\")\n",
        "\n",
        "nn_metrics_df = pd.DataFrame(nn_metrics).T\n",
        "print(\"Métricas do MLP Regressor:\")\n",
        "print(nn_metrics_df)\n",
        "\n",
        "best_params_nn = nn_metrics_df['MSE'].idxmin()\n",
        "print(\"\\nMelhores Parâmetros:\")\n",
        "print(best_params_nn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.523e+08, tolerance: 4.801e+06\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-11 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-11 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-11 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-11 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-11 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-11 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-11 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-11 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#regressão linear\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "best_alpha_ridge = ridge_metrics_df['MSE'].idxmin()\n",
        "best_alpha_lasso = lasso_metrics_df['MSE'].idxmin()\n",
        "\n",
        "# Regressão Ridge\n",
        "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Regressão Lasso\n",
        "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "best_params_gb = gb_metrics_df['MSE'].idxmin()\n",
        "\n",
        "best_n_estimators, best_max_depth = best_params_gb\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(n_estimators=best_n_estimators, max_depth=best_max_depth)\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "best_params_xgb = xgb_metrics_df['MSE'].idxmin()\n",
        "\n",
        "best_n_estimators, best_learning_rate = best_params_xgb\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=best_n_estimators, learning_rate=best_learning_rate)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "best_params_nn = nn_metrics_df['MSE'].idxmin()\n",
        "\n",
        "best_hidden_layer_sizes, best_activation = best_params_nn\n",
        "\n",
        "# MLP Regressor\n",
        "nn_model = MLPRegressor(hidden_layer_sizes=best_hidden_layer_sizes, activation=best_activation, max_iter=500)\n",
        "nn_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVOkqadyqRYK",
        "outputId": "d83e4726-608a-4062-92da-4c513ec98270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previsão do preço do Bitcoin para amanhã: 60368.45\n",
            "Previsão do preço do Bitcoin para amanhã: 60368.45\n",
            "Previsão do preço do Bitcoin para amanhã: 60368.85\n",
            "Previsão do preço do Bitcoin para amanhã: 60444.01\n",
            "Previsão do preço do Bitcoin para amanhã: 60446.72\n",
            "Previsão do preço do Bitcoin para amanhã: 963.30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "last_row = df_features.iloc[-1]\n",
        "\n",
        "new_data = [[last_row['lag_1'], last_row['lag_7'], last_row['ma_7']]]\n",
        "\n",
        "tomorrow_price = model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n",
        "tomorrow_price = ridge_model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n",
        "tomorrow_price = lasso_model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n",
        "tomorrow_price = gb_model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n",
        "tomorrow_price = xgb_model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n",
        "tomorrow_price = nn_model.predict(new_data)\n",
        "print(f'Previsão do preço do Bitcoin para amanhã: {tomorrow_price[0]:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "W3wraan8qTEX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
